"Main interface for sagemaker type defs"
from __future__ import annotations

from datetime import datetime
from typing import Dict, List
from typing_extensions import TypedDict


__all__ = (
    "ClientAddTagsResponseTagsTypeDef",
    "ClientAddTagsResponseTypeDef",
    "ClientAddTagsTagsTypeDef",
    "ClientCreateAlgorithmInferenceSpecificationContainersTypeDef",
    "ClientCreateAlgorithmInferenceSpecificationTypeDef",
    "ClientCreateAlgorithmResponseTypeDef",
    "ClientCreateAlgorithmTrainingSpecificationMetricDefinitionsTypeDef",
    "ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeCategoricalParameterRangeSpecificationTypeDef",
    "ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeContinuousParameterRangeSpecificationTypeDef",
    "ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeIntegerParameterRangeSpecificationTypeDef",
    "ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeTypeDef",
    "ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersTypeDef",
    "ClientCreateAlgorithmTrainingSpecificationSupportedTuningJobObjectiveMetricsTypeDef",
    "ClientCreateAlgorithmTrainingSpecificationTrainingChannelsTypeDef",
    "ClientCreateAlgorithmTrainingSpecificationTypeDef",
    "ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef",
    "ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef",
    "ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceTypeDef",
    "ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef",
    "ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigTypeDef",
    "ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionOutputDataConfigTypeDef",
    "ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionResourceConfigTypeDef",
    "ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionStoppingConditionTypeDef",
    "ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionTypeDef",
    "ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef",
    "ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef",
    "ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef",
    "ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef",
    "ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef",
    "ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef",
    "ClientCreateAlgorithmValidationSpecificationValidationProfilesTypeDef",
    "ClientCreateAlgorithmValidationSpecificationTypeDef",
    "ClientCreateCodeRepositoryGitConfigTypeDef",
    "ClientCreateCodeRepositoryResponseTypeDef",
    "ClientCreateCompilationJobInputConfigTypeDef",
    "ClientCreateCompilationJobOutputConfigTypeDef",
    "ClientCreateCompilationJobResponseTypeDef",
    "ClientCreateCompilationJobStoppingConditionTypeDef",
    "ClientCreateEndpointConfigProductionVariantsTypeDef",
    "ClientCreateEndpointConfigResponseTypeDef",
    "ClientCreateEndpointConfigTagsTypeDef",
    "ClientCreateEndpointResponseTypeDef",
    "ClientCreateEndpointTagsTypeDef",
    "ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigHyperParameterTuningJobObjectiveTypeDef",
    "ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesCategoricalParameterRangesTypeDef",
    "ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesContinuousParameterRangesTypeDef",
    "ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesIntegerParameterRangesTypeDef",
    "ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesTypeDef",
    "ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigResourceLimitsTypeDef",
    "ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigTypeDef",
    "ClientCreateHyperParameterTuningJobResponseTypeDef",
    "ClientCreateHyperParameterTuningJobTagsTypeDef",
    "ClientCreateHyperParameterTuningJobTrainingJobDefinitionAlgorithmSpecificationMetricDefinitionsTypeDef",
    "ClientCreateHyperParameterTuningJobTrainingJobDefinitionAlgorithmSpecificationTypeDef",
    "ClientCreateHyperParameterTuningJobTrainingJobDefinitionCheckpointConfigTypeDef",
    "ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef",
    "ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef",
    "ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceTypeDef",
    "ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef",
    "ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigTypeDef",
    "ClientCreateHyperParameterTuningJobTrainingJobDefinitionOutputDataConfigTypeDef",
    "ClientCreateHyperParameterTuningJobTrainingJobDefinitionResourceConfigTypeDef",
    "ClientCreateHyperParameterTuningJobTrainingJobDefinitionStoppingConditionTypeDef",
    "ClientCreateHyperParameterTuningJobTrainingJobDefinitionVpcConfigTypeDef",
    "ClientCreateHyperParameterTuningJobTrainingJobDefinitionTypeDef",
    "ClientCreateHyperParameterTuningJobWarmStartConfigParentHyperParameterTuningJobsTypeDef",
    "ClientCreateHyperParameterTuningJobWarmStartConfigTypeDef",
    "ClientCreateLabelingJobHumanTaskConfigAnnotationConsolidationConfigTypeDef",
    "ClientCreateLabelingJobHumanTaskConfigPublicWorkforceTaskPriceAmountInUsdTypeDef",
    "ClientCreateLabelingJobHumanTaskConfigPublicWorkforceTaskPriceTypeDef",
    "ClientCreateLabelingJobHumanTaskConfigUiConfigTypeDef",
    "ClientCreateLabelingJobHumanTaskConfigTypeDef",
    "ClientCreateLabelingJobInputConfigDataAttributesTypeDef",
    "ClientCreateLabelingJobInputConfigDataSourceS3DataSourceTypeDef",
    "ClientCreateLabelingJobInputConfigDataSourceTypeDef",
    "ClientCreateLabelingJobInputConfigTypeDef",
    "ClientCreateLabelingJobLabelingJobAlgorithmsConfigLabelingJobResourceConfigTypeDef",
    "ClientCreateLabelingJobLabelingJobAlgorithmsConfigTypeDef",
    "ClientCreateLabelingJobOutputConfigTypeDef",
    "ClientCreateLabelingJobResponseTypeDef",
    "ClientCreateLabelingJobStoppingConditionsTypeDef",
    "ClientCreateLabelingJobTagsTypeDef",
    "ClientCreateModelContainersTypeDef",
    "ClientCreateModelPackageInferenceSpecificationContainersTypeDef",
    "ClientCreateModelPackageInferenceSpecificationTypeDef",
    "ClientCreateModelPackageResponseTypeDef",
    "ClientCreateModelPackageSourceAlgorithmSpecificationSourceAlgorithmsTypeDef",
    "ClientCreateModelPackageSourceAlgorithmSpecificationTypeDef",
    "ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef",
    "ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef",
    "ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef",
    "ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef",
    "ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef",
    "ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef",
    "ClientCreateModelPackageValidationSpecificationValidationProfilesTypeDef",
    "ClientCreateModelPackageValidationSpecificationTypeDef",
    "ClientCreateModelPrimaryContainerTypeDef",
    "ClientCreateModelResponseTypeDef",
    "ClientCreateModelTagsTypeDef",
    "ClientCreateModelVpcConfigTypeDef",
    "ClientCreateNotebookInstanceLifecycleConfigOnCreateTypeDef",
    "ClientCreateNotebookInstanceLifecycleConfigOnStartTypeDef",
    "ClientCreateNotebookInstanceLifecycleConfigResponseTypeDef",
    "ClientCreateNotebookInstanceResponseTypeDef",
    "ClientCreateNotebookInstanceTagsTypeDef",
    "ClientCreatePresignedNotebookInstanceUrlResponseTypeDef",
    "ClientCreateTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef",
    "ClientCreateTrainingJobAlgorithmSpecificationTypeDef",
    "ClientCreateTrainingJobCheckpointConfigTypeDef",
    "ClientCreateTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef",
    "ClientCreateTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef",
    "ClientCreateTrainingJobInputDataConfigDataSourceTypeDef",
    "ClientCreateTrainingJobInputDataConfigShuffleConfigTypeDef",
    "ClientCreateTrainingJobInputDataConfigTypeDef",
    "ClientCreateTrainingJobOutputDataConfigTypeDef",
    "ClientCreateTrainingJobResourceConfigTypeDef",
    "ClientCreateTrainingJobResponseTypeDef",
    "ClientCreateTrainingJobStoppingConditionTypeDef",
    "ClientCreateTrainingJobTagsTypeDef",
    "ClientCreateTrainingJobVpcConfigTypeDef",
    "ClientCreateTransformJobDataProcessingTypeDef",
    "ClientCreateTransformJobResponseTypeDef",
    "ClientCreateTransformJobTagsTypeDef",
    "ClientCreateTransformJobTransformInputDataSourceS3DataSourceTypeDef",
    "ClientCreateTransformJobTransformInputDataSourceTypeDef",
    "ClientCreateTransformJobTransformInputTypeDef",
    "ClientCreateTransformJobTransformOutputTypeDef",
    "ClientCreateTransformJobTransformResourcesTypeDef",
    "ClientCreateWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef",
    "ClientCreateWorkteamMemberDefinitionsTypeDef",
    "ClientCreateWorkteamNotificationConfigurationTypeDef",
    "ClientCreateWorkteamResponseTypeDef",
    "ClientCreateWorkteamTagsTypeDef",
    "ClientDeleteWorkteamResponseTypeDef",
    "ClientDescribeAlgorithmResponseAlgorithmStatusDetailsImageScanStatusesTypeDef",
    "ClientDescribeAlgorithmResponseAlgorithmStatusDetailsValidationStatusesTypeDef",
    "ClientDescribeAlgorithmResponseAlgorithmStatusDetailsTypeDef",
    "ClientDescribeAlgorithmResponseInferenceSpecificationContainersTypeDef",
    "ClientDescribeAlgorithmResponseInferenceSpecificationTypeDef",
    "ClientDescribeAlgorithmResponseTrainingSpecificationMetricDefinitionsTypeDef",
    "ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeCategoricalParameterRangeSpecificationTypeDef",
    "ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeContinuousParameterRangeSpecificationTypeDef",
    "ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeIntegerParameterRangeSpecificationTypeDef",
    "ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeTypeDef",
    "ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersTypeDef",
    "ClientDescribeAlgorithmResponseTrainingSpecificationSupportedTuningJobObjectiveMetricsTypeDef",
    "ClientDescribeAlgorithmResponseTrainingSpecificationTrainingChannelsTypeDef",
    "ClientDescribeAlgorithmResponseTrainingSpecificationTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionOutputDataConfigTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionResourceConfigTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionStoppingConditionTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTypeDef",
    "ClientDescribeAlgorithmResponseValidationSpecificationTypeDef",
    "ClientDescribeAlgorithmResponseTypeDef",
    "ClientDescribeCodeRepositoryResponseGitConfigTypeDef",
    "ClientDescribeCodeRepositoryResponseTypeDef",
    "ClientDescribeCompilationJobResponseInputConfigTypeDef",
    "ClientDescribeCompilationJobResponseModelArtifactsTypeDef",
    "ClientDescribeCompilationJobResponseOutputConfigTypeDef",
    "ClientDescribeCompilationJobResponseStoppingConditionTypeDef",
    "ClientDescribeCompilationJobResponseTypeDef",
    "ClientDescribeEndpointConfigResponseProductionVariantsTypeDef",
    "ClientDescribeEndpointConfigResponseTypeDef",
    "ClientDescribeEndpointResponseProductionVariantsDeployedImagesTypeDef",
    "ClientDescribeEndpointResponseProductionVariantsTypeDef",
    "ClientDescribeEndpointResponseTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseBestTrainingJobFinalHyperParameterTuningJobObjectiveMetricTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseBestTrainingJobTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigHyperParameterTuningJobObjectiveTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesCategoricalParameterRangesTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesContinuousParameterRangesTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesIntegerParameterRangesTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigResourceLimitsTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseObjectiveStatusCountersTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseOverallBestTrainingJobFinalHyperParameterTuningJobObjectiveMetricTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseOverallBestTrainingJobTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionAlgorithmSpecificationMetricDefinitionsTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionAlgorithmSpecificationTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionCheckpointConfigTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionOutputDataConfigTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionResourceConfigTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionStoppingConditionTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionVpcConfigTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseTrainingJobStatusCountersTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseWarmStartConfigParentHyperParameterTuningJobsTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseWarmStartConfigTypeDef",
    "ClientDescribeHyperParameterTuningJobResponseTypeDef",
    "ClientDescribeLabelingJobResponseHumanTaskConfigAnnotationConsolidationConfigTypeDef",
    "ClientDescribeLabelingJobResponseHumanTaskConfigPublicWorkforceTaskPriceAmountInUsdTypeDef",
    "ClientDescribeLabelingJobResponseHumanTaskConfigPublicWorkforceTaskPriceTypeDef",
    "ClientDescribeLabelingJobResponseHumanTaskConfigUiConfigTypeDef",
    "ClientDescribeLabelingJobResponseHumanTaskConfigTypeDef",
    "ClientDescribeLabelingJobResponseInputConfigDataAttributesTypeDef",
    "ClientDescribeLabelingJobResponseInputConfigDataSourceS3DataSourceTypeDef",
    "ClientDescribeLabelingJobResponseInputConfigDataSourceTypeDef",
    "ClientDescribeLabelingJobResponseInputConfigTypeDef",
    "ClientDescribeLabelingJobResponseLabelCountersTypeDef",
    "ClientDescribeLabelingJobResponseLabelingJobAlgorithmsConfigLabelingJobResourceConfigTypeDef",
    "ClientDescribeLabelingJobResponseLabelingJobAlgorithmsConfigTypeDef",
    "ClientDescribeLabelingJobResponseLabelingJobOutputTypeDef",
    "ClientDescribeLabelingJobResponseOutputConfigTypeDef",
    "ClientDescribeLabelingJobResponseStoppingConditionsTypeDef",
    "ClientDescribeLabelingJobResponseTagsTypeDef",
    "ClientDescribeLabelingJobResponseTypeDef",
    "ClientDescribeModelPackageResponseInferenceSpecificationContainersTypeDef",
    "ClientDescribeModelPackageResponseInferenceSpecificationTypeDef",
    "ClientDescribeModelPackageResponseModelPackageStatusDetailsImageScanStatusesTypeDef",
    "ClientDescribeModelPackageResponseModelPackageStatusDetailsValidationStatusesTypeDef",
    "ClientDescribeModelPackageResponseModelPackageStatusDetailsTypeDef",
    "ClientDescribeModelPackageResponseSourceAlgorithmSpecificationSourceAlgorithmsTypeDef",
    "ClientDescribeModelPackageResponseSourceAlgorithmSpecificationTypeDef",
    "ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef",
    "ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef",
    "ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef",
    "ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef",
    "ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef",
    "ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef",
    "ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTypeDef",
    "ClientDescribeModelPackageResponseValidationSpecificationTypeDef",
    "ClientDescribeModelPackageResponseTypeDef",
    "ClientDescribeModelResponseContainersTypeDef",
    "ClientDescribeModelResponsePrimaryContainerTypeDef",
    "ClientDescribeModelResponseVpcConfigTypeDef",
    "ClientDescribeModelResponseTypeDef",
    "ClientDescribeNotebookInstanceLifecycleConfigResponseOnCreateTypeDef",
    "ClientDescribeNotebookInstanceLifecycleConfigResponseOnStartTypeDef",
    "ClientDescribeNotebookInstanceLifecycleConfigResponseTypeDef",
    "ClientDescribeNotebookInstanceResponseTypeDef",
    "ClientDescribeSubscribedWorkteamResponseSubscribedWorkteamTypeDef",
    "ClientDescribeSubscribedWorkteamResponseTypeDef",
    "ClientDescribeTrainingJobResponseAlgorithmSpecificationMetricDefinitionsTypeDef",
    "ClientDescribeTrainingJobResponseAlgorithmSpecificationTypeDef",
    "ClientDescribeTrainingJobResponseCheckpointConfigTypeDef",
    "ClientDescribeTrainingJobResponseFinalMetricDataListTypeDef",
    "ClientDescribeTrainingJobResponseInputDataConfigDataSourceFileSystemDataSourceTypeDef",
    "ClientDescribeTrainingJobResponseInputDataConfigDataSourceS3DataSourceTypeDef",
    "ClientDescribeTrainingJobResponseInputDataConfigDataSourceTypeDef",
    "ClientDescribeTrainingJobResponseInputDataConfigShuffleConfigTypeDef",
    "ClientDescribeTrainingJobResponseInputDataConfigTypeDef",
    "ClientDescribeTrainingJobResponseModelArtifactsTypeDef",
    "ClientDescribeTrainingJobResponseOutputDataConfigTypeDef",
    "ClientDescribeTrainingJobResponseResourceConfigTypeDef",
    "ClientDescribeTrainingJobResponseSecondaryStatusTransitionsTypeDef",
    "ClientDescribeTrainingJobResponseStoppingConditionTypeDef",
    "ClientDescribeTrainingJobResponseVpcConfigTypeDef",
    "ClientDescribeTrainingJobResponseTypeDef",
    "ClientDescribeTransformJobResponseDataProcessingTypeDef",
    "ClientDescribeTransformJobResponseTransformInputDataSourceS3DataSourceTypeDef",
    "ClientDescribeTransformJobResponseTransformInputDataSourceTypeDef",
    "ClientDescribeTransformJobResponseTransformInputTypeDef",
    "ClientDescribeTransformJobResponseTransformOutputTypeDef",
    "ClientDescribeTransformJobResponseTransformResourcesTypeDef",
    "ClientDescribeTransformJobResponseTypeDef",
    "ClientDescribeWorkteamResponseWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef",
    "ClientDescribeWorkteamResponseWorkteamMemberDefinitionsTypeDef",
    "ClientDescribeWorkteamResponseWorkteamNotificationConfigurationTypeDef",
    "ClientDescribeWorkteamResponseWorkteamTypeDef",
    "ClientDescribeWorkteamResponseTypeDef",
    "ClientGetSearchSuggestionsResponsePropertyNameSuggestionsTypeDef",
    "ClientGetSearchSuggestionsResponseTypeDef",
    "ClientGetSearchSuggestionsSuggestionQueryPropertyNameQueryTypeDef",
    "ClientGetSearchSuggestionsSuggestionQueryTypeDef",
    "ClientListAlgorithmsResponseAlgorithmSummaryListTypeDef",
    "ClientListAlgorithmsResponseTypeDef",
    "ClientListCodeRepositoriesResponseCodeRepositorySummaryListGitConfigTypeDef",
    "ClientListCodeRepositoriesResponseCodeRepositorySummaryListTypeDef",
    "ClientListCodeRepositoriesResponseTypeDef",
    "ClientListCompilationJobsResponseCompilationJobSummariesTypeDef",
    "ClientListCompilationJobsResponseTypeDef",
    "ClientListEndpointConfigsResponseEndpointConfigsTypeDef",
    "ClientListEndpointConfigsResponseTypeDef",
    "ClientListEndpointsResponseEndpointsTypeDef",
    "ClientListEndpointsResponseTypeDef",
    "ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesObjectiveStatusCountersTypeDef",
    "ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesResourceLimitsTypeDef",
    "ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesTrainingJobStatusCountersTypeDef",
    "ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesTypeDef",
    "ClientListHyperParameterTuningJobsResponseTypeDef",
    "ClientListLabelingJobsForWorkteamResponseLabelingJobSummaryListLabelCountersTypeDef",
    "ClientListLabelingJobsForWorkteamResponseLabelingJobSummaryListTypeDef",
    "ClientListLabelingJobsForWorkteamResponseTypeDef",
    "ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataAttributesTypeDef",
    "ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataSourceS3DataSourceTypeDef",
    "ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataSourceTypeDef",
    "ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigTypeDef",
    "ClientListLabelingJobsResponseLabelingJobSummaryListLabelCountersTypeDef",
    "ClientListLabelingJobsResponseLabelingJobSummaryListLabelingJobOutputTypeDef",
    "ClientListLabelingJobsResponseLabelingJobSummaryListTypeDef",
    "ClientListLabelingJobsResponseTypeDef",
    "ClientListModelPackagesResponseModelPackageSummaryListTypeDef",
    "ClientListModelPackagesResponseTypeDef",
    "ClientListModelsResponseModelsTypeDef",
    "ClientListModelsResponseTypeDef",
    "ClientListNotebookInstanceLifecycleConfigsResponseNotebookInstanceLifecycleConfigsTypeDef",
    "ClientListNotebookInstanceLifecycleConfigsResponseTypeDef",
    "ClientListNotebookInstancesResponseNotebookInstancesTypeDef",
    "ClientListNotebookInstancesResponseTypeDef",
    "ClientListSubscribedWorkteamsResponseSubscribedWorkteamsTypeDef",
    "ClientListSubscribedWorkteamsResponseTypeDef",
    "ClientListTagsResponseTagsTypeDef",
    "ClientListTagsResponseTypeDef",
    "ClientListTrainingJobsForHyperParameterTuningJobResponseTrainingJobSummariesFinalHyperParameterTuningJobObjectiveMetricTypeDef",
    "ClientListTrainingJobsForHyperParameterTuningJobResponseTrainingJobSummariesTypeDef",
    "ClientListTrainingJobsForHyperParameterTuningJobResponseTypeDef",
    "ClientListTrainingJobsResponseTrainingJobSummariesTypeDef",
    "ClientListTrainingJobsResponseTypeDef",
    "ClientListTransformJobsResponseTransformJobSummariesTypeDef",
    "ClientListTransformJobsResponseTypeDef",
    "ClientListWorkteamsResponseWorkteamsMemberDefinitionsCognitoMemberDefinitionTypeDef",
    "ClientListWorkteamsResponseWorkteamsMemberDefinitionsTypeDef",
    "ClientListWorkteamsResponseWorkteamsNotificationConfigurationTypeDef",
    "ClientListWorkteamsResponseWorkteamsTypeDef",
    "ClientListWorkteamsResponseTypeDef",
    "ClientRenderUiTemplateResponseErrorsTypeDef",
    "ClientRenderUiTemplateResponseTypeDef",
    "ClientRenderUiTemplateTaskTypeDef",
    "ClientRenderUiTemplateUiTemplateTypeDef",
    "ClientSearchResponseResultsTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef",
    "ClientSearchResponseResultsTrainingJobAlgorithmSpecificationTypeDef",
    "ClientSearchResponseResultsTrainingJobFinalMetricDataListTypeDef",
    "ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef",
    "ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef",
    "ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceTypeDef",
    "ClientSearchResponseResultsTrainingJobInputDataConfigShuffleConfigTypeDef",
    "ClientSearchResponseResultsTrainingJobInputDataConfigTypeDef",
    "ClientSearchResponseResultsTrainingJobModelArtifactsTypeDef",
    "ClientSearchResponseResultsTrainingJobOutputDataConfigTypeDef",
    "ClientSearchResponseResultsTrainingJobResourceConfigTypeDef",
    "ClientSearchResponseResultsTrainingJobSecondaryStatusTransitionsTypeDef",
    "ClientSearchResponseResultsTrainingJobStoppingConditionTypeDef",
    "ClientSearchResponseResultsTrainingJobTagsTypeDef",
    "ClientSearchResponseResultsTrainingJobVpcConfigTypeDef",
    "ClientSearchResponseResultsTrainingJobTypeDef",
    "ClientSearchResponseResultsTypeDef",
    "ClientSearchResponseTypeDef",
    "ClientSearchSearchExpressionFiltersTypeDef",
    "ClientSearchSearchExpressionNestedFiltersFiltersTypeDef",
    "ClientSearchSearchExpressionNestedFiltersTypeDef",
    "ClientSearchSearchExpressionTypeDef",
    "ClientUpdateCodeRepositoryGitConfigTypeDef",
    "ClientUpdateCodeRepositoryResponseTypeDef",
    "ClientUpdateEndpointResponseTypeDef",
    "ClientUpdateEndpointWeightsAndCapacitiesDesiredWeightsAndCapacitiesTypeDef",
    "ClientUpdateEndpointWeightsAndCapacitiesResponseTypeDef",
    "ClientUpdateNotebookInstanceLifecycleConfigOnCreateTypeDef",
    "ClientUpdateNotebookInstanceLifecycleConfigOnStartTypeDef",
    "ClientUpdateWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef",
    "ClientUpdateWorkteamMemberDefinitionsTypeDef",
    "ClientUpdateWorkteamNotificationConfigurationTypeDef",
    "ClientUpdateWorkteamResponseWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef",
    "ClientUpdateWorkteamResponseWorkteamMemberDefinitionsTypeDef",
    "ClientUpdateWorkteamResponseWorkteamNotificationConfigurationTypeDef",
    "ClientUpdateWorkteamResponseWorkteamTypeDef",
    "ClientUpdateWorkteamResponseTypeDef",
    "EndpointDeletedWaitWaiterConfigTypeDef",
    "EndpointInServiceWaitWaiterConfigTypeDef",
    "ListAlgorithmsPaginatePaginationConfigTypeDef",
    "ListAlgorithmsPaginateResponseAlgorithmSummaryListTypeDef",
    "ListAlgorithmsPaginateResponseTypeDef",
    "ListCodeRepositoriesPaginatePaginationConfigTypeDef",
    "ListCodeRepositoriesPaginateResponseCodeRepositorySummaryListGitConfigTypeDef",
    "ListCodeRepositoriesPaginateResponseCodeRepositorySummaryListTypeDef",
    "ListCodeRepositoriesPaginateResponseTypeDef",
    "ListCompilationJobsPaginatePaginationConfigTypeDef",
    "ListCompilationJobsPaginateResponseCompilationJobSummariesTypeDef",
    "ListCompilationJobsPaginateResponseTypeDef",
    "ListEndpointConfigsPaginatePaginationConfigTypeDef",
    "ListEndpointConfigsPaginateResponseEndpointConfigsTypeDef",
    "ListEndpointConfigsPaginateResponseTypeDef",
    "ListEndpointsPaginatePaginationConfigTypeDef",
    "ListEndpointsPaginateResponseEndpointsTypeDef",
    "ListEndpointsPaginateResponseTypeDef",
    "ListHyperParameterTuningJobsPaginatePaginationConfigTypeDef",
    "ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesObjectiveStatusCountersTypeDef",
    "ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesResourceLimitsTypeDef",
    "ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesTrainingJobStatusCountersTypeDef",
    "ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesTypeDef",
    "ListHyperParameterTuningJobsPaginateResponseTypeDef",
    "ListLabelingJobsForWorkteamPaginatePaginationConfigTypeDef",
    "ListLabelingJobsForWorkteamPaginateResponseLabelingJobSummaryListLabelCountersTypeDef",
    "ListLabelingJobsForWorkteamPaginateResponseLabelingJobSummaryListTypeDef",
    "ListLabelingJobsForWorkteamPaginateResponseTypeDef",
    "ListLabelingJobsPaginatePaginationConfigTypeDef",
    "ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataAttributesTypeDef",
    "ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataSourceS3DataSourceTypeDef",
    "ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataSourceTypeDef",
    "ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigTypeDef",
    "ListLabelingJobsPaginateResponseLabelingJobSummaryListLabelCountersTypeDef",
    "ListLabelingJobsPaginateResponseLabelingJobSummaryListLabelingJobOutputTypeDef",
    "ListLabelingJobsPaginateResponseLabelingJobSummaryListTypeDef",
    "ListLabelingJobsPaginateResponseTypeDef",
    "ListModelPackagesPaginatePaginationConfigTypeDef",
    "ListModelPackagesPaginateResponseModelPackageSummaryListTypeDef",
    "ListModelPackagesPaginateResponseTypeDef",
    "ListModelsPaginatePaginationConfigTypeDef",
    "ListModelsPaginateResponseModelsTypeDef",
    "ListModelsPaginateResponseTypeDef",
    "ListNotebookInstanceLifecycleConfigsPaginatePaginationConfigTypeDef",
    "ListNotebookInstanceLifecycleConfigsPaginateResponseNotebookInstanceLifecycleConfigsTypeDef",
    "ListNotebookInstanceLifecycleConfigsPaginateResponseTypeDef",
    "ListNotebookInstancesPaginatePaginationConfigTypeDef",
    "ListNotebookInstancesPaginateResponseNotebookInstancesTypeDef",
    "ListNotebookInstancesPaginateResponseTypeDef",
    "ListSubscribedWorkteamsPaginatePaginationConfigTypeDef",
    "ListSubscribedWorkteamsPaginateResponseSubscribedWorkteamsTypeDef",
    "ListSubscribedWorkteamsPaginateResponseTypeDef",
    "ListTagsPaginatePaginationConfigTypeDef",
    "ListTagsPaginateResponseTagsTypeDef",
    "ListTagsPaginateResponseTypeDef",
    "ListTrainingJobsForHyperParameterTuningJobPaginatePaginationConfigTypeDef",
    "ListTrainingJobsForHyperParameterTuningJobPaginateResponseTrainingJobSummariesFinalHyperParameterTuningJobObjectiveMetricTypeDef",
    "ListTrainingJobsForHyperParameterTuningJobPaginateResponseTrainingJobSummariesTypeDef",
    "ListTrainingJobsForHyperParameterTuningJobPaginateResponseTypeDef",
    "ListTrainingJobsPaginatePaginationConfigTypeDef",
    "ListTrainingJobsPaginateResponseTrainingJobSummariesTypeDef",
    "ListTrainingJobsPaginateResponseTypeDef",
    "ListTransformJobsPaginatePaginationConfigTypeDef",
    "ListTransformJobsPaginateResponseTransformJobSummariesTypeDef",
    "ListTransformJobsPaginateResponseTypeDef",
    "ListWorkteamsPaginatePaginationConfigTypeDef",
    "ListWorkteamsPaginateResponseWorkteamsMemberDefinitionsCognitoMemberDefinitionTypeDef",
    "ListWorkteamsPaginateResponseWorkteamsMemberDefinitionsTypeDef",
    "ListWorkteamsPaginateResponseWorkteamsNotificationConfigurationTypeDef",
    "ListWorkteamsPaginateResponseWorkteamsTypeDef",
    "ListWorkteamsPaginateResponseTypeDef",
    "NotebookInstanceDeletedWaitWaiterConfigTypeDef",
    "NotebookInstanceInServiceWaitWaiterConfigTypeDef",
    "NotebookInstanceStoppedWaitWaiterConfigTypeDef",
    "SearchPaginatePaginationConfigTypeDef",
    "SearchPaginateResponseResultsTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef",
    "SearchPaginateResponseResultsTrainingJobAlgorithmSpecificationTypeDef",
    "SearchPaginateResponseResultsTrainingJobFinalMetricDataListTypeDef",
    "SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef",
    "SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef",
    "SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceTypeDef",
    "SearchPaginateResponseResultsTrainingJobInputDataConfigShuffleConfigTypeDef",
    "SearchPaginateResponseResultsTrainingJobInputDataConfigTypeDef",
    "SearchPaginateResponseResultsTrainingJobModelArtifactsTypeDef",
    "SearchPaginateResponseResultsTrainingJobOutputDataConfigTypeDef",
    "SearchPaginateResponseResultsTrainingJobResourceConfigTypeDef",
    "SearchPaginateResponseResultsTrainingJobSecondaryStatusTransitionsTypeDef",
    "SearchPaginateResponseResultsTrainingJobStoppingConditionTypeDef",
    "SearchPaginateResponseResultsTrainingJobTagsTypeDef",
    "SearchPaginateResponseResultsTrainingJobVpcConfigTypeDef",
    "SearchPaginateResponseResultsTrainingJobTypeDef",
    "SearchPaginateResponseResultsTypeDef",
    "SearchPaginateResponseTypeDef",
    "SearchPaginateSearchExpressionFiltersTypeDef",
    "SearchPaginateSearchExpressionNestedFiltersFiltersTypeDef",
    "SearchPaginateSearchExpressionNestedFiltersTypeDef",
    "SearchPaginateSearchExpressionTypeDef",
    "TrainingJobCompletedOrStoppedWaitWaiterConfigTypeDef",
    "TransformJobCompletedOrStoppedWaitWaiterConfigTypeDef",
)


_ClientAddTagsResponseTagsTypeDef = TypedDict(
    "_ClientAddTagsResponseTagsTypeDef", {"Key": str, "Value": str}, total=False
)


class ClientAddTagsResponseTagsTypeDef(_ClientAddTagsResponseTagsTypeDef):
    """
    Type definition for `ClientAddTagsResponse` `Tags`

    Describes a tag.

    - **Key** *(string) --*

      The tag key.

    - **Value** *(string) --*

      The tag value.
    """


_ClientAddTagsResponseTypeDef = TypedDict(
    "_ClientAddTagsResponseTypeDef",
    {"Tags": List[ClientAddTagsResponseTagsTypeDef]},
    total=False,
)


class ClientAddTagsResponseTypeDef(_ClientAddTagsResponseTypeDef):
    """
    Type definition for `ClientAddTags` `Response`

    - **Tags** *(list) --*

      A list of tags associated with the Amazon SageMaker resource.

      - *(dict) --*

        Describes a tag.

        - **Key** *(string) --*

          The tag key.

        - **Value** *(string) --*

          The tag value.
    """


_ClientAddTagsTagsTypeDef = TypedDict(
    "_ClientAddTagsTagsTypeDef", {"Key": str, "Value": str}
)


class ClientAddTagsTagsTypeDef(_ClientAddTagsTagsTypeDef):
    """
    Type definition for `ClientAddTags` `Tags`

    Describes a tag.

    - **Key** *(string) --* **[REQUIRED]**

      The tag key.

    - **Value** *(string) --* **[REQUIRED]**

      The tag value.
    """


_RequiredClientCreateAlgorithmInferenceSpecificationContainersTypeDef = TypedDict(
    "_RequiredClientCreateAlgorithmInferenceSpecificationContainersTypeDef",
    {"Image": str},
)
_OptionalClientCreateAlgorithmInferenceSpecificationContainersTypeDef = TypedDict(
    "_OptionalClientCreateAlgorithmInferenceSpecificationContainersTypeDef",
    {
        "ContainerHostname": str,
        "ImageDigest": str,
        "ModelDataUrl": str,
        "ProductId": str,
    },
    total=False,
)


class ClientCreateAlgorithmInferenceSpecificationContainersTypeDef(
    _RequiredClientCreateAlgorithmInferenceSpecificationContainersTypeDef,
    _OptionalClientCreateAlgorithmInferenceSpecificationContainersTypeDef,
):
    """
    Type definition for `ClientCreateAlgorithmInferenceSpecification` `Containers`

    Describes the Docker container for the model package.

    - **ContainerHostname** *(string) --*

      The DNS host name for the Docker container.

    - **Image** *(string) --* **[REQUIRED]**

      The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.

      If you are using your own custom algorithm instead of an algorithm provided by Amazon
      SageMaker, the inference code must meet Amazon SageMaker requirements. Amazon SageMaker
      supports both ``registry/repository[:tag]`` and ``registry/repository[@digest]`` image path
      formats. For more information, see `Using Your Own Algorithms with Amazon SageMaker
      <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

    - **ImageDigest** *(string) --*

      An MD5 hash of the training algorithm that identifies the Docker image used for training.

    - **ModelDataUrl** *(string) --*

      The Amazon S3 path where the model artifacts, which result from model training, are stored.
      This path must point to a single ``gzip`` compressed tar archive (``.tar.gz`` suffix).

    - **ProductId** *(string) --*

      The AWS Marketplace product ID of the model package.
    """


_ClientCreateAlgorithmInferenceSpecificationTypeDef = TypedDict(
    "_ClientCreateAlgorithmInferenceSpecificationTypeDef",
    {
        "Containers": List[
            ClientCreateAlgorithmInferenceSpecificationContainersTypeDef
        ],
        "SupportedTransformInstanceTypes": List[str],
        "SupportedRealtimeInferenceInstanceTypes": List[str],
        "SupportedContentTypes": List[str],
        "SupportedResponseMIMETypes": List[str],
    },
)


class ClientCreateAlgorithmInferenceSpecificationTypeDef(
    _ClientCreateAlgorithmInferenceSpecificationTypeDef
):
    """
    Type definition for `ClientCreateAlgorithm` `InferenceSpecification`

    Specifies details about inference jobs that the algorithm runs, including the following:

    * The Amazon ECR paths of containers that contain the inference code and model artifacts.

    * The instance types that the algorithm supports for transform jobs and real-time endpoints used
    for inference.

    * The input and output content formats that the algorithm supports for inference.

    - **Containers** *(list) --* **[REQUIRED]**

      The Amazon ECR registry path of the Docker image that contains the inference code.

      - *(dict) --*

        Describes the Docker container for the model package.

        - **ContainerHostname** *(string) --*

          The DNS host name for the Docker container.

        - **Image** *(string) --* **[REQUIRED]**

          The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.

          If you are using your own custom algorithm instead of an algorithm provided by Amazon
          SageMaker, the inference code must meet Amazon SageMaker requirements. Amazon SageMaker
          supports both ``registry/repository[:tag]`` and ``registry/repository[@digest]`` image path
          formats. For more information, see `Using Your Own Algorithms with Amazon SageMaker
          <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

        - **ImageDigest** *(string) --*

          An MD5 hash of the training algorithm that identifies the Docker image used for training.

        - **ModelDataUrl** *(string) --*

          The Amazon S3 path where the model artifacts, which result from model training, are stored.
          This path must point to a single ``gzip`` compressed tar archive (``.tar.gz`` suffix).

        - **ProductId** *(string) --*

          The AWS Marketplace product ID of the model package.

    - **SupportedTransformInstanceTypes** *(list) --* **[REQUIRED]**

      A list of the instance types on which a transformation job can be run or on which an endpoint
      can be deployed.

      - *(string) --*

    - **SupportedRealtimeInferenceInstanceTypes** *(list) --* **[REQUIRED]**

      A list of the instance types that are used to generate inferences in real-time.

      - *(string) --*

    - **SupportedContentTypes** *(list) --* **[REQUIRED]**

      The supported MIME types for the input data.

      - *(string) --*

    - **SupportedResponseMIMETypes** *(list) --* **[REQUIRED]**

      The supported MIME types for the output data.

      - *(string) --*
    """


_ClientCreateAlgorithmResponseTypeDef = TypedDict(
    "_ClientCreateAlgorithmResponseTypeDef", {"AlgorithmArn": str}, total=False
)


class ClientCreateAlgorithmResponseTypeDef(_ClientCreateAlgorithmResponseTypeDef):
    """
    Type definition for `ClientCreateAlgorithm` `Response`

    - **AlgorithmArn** *(string) --*

      The Amazon Resource Name (ARN) of the new algorithm.
    """


_ClientCreateAlgorithmTrainingSpecificationMetricDefinitionsTypeDef = TypedDict(
    "_ClientCreateAlgorithmTrainingSpecificationMetricDefinitionsTypeDef",
    {"Name": str, "Regex": str},
)


class ClientCreateAlgorithmTrainingSpecificationMetricDefinitionsTypeDef(
    _ClientCreateAlgorithmTrainingSpecificationMetricDefinitionsTypeDef
):
    """
    Type definition for `ClientCreateAlgorithmTrainingSpecification` `MetricDefinitions`

    Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` . Amazon
    SageMakerhyperparameter tuning captures all defined metrics. You specify one metric that a
    hyperparameter tuning job uses as its objective metric to choose the best training job.

    - **Name** *(string) --* **[REQUIRED]**

      The name of the metric.

    - **Regex** *(string) --* **[REQUIRED]**

      A regular expression that searches the output of a training job and gets the value of the
      metric. For more information about using regular expressions to define metrics, see
      `Defining Objective Metrics
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
      .
    """


_ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeCategoricalParameterRangeSpecificationTypeDef = TypedDict(
    "_ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeCategoricalParameterRangeSpecificationTypeDef",
    {"Values": List[str]},
)


class ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeCategoricalParameterRangeSpecificationTypeDef(
    _ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeCategoricalParameterRangeSpecificationTypeDef
):
    """
    Type definition for `ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRange` `CategoricalParameterRangeSpecification`

    A ``CategoricalParameterRangeSpecification`` object that defines the possible values for
    a categorical hyperparameter.

    - **Values** *(list) --* **[REQUIRED]**

      The allowed categories for the hyperparameter.

      - *(string) --*
    """


_ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeContinuousParameterRangeSpecificationTypeDef = TypedDict(
    "_ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeContinuousParameterRangeSpecificationTypeDef",
    {"MinValue": str, "MaxValue": str},
)


class ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeContinuousParameterRangeSpecificationTypeDef(
    _ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeContinuousParameterRangeSpecificationTypeDef
):
    """
    Type definition for `ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRange` `ContinuousParameterRangeSpecification`

    A ``ContinuousParameterRangeSpecification`` object that defines the possible values for a
    continuous hyperparameter.

    - **MinValue** *(string) --* **[REQUIRED]**

      The minimum floating-point value allowed.

    - **MaxValue** *(string) --* **[REQUIRED]**

      The maximum floating-point value allowed.
    """


_ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeIntegerParameterRangeSpecificationTypeDef = TypedDict(
    "_ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeIntegerParameterRangeSpecificationTypeDef",
    {"MinValue": str, "MaxValue": str},
)


class ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeIntegerParameterRangeSpecificationTypeDef(
    _ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeIntegerParameterRangeSpecificationTypeDef
):
    """
    Type definition for `ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRange` `IntegerParameterRangeSpecification`

    A ``IntegerParameterRangeSpecification`` object that defines the possible values for an
    integer hyperparameter.

    - **MinValue** *(string) --* **[REQUIRED]**

      The minimum integer value allowed.

    - **MaxValue** *(string) --* **[REQUIRED]**

      The maximum integer value allowed.
    """


_ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeTypeDef = TypedDict(
    "_ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeTypeDef",
    {
        "IntegerParameterRangeSpecification": ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeIntegerParameterRangeSpecificationTypeDef,
        "ContinuousParameterRangeSpecification": ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeContinuousParameterRangeSpecificationTypeDef,
        "CategoricalParameterRangeSpecification": ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeCategoricalParameterRangeSpecificationTypeDef,
    },
    total=False,
)


class ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeTypeDef(
    _ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeTypeDef
):
    """
    Type definition for `ClientCreateAlgorithmTrainingSpecificationSupportedHyperParameters` `Range`

    The allowed range for this hyperparameter.

    - **IntegerParameterRangeSpecification** *(dict) --*

      A ``IntegerParameterRangeSpecification`` object that defines the possible values for an
      integer hyperparameter.

      - **MinValue** *(string) --* **[REQUIRED]**

        The minimum integer value allowed.

      - **MaxValue** *(string) --* **[REQUIRED]**

        The maximum integer value allowed.

    - **ContinuousParameterRangeSpecification** *(dict) --*

      A ``ContinuousParameterRangeSpecification`` object that defines the possible values for a
      continuous hyperparameter.

      - **MinValue** *(string) --* **[REQUIRED]**

        The minimum floating-point value allowed.

      - **MaxValue** *(string) --* **[REQUIRED]**

        The maximum floating-point value allowed.

    - **CategoricalParameterRangeSpecification** *(dict) --*

      A ``CategoricalParameterRangeSpecification`` object that defines the possible values for
      a categorical hyperparameter.

      - **Values** *(list) --* **[REQUIRED]**

        The allowed categories for the hyperparameter.

        - *(string) --*
    """


_RequiredClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersTypeDef = TypedDict(
    "_RequiredClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersTypeDef",
    {"Name": str, "Type": str},
)
_OptionalClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersTypeDef = TypedDict(
    "_OptionalClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersTypeDef",
    {
        "Description": str,
        "Range": ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersRangeTypeDef,
        "IsTunable": bool,
        "IsRequired": bool,
        "DefaultValue": str,
    },
    total=False,
)


class ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersTypeDef(
    _RequiredClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersTypeDef,
    _OptionalClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersTypeDef,
):
    """
    Type definition for `ClientCreateAlgorithmTrainingSpecification` `SupportedHyperParameters`

    Defines a hyperparameter to be used by an algorithm.

    - **Name** *(string) --* **[REQUIRED]**

      The name of this hyperparameter. The name must be unique.

    - **Description** *(string) --*

      A brief description of the hyperparameter.

    - **Type** *(string) --* **[REQUIRED]**

      The type of this hyperparameter. The valid types are ``Integer`` , ``Continuous`` ,
      ``Categorical`` , and ``FreeText`` .

    - **Range** *(dict) --*

      The allowed range for this hyperparameter.

      - **IntegerParameterRangeSpecification** *(dict) --*

        A ``IntegerParameterRangeSpecification`` object that defines the possible values for an
        integer hyperparameter.

        - **MinValue** *(string) --* **[REQUIRED]**

          The minimum integer value allowed.

        - **MaxValue** *(string) --* **[REQUIRED]**

          The maximum integer value allowed.

      - **ContinuousParameterRangeSpecification** *(dict) --*

        A ``ContinuousParameterRangeSpecification`` object that defines the possible values for a
        continuous hyperparameter.

        - **MinValue** *(string) --* **[REQUIRED]**

          The minimum floating-point value allowed.

        - **MaxValue** *(string) --* **[REQUIRED]**

          The maximum floating-point value allowed.

      - **CategoricalParameterRangeSpecification** *(dict) --*

        A ``CategoricalParameterRangeSpecification`` object that defines the possible values for
        a categorical hyperparameter.

        - **Values** *(list) --* **[REQUIRED]**

          The allowed categories for the hyperparameter.

          - *(string) --*

    - **IsTunable** *(boolean) --*

      Indicates whether this hyperparameter is tunable in a hyperparameter tuning job.

    - **IsRequired** *(boolean) --*

      Indicates whether this hyperparameter is required.

    - **DefaultValue** *(string) --*

      The default value for this hyperparameter. If a default value is specified, a
      hyperparameter cannot be required.
    """


_ClientCreateAlgorithmTrainingSpecificationSupportedTuningJobObjectiveMetricsTypeDef = TypedDict(
    "_ClientCreateAlgorithmTrainingSpecificationSupportedTuningJobObjectiveMetricsTypeDef",
    {"Type": str, "MetricName": str},
)


class ClientCreateAlgorithmTrainingSpecificationSupportedTuningJobObjectiveMetricsTypeDef(
    _ClientCreateAlgorithmTrainingSpecificationSupportedTuningJobObjectiveMetricsTypeDef
):
    """
    Type definition for `ClientCreateAlgorithmTrainingSpecification` `SupportedTuningJobObjectiveMetrics`

    Defines the objective metric for a hyperparameter tuning job. Hyperparameter tuning uses the
    value of this metric to evaluate the training jobs it launches, and returns the training job
    that results in either the highest or lowest value for this metric, depending on the value
    you specify for the ``Type`` parameter.

    - **Type** *(string) --* **[REQUIRED]**

      Whether to minimize or maximize the objective metric.

    - **MetricName** *(string) --* **[REQUIRED]**

      The name of the metric to use for the objective metric.
    """


_RequiredClientCreateAlgorithmTrainingSpecificationTrainingChannelsTypeDef = TypedDict(
    "_RequiredClientCreateAlgorithmTrainingSpecificationTrainingChannelsTypeDef",
    {"Name": str, "SupportedContentTypes": List[str], "SupportedInputModes": List[str]},
)
_OptionalClientCreateAlgorithmTrainingSpecificationTrainingChannelsTypeDef = TypedDict(
    "_OptionalClientCreateAlgorithmTrainingSpecificationTrainingChannelsTypeDef",
    {"Description": str, "IsRequired": bool, "SupportedCompressionTypes": List[str]},
    total=False,
)


class ClientCreateAlgorithmTrainingSpecificationTrainingChannelsTypeDef(
    _RequiredClientCreateAlgorithmTrainingSpecificationTrainingChannelsTypeDef,
    _OptionalClientCreateAlgorithmTrainingSpecificationTrainingChannelsTypeDef,
):
    """
    Type definition for `ClientCreateAlgorithmTrainingSpecification` `TrainingChannels`

    Defines a named input source, called a channel, to be used by an algorithm.

    - **Name** *(string) --* **[REQUIRED]**

      The name of the channel.

    - **Description** *(string) --*

      A brief description of the channel.

    - **IsRequired** *(boolean) --*

      Indicates whether the channel is required by the algorithm.

    - **SupportedContentTypes** *(list) --* **[REQUIRED]**

      The supported MIME types for the data.

      - *(string) --*

    - **SupportedCompressionTypes** *(list) --*

      The allowed compression types, if data compression is used.

      - *(string) --*

    - **SupportedInputModes** *(list) --* **[REQUIRED]**

      The allowed input mode, either FILE or PIPE.

      In FILE mode, Amazon SageMaker copies the data from the input source onto the local Amazon
      Elastic Block Store (Amazon EBS) volumes before starting your training algorithm. This is
      the most commonly used input mode.

      In PIPE mode, Amazon SageMaker streams input data from the source directly to your
      algorithm without using the EBS volume.

      - *(string) --*
    """


_RequiredClientCreateAlgorithmTrainingSpecificationTypeDef = TypedDict(
    "_RequiredClientCreateAlgorithmTrainingSpecificationTypeDef",
    {
        "TrainingImage": str,
        "SupportedTrainingInstanceTypes": List[str],
        "TrainingChannels": List[
            ClientCreateAlgorithmTrainingSpecificationTrainingChannelsTypeDef
        ],
    },
)
_OptionalClientCreateAlgorithmTrainingSpecificationTypeDef = TypedDict(
    "_OptionalClientCreateAlgorithmTrainingSpecificationTypeDef",
    {
        "TrainingImageDigest": str,
        "SupportedHyperParameters": List[
            ClientCreateAlgorithmTrainingSpecificationSupportedHyperParametersTypeDef
        ],
        "SupportsDistributedTraining": bool,
        "MetricDefinitions": List[
            ClientCreateAlgorithmTrainingSpecificationMetricDefinitionsTypeDef
        ],
        "SupportedTuningJobObjectiveMetrics": List[
            ClientCreateAlgorithmTrainingSpecificationSupportedTuningJobObjectiveMetricsTypeDef
        ],
    },
    total=False,
)


class ClientCreateAlgorithmTrainingSpecificationTypeDef(
    _RequiredClientCreateAlgorithmTrainingSpecificationTypeDef,
    _OptionalClientCreateAlgorithmTrainingSpecificationTypeDef,
):
    """
    Type definition for `ClientCreateAlgorithm` `TrainingSpecification`

    Specifies details about training jobs run by this algorithm, including the following:

    * The Amazon ECR path of the container and the version digest of the algorithm.

    * The hyperparameters that the algorithm supports.

    * The instance types that the algorithm supports for training.

    * Whether the algorithm supports distributed training.

    * The metrics that the algorithm emits to Amazon CloudWatch.

    * Which metrics that the algorithm emits can be used as the objective metric for hyperparameter
    tuning jobs.

    * The input channels that the algorithm supports for training data. For example, an algorithm
    might support ``train`` , ``validation`` , and ``test`` channels.

    - **TrainingImage** *(string) --* **[REQUIRED]**

      The Amazon ECR registry path of the Docker image that contains the training algorithm.

    - **TrainingImageDigest** *(string) --*

      An MD5 hash of the training algorithm that identifies the Docker image used for training.

    - **SupportedHyperParameters** *(list) --*

      A list of the ``HyperParameterSpecification`` objects, that define the supported
      hyperparameters. This is required if the algorithm supports automatic model tuning.>

      - *(dict) --*

        Defines a hyperparameter to be used by an algorithm.

        - **Name** *(string) --* **[REQUIRED]**

          The name of this hyperparameter. The name must be unique.

        - **Description** *(string) --*

          A brief description of the hyperparameter.

        - **Type** *(string) --* **[REQUIRED]**

          The type of this hyperparameter. The valid types are ``Integer`` , ``Continuous`` ,
          ``Categorical`` , and ``FreeText`` .

        - **Range** *(dict) --*

          The allowed range for this hyperparameter.

          - **IntegerParameterRangeSpecification** *(dict) --*

            A ``IntegerParameterRangeSpecification`` object that defines the possible values for an
            integer hyperparameter.

            - **MinValue** *(string) --* **[REQUIRED]**

              The minimum integer value allowed.

            - **MaxValue** *(string) --* **[REQUIRED]**

              The maximum integer value allowed.

          - **ContinuousParameterRangeSpecification** *(dict) --*

            A ``ContinuousParameterRangeSpecification`` object that defines the possible values for a
            continuous hyperparameter.

            - **MinValue** *(string) --* **[REQUIRED]**

              The minimum floating-point value allowed.

            - **MaxValue** *(string) --* **[REQUIRED]**

              The maximum floating-point value allowed.

          - **CategoricalParameterRangeSpecification** *(dict) --*

            A ``CategoricalParameterRangeSpecification`` object that defines the possible values for
            a categorical hyperparameter.

            - **Values** *(list) --* **[REQUIRED]**

              The allowed categories for the hyperparameter.

              - *(string) --*

        - **IsTunable** *(boolean) --*

          Indicates whether this hyperparameter is tunable in a hyperparameter tuning job.

        - **IsRequired** *(boolean) --*

          Indicates whether this hyperparameter is required.

        - **DefaultValue** *(string) --*

          The default value for this hyperparameter. If a default value is specified, a
          hyperparameter cannot be required.

    - **SupportedTrainingInstanceTypes** *(list) --* **[REQUIRED]**

      A list of the instance types that this algorithm can use for training.

      - *(string) --*

    - **SupportsDistributedTraining** *(boolean) --*

      Indicates whether the algorithm supports distributed training. If set to false, buyers cant
      request more than one instance during training.

    - **MetricDefinitions** *(list) --*

      A list of ``MetricDefinition`` objects, which are used for parsing metrics generated by the
      algorithm.

      - *(dict) --*

        Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` . Amazon
        SageMakerhyperparameter tuning captures all defined metrics. You specify one metric that a
        hyperparameter tuning job uses as its objective metric to choose the best training job.

        - **Name** *(string) --* **[REQUIRED]**

          The name of the metric.

        - **Regex** *(string) --* **[REQUIRED]**

          A regular expression that searches the output of a training job and gets the value of the
          metric. For more information about using regular expressions to define metrics, see
          `Defining Objective Metrics
          <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
          .

    - **TrainingChannels** *(list) --* **[REQUIRED]**

      A list of ``ChannelSpecification`` objects, which specify the input sources to be used by the
      algorithm.

      - *(dict) --*

        Defines a named input source, called a channel, to be used by an algorithm.

        - **Name** *(string) --* **[REQUIRED]**

          The name of the channel.

        - **Description** *(string) --*

          A brief description of the channel.

        - **IsRequired** *(boolean) --*

          Indicates whether the channel is required by the algorithm.

        - **SupportedContentTypes** *(list) --* **[REQUIRED]**

          The supported MIME types for the data.

          - *(string) --*

        - **SupportedCompressionTypes** *(list) --*

          The allowed compression types, if data compression is used.

          - *(string) --*

        - **SupportedInputModes** *(list) --* **[REQUIRED]**

          The allowed input mode, either FILE or PIPE.

          In FILE mode, Amazon SageMaker copies the data from the input source onto the local Amazon
          Elastic Block Store (Amazon EBS) volumes before starting your training algorithm. This is
          the most commonly used input mode.

          In PIPE mode, Amazon SageMaker streams input data from the source directly to your
          algorithm without using the EBS volume.

          - *(string) --*

    - **SupportedTuningJobObjectiveMetrics** *(list) --*

      A list of the metrics that the algorithm emits that can be used as the objective metric in a
      hyperparameter tuning job.

      - *(dict) --*

        Defines the objective metric for a hyperparameter tuning job. Hyperparameter tuning uses the
        value of this metric to evaluate the training jobs it launches, and returns the training job
        that results in either the highest or lowest value for this metric, depending on the value
        you specify for the ``Type`` parameter.

        - **Type** *(string) --* **[REQUIRED]**

          Whether to minimize or maximize the objective metric.

        - **MetricName** *(string) --* **[REQUIRED]**

          The name of the metric to use for the objective metric.
    """


_ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef = TypedDict(
    "_ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef",
    {
        "FileSystemId": str,
        "FileSystemAccessMode": str,
        "FileSystemType": str,
        "DirectoryPath": str,
    },
)


class ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef(
    _ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef
):
    """
    Type definition for `ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSource` `FileSystemDataSource`

    The file system that is associated with a channel.

    - **FileSystemId** *(string) --* **[REQUIRED]**

      The file system id.

    - **FileSystemAccessMode** *(string) --* **[REQUIRED]**

      The access mode of the mount of the directory associated with the channel. A
      directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

    - **FileSystemType** *(string) --* **[REQUIRED]**

      The file system type.

    - **DirectoryPath** *(string) --* **[REQUIRED]**

      The full path to the directory to associate with the channel.
    """


_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef = TypedDict(
    "_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef",
    {"S3DataType": str, "S3Uri": str},
)
_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef = TypedDict(
    "_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef",
    {"S3DataDistributionType": str, "AttributeNames": List[str]},
    total=False,
)


class ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef(
    _RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef,
    _OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef,
):
    """
    Type definition for `ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSource` `S3DataSource`

    The S3 location of the data source that is associated with a channel.

    - **S3DataType** *(string) --* **[REQUIRED]**

      If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
      SageMaker uses all objects that match the specified key name prefix for model
      training.

      If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
      manifest file containing a list of object keys that you want Amazon SageMaker to
      use for model training.

      If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
      augmented manifest file in JSON lines format. This file contains the data you
      want to use for model training. ``AugmentedManifestFile`` can only be used if the
      Channel's input mode is ``Pipe`` .

    - **S3Uri** *(string) --* **[REQUIRED]**

      Depending on the value specified for the ``S3DataType`` , identifies either a key
      name prefix or a manifest. For example:

      * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

      * A manifest might look like this: ``s3://bucketname/example.manifest``   The
      manifest is an S3 object which is a JSON file with the following format:  The
      preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
      "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
      ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
      ``]``   The preceding JSON matches the following ``s3Uris`` :
      ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set
      of ``s3uris`` in this manifest is the input data for the channel for this
      datasource. The object that each ``s3uris`` points to must be readable by the IAM
      role that Amazon SageMaker uses to perform tasks on your behalf.

    - **S3DataDistributionType** *(string) --*

      If you want Amazon SageMaker to replicate the entire dataset on each ML compute
      instance that is launched for model training, specify ``FullyReplicated`` .

      If you want Amazon SageMaker to replicate a subset of data on each ML compute
      instance that is launched for model training, specify ``ShardedByS3Key`` . If
      there are *n* ML compute instances launched for a training job, each instance
      gets approximately 1/*n* of the number of S3 objects. In this case, model
      training on each machine uses only the subset of training data.

      Don't choose more ML compute instances for training than available S3 objects. If
      you do, some nodes won't get any data and you will pay for nodes that aren't
      getting any training data. This applies in both File and Pipe modes. Keep this in
      mind when developing algorithms.

      In distributed training, where you use multiple ML compute EC2 instances, you
      might choose ``ShardedByS3Key`` . If the algorithm requires copying training data
      to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ), this
      copies 1/*n* of the number of objects.

    - **AttributeNames** *(list) --*

      A list of one or more attribute names to use that are found in a specified
      augmented manifest file.

      - *(string) --*
    """


_ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceTypeDef = TypedDict(
    "_ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceTypeDef",
    {
        "S3DataSource": ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef,
        "FileSystemDataSource": ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef,
    },
    total=False,
)


class ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceTypeDef(
    _ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceTypeDef
):
    """
    Type definition for `ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfig` `DataSource`

    The location of the channel data.

    - **S3DataSource** *(dict) --*

      The S3 location of the data source that is associated with a channel.

      - **S3DataType** *(string) --* **[REQUIRED]**

        If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
        SageMaker uses all objects that match the specified key name prefix for model
        training.

        If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
        manifest file containing a list of object keys that you want Amazon SageMaker to
        use for model training.

        If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
        augmented manifest file in JSON lines format. This file contains the data you
        want to use for model training. ``AugmentedManifestFile`` can only be used if the
        Channel's input mode is ``Pipe`` .

      - **S3Uri** *(string) --* **[REQUIRED]**

        Depending on the value specified for the ``S3DataType`` , identifies either a key
        name prefix or a manifest. For example:

        * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

        * A manifest might look like this: ``s3://bucketname/example.manifest``   The
        manifest is an S3 object which is a JSON file with the following format:  The
        preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
        "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
        ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
        ``]``   The preceding JSON matches the following ``s3Uris`` :
        ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set
        of ``s3uris`` in this manifest is the input data for the channel for this
        datasource. The object that each ``s3uris`` points to must be readable by the IAM
        role that Amazon SageMaker uses to perform tasks on your behalf.

      - **S3DataDistributionType** *(string) --*

        If you want Amazon SageMaker to replicate the entire dataset on each ML compute
        instance that is launched for model training, specify ``FullyReplicated`` .

        If you want Amazon SageMaker to replicate a subset of data on each ML compute
        instance that is launched for model training, specify ``ShardedByS3Key`` . If
        there are *n* ML compute instances launched for a training job, each instance
        gets approximately 1/*n* of the number of S3 objects. In this case, model
        training on each machine uses only the subset of training data.

        Don't choose more ML compute instances for training than available S3 objects. If
        you do, some nodes won't get any data and you will pay for nodes that aren't
        getting any training data. This applies in both File and Pipe modes. Keep this in
        mind when developing algorithms.

        In distributed training, where you use multiple ML compute EC2 instances, you
        might choose ``ShardedByS3Key`` . If the algorithm requires copying training data
        to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ), this
        copies 1/*n* of the number of objects.

      - **AttributeNames** *(list) --*

        A list of one or more attribute names to use that are found in a specified
        augmented manifest file.

        - *(string) --*

    - **FileSystemDataSource** *(dict) --*

      The file system that is associated with a channel.

      - **FileSystemId** *(string) --* **[REQUIRED]**

        The file system id.

      - **FileSystemAccessMode** *(string) --* **[REQUIRED]**

        The access mode of the mount of the directory associated with the channel. A
        directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

      - **FileSystemType** *(string) --* **[REQUIRED]**

        The file system type.

      - **DirectoryPath** *(string) --* **[REQUIRED]**

        The full path to the directory to associate with the channel.
    """


_ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef = TypedDict(
    "_ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef",
    {"Seed": int},
)


class ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef(
    _ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef
):
    """
    Type definition for `ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfig` `ShuffleConfig`

    A configuration for a shuffle option for input data in a channel. If you use
    ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
    matches. If you use ``ManifestFile`` , the order of the S3 object references in the
    ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of the
    JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
    determined using the ``Seed`` value.

    For Pipe input mode, shuffling is done at the start of every epoch. With large
    datasets this ensures that the order of the training data is different for each
    epoch, it helps reduce bias and possible overfitting. In a multi-node training job
    when ShuffleConfig is combined with ``S3DataDistributionType`` of ``ShardedByS3Key``
    , the data is shuffled across nodes so that the content sent to a particular node on
    the first epoch might be sent to a different node on the second epoch.

    - **Seed** *(integer) --* **[REQUIRED]**

      Determines the shuffling order in ``ShuffleConfig`` value.
    """


_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigTypeDef = TypedDict(
    "_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigTypeDef",
    {
        "ChannelName": str,
        "DataSource": ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceTypeDef,
    },
)
_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigTypeDef = TypedDict(
    "_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigTypeDef",
    {
        "ContentType": str,
        "CompressionType": str,
        "RecordWrapperType": str,
        "InputMode": str,
        "ShuffleConfig": ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef,
    },
    total=False,
)


class ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigTypeDef(
    _RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigTypeDef,
    _OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigTypeDef,
):
    """
    Type definition for `ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinition` `InputDataConfig`

    A channel is a named input source that training algorithms can consume.

    - **ChannelName** *(string) --* **[REQUIRED]**

      The name of the channel.

    - **DataSource** *(dict) --* **[REQUIRED]**

      The location of the channel data.

      - **S3DataSource** *(dict) --*

        The S3 location of the data source that is associated with a channel.

        - **S3DataType** *(string) --* **[REQUIRED]**

          If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
          SageMaker uses all objects that match the specified key name prefix for model
          training.

          If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
          manifest file containing a list of object keys that you want Amazon SageMaker to
          use for model training.

          If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
          augmented manifest file in JSON lines format. This file contains the data you
          want to use for model training. ``AugmentedManifestFile`` can only be used if the
          Channel's input mode is ``Pipe`` .

        - **S3Uri** *(string) --* **[REQUIRED]**

          Depending on the value specified for the ``S3DataType`` , identifies either a key
          name prefix or a manifest. For example:

          * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

          * A manifest might look like this: ``s3://bucketname/example.manifest``   The
          manifest is an S3 object which is a JSON file with the following format:  The
          preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
          "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
          ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
          ``]``   The preceding JSON matches the following ``s3Uris`` :
          ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set
          of ``s3uris`` in this manifest is the input data for the channel for this
          datasource. The object that each ``s3uris`` points to must be readable by the IAM
          role that Amazon SageMaker uses to perform tasks on your behalf.

        - **S3DataDistributionType** *(string) --*

          If you want Amazon SageMaker to replicate the entire dataset on each ML compute
          instance that is launched for model training, specify ``FullyReplicated`` .

          If you want Amazon SageMaker to replicate a subset of data on each ML compute
          instance that is launched for model training, specify ``ShardedByS3Key`` . If
          there are *n* ML compute instances launched for a training job, each instance
          gets approximately 1/*n* of the number of S3 objects. In this case, model
          training on each machine uses only the subset of training data.

          Don't choose more ML compute instances for training than available S3 objects. If
          you do, some nodes won't get any data and you will pay for nodes that aren't
          getting any training data. This applies in both File and Pipe modes. Keep this in
          mind when developing algorithms.

          In distributed training, where you use multiple ML compute EC2 instances, you
          might choose ``ShardedByS3Key`` . If the algorithm requires copying training data
          to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ), this
          copies 1/*n* of the number of objects.

        - **AttributeNames** *(list) --*

          A list of one or more attribute names to use that are found in a specified
          augmented manifest file.

          - *(string) --*

      - **FileSystemDataSource** *(dict) --*

        The file system that is associated with a channel.

        - **FileSystemId** *(string) --* **[REQUIRED]**

          The file system id.

        - **FileSystemAccessMode** *(string) --* **[REQUIRED]**

          The access mode of the mount of the directory associated with the channel. A
          directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

        - **FileSystemType** *(string) --* **[REQUIRED]**

          The file system type.

        - **DirectoryPath** *(string) --* **[REQUIRED]**

          The full path to the directory to associate with the channel.

    - **ContentType** *(string) --*

      The MIME type of the data.

    - **CompressionType** *(string) --*

      If training data is compressed, the compression type. The default value is ``None`` .
      ``CompressionType`` is used only in Pipe input mode. In File mode, leave this field
      unset or set it to None.

    - **RecordWrapperType** *(string) --*

      Specify RecordIO as the value when input data is in raw format but the training
      algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
      individual S3 object in a RecordIO record. If the input data is already in RecordIO
      format, you don't need to set this attribute. For more information, see `Create a
      Dataset Using RecordIO
      <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
      .

      In File mode, leave this field unset or set it to None.

    - **InputMode** *(string) --*

      (Optional) The input mode to use for the data channel in a training job. If you don't
      set a value for ``InputMode`` , Amazon SageMaker uses the value set for
      ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
      setting in a  AlgorithmSpecification request when you have a channel that needs a
      different input mode from the training job's general setting. To download the data
      from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage volume,
      and mount the directory to a Docker volume, use ``File`` input mode. To stream data
      directly from Amazon S3 to the container, choose ``Pipe`` input mode.

      To use a model for incremental training, choose ``File`` input model.

    - **ShuffleConfig** *(dict) --*

      A configuration for a shuffle option for input data in a channel. If you use
      ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
      matches. If you use ``ManifestFile`` , the order of the S3 object references in the
      ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of the
      JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
      determined using the ``Seed`` value.

      For Pipe input mode, shuffling is done at the start of every epoch. With large
      datasets this ensures that the order of the training data is different for each
      epoch, it helps reduce bias and possible overfitting. In a multi-node training job
      when ShuffleConfig is combined with ``S3DataDistributionType`` of ``ShardedByS3Key``
      , the data is shuffled across nodes so that the content sent to a particular node on
      the first epoch might be sent to a different node on the second epoch.

      - **Seed** *(integer) --* **[REQUIRED]**

        Determines the shuffling order in ``ShuffleConfig`` value.
    """


_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionOutputDataConfigTypeDef = TypedDict(
    "_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionOutputDataConfigTypeDef",
    {"S3OutputPath": str},
)
_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionOutputDataConfigTypeDef = TypedDict(
    "_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionOutputDataConfigTypeDef",
    {"KmsKeyId": str},
    total=False,
)


class ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionOutputDataConfigTypeDef(
    _RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionOutputDataConfigTypeDef,
    _OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionOutputDataConfigTypeDef,
):
    """
    Type definition for `ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinition` `OutputDataConfig`

    the path to the S3 bucket where you want to store model artifacts. Amazon SageMaker
    creates subfolders for the artifacts.

    - **KmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
      model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be
      any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // KMS Key Alias  ``"alias/ExampleAlias"``

      * // Amazon Resource Name (ARN) of a KMS Key Alias
      ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

      If you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution
      role must include permissions to call ``kms:Encrypt`` . If you don't provide a KMS key
      ID, Amazon SageMaker uses the default KMS key for Amazon S3 for your role's account.
      Amazon SageMaker uses server-side encryption with KMS-managed keys for
      ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject`` permission
      that only allows objects with server-side encryption, set the condition key of
      ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information, see
      `KMS-Managed Encryption Keys
      <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
      *Amazon Simple Storage Service Developer Guide.*

      The KMS key policy must grant permission to the IAM role that you specify in your
      ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
      requests. For more information, see `Using Key Policies in AWS KMS
      <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
      in the *AWS Key Management Service Developer Guide* .

    - **S3OutputPath** *(string) --* **[REQUIRED]**

      Identifies the S3 path where you want Amazon SageMaker to store the model artifacts.
      For example, ``s3://bucket-name/key-name-prefix`` .
    """


_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionResourceConfigTypeDef = TypedDict(
    "_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionResourceConfigTypeDef",
    {"InstanceType": str, "InstanceCount": int, "VolumeSizeInGB": int},
)
_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionResourceConfigTypeDef = TypedDict(
    "_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionResourceConfigTypeDef",
    {"VolumeKmsKeyId": str},
    total=False,
)


class ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionResourceConfigTypeDef(
    _RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionResourceConfigTypeDef,
    _OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionResourceConfigTypeDef,
):
    """
    Type definition for `ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinition` `ResourceConfig`

    The resources, including the ML compute instances and ML storage volumes, to use for
    model training.

    - **InstanceType** *(string) --* **[REQUIRED]**

      The ML compute instance type.

    - **InstanceCount** *(integer) --* **[REQUIRED]**

      The number of ML compute instances to use. For distributed training, provide a value
      greater than 1.

    - **VolumeSizeInGB** *(integer) --* **[REQUIRED]**

      The size of the ML storage volume that you want to provision.

      ML storage volumes store model artifacts and incremental states. Training algorithms
      might also use the ML storage volume for scratch space. If you want to store the
      training data in the ML storage volume, choose ``File`` as the ``TrainingInputMode`` in
      the algorithm specification.

      You must specify sufficient ML storage for your scenario.

      .. note::

        Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

      .. note::

        Certain Nitro-based instances include local storage with a fixed total size,
        dependent on the instance type. When using these instances for training, Amazon
        SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage. You
        can't request a ``VolumeSizeInGB`` greater than the total size of the local instance
        storage.

        For a list of instance types that support local instance storage, including the total
        size per instance type, see `Instance Store Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
        .

    - **VolumeKmsKeyId** *(string) --*

      The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
      attached to the ML compute instance(s) that run the training job.

      .. note::

        Certain Nitro-based instances include local storage, dependent on the instance type.
        Local storage volumes are encrypted using a hardware module on the instance. You
        can't request a ``VolumeKmsKeyId`` when using an instance type with local storage.

        For a list of instance types that support local instance storage, see `Instance Store
        Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
        .

        For more information about local instance storage encryption, see `SSD Instance Store
        Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

      The ``VolumeKmsKeyId`` can be in any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionStoppingConditionTypeDef = TypedDict(
    "_ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionStoppingConditionTypeDef",
    {"MaxRuntimeInSeconds": int, "MaxWaitTimeInSeconds": int},
    total=False,
)


class ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionStoppingConditionTypeDef(
    _ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionStoppingConditionTypeDef
):
    """
    Type definition for `ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinition` `StoppingCondition`

    Specifies a limit to how long a model training job can run. When the job reaches the time
    limit, Amazon SageMaker ends the training job. Use this API to cap model training costs.

    To stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays job
    termination for 120 seconds. Algorithms can use this 120-second window to save the model
    artifacts.

    - **MaxRuntimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, that the training or compilation job can run.
      If job does not complete during this time, Amazon SageMaker ends the job. If value is
      not specified, default value is 1 day. The maximum value is 28 days.

    - **MaxWaitTimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, how long you are willing to wait for a managed
      spot training job to complete. It is the amount of time spent waiting for Spot capacity
      plus the amount of time the training job runs. It must be equal to or greater than
      ``MaxRuntimeInSeconds`` .
    """


_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionTypeDef = TypedDict(
    "_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionTypeDef",
    {
        "TrainingInputMode": str,
        "InputDataConfig": List[
            ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigTypeDef
        ],
        "OutputDataConfig": ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionOutputDataConfigTypeDef,
        "ResourceConfig": ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionResourceConfigTypeDef,
        "StoppingCondition": ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionStoppingConditionTypeDef,
    },
)
_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionTypeDef = TypedDict(
    "_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionTypeDef",
    {"HyperParameters": Dict[str, str]},
    total=False,
)


class ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionTypeDef(
    _RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionTypeDef,
    _OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionTypeDef,
):
    """
    Type definition for `ClientCreateAlgorithmValidationSpecificationValidationProfiles` `TrainingJobDefinition`

    The ``TrainingJobDefinition`` object that describes the training job that Amazon SageMaker
    runs to validate your algorithm.

    - **TrainingInputMode** *(string) --* **[REQUIRED]**

      The input mode used by the algorithm for the training job. For the input modes that
      Amazon SageMaker algorithms support, see `Algorithms
      <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ .

      If an algorithm supports the ``File`` input mode, Amazon SageMaker downloads the training
      data from S3 to the provisioned ML storage Volume, and mounts the directory to docker
      volume for training container. If an algorithm supports the ``Pipe`` input mode, Amazon
      SageMaker streams data directly from S3 to the container.

    - **HyperParameters** *(dict) --*

      The hyperparameters used for the training job.

      - *(string) --*

        - *(string) --*

    - **InputDataConfig** *(list) --* **[REQUIRED]**

      An array of ``Channel`` objects, each of which specifies an input source.

      - *(dict) --*

        A channel is a named input source that training algorithms can consume.

        - **ChannelName** *(string) --* **[REQUIRED]**

          The name of the channel.

        - **DataSource** *(dict) --* **[REQUIRED]**

          The location of the channel data.

          - **S3DataSource** *(dict) --*

            The S3 location of the data source that is associated with a channel.

            - **S3DataType** *(string) --* **[REQUIRED]**

              If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
              SageMaker uses all objects that match the specified key name prefix for model
              training.

              If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
              manifest file containing a list of object keys that you want Amazon SageMaker to
              use for model training.

              If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
              augmented manifest file in JSON lines format. This file contains the data you
              want to use for model training. ``AugmentedManifestFile`` can only be used if the
              Channel's input mode is ``Pipe`` .

            - **S3Uri** *(string) --* **[REQUIRED]**

              Depending on the value specified for the ``S3DataType`` , identifies either a key
              name prefix or a manifest. For example:

              * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

              * A manifest might look like this: ``s3://bucketname/example.manifest``   The
              manifest is an S3 object which is a JSON file with the following format:  The
              preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
              "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
              ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
              ``]``   The preceding JSON matches the following ``s3Uris`` :
              ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
              ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
              ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set
              of ``s3uris`` in this manifest is the input data for the channel for this
              datasource. The object that each ``s3uris`` points to must be readable by the IAM
              role that Amazon SageMaker uses to perform tasks on your behalf.

            - **S3DataDistributionType** *(string) --*

              If you want Amazon SageMaker to replicate the entire dataset on each ML compute
              instance that is launched for model training, specify ``FullyReplicated`` .

              If you want Amazon SageMaker to replicate a subset of data on each ML compute
              instance that is launched for model training, specify ``ShardedByS3Key`` . If
              there are *n* ML compute instances launched for a training job, each instance
              gets approximately 1/*n* of the number of S3 objects. In this case, model
              training on each machine uses only the subset of training data.

              Don't choose more ML compute instances for training than available S3 objects. If
              you do, some nodes won't get any data and you will pay for nodes that aren't
              getting any training data. This applies in both File and Pipe modes. Keep this in
              mind when developing algorithms.

              In distributed training, where you use multiple ML compute EC2 instances, you
              might choose ``ShardedByS3Key`` . If the algorithm requires copying training data
              to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ), this
              copies 1/*n* of the number of objects.

            - **AttributeNames** *(list) --*

              A list of one or more attribute names to use that are found in a specified
              augmented manifest file.

              - *(string) --*

          - **FileSystemDataSource** *(dict) --*

            The file system that is associated with a channel.

            - **FileSystemId** *(string) --* **[REQUIRED]**

              The file system id.

            - **FileSystemAccessMode** *(string) --* **[REQUIRED]**

              The access mode of the mount of the directory associated with the channel. A
              directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

            - **FileSystemType** *(string) --* **[REQUIRED]**

              The file system type.

            - **DirectoryPath** *(string) --* **[REQUIRED]**

              The full path to the directory to associate with the channel.

        - **ContentType** *(string) --*

          The MIME type of the data.

        - **CompressionType** *(string) --*

          If training data is compressed, the compression type. The default value is ``None`` .
          ``CompressionType`` is used only in Pipe input mode. In File mode, leave this field
          unset or set it to None.

        - **RecordWrapperType** *(string) --*

          Specify RecordIO as the value when input data is in raw format but the training
          algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
          individual S3 object in a RecordIO record. If the input data is already in RecordIO
          format, you don't need to set this attribute. For more information, see `Create a
          Dataset Using RecordIO
          <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
          .

          In File mode, leave this field unset or set it to None.

        - **InputMode** *(string) --*

          (Optional) The input mode to use for the data channel in a training job. If you don't
          set a value for ``InputMode`` , Amazon SageMaker uses the value set for
          ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
          setting in a  AlgorithmSpecification request when you have a channel that needs a
          different input mode from the training job's general setting. To download the data
          from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage volume,
          and mount the directory to a Docker volume, use ``File`` input mode. To stream data
          directly from Amazon S3 to the container, choose ``Pipe`` input mode.

          To use a model for incremental training, choose ``File`` input model.

        - **ShuffleConfig** *(dict) --*

          A configuration for a shuffle option for input data in a channel. If you use
          ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
          matches. If you use ``ManifestFile`` , the order of the S3 object references in the
          ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of the
          JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
          determined using the ``Seed`` value.

          For Pipe input mode, shuffling is done at the start of every epoch. With large
          datasets this ensures that the order of the training data is different for each
          epoch, it helps reduce bias and possible overfitting. In a multi-node training job
          when ShuffleConfig is combined with ``S3DataDistributionType`` of ``ShardedByS3Key``
          , the data is shuffled across nodes so that the content sent to a particular node on
          the first epoch might be sent to a different node on the second epoch.

          - **Seed** *(integer) --* **[REQUIRED]**

            Determines the shuffling order in ``ShuffleConfig`` value.

    - **OutputDataConfig** *(dict) --* **[REQUIRED]**

      the path to the S3 bucket where you want to store model artifacts. Amazon SageMaker
      creates subfolders for the artifacts.

      - **KmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
        model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be
        any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // KMS Key Alias  ``"alias/ExampleAlias"``

        * // Amazon Resource Name (ARN) of a KMS Key Alias
        ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

        If you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution
        role must include permissions to call ``kms:Encrypt`` . If you don't provide a KMS key
        ID, Amazon SageMaker uses the default KMS key for Amazon S3 for your role's account.
        Amazon SageMaker uses server-side encryption with KMS-managed keys for
        ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject`` permission
        that only allows objects with server-side encryption, set the condition key of
        ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information, see
        `KMS-Managed Encryption Keys
        <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
        *Amazon Simple Storage Service Developer Guide.*

        The KMS key policy must grant permission to the IAM role that you specify in your
        ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
        requests. For more information, see `Using Key Policies in AWS KMS
        <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
        in the *AWS Key Management Service Developer Guide* .

      - **S3OutputPath** *(string) --* **[REQUIRED]**

        Identifies the S3 path where you want Amazon SageMaker to store the model artifacts.
        For example, ``s3://bucket-name/key-name-prefix`` .

    - **ResourceConfig** *(dict) --* **[REQUIRED]**

      The resources, including the ML compute instances and ML storage volumes, to use for
      model training.

      - **InstanceType** *(string) --* **[REQUIRED]**

        The ML compute instance type.

      - **InstanceCount** *(integer) --* **[REQUIRED]**

        The number of ML compute instances to use. For distributed training, provide a value
        greater than 1.

      - **VolumeSizeInGB** *(integer) --* **[REQUIRED]**

        The size of the ML storage volume that you want to provision.

        ML storage volumes store model artifacts and incremental states. Training algorithms
        might also use the ML storage volume for scratch space. If you want to store the
        training data in the ML storage volume, choose ``File`` as the ``TrainingInputMode`` in
        the algorithm specification.

        You must specify sufficient ML storage for your scenario.

        .. note::

          Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

        .. note::

          Certain Nitro-based instances include local storage with a fixed total size,
          dependent on the instance type. When using these instances for training, Amazon
          SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage. You
          can't request a ``VolumeSizeInGB`` greater than the total size of the local instance
          storage.

          For a list of instance types that support local instance storage, including the total
          size per instance type, see `Instance Store Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
          .

      - **VolumeKmsKeyId** *(string) --*

        The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
        attached to the ML compute instance(s) that run the training job.

        .. note::

          Certain Nitro-based instances include local storage, dependent on the instance type.
          Local storage volumes are encrypted using a hardware module on the instance. You
          can't request a ``VolumeKmsKeyId`` when using an instance type with local storage.

          For a list of instance types that support local instance storage, see `Instance Store
          Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
          .

          For more information about local instance storage encryption, see `SSD Instance Store
          Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

        The ``VolumeKmsKeyId`` can be in any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

    - **StoppingCondition** *(dict) --* **[REQUIRED]**

      Specifies a limit to how long a model training job can run. When the job reaches the time
      limit, Amazon SageMaker ends the training job. Use this API to cap model training costs.

      To stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays job
      termination for 120 seconds. Algorithms can use this 120-second window to save the model
      artifacts.

      - **MaxRuntimeInSeconds** *(integer) --*

        The maximum length of time, in seconds, that the training or compilation job can run.
        If job does not complete during this time, Amazon SageMaker ends the job. If value is
        not specified, default value is 1 day. The maximum value is 28 days.

      - **MaxWaitTimeInSeconds** *(integer) --*

        The maximum length of time, in seconds, how long you are willing to wait for a managed
        spot training job to complete. It is the amount of time spent waiting for Spot capacity
        plus the amount of time the training job runs. It must be equal to or greater than
        ``MaxRuntimeInSeconds`` .
    """


_ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef = TypedDict(
    "_ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef",
    {"S3DataType": str, "S3Uri": str},
)


class ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef(
    _ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef
):
    """
    Type definition for `ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSource` `S3DataSource`

    The S3 location of the data source that is associated with a channel.

    - **S3DataType** *(string) --* **[REQUIRED]**

      If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
      SageMaker uses all objects with the specified key name prefix for batch transform.

      If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
      file containing a list of object keys that you want Amazon SageMaker to use for
      batch transform.

      The following values are compatible: ``ManifestFile`` , ``S3Prefix``

      The following value is not compatible: ``AugmentedManifestFile``

    - **S3Uri** *(string) --* **[REQUIRED]**

      Depending on the value specified for the ``S3DataType`` , identifies either a key
      name prefix or a manifest. For example:

      * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

      * A manifest might look like this: ``s3://bucketname/example.manifest``   The
      manifest is an S3 object which is a JSON file with the following format:   ``[
      {"prefix": "s3://customer_bucket/some/prefix/"},``
      ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``    ``...``
      ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the following
      ``s3Uris`` :   ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
      ``S3Uris`` in this manifest constitutes the input data for the channel for this
      datasource. The object that each ``S3Uris`` points to must be readable by the IAM
      role that Amazon SageMaker uses to perform tasks on your behalf.
    """


_ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef = TypedDict(
    "_ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef",
    {
        "S3DataSource": ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef
    },
)


class ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef(
    _ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef
):
    """
    Type definition for `ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInput` `DataSource`

    Describes the location of the channel data, which is, the S3 location of the input data
    that the model can consume.

    - **S3DataSource** *(dict) --* **[REQUIRED]**

      The S3 location of the data source that is associated with a channel.

      - **S3DataType** *(string) --* **[REQUIRED]**

        If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
        SageMaker uses all objects with the specified key name prefix for batch transform.

        If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
        file containing a list of object keys that you want Amazon SageMaker to use for
        batch transform.

        The following values are compatible: ``ManifestFile`` , ``S3Prefix``

        The following value is not compatible: ``AugmentedManifestFile``

      - **S3Uri** *(string) --* **[REQUIRED]**

        Depending on the value specified for the ``S3DataType`` , identifies either a key
        name prefix or a manifest. For example:

        * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

        * A manifest might look like this: ``s3://bucketname/example.manifest``   The
        manifest is an S3 object which is a JSON file with the following format:   ``[
        {"prefix": "s3://customer_bucket/some/prefix/"},``
        ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``    ``...``
        ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the following
        ``s3Uris`` :   ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
        ``S3Uris`` in this manifest constitutes the input data for the channel for this
        datasource. The object that each ``S3Uris`` points to must be readable by the IAM
        role that Amazon SageMaker uses to perform tasks on your behalf.
    """


_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef = TypedDict(
    "_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef",
    {
        "DataSource": ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef
    },
)
_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef = TypedDict(
    "_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef",
    {"ContentType": str, "CompressionType": str, "SplitType": str},
    total=False,
)


class ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef(
    _RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef,
    _OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef,
):
    """
    Type definition for `ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinition` `TransformInput`

    A description of the input source and the way the transform job consumes it.

    - **DataSource** *(dict) --* **[REQUIRED]**

      Describes the location of the channel data, which is, the S3 location of the input data
      that the model can consume.

      - **S3DataSource** *(dict) --* **[REQUIRED]**

        The S3 location of the data source that is associated with a channel.

        - **S3DataType** *(string) --* **[REQUIRED]**

          If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
          SageMaker uses all objects with the specified key name prefix for batch transform.

          If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
          file containing a list of object keys that you want Amazon SageMaker to use for
          batch transform.

          The following values are compatible: ``ManifestFile`` , ``S3Prefix``

          The following value is not compatible: ``AugmentedManifestFile``

        - **S3Uri** *(string) --* **[REQUIRED]**

          Depending on the value specified for the ``S3DataType`` , identifies either a key
          name prefix or a manifest. For example:

          * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

          * A manifest might look like this: ``s3://bucketname/example.manifest``   The
          manifest is an S3 object which is a JSON file with the following format:   ``[
          {"prefix": "s3://customer_bucket/some/prefix/"},``
          ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``    ``...``
          ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the following
          ``s3Uris`` :   ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
          ``S3Uris`` in this manifest constitutes the input data for the channel for this
          datasource. The object that each ``S3Uris`` points to must be readable by the IAM
          role that Amazon SageMaker uses to perform tasks on your behalf.

    - **ContentType** *(string) --*

      The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker uses
      the MIME type with each http call to transfer data to the transform job.

    - **CompressionType** *(string) --*

      If your transform data is compressed, specify the compression type. Amazon SageMaker
      automatically decompresses the data for the transform job accordingly. The default
      value is ``None`` .

    - **SplitType** *(string) --*

      The method to use to split the transform job's data files into smaller batches.
      Splitting is necessary when the total size of each object is too large to fit in a
      single request. You can also use data splitting to improve performance by processing
      multiple concurrent mini-batches. The default value for ``SplitType`` is ``None`` ,
      which indicates that input data files are not split, and request payloads contain the
      entire contents of an input object. Set the value of this parameter to ``Line`` to
      split records on a newline character boundary. ``SplitType`` also supports a number of
      record-oriented binary data formats.

      When splitting is enabled, the size of a mini-batch depends on the values of the
      ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
      ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
      records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
      ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records in
      each request.

      .. note::

        Some data formats represent a record as a binary payload wrapped with extra padding
        bytes. When splitting is applied to a binary data format, padding is removed if the
        value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is not removed if the
        value of ``BatchStrategy`` is set to ``MultiRecord`` .

        For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
        <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For more
        information about ``TFRecord`` , see `Consuming TFRecord data
        <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
        TensorFlow documentation.
    """


_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef = TypedDict(
    "_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef",
    {"S3OutputPath": str},
)
_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef = TypedDict(
    "_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef",
    {"Accept": str, "AssembleWith": str, "KmsKeyId": str},
    total=False,
)


class ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef(
    _RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef,
    _OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef,
):
    """
    Type definition for `ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinition` `TransformOutput`

    Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
    from the transform job.

    - **S3OutputPath** *(string) --* **[REQUIRED]**

      The Amazon S3 path where you want Amazon SageMaker to store the results of the
      transform job. For example, ``s3://bucket-name/key-name-prefix`` .

      For every S3 object used as input for the transform job, batch transform stores the
      transformed data with an .``out`` suffix in a corresponding subfolder in the location
      in the output prefix. For example, for the input data stored at
      ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores the
      transformed data at
      ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
      transform doesn't upload partially processed objects. For an input S3 object that
      contains multiple records, it creates an .``out`` file only if the transform job
      succeeds on the entire file. When the input contains multiple S3 objects, the batch
      transform job processes the listed S3 objects and uploads only the output for
      successfully processed objects. If any object fails in the transform job batch
      transform marks the job as failed to prompt investigation.

    - **Accept** *(string) --*

      The MIME type used to specify the output data. Amazon SageMaker uses the MIME type with
      each http call to transfer data from the transform job.

    - **AssembleWith** *(string) --*

      Defines how to assemble the results of the transform job as a single S3 object. Choose
      a format that is most convenient to you. To concatenate the results in binary format,
      specify ``None`` . To add a newline character at the end of every transformed record,
      specify ``Line`` .

    - **KmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
      model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be
      any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // KMS Key Alias  ``"alias/ExampleAlias"``

      * // Amazon Resource Name (ARN) of a KMS Key Alias
      ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

      If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon
      S3 for your role's account. For more information, see `KMS-Managed Encryption Keys
      <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
      *Amazon Simple Storage Service Developer Guide.*

      The KMS key policy must grant permission to the IAM role that you specify in your
      CreateModel request. For more information, see `Using Key Policies in AWS KMS
      <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the *AWS
      Key Management Service Developer Guide* .
    """


_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef = TypedDict(
    "_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef",
    {"InstanceType": str, "InstanceCount": int},
)
_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef = TypedDict(
    "_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef",
    {"VolumeKmsKeyId": str},
    total=False,
)


class ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef(
    _RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef,
    _OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef,
):
    """
    Type definition for `ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinition` `TransformResources`

    Identifies the ML compute instances for the transform job.

    - **InstanceType** *(string) --* **[REQUIRED]**

      The ML compute instance type for the transform job. If you are using built-in
      algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge or
      ``ml.m5.large`` instance types.

    - **InstanceCount** *(integer) --* **[REQUIRED]**

      The number of ML compute instances to use in the transform job. For distributed
      transform jobs, specify a value greater than 1. The default value is ``1`` .

    - **VolumeKmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data
      on the storage volume attached to the ML compute instance(s) that run the batch
      transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef = TypedDict(
    "_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef",
    {
        "TransformInput": ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef,
        "TransformOutput": ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef,
        "TransformResources": ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef,
    },
)
_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef = TypedDict(
    "_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef",
    {
        "MaxConcurrentTransforms": int,
        "MaxPayloadInMB": int,
        "BatchStrategy": str,
        "Environment": Dict[str, str],
    },
    total=False,
)


class ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef(
    _RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef,
    _OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef,
):
    """
    Type definition for `ClientCreateAlgorithmValidationSpecificationValidationProfiles` `TransformJobDefinition`

    The ``TransformJobDefinition`` object that describes the transform job that Amazon
    SageMaker runs to validate your algorithm.

    - **MaxConcurrentTransforms** *(integer) --*

      The maximum number of parallel requests that can be sent to each instance in a transform
      job. The default value is 1.

    - **MaxPayloadInMB** *(integer) --*

      The maximum payload size allowed, in MB. A payload is the data portion of a record
      (without metadata).

    - **BatchStrategy** *(string) --*

      A string that determines the number of records included in a single mini-batch.

       ``SingleRecord`` means only one record is used per mini-batch. ``MultiRecord`` means a
       mini-batch is set to contain as many records that can fit within the ``MaxPayloadInMB``
       limit.

    - **Environment** *(dict) --*

      The environment variables to set in the Docker container. We support up to 16 key and
      values entries in the map.

      - *(string) --*

        - *(string) --*

    - **TransformInput** *(dict) --* **[REQUIRED]**

      A description of the input source and the way the transform job consumes it.

      - **DataSource** *(dict) --* **[REQUIRED]**

        Describes the location of the channel data, which is, the S3 location of the input data
        that the model can consume.

        - **S3DataSource** *(dict) --* **[REQUIRED]**

          The S3 location of the data source that is associated with a channel.

          - **S3DataType** *(string) --* **[REQUIRED]**

            If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
            SageMaker uses all objects with the specified key name prefix for batch transform.

            If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
            file containing a list of object keys that you want Amazon SageMaker to use for
            batch transform.

            The following values are compatible: ``ManifestFile`` , ``S3Prefix``

            The following value is not compatible: ``AugmentedManifestFile``

          - **S3Uri** *(string) --* **[REQUIRED]**

            Depending on the value specified for the ``S3DataType`` , identifies either a key
            name prefix or a manifest. For example:

            * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

            * A manifest might look like this: ``s3://bucketname/example.manifest``   The
            manifest is an S3 object which is a JSON file with the following format:   ``[
            {"prefix": "s3://customer_bucket/some/prefix/"},``
            ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``    ``...``
            ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the following
            ``s3Uris`` :   ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
            ``S3Uris`` in this manifest constitutes the input data for the channel for this
            datasource. The object that each ``S3Uris`` points to must be readable by the IAM
            role that Amazon SageMaker uses to perform tasks on your behalf.

      - **ContentType** *(string) --*

        The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker uses
        the MIME type with each http call to transfer data to the transform job.

      - **CompressionType** *(string) --*

        If your transform data is compressed, specify the compression type. Amazon SageMaker
        automatically decompresses the data for the transform job accordingly. The default
        value is ``None`` .

      - **SplitType** *(string) --*

        The method to use to split the transform job's data files into smaller batches.
        Splitting is necessary when the total size of each object is too large to fit in a
        single request. You can also use data splitting to improve performance by processing
        multiple concurrent mini-batches. The default value for ``SplitType`` is ``None`` ,
        which indicates that input data files are not split, and request payloads contain the
        entire contents of an input object. Set the value of this parameter to ``Line`` to
        split records on a newline character boundary. ``SplitType`` also supports a number of
        record-oriented binary data formats.

        When splitting is enabled, the size of a mini-batch depends on the values of the
        ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
        ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
        records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
        ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records in
        each request.

        .. note::

          Some data formats represent a record as a binary payload wrapped with extra padding
          bytes. When splitting is applied to a binary data format, padding is removed if the
          value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is not removed if the
          value of ``BatchStrategy`` is set to ``MultiRecord`` .

          For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
          <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For more
          information about ``TFRecord`` , see `Consuming TFRecord data
          <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
          TensorFlow documentation.

    - **TransformOutput** *(dict) --* **[REQUIRED]**

      Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
      from the transform job.

      - **S3OutputPath** *(string) --* **[REQUIRED]**

        The Amazon S3 path where you want Amazon SageMaker to store the results of the
        transform job. For example, ``s3://bucket-name/key-name-prefix`` .

        For every S3 object used as input for the transform job, batch transform stores the
        transformed data with an .``out`` suffix in a corresponding subfolder in the location
        in the output prefix. For example, for the input data stored at
        ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores the
        transformed data at
        ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
        transform doesn't upload partially processed objects. For an input S3 object that
        contains multiple records, it creates an .``out`` file only if the transform job
        succeeds on the entire file. When the input contains multiple S3 objects, the batch
        transform job processes the listed S3 objects and uploads only the output for
        successfully processed objects. If any object fails in the transform job batch
        transform marks the job as failed to prompt investigation.

      - **Accept** *(string) --*

        The MIME type used to specify the output data. Amazon SageMaker uses the MIME type with
        each http call to transfer data from the transform job.

      - **AssembleWith** *(string) --*

        Defines how to assemble the results of the transform job as a single S3 object. Choose
        a format that is most convenient to you. To concatenate the results in binary format,
        specify ``None`` . To add a newline character at the end of every transformed record,
        specify ``Line`` .

      - **KmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
        model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be
        any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // KMS Key Alias  ``"alias/ExampleAlias"``

        * // Amazon Resource Name (ARN) of a KMS Key Alias
        ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

        If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon
        S3 for your role's account. For more information, see `KMS-Managed Encryption Keys
        <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
        *Amazon Simple Storage Service Developer Guide.*

        The KMS key policy must grant permission to the IAM role that you specify in your
        CreateModel request. For more information, see `Using Key Policies in AWS KMS
        <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the *AWS
        Key Management Service Developer Guide* .

    - **TransformResources** *(dict) --* **[REQUIRED]**

      Identifies the ML compute instances for the transform job.

      - **InstanceType** *(string) --* **[REQUIRED]**

        The ML compute instance type for the transform job. If you are using built-in
        algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge or
        ``ml.m5.large`` instance types.

      - **InstanceCount** *(integer) --* **[REQUIRED]**

        The number of ML compute instances to use in the transform job. For distributed
        transform jobs, specify a value greater than 1. The default value is ``1`` .

      - **VolumeKmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data
        on the storage volume attached to the ML compute instance(s) that run the batch
        transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTypeDef = TypedDict(
    "_RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTypeDef",
    {
        "ProfileName": str,
        "TrainingJobDefinition": ClientCreateAlgorithmValidationSpecificationValidationProfilesTrainingJobDefinitionTypeDef,
    },
)
_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTypeDef = TypedDict(
    "_OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTypeDef",
    {
        "TransformJobDefinition": ClientCreateAlgorithmValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef
    },
    total=False,
)


class ClientCreateAlgorithmValidationSpecificationValidationProfilesTypeDef(
    _RequiredClientCreateAlgorithmValidationSpecificationValidationProfilesTypeDef,
    _OptionalClientCreateAlgorithmValidationSpecificationValidationProfilesTypeDef,
):
    """
    Type definition for `ClientCreateAlgorithmValidationSpecification` `ValidationProfiles`

    Defines a training job and a batch transform job that Amazon SageMaker runs to validate your
    algorithm.

    The data provided in the validation profile is made available to your buyers on AWS
    Marketplace.

    - **ProfileName** *(string) --* **[REQUIRED]**

      The name of the profile for the algorithm. The name must have 1 to 63 characters. Valid
      characters are a-z, A-Z, 0-9, and - (hyphen).

    - **TrainingJobDefinition** *(dict) --* **[REQUIRED]**

      The ``TrainingJobDefinition`` object that describes the training job that Amazon SageMaker
      runs to validate your algorithm.

      - **TrainingInputMode** *(string) --* **[REQUIRED]**

        The input mode used by the algorithm for the training job. For the input modes that
        Amazon SageMaker algorithms support, see `Algorithms
        <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ .

        If an algorithm supports the ``File`` input mode, Amazon SageMaker downloads the training
        data from S3 to the provisioned ML storage Volume, and mounts the directory to docker
        volume for training container. If an algorithm supports the ``Pipe`` input mode, Amazon
        SageMaker streams data directly from S3 to the container.

      - **HyperParameters** *(dict) --*

        The hyperparameters used for the training job.

        - *(string) --*

          - *(string) --*

      - **InputDataConfig** *(list) --* **[REQUIRED]**

        An array of ``Channel`` objects, each of which specifies an input source.

        - *(dict) --*

          A channel is a named input source that training algorithms can consume.

          - **ChannelName** *(string) --* **[REQUIRED]**

            The name of the channel.

          - **DataSource** *(dict) --* **[REQUIRED]**

            The location of the channel data.

            - **S3DataSource** *(dict) --*

              The S3 location of the data source that is associated with a channel.

              - **S3DataType** *(string) --* **[REQUIRED]**

                If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
                SageMaker uses all objects that match the specified key name prefix for model
                training.

                If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
                manifest file containing a list of object keys that you want Amazon SageMaker to
                use for model training.

                If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
                augmented manifest file in JSON lines format. This file contains the data you
                want to use for model training. ``AugmentedManifestFile`` can only be used if the
                Channel's input mode is ``Pipe`` .

              - **S3Uri** *(string) --* **[REQUIRED]**

                Depending on the value specified for the ``S3DataType`` , identifies either a key
                name prefix or a manifest. For example:

                * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

                * A manifest might look like this: ``s3://bucketname/example.manifest``   The
                manifest is an S3 object which is a JSON file with the following format:  The
                preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
                "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
                ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
                ``]``   The preceding JSON matches the following ``s3Uris`` :
                ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set
                of ``s3uris`` in this manifest is the input data for the channel for this
                datasource. The object that each ``s3uris`` points to must be readable by the IAM
                role that Amazon SageMaker uses to perform tasks on your behalf.

              - **S3DataDistributionType** *(string) --*

                If you want Amazon SageMaker to replicate the entire dataset on each ML compute
                instance that is launched for model training, specify ``FullyReplicated`` .

                If you want Amazon SageMaker to replicate a subset of data on each ML compute
                instance that is launched for model training, specify ``ShardedByS3Key`` . If
                there are *n* ML compute instances launched for a training job, each instance
                gets approximately 1/*n* of the number of S3 objects. In this case, model
                training on each machine uses only the subset of training data.

                Don't choose more ML compute instances for training than available S3 objects. If
                you do, some nodes won't get any data and you will pay for nodes that aren't
                getting any training data. This applies in both File and Pipe modes. Keep this in
                mind when developing algorithms.

                In distributed training, where you use multiple ML compute EC2 instances, you
                might choose ``ShardedByS3Key`` . If the algorithm requires copying training data
                to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ), this
                copies 1/*n* of the number of objects.

              - **AttributeNames** *(list) --*

                A list of one or more attribute names to use that are found in a specified
                augmented manifest file.

                - *(string) --*

            - **FileSystemDataSource** *(dict) --*

              The file system that is associated with a channel.

              - **FileSystemId** *(string) --* **[REQUIRED]**

                The file system id.

              - **FileSystemAccessMode** *(string) --* **[REQUIRED]**

                The access mode of the mount of the directory associated with the channel. A
                directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

              - **FileSystemType** *(string) --* **[REQUIRED]**

                The file system type.

              - **DirectoryPath** *(string) --* **[REQUIRED]**

                The full path to the directory to associate with the channel.

          - **ContentType** *(string) --*

            The MIME type of the data.

          - **CompressionType** *(string) --*

            If training data is compressed, the compression type. The default value is ``None`` .
            ``CompressionType`` is used only in Pipe input mode. In File mode, leave this field
            unset or set it to None.

          - **RecordWrapperType** *(string) --*

            Specify RecordIO as the value when input data is in raw format but the training
            algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
            individual S3 object in a RecordIO record. If the input data is already in RecordIO
            format, you don't need to set this attribute. For more information, see `Create a
            Dataset Using RecordIO
            <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
            .

            In File mode, leave this field unset or set it to None.

          - **InputMode** *(string) --*

            (Optional) The input mode to use for the data channel in a training job. If you don't
            set a value for ``InputMode`` , Amazon SageMaker uses the value set for
            ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
            setting in a  AlgorithmSpecification request when you have a channel that needs a
            different input mode from the training job's general setting. To download the data
            from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage volume,
            and mount the directory to a Docker volume, use ``File`` input mode. To stream data
            directly from Amazon S3 to the container, choose ``Pipe`` input mode.

            To use a model for incremental training, choose ``File`` input model.

          - **ShuffleConfig** *(dict) --*

            A configuration for a shuffle option for input data in a channel. If you use
            ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
            matches. If you use ``ManifestFile`` , the order of the S3 object references in the
            ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of the
            JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
            determined using the ``Seed`` value.

            For Pipe input mode, shuffling is done at the start of every epoch. With large
            datasets this ensures that the order of the training data is different for each
            epoch, it helps reduce bias and possible overfitting. In a multi-node training job
            when ShuffleConfig is combined with ``S3DataDistributionType`` of ``ShardedByS3Key``
            , the data is shuffled across nodes so that the content sent to a particular node on
            the first epoch might be sent to a different node on the second epoch.

            - **Seed** *(integer) --* **[REQUIRED]**

              Determines the shuffling order in ``ShuffleConfig`` value.

      - **OutputDataConfig** *(dict) --* **[REQUIRED]**

        the path to the S3 bucket where you want to store model artifacts. Amazon SageMaker
        creates subfolders for the artifacts.

        - **KmsKeyId** *(string) --*

          The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
          model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be
          any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // KMS Key Alias  ``"alias/ExampleAlias"``

          * // Amazon Resource Name (ARN) of a KMS Key Alias
          ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

          If you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution
          role must include permissions to call ``kms:Encrypt`` . If you don't provide a KMS key
          ID, Amazon SageMaker uses the default KMS key for Amazon S3 for your role's account.
          Amazon SageMaker uses server-side encryption with KMS-managed keys for
          ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject`` permission
          that only allows objects with server-side encryption, set the condition key of
          ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information, see
          `KMS-Managed Encryption Keys
          <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
          *Amazon Simple Storage Service Developer Guide.*

          The KMS key policy must grant permission to the IAM role that you specify in your
          ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
          requests. For more information, see `Using Key Policies in AWS KMS
          <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
          in the *AWS Key Management Service Developer Guide* .

        - **S3OutputPath** *(string) --* **[REQUIRED]**

          Identifies the S3 path where you want Amazon SageMaker to store the model artifacts.
          For example, ``s3://bucket-name/key-name-prefix`` .

      - **ResourceConfig** *(dict) --* **[REQUIRED]**

        The resources, including the ML compute instances and ML storage volumes, to use for
        model training.

        - **InstanceType** *(string) --* **[REQUIRED]**

          The ML compute instance type.

        - **InstanceCount** *(integer) --* **[REQUIRED]**

          The number of ML compute instances to use. For distributed training, provide a value
          greater than 1.

        - **VolumeSizeInGB** *(integer) --* **[REQUIRED]**

          The size of the ML storage volume that you want to provision.

          ML storage volumes store model artifacts and incremental states. Training algorithms
          might also use the ML storage volume for scratch space. If you want to store the
          training data in the ML storage volume, choose ``File`` as the ``TrainingInputMode`` in
          the algorithm specification.

          You must specify sufficient ML storage for your scenario.

          .. note::

            Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

          .. note::

            Certain Nitro-based instances include local storage with a fixed total size,
            dependent on the instance type. When using these instances for training, Amazon
            SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage. You
            can't request a ``VolumeSizeInGB`` greater than the total size of the local instance
            storage.

            For a list of instance types that support local instance storage, including the total
            size per instance type, see `Instance Store Volumes
            <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
            .

        - **VolumeKmsKeyId** *(string) --*

          The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
          attached to the ML compute instance(s) that run the training job.

          .. note::

            Certain Nitro-based instances include local storage, dependent on the instance type.
            Local storage volumes are encrypted using a hardware module on the instance. You
            can't request a ``VolumeKmsKeyId`` when using an instance type with local storage.

            For a list of instance types that support local instance storage, see `Instance Store
            Volumes
            <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
            .

            For more information about local instance storage encryption, see `SSD Instance Store
            Volumes
            <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

          The ``VolumeKmsKeyId`` can be in any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      - **StoppingCondition** *(dict) --* **[REQUIRED]**

        Specifies a limit to how long a model training job can run. When the job reaches the time
        limit, Amazon SageMaker ends the training job. Use this API to cap model training costs.

        To stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays job
        termination for 120 seconds. Algorithms can use this 120-second window to save the model
        artifacts.

        - **MaxRuntimeInSeconds** *(integer) --*

          The maximum length of time, in seconds, that the training or compilation job can run.
          If job does not complete during this time, Amazon SageMaker ends the job. If value is
          not specified, default value is 1 day. The maximum value is 28 days.

        - **MaxWaitTimeInSeconds** *(integer) --*

          The maximum length of time, in seconds, how long you are willing to wait for a managed
          spot training job to complete. It is the amount of time spent waiting for Spot capacity
          plus the amount of time the training job runs. It must be equal to or greater than
          ``MaxRuntimeInSeconds`` .

    - **TransformJobDefinition** *(dict) --*

      The ``TransformJobDefinition`` object that describes the transform job that Amazon
      SageMaker runs to validate your algorithm.

      - **MaxConcurrentTransforms** *(integer) --*

        The maximum number of parallel requests that can be sent to each instance in a transform
        job. The default value is 1.

      - **MaxPayloadInMB** *(integer) --*

        The maximum payload size allowed, in MB. A payload is the data portion of a record
        (without metadata).

      - **BatchStrategy** *(string) --*

        A string that determines the number of records included in a single mini-batch.

         ``SingleRecord`` means only one record is used per mini-batch. ``MultiRecord`` means a
         mini-batch is set to contain as many records that can fit within the ``MaxPayloadInMB``
         limit.

      - **Environment** *(dict) --*

        The environment variables to set in the Docker container. We support up to 16 key and
        values entries in the map.

        - *(string) --*

          - *(string) --*

      - **TransformInput** *(dict) --* **[REQUIRED]**

        A description of the input source and the way the transform job consumes it.

        - **DataSource** *(dict) --* **[REQUIRED]**

          Describes the location of the channel data, which is, the S3 location of the input data
          that the model can consume.

          - **S3DataSource** *(dict) --* **[REQUIRED]**

            The S3 location of the data source that is associated with a channel.

            - **S3DataType** *(string) --* **[REQUIRED]**

              If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
              SageMaker uses all objects with the specified key name prefix for batch transform.

              If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
              file containing a list of object keys that you want Amazon SageMaker to use for
              batch transform.

              The following values are compatible: ``ManifestFile`` , ``S3Prefix``

              The following value is not compatible: ``AugmentedManifestFile``

            - **S3Uri** *(string) --* **[REQUIRED]**

              Depending on the value specified for the ``S3DataType`` , identifies either a key
              name prefix or a manifest. For example:

              * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

              * A manifest might look like this: ``s3://bucketname/example.manifest``   The
              manifest is an S3 object which is a JSON file with the following format:   ``[
              {"prefix": "s3://customer_bucket/some/prefix/"},``
              ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``    ``...``
              ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the following
              ``s3Uris`` :   ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
              ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
              ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
              ``S3Uris`` in this manifest constitutes the input data for the channel for this
              datasource. The object that each ``S3Uris`` points to must be readable by the IAM
              role that Amazon SageMaker uses to perform tasks on your behalf.

        - **ContentType** *(string) --*

          The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker uses
          the MIME type with each http call to transfer data to the transform job.

        - **CompressionType** *(string) --*

          If your transform data is compressed, specify the compression type. Amazon SageMaker
          automatically decompresses the data for the transform job accordingly. The default
          value is ``None`` .

        - **SplitType** *(string) --*

          The method to use to split the transform job's data files into smaller batches.
          Splitting is necessary when the total size of each object is too large to fit in a
          single request. You can also use data splitting to improve performance by processing
          multiple concurrent mini-batches. The default value for ``SplitType`` is ``None`` ,
          which indicates that input data files are not split, and request payloads contain the
          entire contents of an input object. Set the value of this parameter to ``Line`` to
          split records on a newline character boundary. ``SplitType`` also supports a number of
          record-oriented binary data formats.

          When splitting is enabled, the size of a mini-batch depends on the values of the
          ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
          ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
          records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
          ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records in
          each request.

          .. note::

            Some data formats represent a record as a binary payload wrapped with extra padding
            bytes. When splitting is applied to a binary data format, padding is removed if the
            value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is not removed if the
            value of ``BatchStrategy`` is set to ``MultiRecord`` .

            For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
            <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For more
            information about ``TFRecord`` , see `Consuming TFRecord data
            <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
            TensorFlow documentation.

      - **TransformOutput** *(dict) --* **[REQUIRED]**

        Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
        from the transform job.

        - **S3OutputPath** *(string) --* **[REQUIRED]**

          The Amazon S3 path where you want Amazon SageMaker to store the results of the
          transform job. For example, ``s3://bucket-name/key-name-prefix`` .

          For every S3 object used as input for the transform job, batch transform stores the
          transformed data with an .``out`` suffix in a corresponding subfolder in the location
          in the output prefix. For example, for the input data stored at
          ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores the
          transformed data at
          ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
          transform doesn't upload partially processed objects. For an input S3 object that
          contains multiple records, it creates an .``out`` file only if the transform job
          succeeds on the entire file. When the input contains multiple S3 objects, the batch
          transform job processes the listed S3 objects and uploads only the output for
          successfully processed objects. If any object fails in the transform job batch
          transform marks the job as failed to prompt investigation.

        - **Accept** *(string) --*

          The MIME type used to specify the output data. Amazon SageMaker uses the MIME type with
          each http call to transfer data from the transform job.

        - **AssembleWith** *(string) --*

          Defines how to assemble the results of the transform job as a single S3 object. Choose
          a format that is most convenient to you. To concatenate the results in binary format,
          specify ``None`` . To add a newline character at the end of every transformed record,
          specify ``Line`` .

        - **KmsKeyId** *(string) --*

          The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
          model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be
          any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // KMS Key Alias  ``"alias/ExampleAlias"``

          * // Amazon Resource Name (ARN) of a KMS Key Alias
          ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

          If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon
          S3 for your role's account. For more information, see `KMS-Managed Encryption Keys
          <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
          *Amazon Simple Storage Service Developer Guide.*

          The KMS key policy must grant permission to the IAM role that you specify in your
          CreateModel request. For more information, see `Using Key Policies in AWS KMS
          <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the *AWS
          Key Management Service Developer Guide* .

      - **TransformResources** *(dict) --* **[REQUIRED]**

        Identifies the ML compute instances for the transform job.

        - **InstanceType** *(string) --* **[REQUIRED]**

          The ML compute instance type for the transform job. If you are using built-in
          algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge or
          ``ml.m5.large`` instance types.

        - **InstanceCount** *(integer) --* **[REQUIRED]**

          The number of ML compute instances to use in the transform job. For distributed
          transform jobs, specify a value greater than 1. The default value is ``1`` .

        - **VolumeKmsKeyId** *(string) --*

          The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data
          on the storage volume attached to the ML compute instance(s) that run the batch
          transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientCreateAlgorithmValidationSpecificationTypeDef = TypedDict(
    "_ClientCreateAlgorithmValidationSpecificationTypeDef",
    {
        "ValidationRole": str,
        "ValidationProfiles": List[
            ClientCreateAlgorithmValidationSpecificationValidationProfilesTypeDef
        ],
    },
)


class ClientCreateAlgorithmValidationSpecificationTypeDef(
    _ClientCreateAlgorithmValidationSpecificationTypeDef
):
    """
    Type definition for `ClientCreateAlgorithm` `ValidationSpecification`

    Specifies configurations for one or more training jobs and that Amazon SageMaker runs to test the
    algorithm's training code and, optionally, one or more batch transform jobs that Amazon SageMaker
    runs to test the algorithm's inference code.

    - **ValidationRole** *(string) --* **[REQUIRED]**

      The IAM roles that Amazon SageMaker uses to run the training jobs.

    - **ValidationProfiles** *(list) --* **[REQUIRED]**

      An array of ``AlgorithmValidationProfile`` objects, each of which specifies a training job and
      batch transform job that Amazon SageMaker runs to validate your algorithm.

      - *(dict) --*

        Defines a training job and a batch transform job that Amazon SageMaker runs to validate your
        algorithm.

        The data provided in the validation profile is made available to your buyers on AWS
        Marketplace.

        - **ProfileName** *(string) --* **[REQUIRED]**

          The name of the profile for the algorithm. The name must have 1 to 63 characters. Valid
          characters are a-z, A-Z, 0-9, and - (hyphen).

        - **TrainingJobDefinition** *(dict) --* **[REQUIRED]**

          The ``TrainingJobDefinition`` object that describes the training job that Amazon SageMaker
          runs to validate your algorithm.

          - **TrainingInputMode** *(string) --* **[REQUIRED]**

            The input mode used by the algorithm for the training job. For the input modes that
            Amazon SageMaker algorithms support, see `Algorithms
            <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ .

            If an algorithm supports the ``File`` input mode, Amazon SageMaker downloads the training
            data from S3 to the provisioned ML storage Volume, and mounts the directory to docker
            volume for training container. If an algorithm supports the ``Pipe`` input mode, Amazon
            SageMaker streams data directly from S3 to the container.

          - **HyperParameters** *(dict) --*

            The hyperparameters used for the training job.

            - *(string) --*

              - *(string) --*

          - **InputDataConfig** *(list) --* **[REQUIRED]**

            An array of ``Channel`` objects, each of which specifies an input source.

            - *(dict) --*

              A channel is a named input source that training algorithms can consume.

              - **ChannelName** *(string) --* **[REQUIRED]**

                The name of the channel.

              - **DataSource** *(dict) --* **[REQUIRED]**

                The location of the channel data.

                - **S3DataSource** *(dict) --*

                  The S3 location of the data source that is associated with a channel.

                  - **S3DataType** *(string) --* **[REQUIRED]**

                    If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
                    SageMaker uses all objects that match the specified key name prefix for model
                    training.

                    If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
                    manifest file containing a list of object keys that you want Amazon SageMaker to
                    use for model training.

                    If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
                    augmented manifest file in JSON lines format. This file contains the data you
                    want to use for model training. ``AugmentedManifestFile`` can only be used if the
                    Channel's input mode is ``Pipe`` .

                  - **S3Uri** *(string) --* **[REQUIRED]**

                    Depending on the value specified for the ``S3DataType`` , identifies either a key
                    name prefix or a manifest. For example:

                    * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

                    * A manifest might look like this: ``s3://bucketname/example.manifest``   The
                    manifest is an S3 object which is a JSON file with the following format:  The
                    preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
                    "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
                    ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
                    ``]``   The preceding JSON matches the following ``s3Uris`` :
                    ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                    ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                    ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set
                    of ``s3uris`` in this manifest is the input data for the channel for this
                    datasource. The object that each ``s3uris`` points to must be readable by the IAM
                    role that Amazon SageMaker uses to perform tasks on your behalf.

                  - **S3DataDistributionType** *(string) --*

                    If you want Amazon SageMaker to replicate the entire dataset on each ML compute
                    instance that is launched for model training, specify ``FullyReplicated`` .

                    If you want Amazon SageMaker to replicate a subset of data on each ML compute
                    instance that is launched for model training, specify ``ShardedByS3Key`` . If
                    there are *n* ML compute instances launched for a training job, each instance
                    gets approximately 1/*n* of the number of S3 objects. In this case, model
                    training on each machine uses only the subset of training data.

                    Don't choose more ML compute instances for training than available S3 objects. If
                    you do, some nodes won't get any data and you will pay for nodes that aren't
                    getting any training data. This applies in both File and Pipe modes. Keep this in
                    mind when developing algorithms.

                    In distributed training, where you use multiple ML compute EC2 instances, you
                    might choose ``ShardedByS3Key`` . If the algorithm requires copying training data
                    to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ), this
                    copies 1/*n* of the number of objects.

                  - **AttributeNames** *(list) --*

                    A list of one or more attribute names to use that are found in a specified
                    augmented manifest file.

                    - *(string) --*

                - **FileSystemDataSource** *(dict) --*

                  The file system that is associated with a channel.

                  - **FileSystemId** *(string) --* **[REQUIRED]**

                    The file system id.

                  - **FileSystemAccessMode** *(string) --* **[REQUIRED]**

                    The access mode of the mount of the directory associated with the channel. A
                    directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

                  - **FileSystemType** *(string) --* **[REQUIRED]**

                    The file system type.

                  - **DirectoryPath** *(string) --* **[REQUIRED]**

                    The full path to the directory to associate with the channel.

              - **ContentType** *(string) --*

                The MIME type of the data.

              - **CompressionType** *(string) --*

                If training data is compressed, the compression type. The default value is ``None`` .
                ``CompressionType`` is used only in Pipe input mode. In File mode, leave this field
                unset or set it to None.

              - **RecordWrapperType** *(string) --*

                Specify RecordIO as the value when input data is in raw format but the training
                algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
                individual S3 object in a RecordIO record. If the input data is already in RecordIO
                format, you don't need to set this attribute. For more information, see `Create a
                Dataset Using RecordIO
                <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
                .

                In File mode, leave this field unset or set it to None.

              - **InputMode** *(string) --*

                (Optional) The input mode to use for the data channel in a training job. If you don't
                set a value for ``InputMode`` , Amazon SageMaker uses the value set for
                ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
                setting in a  AlgorithmSpecification request when you have a channel that needs a
                different input mode from the training job's general setting. To download the data
                from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage volume,
                and mount the directory to a Docker volume, use ``File`` input mode. To stream data
                directly from Amazon S3 to the container, choose ``Pipe`` input mode.

                To use a model for incremental training, choose ``File`` input model.

              - **ShuffleConfig** *(dict) --*

                A configuration for a shuffle option for input data in a channel. If you use
                ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
                matches. If you use ``ManifestFile`` , the order of the S3 object references in the
                ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of the
                JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
                determined using the ``Seed`` value.

                For Pipe input mode, shuffling is done at the start of every epoch. With large
                datasets this ensures that the order of the training data is different for each
                epoch, it helps reduce bias and possible overfitting. In a multi-node training job
                when ShuffleConfig is combined with ``S3DataDistributionType`` of ``ShardedByS3Key``
                , the data is shuffled across nodes so that the content sent to a particular node on
                the first epoch might be sent to a different node on the second epoch.

                - **Seed** *(integer) --* **[REQUIRED]**

                  Determines the shuffling order in ``ShuffleConfig`` value.

          - **OutputDataConfig** *(dict) --* **[REQUIRED]**

            the path to the S3 bucket where you want to store model artifacts. Amazon SageMaker
            creates subfolders for the artifacts.

            - **KmsKeyId** *(string) --*

              The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
              model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be
              any of the following formats:

              * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // Amazon Resource Name (ARN) of a KMS Key
              ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // KMS Key Alias  ``"alias/ExampleAlias"``

              * // Amazon Resource Name (ARN) of a KMS Key Alias
              ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

              If you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution
              role must include permissions to call ``kms:Encrypt`` . If you don't provide a KMS key
              ID, Amazon SageMaker uses the default KMS key for Amazon S3 for your role's account.
              Amazon SageMaker uses server-side encryption with KMS-managed keys for
              ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject`` permission
              that only allows objects with server-side encryption, set the condition key of
              ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information, see
              `KMS-Managed Encryption Keys
              <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
              *Amazon Simple Storage Service Developer Guide.*

              The KMS key policy must grant permission to the IAM role that you specify in your
              ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
              requests. For more information, see `Using Key Policies in AWS KMS
              <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
              in the *AWS Key Management Service Developer Guide* .

            - **S3OutputPath** *(string) --* **[REQUIRED]**

              Identifies the S3 path where you want Amazon SageMaker to store the model artifacts.
              For example, ``s3://bucket-name/key-name-prefix`` .

          - **ResourceConfig** *(dict) --* **[REQUIRED]**

            The resources, including the ML compute instances and ML storage volumes, to use for
            model training.

            - **InstanceType** *(string) --* **[REQUIRED]**

              The ML compute instance type.

            - **InstanceCount** *(integer) --* **[REQUIRED]**

              The number of ML compute instances to use. For distributed training, provide a value
              greater than 1.

            - **VolumeSizeInGB** *(integer) --* **[REQUIRED]**

              The size of the ML storage volume that you want to provision.

              ML storage volumes store model artifacts and incremental states. Training algorithms
              might also use the ML storage volume for scratch space. If you want to store the
              training data in the ML storage volume, choose ``File`` as the ``TrainingInputMode`` in
              the algorithm specification.

              You must specify sufficient ML storage for your scenario.

              .. note::

                Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

              .. note::

                Certain Nitro-based instances include local storage with a fixed total size,
                dependent on the instance type. When using these instances for training, Amazon
                SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage. You
                can't request a ``VolumeSizeInGB`` greater than the total size of the local instance
                storage.

                For a list of instance types that support local instance storage, including the total
                size per instance type, see `Instance Store Volumes
                <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
                .

            - **VolumeKmsKeyId** *(string) --*

              The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
              attached to the ML compute instance(s) that run the training job.

              .. note::

                Certain Nitro-based instances include local storage, dependent on the instance type.
                Local storage volumes are encrypted using a hardware module on the instance. You
                can't request a ``VolumeKmsKeyId`` when using an instance type with local storage.

                For a list of instance types that support local instance storage, see `Instance Store
                Volumes
                <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
                .

                For more information about local instance storage encryption, see `SSD Instance Store
                Volumes
                <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

              The ``VolumeKmsKeyId`` can be in any of the following formats:

              * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // Amazon Resource Name (ARN) of a KMS Key
              ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

          - **StoppingCondition** *(dict) --* **[REQUIRED]**

            Specifies a limit to how long a model training job can run. When the job reaches the time
            limit, Amazon SageMaker ends the training job. Use this API to cap model training costs.

            To stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays job
            termination for 120 seconds. Algorithms can use this 120-second window to save the model
            artifacts.

            - **MaxRuntimeInSeconds** *(integer) --*

              The maximum length of time, in seconds, that the training or compilation job can run.
              If job does not complete during this time, Amazon SageMaker ends the job. If value is
              not specified, default value is 1 day. The maximum value is 28 days.

            - **MaxWaitTimeInSeconds** *(integer) --*

              The maximum length of time, in seconds, how long you are willing to wait for a managed
              spot training job to complete. It is the amount of time spent waiting for Spot capacity
              plus the amount of time the training job runs. It must be equal to or greater than
              ``MaxRuntimeInSeconds`` .

        - **TransformJobDefinition** *(dict) --*

          The ``TransformJobDefinition`` object that describes the transform job that Amazon
          SageMaker runs to validate your algorithm.

          - **MaxConcurrentTransforms** *(integer) --*

            The maximum number of parallel requests that can be sent to each instance in a transform
            job. The default value is 1.

          - **MaxPayloadInMB** *(integer) --*

            The maximum payload size allowed, in MB. A payload is the data portion of a record
            (without metadata).

          - **BatchStrategy** *(string) --*

            A string that determines the number of records included in a single mini-batch.

             ``SingleRecord`` means only one record is used per mini-batch. ``MultiRecord`` means a
             mini-batch is set to contain as many records that can fit within the ``MaxPayloadInMB``
             limit.

          - **Environment** *(dict) --*

            The environment variables to set in the Docker container. We support up to 16 key and
            values entries in the map.

            - *(string) --*

              - *(string) --*

          - **TransformInput** *(dict) --* **[REQUIRED]**

            A description of the input source and the way the transform job consumes it.

            - **DataSource** *(dict) --* **[REQUIRED]**

              Describes the location of the channel data, which is, the S3 location of the input data
              that the model can consume.

              - **S3DataSource** *(dict) --* **[REQUIRED]**

                The S3 location of the data source that is associated with a channel.

                - **S3DataType** *(string) --* **[REQUIRED]**

                  If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
                  SageMaker uses all objects with the specified key name prefix for batch transform.

                  If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
                  file containing a list of object keys that you want Amazon SageMaker to use for
                  batch transform.

                  The following values are compatible: ``ManifestFile`` , ``S3Prefix``

                  The following value is not compatible: ``AugmentedManifestFile``

                - **S3Uri** *(string) --* **[REQUIRED]**

                  Depending on the value specified for the ``S3DataType`` , identifies either a key
                  name prefix or a manifest. For example:

                  * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

                  * A manifest might look like this: ``s3://bucketname/example.manifest``   The
                  manifest is an S3 object which is a JSON file with the following format:   ``[
                  {"prefix": "s3://customer_bucket/some/prefix/"},``
                  ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``    ``...``
                  ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the following
                  ``s3Uris`` :   ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                  ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                  ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
                  ``S3Uris`` in this manifest constitutes the input data for the channel for this
                  datasource. The object that each ``S3Uris`` points to must be readable by the IAM
                  role that Amazon SageMaker uses to perform tasks on your behalf.

            - **ContentType** *(string) --*

              The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker uses
              the MIME type with each http call to transfer data to the transform job.

            - **CompressionType** *(string) --*

              If your transform data is compressed, specify the compression type. Amazon SageMaker
              automatically decompresses the data for the transform job accordingly. The default
              value is ``None`` .

            - **SplitType** *(string) --*

              The method to use to split the transform job's data files into smaller batches.
              Splitting is necessary when the total size of each object is too large to fit in a
              single request. You can also use data splitting to improve performance by processing
              multiple concurrent mini-batches. The default value for ``SplitType`` is ``None`` ,
              which indicates that input data files are not split, and request payloads contain the
              entire contents of an input object. Set the value of this parameter to ``Line`` to
              split records on a newline character boundary. ``SplitType`` also supports a number of
              record-oriented binary data formats.

              When splitting is enabled, the size of a mini-batch depends on the values of the
              ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
              ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
              records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
              ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records in
              each request.

              .. note::

                Some data formats represent a record as a binary payload wrapped with extra padding
                bytes. When splitting is applied to a binary data format, padding is removed if the
                value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is not removed if the
                value of ``BatchStrategy`` is set to ``MultiRecord`` .

                For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
                <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For more
                information about ``TFRecord`` , see `Consuming TFRecord data
                <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
                TensorFlow documentation.

          - **TransformOutput** *(dict) --* **[REQUIRED]**

            Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
            from the transform job.

            - **S3OutputPath** *(string) --* **[REQUIRED]**

              The Amazon S3 path where you want Amazon SageMaker to store the results of the
              transform job. For example, ``s3://bucket-name/key-name-prefix`` .

              For every S3 object used as input for the transform job, batch transform stores the
              transformed data with an .``out`` suffix in a corresponding subfolder in the location
              in the output prefix. For example, for the input data stored at
              ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores the
              transformed data at
              ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
              transform doesn't upload partially processed objects. For an input S3 object that
              contains multiple records, it creates an .``out`` file only if the transform job
              succeeds on the entire file. When the input contains multiple S3 objects, the batch
              transform job processes the listed S3 objects and uploads only the output for
              successfully processed objects. If any object fails in the transform job batch
              transform marks the job as failed to prompt investigation.

            - **Accept** *(string) --*

              The MIME type used to specify the output data. Amazon SageMaker uses the MIME type with
              each http call to transfer data from the transform job.

            - **AssembleWith** *(string) --*

              Defines how to assemble the results of the transform job as a single S3 object. Choose
              a format that is most convenient to you. To concatenate the results in binary format,
              specify ``None`` . To add a newline character at the end of every transformed record,
              specify ``Line`` .

            - **KmsKeyId** *(string) --*

              The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
              model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be
              any of the following formats:

              * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // Amazon Resource Name (ARN) of a KMS Key
              ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // KMS Key Alias  ``"alias/ExampleAlias"``

              * // Amazon Resource Name (ARN) of a KMS Key Alias
              ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

              If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon
              S3 for your role's account. For more information, see `KMS-Managed Encryption Keys
              <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
              *Amazon Simple Storage Service Developer Guide.*

              The KMS key policy must grant permission to the IAM role that you specify in your
              CreateModel request. For more information, see `Using Key Policies in AWS KMS
              <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the *AWS
              Key Management Service Developer Guide* .

          - **TransformResources** *(dict) --* **[REQUIRED]**

            Identifies the ML compute instances for the transform job.

            - **InstanceType** *(string) --* **[REQUIRED]**

              The ML compute instance type for the transform job. If you are using built-in
              algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge or
              ``ml.m5.large`` instance types.

            - **InstanceCount** *(integer) --* **[REQUIRED]**

              The number of ML compute instances to use in the transform job. For distributed
              transform jobs, specify a value greater than 1. The default value is ``1`` .

            - **VolumeKmsKeyId** *(string) --*

              The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data
              on the storage volume attached to the ML compute instance(s) that run the batch
              transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

              * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // Amazon Resource Name (ARN) of a KMS Key
              ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_RequiredClientCreateCodeRepositoryGitConfigTypeDef = TypedDict(
    "_RequiredClientCreateCodeRepositoryGitConfigTypeDef", {"RepositoryUrl": str}
)
_OptionalClientCreateCodeRepositoryGitConfigTypeDef = TypedDict(
    "_OptionalClientCreateCodeRepositoryGitConfigTypeDef",
    {"Branch": str, "SecretArn": str},
    total=False,
)


class ClientCreateCodeRepositoryGitConfigTypeDef(
    _RequiredClientCreateCodeRepositoryGitConfigTypeDef,
    _OptionalClientCreateCodeRepositoryGitConfigTypeDef,
):
    """
    Type definition for `ClientCreateCodeRepository` `GitConfig`

    Specifies details about the repository, including the URL where the repository is located, the
    default branch, and credentials to use to access the repository.

    - **RepositoryUrl** *(string) --* **[REQUIRED]**

      The URL where the Git repository is located.

    - **Branch** *(string) --*

      The default branch for the Git repository.

    - **SecretArn** *(string) --*

      The Amazon Resource Name (ARN) of the AWS Secrets Manager secret that contains the credentials
      used to access the git repository. The secret must have a staging label of ``AWSCURRENT`` and
      must be in the following format:

       ``{"username": *UserName* , "password": *Password* }``
    """


_ClientCreateCodeRepositoryResponseTypeDef = TypedDict(
    "_ClientCreateCodeRepositoryResponseTypeDef",
    {"CodeRepositoryArn": str},
    total=False,
)


class ClientCreateCodeRepositoryResponseTypeDef(
    _ClientCreateCodeRepositoryResponseTypeDef
):
    """
    Type definition for `ClientCreateCodeRepository` `Response`

    - **CodeRepositoryArn** *(string) --*

      The Amazon Resource Name (ARN) of the new repository.
    """


_ClientCreateCompilationJobInputConfigTypeDef = TypedDict(
    "_ClientCreateCompilationJobInputConfigTypeDef",
    {"S3Uri": str, "DataInputConfig": str, "Framework": str},
)


class ClientCreateCompilationJobInputConfigTypeDef(
    _ClientCreateCompilationJobInputConfigTypeDef
):
    """
    Type definition for `ClientCreateCompilationJob` `InputConfig`

    Provides information about the location of input model artifacts, the name and shape of the
    expected data inputs, and the framework in which the model was trained.

    - **S3Uri** *(string) --* **[REQUIRED]**

      The S3 path where the model artifacts, which result from model training, are stored. This path
      must point to a single gzip compressed tar archive (.tar.gz suffix).

    - **DataInputConfig** *(string) --* **[REQUIRED]**

      Specifies the name and shape of the expected data inputs for your trained model with a JSON
      dictionary form. The data inputs are  InputConfig$Framework specific.

      * ``TensorFlow`` : You must specify the name and shape (NHWC format) of the expected data
      inputs using a dictionary format for your trained model. The dictionary formats required for
      the console and CLI are different.

        * Examples for one input:

          * If using the console, ``{"input":[1,1024,1024,3]}``

          * If using the CLI, ``{\\"input\\":[1,1024,1024,3]}``

        * Examples for two inputs:

          * If using the console, ``{"data1": [1,28,28,1], "data2":[1,28,28,1]}``

          * If using the CLI, ``{\\"data1\\": [1,28,28,1], \\"data2\\":[1,28,28,1]}``

      * ``MXNET/ONNX`` : You must specify the name and shape (NCHW format) of the expected data
      inputs in order using a dictionary format for your trained model. The dictionary formats
      required for the console and CLI are different.

        * Examples for one input:

          * If using the console, ``{"data":[1,3,1024,1024]}``

          * If using the CLI, ``{\\"data\\":[1,3,1024,1024]}``

        * Examples for two inputs:

          * If using the console, ``{"var1": [1,1,28,28], "var2":[1,1,28,28]}``

          * If using the CLI, ``{\\"var1\\": [1,1,28,28], \\"var2\\":[1,1,28,28]}``

      * ``PyTorch`` : You can either specify the name and shape (NCHW format) of expected data inputs
      in order using a dictionary format for your trained model or you can specify the shape only
      using a list format. The dictionary formats required for the console and CLI are different. The
      list formats for the console and CLI are the same.

        * Examples for one input in dictionary format:

          * If using the console, ``{"input0":[1,3,224,224]}``

          * If using the CLI, ``{\\"input0\\":[1,3,224,224]}``

        * Example for one input in list format: ``[[1,3,224,224]]``

        * Examples for two inputs in dictionary format:

          * If using the console, ``{"input0":[1,3,224,224], "input1":[1,3,224,224]}``

          * If using the CLI, ``{\\"input0\\":[1,3,224,224], \\"input1\\":[1,3,224,224]}``

        * Example for two inputs in list format: ``[[1,3,224,224], [1,3,224,224]]``

      * ``XGBOOST`` : input data name and shape are not needed.

    - **Framework** *(string) --* **[REQUIRED]**

      Identifies the framework in which the model was trained. For example: TENSORFLOW.
    """


_ClientCreateCompilationJobOutputConfigTypeDef = TypedDict(
    "_ClientCreateCompilationJobOutputConfigTypeDef",
    {"S3OutputLocation": str, "TargetDevice": str},
)


class ClientCreateCompilationJobOutputConfigTypeDef(
    _ClientCreateCompilationJobOutputConfigTypeDef
):
    """
    Type definition for `ClientCreateCompilationJob` `OutputConfig`

    Provides information about the output location for the compiled model and the target device the
    model runs on.

    - **S3OutputLocation** *(string) --* **[REQUIRED]**

      Identifies the S3 path where you want Amazon SageMaker to store the model artifacts. For
      example, s3://bucket-name/key-name-prefix.

    - **TargetDevice** *(string) --* **[REQUIRED]**

      Identifies the device that you want to run your model on after it has been compiled. For
      example: ml_c5.
    """


_ClientCreateCompilationJobResponseTypeDef = TypedDict(
    "_ClientCreateCompilationJobResponseTypeDef",
    {"CompilationJobArn": str},
    total=False,
)


class ClientCreateCompilationJobResponseTypeDef(
    _ClientCreateCompilationJobResponseTypeDef
):
    """
    Type definition for `ClientCreateCompilationJob` `Response`

    - **CompilationJobArn** *(string) --*

      If the action is successful, the service sends back an HTTP 200 response. Amazon SageMaker
      returns the following data in JSON format:

      * ``CompilationJobArn`` : The Amazon Resource Name (ARN) of the compiled job.
    """


_ClientCreateCompilationJobStoppingConditionTypeDef = TypedDict(
    "_ClientCreateCompilationJobStoppingConditionTypeDef",
    {"MaxRuntimeInSeconds": int, "MaxWaitTimeInSeconds": int},
    total=False,
)


class ClientCreateCompilationJobStoppingConditionTypeDef(
    _ClientCreateCompilationJobStoppingConditionTypeDef
):
    """
    Type definition for `ClientCreateCompilationJob` `StoppingCondition`

    Specifies a limit to how long a model compilation job can run. When the job reaches the time
    limit, Amazon SageMaker ends the compilation job. Use this API to cap model training costs.

    - **MaxRuntimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, that the training or compilation job can run. If job
      does not complete during this time, Amazon SageMaker ends the job. If value is not specified,
      default value is 1 day. The maximum value is 28 days.

    - **MaxWaitTimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, how long you are willing to wait for a managed spot
      training job to complete. It is the amount of time spent waiting for Spot capacity plus the
      amount of time the training job runs. It must be equal to or greater than
      ``MaxRuntimeInSeconds`` .
    """


_RequiredClientCreateEndpointConfigProductionVariantsTypeDef = TypedDict(
    "_RequiredClientCreateEndpointConfigProductionVariantsTypeDef",
    {
        "VariantName": str,
        "ModelName": str,
        "InitialInstanceCount": int,
        "InstanceType": str,
    },
)
_OptionalClientCreateEndpointConfigProductionVariantsTypeDef = TypedDict(
    "_OptionalClientCreateEndpointConfigProductionVariantsTypeDef",
    {"InitialVariantWeight": float, "AcceleratorType": str},
    total=False,
)


class ClientCreateEndpointConfigProductionVariantsTypeDef(
    _RequiredClientCreateEndpointConfigProductionVariantsTypeDef,
    _OptionalClientCreateEndpointConfigProductionVariantsTypeDef,
):
    """
    Type definition for `ClientCreateEndpointConfig` `ProductionVariants`

    Identifies a model that you want to host and the resources to deploy for hosting it. If you are
    deploying multiple models, tell Amazon SageMaker how to distribute traffic among the models by
    specifying variant weights.

    - **VariantName** *(string) --* **[REQUIRED]**

      The name of the production variant.

    - **ModelName** *(string) --* **[REQUIRED]**

      The name of the model that you want to host. This is the name that you specified when
      creating the model.

    - **InitialInstanceCount** *(integer) --* **[REQUIRED]**

      Number of instances to launch initially.

    - **InstanceType** *(string) --* **[REQUIRED]**

      The ML compute instance type.

    - **InitialVariantWeight** *(float) --*

      Determines initial traffic distribution among all of the models that you specify in the
      endpoint configuration. The traffic to a production variant is determined by the ratio of the
      ``VariantWeight`` to the sum of all ``VariantWeight`` values across all ProductionVariants.
      If unspecified, it defaults to 1.0.

    - **AcceleratorType** *(string) --*

      The size of the Elastic Inference (EI) instance to use for the production variant. EI
      instances provide on-demand GPU computing for inference. For more information, see `Using
      Elastic Inference in Amazon SageMaker
      <https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html>`__ .
    """


_ClientCreateEndpointConfigResponseTypeDef = TypedDict(
    "_ClientCreateEndpointConfigResponseTypeDef",
    {"EndpointConfigArn": str},
    total=False,
)


class ClientCreateEndpointConfigResponseTypeDef(
    _ClientCreateEndpointConfigResponseTypeDef
):
    """
    Type definition for `ClientCreateEndpointConfig` `Response`

    - **EndpointConfigArn** *(string) --*

      The Amazon Resource Name (ARN) of the endpoint configuration.
    """


_ClientCreateEndpointConfigTagsTypeDef = TypedDict(
    "_ClientCreateEndpointConfigTagsTypeDef", {"Key": str, "Value": str}
)


class ClientCreateEndpointConfigTagsTypeDef(_ClientCreateEndpointConfigTagsTypeDef):
    """
    Type definition for `ClientCreateEndpointConfig` `Tags`

    Describes a tag.

    - **Key** *(string) --* **[REQUIRED]**

      The tag key.

    - **Value** *(string) --* **[REQUIRED]**

      The tag value.
    """


_ClientCreateEndpointResponseTypeDef = TypedDict(
    "_ClientCreateEndpointResponseTypeDef", {"EndpointArn": str}, total=False
)


class ClientCreateEndpointResponseTypeDef(_ClientCreateEndpointResponseTypeDef):
    """
    Type definition for `ClientCreateEndpoint` `Response`

    - **EndpointArn** *(string) --*

      The Amazon Resource Name (ARN) of the endpoint.
    """


_ClientCreateEndpointTagsTypeDef = TypedDict(
    "_ClientCreateEndpointTagsTypeDef", {"Key": str, "Value": str}
)


class ClientCreateEndpointTagsTypeDef(_ClientCreateEndpointTagsTypeDef):
    """
    Type definition for `ClientCreateEndpoint` `Tags`

    Describes a tag.

    - **Key** *(string) --* **[REQUIRED]**

      The tag key.

    - **Value** *(string) --* **[REQUIRED]**

      The tag value.
    """


_ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigHyperParameterTuningJobObjectiveTypeDef = TypedDict(
    "_ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigHyperParameterTuningJobObjectiveTypeDef",
    {"Type": str, "MetricName": str},
)


class ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigHyperParameterTuningJobObjectiveTypeDef(
    _ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigHyperParameterTuningJobObjectiveTypeDef
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfig` `HyperParameterTuningJobObjective`

    The  HyperParameterTuningJobObjective object that specifies the objective metric for this
    tuning job.

    - **Type** *(string) --* **[REQUIRED]**

      Whether to minimize or maximize the objective metric.

    - **MetricName** *(string) --* **[REQUIRED]**

      The name of the metric to use for the objective metric.
    """


_ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesCategoricalParameterRangesTypeDef = TypedDict(
    "_ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesCategoricalParameterRangesTypeDef",
    {"Name": str, "Values": List[str]},
)


class ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesCategoricalParameterRangesTypeDef(
    _ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesCategoricalParameterRangesTypeDef
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRanges` `CategoricalParameterRanges`

    A list of categorical hyperparameters to tune.

    - **Name** *(string) --* **[REQUIRED]**

      The name of the categorical hyperparameter to tune.

    - **Values** *(list) --* **[REQUIRED]**

      A list of the categories for the hyperparameter.

      - *(string) --*
    """


_RequiredClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesContinuousParameterRangesTypeDef = TypedDict(
    "_RequiredClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesContinuousParameterRangesTypeDef",
    {"Name": str, "MinValue": str, "MaxValue": str},
)
_OptionalClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesContinuousParameterRangesTypeDef = TypedDict(
    "_OptionalClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesContinuousParameterRangesTypeDef",
    {"ScalingType": str},
    total=False,
)


class ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesContinuousParameterRangesTypeDef(
    _RequiredClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesContinuousParameterRangesTypeDef,
    _OptionalClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesContinuousParameterRangesTypeDef,
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRanges` `ContinuousParameterRanges`

    A list of continuous hyperparameters to tune.

    - **Name** *(string) --* **[REQUIRED]**

      The name of the continuous hyperparameter to tune.

    - **MinValue** *(string) --* **[REQUIRED]**

      The minimum value for the hyperparameter. The tuning job uses floating-point values
      between this value and ``MaxValue`` for tuning.

    - **MaxValue** *(string) --* **[REQUIRED]**

      The maximum value for the hyperparameter. The tuning job uses floating-point values
      between ``MinValue`` value and this value for tuning.

    - **ScalingType** *(string) --*

      The scale that hyperparameter tuning uses to search the hyperparameter range. For
      information about choosing a hyperparameter scale, see `Hyperparameter Scaling
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html#scaling-type>`__
      . One of the following values:

        Auto

      Amazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.

        Linear

      Hyperparameter tuning searches the values in the hyperparameter range by using a linear
      scale.

        Logarithmic

      Hyperparameter tuning searches the values in the hyperparameter range by using a
      logarithmic scale.

      Logarithmic scaling works only for ranges that have only values greater than 0.

        ReverseLogarithmic

      Hyperparameter tuning searches the values in the hyperparameter range by using a reverse
      logarithmic scale.

      Reverse logarithmic scaling works only for ranges that are entirely within the range
      0<=x<1.0.
    """


_RequiredClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesIntegerParameterRangesTypeDef = TypedDict(
    "_RequiredClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesIntegerParameterRangesTypeDef",
    {"Name": str, "MinValue": str, "MaxValue": str},
)
_OptionalClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesIntegerParameterRangesTypeDef = TypedDict(
    "_OptionalClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesIntegerParameterRangesTypeDef",
    {"ScalingType": str},
    total=False,
)


class ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesIntegerParameterRangesTypeDef(
    _RequiredClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesIntegerParameterRangesTypeDef,
    _OptionalClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesIntegerParameterRangesTypeDef,
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRanges` `IntegerParameterRanges`

    For a hyperparameter of the integer type, specifies the range that a hyperparameter tuning
    job searches.

    - **Name** *(string) --* **[REQUIRED]**

      The name of the hyperparameter to search.

    - **MinValue** *(string) --* **[REQUIRED]**

      The minimum value of the hyperparameter to search.

    - **MaxValue** *(string) --* **[REQUIRED]**

      The maximum value of the hyperparameter to search.

    - **ScalingType** *(string) --*

      The scale that hyperparameter tuning uses to search the hyperparameter range. For
      information about choosing a hyperparameter scale, see `Hyperparameter Scaling
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html#scaling-type>`__
      . One of the following values:

        Auto

      Amazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.

        Linear

      Hyperparameter tuning searches the values in the hyperparameter range by using a linear
      scale.

        Logarithmic

      Hyperparameter tuning searches the values in the hyperparameter range by using a
      logarithmic scale.

      Logarithmic scaling works only for ranges that have only values greater than 0.
    """


_ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesTypeDef = TypedDict(
    "_ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesTypeDef",
    {
        "IntegerParameterRanges": List[
            ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesIntegerParameterRangesTypeDef
        ],
        "ContinuousParameterRanges": List[
            ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesContinuousParameterRangesTypeDef
        ],
        "CategoricalParameterRanges": List[
            ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesCategoricalParameterRangesTypeDef
        ],
    },
    total=False,
)


class ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesTypeDef(
    _ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesTypeDef
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfig` `ParameterRanges`

    The  ParameterRanges object that specifies the ranges of hyperparameters that this tuning job
    searches.

    - **IntegerParameterRanges** *(list) --*

      The array of  IntegerParameterRange objects that specify ranges of integer hyperparameters
      that a hyperparameter tuning job searches.

      - *(dict) --*

        For a hyperparameter of the integer type, specifies the range that a hyperparameter tuning
        job searches.

        - **Name** *(string) --* **[REQUIRED]**

          The name of the hyperparameter to search.

        - **MinValue** *(string) --* **[REQUIRED]**

          The minimum value of the hyperparameter to search.

        - **MaxValue** *(string) --* **[REQUIRED]**

          The maximum value of the hyperparameter to search.

        - **ScalingType** *(string) --*

          The scale that hyperparameter tuning uses to search the hyperparameter range. For
          information about choosing a hyperparameter scale, see `Hyperparameter Scaling
          <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html#scaling-type>`__
          . One of the following values:

            Auto

          Amazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.

            Linear

          Hyperparameter tuning searches the values in the hyperparameter range by using a linear
          scale.

            Logarithmic

          Hyperparameter tuning searches the values in the hyperparameter range by using a
          logarithmic scale.

          Logarithmic scaling works only for ranges that have only values greater than 0.

    - **ContinuousParameterRanges** *(list) --*

      The array of  ContinuousParameterRange objects that specify ranges of continuous
      hyperparameters that a hyperparameter tuning job searches.

      - *(dict) --*

        A list of continuous hyperparameters to tune.

        - **Name** *(string) --* **[REQUIRED]**

          The name of the continuous hyperparameter to tune.

        - **MinValue** *(string) --* **[REQUIRED]**

          The minimum value for the hyperparameter. The tuning job uses floating-point values
          between this value and ``MaxValue`` for tuning.

        - **MaxValue** *(string) --* **[REQUIRED]**

          The maximum value for the hyperparameter. The tuning job uses floating-point values
          between ``MinValue`` value and this value for tuning.

        - **ScalingType** *(string) --*

          The scale that hyperparameter tuning uses to search the hyperparameter range. For
          information about choosing a hyperparameter scale, see `Hyperparameter Scaling
          <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html#scaling-type>`__
          . One of the following values:

            Auto

          Amazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.

            Linear

          Hyperparameter tuning searches the values in the hyperparameter range by using a linear
          scale.

            Logarithmic

          Hyperparameter tuning searches the values in the hyperparameter range by using a
          logarithmic scale.

          Logarithmic scaling works only for ranges that have only values greater than 0.

            ReverseLogarithmic

          Hyperparameter tuning searches the values in the hyperparameter range by using a reverse
          logarithmic scale.

          Reverse logarithmic scaling works only for ranges that are entirely within the range
          0<=x<1.0.

    - **CategoricalParameterRanges** *(list) --*

      The array of  CategoricalParameterRange objects that specify ranges of categorical
      hyperparameters that a hyperparameter tuning job searches.

      - *(dict) --*

        A list of categorical hyperparameters to tune.

        - **Name** *(string) --* **[REQUIRED]**

          The name of the categorical hyperparameter to tune.

        - **Values** *(list) --* **[REQUIRED]**

          A list of the categories for the hyperparameter.

          - *(string) --*
    """


_ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigResourceLimitsTypeDef = TypedDict(
    "_ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigResourceLimitsTypeDef",
    {"MaxNumberOfTrainingJobs": int, "MaxParallelTrainingJobs": int},
)


class ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigResourceLimitsTypeDef(
    _ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigResourceLimitsTypeDef
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfig` `ResourceLimits`

    The  ResourceLimits object that specifies the maximum number of training jobs and parallel
    training jobs for this tuning job.

    - **MaxNumberOfTrainingJobs** *(integer) --* **[REQUIRED]**

      The maximum number of training jobs that a hyperparameter tuning job can launch.

    - **MaxParallelTrainingJobs** *(integer) --* **[REQUIRED]**

      The maximum number of concurrent training jobs that a hyperparameter tuning job can launch.
    """


_RequiredClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigTypeDef = TypedDict(
    "_RequiredClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigTypeDef",
    {
        "Strategy": str,
        "ResourceLimits": ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigResourceLimitsTypeDef,
    },
)
_OptionalClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigTypeDef = TypedDict(
    "_OptionalClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigTypeDef",
    {
        "HyperParameterTuningJobObjective": ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigHyperParameterTuningJobObjectiveTypeDef,
        "ParameterRanges": ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigParameterRangesTypeDef,
        "TrainingJobEarlyStoppingType": str,
    },
    total=False,
)


class ClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigTypeDef(
    _RequiredClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigTypeDef,
    _OptionalClientCreateHyperParameterTuningJobHyperParameterTuningJobConfigTypeDef,
):
    """
    Type definition for `ClientCreateHyperParameterTuningJob` `HyperParameterTuningJobConfig`

    The  HyperParameterTuningJobConfig object that describes the tuning job, including the search
    strategy, the objective metric used to evaluate training jobs, ranges of parameters to search,
    and resource limits for the tuning job. For more information, see  automatic-model-tuning

    - **Strategy** *(string) --* **[REQUIRED]**

      Specifies how hyperparameter tuning chooses the combinations of hyperparameter values to use
      for the training job it launches. To use the Bayesian search stategy, set this to ``Bayesian``
      . To randomly search, set it to ``Random`` . For information about search strategies, see `How
      Hyperparameter Tuning Works
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html>`__ .

    - **HyperParameterTuningJobObjective** *(dict) --*

      The  HyperParameterTuningJobObjective object that specifies the objective metric for this
      tuning job.

      - **Type** *(string) --* **[REQUIRED]**

        Whether to minimize or maximize the objective metric.

      - **MetricName** *(string) --* **[REQUIRED]**

        The name of the metric to use for the objective metric.

    - **ResourceLimits** *(dict) --* **[REQUIRED]**

      The  ResourceLimits object that specifies the maximum number of training jobs and parallel
      training jobs for this tuning job.

      - **MaxNumberOfTrainingJobs** *(integer) --* **[REQUIRED]**

        The maximum number of training jobs that a hyperparameter tuning job can launch.

      - **MaxParallelTrainingJobs** *(integer) --* **[REQUIRED]**

        The maximum number of concurrent training jobs that a hyperparameter tuning job can launch.

    - **ParameterRanges** *(dict) --*

      The  ParameterRanges object that specifies the ranges of hyperparameters that this tuning job
      searches.

      - **IntegerParameterRanges** *(list) --*

        The array of  IntegerParameterRange objects that specify ranges of integer hyperparameters
        that a hyperparameter tuning job searches.

        - *(dict) --*

          For a hyperparameter of the integer type, specifies the range that a hyperparameter tuning
          job searches.

          - **Name** *(string) --* **[REQUIRED]**

            The name of the hyperparameter to search.

          - **MinValue** *(string) --* **[REQUIRED]**

            The minimum value of the hyperparameter to search.

          - **MaxValue** *(string) --* **[REQUIRED]**

            The maximum value of the hyperparameter to search.

          - **ScalingType** *(string) --*

            The scale that hyperparameter tuning uses to search the hyperparameter range. For
            information about choosing a hyperparameter scale, see `Hyperparameter Scaling
            <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html#scaling-type>`__
            . One of the following values:

              Auto

            Amazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.

              Linear

            Hyperparameter tuning searches the values in the hyperparameter range by using a linear
            scale.

              Logarithmic

            Hyperparameter tuning searches the values in the hyperparameter range by using a
            logarithmic scale.

            Logarithmic scaling works only for ranges that have only values greater than 0.

      - **ContinuousParameterRanges** *(list) --*

        The array of  ContinuousParameterRange objects that specify ranges of continuous
        hyperparameters that a hyperparameter tuning job searches.

        - *(dict) --*

          A list of continuous hyperparameters to tune.

          - **Name** *(string) --* **[REQUIRED]**

            The name of the continuous hyperparameter to tune.

          - **MinValue** *(string) --* **[REQUIRED]**

            The minimum value for the hyperparameter. The tuning job uses floating-point values
            between this value and ``MaxValue`` for tuning.

          - **MaxValue** *(string) --* **[REQUIRED]**

            The maximum value for the hyperparameter. The tuning job uses floating-point values
            between ``MinValue`` value and this value for tuning.

          - **ScalingType** *(string) --*

            The scale that hyperparameter tuning uses to search the hyperparameter range. For
            information about choosing a hyperparameter scale, see `Hyperparameter Scaling
            <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html#scaling-type>`__
            . One of the following values:

              Auto

            Amazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.

              Linear

            Hyperparameter tuning searches the values in the hyperparameter range by using a linear
            scale.

              Logarithmic

            Hyperparameter tuning searches the values in the hyperparameter range by using a
            logarithmic scale.

            Logarithmic scaling works only for ranges that have only values greater than 0.

              ReverseLogarithmic

            Hyperparameter tuning searches the values in the hyperparameter range by using a reverse
            logarithmic scale.

            Reverse logarithmic scaling works only for ranges that are entirely within the range
            0<=x<1.0.

      - **CategoricalParameterRanges** *(list) --*

        The array of  CategoricalParameterRange objects that specify ranges of categorical
        hyperparameters that a hyperparameter tuning job searches.

        - *(dict) --*

          A list of categorical hyperparameters to tune.

          - **Name** *(string) --* **[REQUIRED]**

            The name of the categorical hyperparameter to tune.

          - **Values** *(list) --* **[REQUIRED]**

            A list of the categories for the hyperparameter.

            - *(string) --*

    - **TrainingJobEarlyStoppingType** *(string) --*

      Specifies whether to use early stopping for training jobs launched by the hyperparameter tuning
      job. This can be one of the following values (the default value is ``OFF`` ):

        OFF

      Training jobs launched by the hyperparameter tuning job do not use early stopping.

        AUTO

      Amazon SageMaker stops training jobs launched by the hyperparameter tuning job when they are
      unlikely to perform better than previously completed training jobs. For more information, see
      `Stop Training Jobs Early
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-early-stopping.html>`__
      .
    """


_ClientCreateHyperParameterTuningJobResponseTypeDef = TypedDict(
    "_ClientCreateHyperParameterTuningJobResponseTypeDef",
    {"HyperParameterTuningJobArn": str},
    total=False,
)


class ClientCreateHyperParameterTuningJobResponseTypeDef(
    _ClientCreateHyperParameterTuningJobResponseTypeDef
):
    """
    Type definition for `ClientCreateHyperParameterTuningJob` `Response`

    - **HyperParameterTuningJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the tuning job. Amazon SageMaker assigns an ARN to a
      hyperparameter tuning job when you create it.
    """


_ClientCreateHyperParameterTuningJobTagsTypeDef = TypedDict(
    "_ClientCreateHyperParameterTuningJobTagsTypeDef", {"Key": str, "Value": str}
)


class ClientCreateHyperParameterTuningJobTagsTypeDef(
    _ClientCreateHyperParameterTuningJobTagsTypeDef
):
    """
    Type definition for `ClientCreateHyperParameterTuningJob` `Tags`

    Describes a tag.

    - **Key** *(string) --* **[REQUIRED]**

      The tag key.

    - **Value** *(string) --* **[REQUIRED]**

      The tag value.
    """


_ClientCreateHyperParameterTuningJobTrainingJobDefinitionAlgorithmSpecificationMetricDefinitionsTypeDef = TypedDict(
    "_ClientCreateHyperParameterTuningJobTrainingJobDefinitionAlgorithmSpecificationMetricDefinitionsTypeDef",
    {"Name": str, "Regex": str},
)


class ClientCreateHyperParameterTuningJobTrainingJobDefinitionAlgorithmSpecificationMetricDefinitionsTypeDef(
    _ClientCreateHyperParameterTuningJobTrainingJobDefinitionAlgorithmSpecificationMetricDefinitionsTypeDef
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobTrainingJobDefinitionAlgorithmSpecification` `MetricDefinitions`

    Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` . Amazon
    SageMakerhyperparameter tuning captures all defined metrics. You specify one metric that a
    hyperparameter tuning job uses as its objective metric to choose the best training job.

    - **Name** *(string) --* **[REQUIRED]**

      The name of the metric.

    - **Regex** *(string) --* **[REQUIRED]**

      A regular expression that searches the output of a training job and gets the value of the
      metric. For more information about using regular expressions to define metrics, see
      `Defining Objective Metrics
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
      .
    """


_RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionAlgorithmSpecificationTypeDef = TypedDict(
    "_RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionAlgorithmSpecificationTypeDef",
    {"TrainingInputMode": str},
)
_OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionAlgorithmSpecificationTypeDef = TypedDict(
    "_OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionAlgorithmSpecificationTypeDef",
    {
        "TrainingImage": str,
        "AlgorithmName": str,
        "MetricDefinitions": List[
            ClientCreateHyperParameterTuningJobTrainingJobDefinitionAlgorithmSpecificationMetricDefinitionsTypeDef
        ],
    },
    total=False,
)


class ClientCreateHyperParameterTuningJobTrainingJobDefinitionAlgorithmSpecificationTypeDef(
    _RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionAlgorithmSpecificationTypeDef,
    _OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionAlgorithmSpecificationTypeDef,
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobTrainingJobDefinition` `AlgorithmSpecification`

    The  HyperParameterAlgorithmSpecification object that specifies the resource algorithm to use
    for the training jobs that the tuning job launches.

    - **TrainingImage** *(string) --*

      The registry path of the Docker image that contains the training algorithm. For information
      about Docker registry paths for built-in algorithms, see `Algorithms Provided by Amazon
      SageMaker\\: Common Parameters
      <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
      . Amazon SageMaker supports both ``registry/repository[:tag]`` and
      ``registry/repository[@digest]`` image path formats. For more information, see `Using Your
      Own Algorithms with Amazon SageMaker
      <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

    - **TrainingInputMode** *(string) --* **[REQUIRED]**

      The input mode that the algorithm supports: File or Pipe. In File input mode, Amazon
      SageMaker downloads the training data from Amazon S3 to the storage volume that is attached
      to the training instance and mounts the directory to the Docker volume for the training
      container. In Pipe input mode, Amazon SageMaker streams data directly from Amazon S3 to the
      container.

      If you specify File mode, make sure that you provision the storage volume that is attached to
      the training instance with enough capacity to accommodate the training data downloaded from
      Amazon S3, the model artifacts, and intermediate information.

      For more information about input modes, see `Algorithms
      <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ .

    - **AlgorithmName** *(string) --*

      The name of the resource algorithm to use for the hyperparameter tuning job. If you specify a
      value for this parameter, do not specify a value for ``TrainingImage`` .

    - **MetricDefinitions** *(list) --*

      An array of  MetricDefinition objects that specify the metrics that the algorithm emits.

      - *(dict) --*

        Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` . Amazon
        SageMakerhyperparameter tuning captures all defined metrics. You specify one metric that a
        hyperparameter tuning job uses as its objective metric to choose the best training job.

        - **Name** *(string) --* **[REQUIRED]**

          The name of the metric.

        - **Regex** *(string) --* **[REQUIRED]**

          A regular expression that searches the output of a training job and gets the value of the
          metric. For more information about using regular expressions to define metrics, see
          `Defining Objective Metrics
          <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
          .
    """


_RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionCheckpointConfigTypeDef = TypedDict(
    "_RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionCheckpointConfigTypeDef",
    {"S3Uri": str},
)
_OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionCheckpointConfigTypeDef = TypedDict(
    "_OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionCheckpointConfigTypeDef",
    {"LocalPath": str},
    total=False,
)


class ClientCreateHyperParameterTuningJobTrainingJobDefinitionCheckpointConfigTypeDef(
    _RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionCheckpointConfigTypeDef,
    _OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionCheckpointConfigTypeDef,
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobTrainingJobDefinition` `CheckpointConfig`

    Contains information about the output location for managed spot training checkpoint data.

    - **S3Uri** *(string) --* **[REQUIRED]**

      Identifies the S3 path where you want Amazon SageMaker to store checkpoints. For example,
      ``s3://bucket-name/key-name-prefix`` .

    - **LocalPath** *(string) --*

      (Optional) The local directory where checkpoints are written. The default directory is
      ``/opt/ml/checkpoints/`` .
    """


_ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef = TypedDict(
    "_ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef",
    {
        "FileSystemId": str,
        "FileSystemAccessMode": str,
        "FileSystemType": str,
        "DirectoryPath": str,
    },
)


class ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef(
    _ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSource` `FileSystemDataSource`

    The file system that is associated with a channel.

    - **FileSystemId** *(string) --* **[REQUIRED]**

      The file system id.

    - **FileSystemAccessMode** *(string) --* **[REQUIRED]**

      The access mode of the mount of the directory associated with the channel. A directory
      can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

    - **FileSystemType** *(string) --* **[REQUIRED]**

      The file system type.

    - **DirectoryPath** *(string) --* **[REQUIRED]**

      The full path to the directory to associate with the channel.
    """


_RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef = TypedDict(
    "_RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef",
    {"S3DataType": str, "S3Uri": str},
)
_OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef = TypedDict(
    "_OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef",
    {"S3DataDistributionType": str, "AttributeNames": List[str]},
    total=False,
)


class ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef(
    _RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef,
    _OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef,
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSource` `S3DataSource`

    The S3 location of the data source that is associated with a channel.

    - **S3DataType** *(string) --* **[REQUIRED]**

      If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker
      uses all objects that match the specified key name prefix for model training.

      If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest file
      containing a list of object keys that you want Amazon SageMaker to use for model
      training.

      If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
      augmented manifest file in JSON lines format. This file contains the data you want to
      use for model training. ``AugmentedManifestFile`` can only be used if the Channel's
      input mode is ``Pipe`` .

    - **S3Uri** *(string) --* **[REQUIRED]**

      Depending on the value specified for the ``S3DataType`` , identifies either a key name
      prefix or a manifest. For example:

      * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

      * A manifest might look like this: ``s3://bucketname/example.manifest``   The manifest
      is an S3 object which is a JSON file with the following format:  The preceding JSON
      matches the following ``s3Uris`` :   ``[ {"prefix":
      "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
      ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``    ``]``
      The preceding JSON matches the following ``s3Uris`` :
      ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
      ``s3uris`` in this manifest is the input data for the channel for this datasource. The
      object that each ``s3uris`` points to must be readable by the IAM role that Amazon
      SageMaker uses to perform tasks on your behalf.

    - **S3DataDistributionType** *(string) --*

      If you want Amazon SageMaker to replicate the entire dataset on each ML compute
      instance that is launched for model training, specify ``FullyReplicated`` .

      If you want Amazon SageMaker to replicate a subset of data on each ML compute instance
      that is launched for model training, specify ``ShardedByS3Key`` . If there are *n* ML
      compute instances launched for a training job, each instance gets approximately 1/*n*
      of the number of S3 objects. In this case, model training on each machine uses only the
      subset of training data.

      Don't choose more ML compute instances for training than available S3 objects. If you
      do, some nodes won't get any data and you will pay for nodes that aren't getting any
      training data. This applies in both File and Pipe modes. Keep this in mind when
      developing algorithms.

      In distributed training, where you use multiple ML compute EC2 instances, you might
      choose ``ShardedByS3Key`` . If the algorithm requires copying training data to the ML
      storage volume (when ``TrainingInputMode`` is set to ``File`` ), this copies 1/*n* of
      the number of objects.

    - **AttributeNames** *(list) --*

      A list of one or more attribute names to use that are found in a specified augmented
      manifest file.

      - *(string) --*
    """


_ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceTypeDef = TypedDict(
    "_ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceTypeDef",
    {
        "S3DataSource": ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef,
        "FileSystemDataSource": ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef,
    },
    total=False,
)


class ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceTypeDef(
    _ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceTypeDef
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfig` `DataSource`

    The location of the channel data.

    - **S3DataSource** *(dict) --*

      The S3 location of the data source that is associated with a channel.

      - **S3DataType** *(string) --* **[REQUIRED]**

        If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker
        uses all objects that match the specified key name prefix for model training.

        If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest file
        containing a list of object keys that you want Amazon SageMaker to use for model
        training.

        If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
        augmented manifest file in JSON lines format. This file contains the data you want to
        use for model training. ``AugmentedManifestFile`` can only be used if the Channel's
        input mode is ``Pipe`` .

      - **S3Uri** *(string) --* **[REQUIRED]**

        Depending on the value specified for the ``S3DataType`` , identifies either a key name
        prefix or a manifest. For example:

        * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

        * A manifest might look like this: ``s3://bucketname/example.manifest``   The manifest
        is an S3 object which is a JSON file with the following format:  The preceding JSON
        matches the following ``s3Uris`` :   ``[ {"prefix":
        "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
        ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``    ``]``
        The preceding JSON matches the following ``s3Uris`` :
        ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
        ``s3uris`` in this manifest is the input data for the channel for this datasource. The
        object that each ``s3uris`` points to must be readable by the IAM role that Amazon
        SageMaker uses to perform tasks on your behalf.

      - **S3DataDistributionType** *(string) --*

        If you want Amazon SageMaker to replicate the entire dataset on each ML compute
        instance that is launched for model training, specify ``FullyReplicated`` .

        If you want Amazon SageMaker to replicate a subset of data on each ML compute instance
        that is launched for model training, specify ``ShardedByS3Key`` . If there are *n* ML
        compute instances launched for a training job, each instance gets approximately 1/*n*
        of the number of S3 objects. In this case, model training on each machine uses only the
        subset of training data.

        Don't choose more ML compute instances for training than available S3 objects. If you
        do, some nodes won't get any data and you will pay for nodes that aren't getting any
        training data. This applies in both File and Pipe modes. Keep this in mind when
        developing algorithms.

        In distributed training, where you use multiple ML compute EC2 instances, you might
        choose ``ShardedByS3Key`` . If the algorithm requires copying training data to the ML
        storage volume (when ``TrainingInputMode`` is set to ``File`` ), this copies 1/*n* of
        the number of objects.

      - **AttributeNames** *(list) --*

        A list of one or more attribute names to use that are found in a specified augmented
        manifest file.

        - *(string) --*

    - **FileSystemDataSource** *(dict) --*

      The file system that is associated with a channel.

      - **FileSystemId** *(string) --* **[REQUIRED]**

        The file system id.

      - **FileSystemAccessMode** *(string) --* **[REQUIRED]**

        The access mode of the mount of the directory associated with the channel. A directory
        can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

      - **FileSystemType** *(string) --* **[REQUIRED]**

        The file system type.

      - **DirectoryPath** *(string) --* **[REQUIRED]**

        The full path to the directory to associate with the channel.
    """


_ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef = TypedDict(
    "_ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef",
    {"Seed": int},
)


class ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef(
    _ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfig` `ShuffleConfig`

    A configuration for a shuffle option for input data in a channel. If you use ``S3Prefix``
    for ``S3DataType`` , this shuffles the results of the S3 key prefix matches. If you use
    ``ManifestFile`` , the order of the S3 object references in the ``ManifestFile`` is
    shuffled. If you use ``AugmentedManifestFile`` , the order of the JSON lines in the
    ``AugmentedManifestFile`` is shuffled. The shuffling order is determined using the ``Seed``
    value.

    For Pipe input mode, shuffling is done at the start of every epoch. With large datasets
    this ensures that the order of the training data is different for each epoch, it helps
    reduce bias and possible overfitting. In a multi-node training job when ShuffleConfig is
    combined with ``S3DataDistributionType`` of ``ShardedByS3Key`` , the data is shuffled
    across nodes so that the content sent to a particular node on the first epoch might be sent
    to a different node on the second epoch.

    - **Seed** *(integer) --* **[REQUIRED]**

      Determines the shuffling order in ``ShuffleConfig`` value.
    """


_RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigTypeDef = TypedDict(
    "_RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigTypeDef",
    {
        "ChannelName": str,
        "DataSource": ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigDataSourceTypeDef,
    },
)
_OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigTypeDef = TypedDict(
    "_OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigTypeDef",
    {
        "ContentType": str,
        "CompressionType": str,
        "RecordWrapperType": str,
        "InputMode": str,
        "ShuffleConfig": ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef,
    },
    total=False,
)


class ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigTypeDef(
    _RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigTypeDef,
    _OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigTypeDef,
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobTrainingJobDefinition` `InputDataConfig`

    A channel is a named input source that training algorithms can consume.

    - **ChannelName** *(string) --* **[REQUIRED]**

      The name of the channel.

    - **DataSource** *(dict) --* **[REQUIRED]**

      The location of the channel data.

      - **S3DataSource** *(dict) --*

        The S3 location of the data source that is associated with a channel.

        - **S3DataType** *(string) --* **[REQUIRED]**

          If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker
          uses all objects that match the specified key name prefix for model training.

          If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest file
          containing a list of object keys that you want Amazon SageMaker to use for model
          training.

          If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
          augmented manifest file in JSON lines format. This file contains the data you want to
          use for model training. ``AugmentedManifestFile`` can only be used if the Channel's
          input mode is ``Pipe`` .

        - **S3Uri** *(string) --* **[REQUIRED]**

          Depending on the value specified for the ``S3DataType`` , identifies either a key name
          prefix or a manifest. For example:

          * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

          * A manifest might look like this: ``s3://bucketname/example.manifest``   The manifest
          is an S3 object which is a JSON file with the following format:  The preceding JSON
          matches the following ``s3Uris`` :   ``[ {"prefix":
          "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
          ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``    ``]``
          The preceding JSON matches the following ``s3Uris`` :
          ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
          ``s3uris`` in this manifest is the input data for the channel for this datasource. The
          object that each ``s3uris`` points to must be readable by the IAM role that Amazon
          SageMaker uses to perform tasks on your behalf.

        - **S3DataDistributionType** *(string) --*

          If you want Amazon SageMaker to replicate the entire dataset on each ML compute
          instance that is launched for model training, specify ``FullyReplicated`` .

          If you want Amazon SageMaker to replicate a subset of data on each ML compute instance
          that is launched for model training, specify ``ShardedByS3Key`` . If there are *n* ML
          compute instances launched for a training job, each instance gets approximately 1/*n*
          of the number of S3 objects. In this case, model training on each machine uses only the
          subset of training data.

          Don't choose more ML compute instances for training than available S3 objects. If you
          do, some nodes won't get any data and you will pay for nodes that aren't getting any
          training data. This applies in both File and Pipe modes. Keep this in mind when
          developing algorithms.

          In distributed training, where you use multiple ML compute EC2 instances, you might
          choose ``ShardedByS3Key`` . If the algorithm requires copying training data to the ML
          storage volume (when ``TrainingInputMode`` is set to ``File`` ), this copies 1/*n* of
          the number of objects.

        - **AttributeNames** *(list) --*

          A list of one or more attribute names to use that are found in a specified augmented
          manifest file.

          - *(string) --*

      - **FileSystemDataSource** *(dict) --*

        The file system that is associated with a channel.

        - **FileSystemId** *(string) --* **[REQUIRED]**

          The file system id.

        - **FileSystemAccessMode** *(string) --* **[REQUIRED]**

          The access mode of the mount of the directory associated with the channel. A directory
          can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

        - **FileSystemType** *(string) --* **[REQUIRED]**

          The file system type.

        - **DirectoryPath** *(string) --* **[REQUIRED]**

          The full path to the directory to associate with the channel.

    - **ContentType** *(string) --*

      The MIME type of the data.

    - **CompressionType** *(string) --*

      If training data is compressed, the compression type. The default value is ``None`` .
      ``CompressionType`` is used only in Pipe input mode. In File mode, leave this field unset
      or set it to None.

    - **RecordWrapperType** *(string) --*

      Specify RecordIO as the value when input data is in raw format but the training algorithm
      requires the RecordIO format. In this case, Amazon SageMaker wraps each individual S3
      object in a RecordIO record. If the input data is already in RecordIO format, you don't
      need to set this attribute. For more information, see `Create a Dataset Using RecordIO
      <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__ .

      In File mode, leave this field unset or set it to None.

    - **InputMode** *(string) --*

      (Optional) The input mode to use for the data channel in a training job. If you don't set a
      value for ``InputMode`` , Amazon SageMaker uses the value set for ``TrainingInputMode`` .
      Use this parameter to override the ``TrainingInputMode`` setting in a
      AlgorithmSpecification request when you have a channel that needs a different input mode
      from the training job's general setting. To download the data from Amazon Simple Storage
      Service (Amazon S3) to the provisioned ML storage volume, and mount the directory to a
      Docker volume, use ``File`` input mode. To stream data directly from Amazon S3 to the
      container, choose ``Pipe`` input mode.

      To use a model for incremental training, choose ``File`` input model.

    - **ShuffleConfig** *(dict) --*

      A configuration for a shuffle option for input data in a channel. If you use ``S3Prefix``
      for ``S3DataType`` , this shuffles the results of the S3 key prefix matches. If you use
      ``ManifestFile`` , the order of the S3 object references in the ``ManifestFile`` is
      shuffled. If you use ``AugmentedManifestFile`` , the order of the JSON lines in the
      ``AugmentedManifestFile`` is shuffled. The shuffling order is determined using the ``Seed``
      value.

      For Pipe input mode, shuffling is done at the start of every epoch. With large datasets
      this ensures that the order of the training data is different for each epoch, it helps
      reduce bias and possible overfitting. In a multi-node training job when ShuffleConfig is
      combined with ``S3DataDistributionType`` of ``ShardedByS3Key`` , the data is shuffled
      across nodes so that the content sent to a particular node on the first epoch might be sent
      to a different node on the second epoch.

      - **Seed** *(integer) --* **[REQUIRED]**

        Determines the shuffling order in ``ShuffleConfig`` value.
    """


_RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionOutputDataConfigTypeDef = TypedDict(
    "_RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionOutputDataConfigTypeDef",
    {"S3OutputPath": str},
)
_OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionOutputDataConfigTypeDef = TypedDict(
    "_OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionOutputDataConfigTypeDef",
    {"KmsKeyId": str},
    total=False,
)


class ClientCreateHyperParameterTuningJobTrainingJobDefinitionOutputDataConfigTypeDef(
    _RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionOutputDataConfigTypeDef,
    _OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionOutputDataConfigTypeDef,
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobTrainingJobDefinition` `OutputDataConfig`

    Specifies the path to the Amazon S3 bucket where you store model artifacts from the training
    jobs that the tuning job launches.

    - **KmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the model
      artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be any of the
      following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // KMS Key Alias  ``"alias/ExampleAlias"``

      * // Amazon Resource Name (ARN) of a KMS Key Alias
      ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

      If you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution role
      must include permissions to call ``kms:Encrypt`` . If you don't provide a KMS key ID, Amazon
      SageMaker uses the default KMS key for Amazon S3 for your role's account. Amazon SageMaker
      uses server-side encryption with KMS-managed keys for ``OutputDataConfig`` . If you use a
      bucket policy with an ``s3:PutObject`` permission that only allows objects with server-side
      encryption, set the condition key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` .
      For more information, see `KMS-Managed Encryption Keys
      <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the *Amazon
      Simple Storage Service Developer Guide.*

      The KMS key policy must grant permission to the IAM role that you specify in your
      ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
      requests. For more information, see `Using Key Policies in AWS KMS
      <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
      in the *AWS Key Management Service Developer Guide* .

    - **S3OutputPath** *(string) --* **[REQUIRED]**

      Identifies the S3 path where you want Amazon SageMaker to store the model artifacts. For
      example, ``s3://bucket-name/key-name-prefix`` .
    """


_RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionResourceConfigTypeDef = TypedDict(
    "_RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionResourceConfigTypeDef",
    {"InstanceType": str, "InstanceCount": int, "VolumeSizeInGB": int},
)
_OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionResourceConfigTypeDef = TypedDict(
    "_OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionResourceConfigTypeDef",
    {"VolumeKmsKeyId": str},
    total=False,
)


class ClientCreateHyperParameterTuningJobTrainingJobDefinitionResourceConfigTypeDef(
    _RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionResourceConfigTypeDef,
    _OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionResourceConfigTypeDef,
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobTrainingJobDefinition` `ResourceConfig`

    The resources, including the compute instances and storage volumes, to use for the training
    jobs that the tuning job launches.

    Storage volumes store model artifacts and incremental states. Training algorithms might also
    use storage volumes for scratch space. If you want Amazon SageMaker to use the storage volume
    to store the training data, choose ``File`` as the ``TrainingInputMode`` in the algorithm
    specification. For distributed training algorithms, specify an instance count greater than 1.

    - **InstanceType** *(string) --* **[REQUIRED]**

      The ML compute instance type.

    - **InstanceCount** *(integer) --* **[REQUIRED]**

      The number of ML compute instances to use. For distributed training, provide a value greater
      than 1.

    - **VolumeSizeInGB** *(integer) --* **[REQUIRED]**

      The size of the ML storage volume that you want to provision.

      ML storage volumes store model artifacts and incremental states. Training algorithms might
      also use the ML storage volume for scratch space. If you want to store the training data in
      the ML storage volume, choose ``File`` as the ``TrainingInputMode`` in the algorithm
      specification.

      You must specify sufficient ML storage for your scenario.

      .. note::

        Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

      .. note::

        Certain Nitro-based instances include local storage with a fixed total size, dependent on
        the instance type. When using these instances for training, Amazon SageMaker mounts the
        local instance storage instead of Amazon EBS gp2 storage. You can't request a
        ``VolumeSizeInGB`` greater than the total size of the local instance storage.

        For a list of instance types that support local instance storage, including the total size
        per instance type, see `Instance Store Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
        .

    - **VolumeKmsKeyId** *(string) --*

      The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume attached to
      the ML compute instance(s) that run the training job.

      .. note::

        Certain Nitro-based instances include local storage, dependent on the instance type. Local
        storage volumes are encrypted using a hardware module on the instance. You can't request a
        ``VolumeKmsKeyId`` when using an instance type with local storage.

        For a list of instance types that support local instance storage, see `Instance Store
        Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
        .

        For more information about local instance storage encryption, see `SSD Instance Store
        Volumes <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

      The ``VolumeKmsKeyId`` can be in any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientCreateHyperParameterTuningJobTrainingJobDefinitionStoppingConditionTypeDef = TypedDict(
    "_ClientCreateHyperParameterTuningJobTrainingJobDefinitionStoppingConditionTypeDef",
    {"MaxRuntimeInSeconds": int, "MaxWaitTimeInSeconds": int},
    total=False,
)


class ClientCreateHyperParameterTuningJobTrainingJobDefinitionStoppingConditionTypeDef(
    _ClientCreateHyperParameterTuningJobTrainingJobDefinitionStoppingConditionTypeDef
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobTrainingJobDefinition` `StoppingCondition`

    Specifies a limit to how long a model hyperparameter training job can run. It also specifies
    how long you are willing to wait for a managed spot training job to complete. When the job
    reaches the a limit, Amazon SageMaker ends the training job. Use this API to cap model training
    costs.

    - **MaxRuntimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, that the training or compilation job can run. If job
      does not complete during this time, Amazon SageMaker ends the job. If value is not specified,
      default value is 1 day. The maximum value is 28 days.

    - **MaxWaitTimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, how long you are willing to wait for a managed spot
      training job to complete. It is the amount of time spent waiting for Spot capacity plus the
      amount of time the training job runs. It must be equal to or greater than
      ``MaxRuntimeInSeconds`` .
    """


_ClientCreateHyperParameterTuningJobTrainingJobDefinitionVpcConfigTypeDef = TypedDict(
    "_ClientCreateHyperParameterTuningJobTrainingJobDefinitionVpcConfigTypeDef",
    {"SecurityGroupIds": List[str], "Subnets": List[str]},
)


class ClientCreateHyperParameterTuningJobTrainingJobDefinitionVpcConfigTypeDef(
    _ClientCreateHyperParameterTuningJobTrainingJobDefinitionVpcConfigTypeDef
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobTrainingJobDefinition` `VpcConfig`

    The  VpcConfig object that specifies the VPC that you want the training jobs that this
    hyperparameter tuning job launches to connect to. Control access to and from your training
    container by configuring the VPC. For more information, see `Protect Training Jobs by Using an
    Amazon Virtual Private Cloud
    <https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html>`__ .

    - **SecurityGroupIds** *(list) --* **[REQUIRED]**

      The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for the VPC
      that is specified in the ``Subnets`` field.

      - *(string) --*

    - **Subnets** *(list) --* **[REQUIRED]**

      The ID of the subnets in the VPC to which you want to connect your training job or model.

      .. note::

        Amazon EC2 P3 accelerated computing instances are not available in the c/d/e availability
        zones of region us-east-1. If you want to create endpoints with P3 instances in VPC mode in
        region us-east-1, create subnets in a/b/f availability zones instead.

      - *(string) --*
    """


_RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionTypeDef = TypedDict(
    "_RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionTypeDef",
    {
        "AlgorithmSpecification": ClientCreateHyperParameterTuningJobTrainingJobDefinitionAlgorithmSpecificationTypeDef,
        "RoleArn": str,
        "OutputDataConfig": ClientCreateHyperParameterTuningJobTrainingJobDefinitionOutputDataConfigTypeDef,
        "ResourceConfig": ClientCreateHyperParameterTuningJobTrainingJobDefinitionResourceConfigTypeDef,
        "StoppingCondition": ClientCreateHyperParameterTuningJobTrainingJobDefinitionStoppingConditionTypeDef,
    },
)
_OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionTypeDef = TypedDict(
    "_OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionTypeDef",
    {
        "StaticHyperParameters": Dict[str, str],
        "InputDataConfig": List[
            ClientCreateHyperParameterTuningJobTrainingJobDefinitionInputDataConfigTypeDef
        ],
        "VpcConfig": ClientCreateHyperParameterTuningJobTrainingJobDefinitionVpcConfigTypeDef,
        "EnableNetworkIsolation": bool,
        "EnableInterContainerTrafficEncryption": bool,
        "EnableManagedSpotTraining": bool,
        "CheckpointConfig": ClientCreateHyperParameterTuningJobTrainingJobDefinitionCheckpointConfigTypeDef,
    },
    total=False,
)


class ClientCreateHyperParameterTuningJobTrainingJobDefinitionTypeDef(
    _RequiredClientCreateHyperParameterTuningJobTrainingJobDefinitionTypeDef,
    _OptionalClientCreateHyperParameterTuningJobTrainingJobDefinitionTypeDef,
):
    """
    Type definition for `ClientCreateHyperParameterTuningJob` `TrainingJobDefinition`

    The  HyperParameterTrainingJobDefinition object that describes the training jobs that this tuning
    job launches, including static hyperparameters, input data configuration, output data
    configuration, resource configuration, and stopping condition.

    - **StaticHyperParameters** *(dict) --*

      Specifies the values of hyperparameters that do not change for the tuning job.

      - *(string) --*

        - *(string) --*

    - **AlgorithmSpecification** *(dict) --* **[REQUIRED]**

      The  HyperParameterAlgorithmSpecification object that specifies the resource algorithm to use
      for the training jobs that the tuning job launches.

      - **TrainingImage** *(string) --*

        The registry path of the Docker image that contains the training algorithm. For information
        about Docker registry paths for built-in algorithms, see `Algorithms Provided by Amazon
        SageMaker\\: Common Parameters
        <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
        . Amazon SageMaker supports both ``registry/repository[:tag]`` and
        ``registry/repository[@digest]`` image path formats. For more information, see `Using Your
        Own Algorithms with Amazon SageMaker
        <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

      - **TrainingInputMode** *(string) --* **[REQUIRED]**

        The input mode that the algorithm supports: File or Pipe. In File input mode, Amazon
        SageMaker downloads the training data from Amazon S3 to the storage volume that is attached
        to the training instance and mounts the directory to the Docker volume for the training
        container. In Pipe input mode, Amazon SageMaker streams data directly from Amazon S3 to the
        container.

        If you specify File mode, make sure that you provision the storage volume that is attached to
        the training instance with enough capacity to accommodate the training data downloaded from
        Amazon S3, the model artifacts, and intermediate information.

        For more information about input modes, see `Algorithms
        <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ .

      - **AlgorithmName** *(string) --*

        The name of the resource algorithm to use for the hyperparameter tuning job. If you specify a
        value for this parameter, do not specify a value for ``TrainingImage`` .

      - **MetricDefinitions** *(list) --*

        An array of  MetricDefinition objects that specify the metrics that the algorithm emits.

        - *(dict) --*

          Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` . Amazon
          SageMakerhyperparameter tuning captures all defined metrics. You specify one metric that a
          hyperparameter tuning job uses as its objective metric to choose the best training job.

          - **Name** *(string) --* **[REQUIRED]**

            The name of the metric.

          - **Regex** *(string) --* **[REQUIRED]**

            A regular expression that searches the output of a training job and gets the value of the
            metric. For more information about using regular expressions to define metrics, see
            `Defining Objective Metrics
            <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
            .

    - **RoleArn** *(string) --* **[REQUIRED]**

      The Amazon Resource Name (ARN) of the IAM role associated with the training jobs that the
      tuning job launches.

    - **InputDataConfig** *(list) --*

      An array of  Channel objects that specify the input for the training jobs that the tuning job
      launches.

      - *(dict) --*

        A channel is a named input source that training algorithms can consume.

        - **ChannelName** *(string) --* **[REQUIRED]**

          The name of the channel.

        - **DataSource** *(dict) --* **[REQUIRED]**

          The location of the channel data.

          - **S3DataSource** *(dict) --*

            The S3 location of the data source that is associated with a channel.

            - **S3DataType** *(string) --* **[REQUIRED]**

              If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker
              uses all objects that match the specified key name prefix for model training.

              If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest file
              containing a list of object keys that you want Amazon SageMaker to use for model
              training.

              If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
              augmented manifest file in JSON lines format. This file contains the data you want to
              use for model training. ``AugmentedManifestFile`` can only be used if the Channel's
              input mode is ``Pipe`` .

            - **S3Uri** *(string) --* **[REQUIRED]**

              Depending on the value specified for the ``S3DataType`` , identifies either a key name
              prefix or a manifest. For example:

              * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

              * A manifest might look like this: ``s3://bucketname/example.manifest``   The manifest
              is an S3 object which is a JSON file with the following format:  The preceding JSON
              matches the following ``s3Uris`` :   ``[ {"prefix":
              "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
              ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``    ``]``
              The preceding JSON matches the following ``s3Uris`` :
              ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
              ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
              ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
              ``s3uris`` in this manifest is the input data for the channel for this datasource. The
              object that each ``s3uris`` points to must be readable by the IAM role that Amazon
              SageMaker uses to perform tasks on your behalf.

            - **S3DataDistributionType** *(string) --*

              If you want Amazon SageMaker to replicate the entire dataset on each ML compute
              instance that is launched for model training, specify ``FullyReplicated`` .

              If you want Amazon SageMaker to replicate a subset of data on each ML compute instance
              that is launched for model training, specify ``ShardedByS3Key`` . If there are *n* ML
              compute instances launched for a training job, each instance gets approximately 1/*n*
              of the number of S3 objects. In this case, model training on each machine uses only the
              subset of training data.

              Don't choose more ML compute instances for training than available S3 objects. If you
              do, some nodes won't get any data and you will pay for nodes that aren't getting any
              training data. This applies in both File and Pipe modes. Keep this in mind when
              developing algorithms.

              In distributed training, where you use multiple ML compute EC2 instances, you might
              choose ``ShardedByS3Key`` . If the algorithm requires copying training data to the ML
              storage volume (when ``TrainingInputMode`` is set to ``File`` ), this copies 1/*n* of
              the number of objects.

            - **AttributeNames** *(list) --*

              A list of one or more attribute names to use that are found in a specified augmented
              manifest file.

              - *(string) --*

          - **FileSystemDataSource** *(dict) --*

            The file system that is associated with a channel.

            - **FileSystemId** *(string) --* **[REQUIRED]**

              The file system id.

            - **FileSystemAccessMode** *(string) --* **[REQUIRED]**

              The access mode of the mount of the directory associated with the channel. A directory
              can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

            - **FileSystemType** *(string) --* **[REQUIRED]**

              The file system type.

            - **DirectoryPath** *(string) --* **[REQUIRED]**

              The full path to the directory to associate with the channel.

        - **ContentType** *(string) --*

          The MIME type of the data.

        - **CompressionType** *(string) --*

          If training data is compressed, the compression type. The default value is ``None`` .
          ``CompressionType`` is used only in Pipe input mode. In File mode, leave this field unset
          or set it to None.

        - **RecordWrapperType** *(string) --*

          Specify RecordIO as the value when input data is in raw format but the training algorithm
          requires the RecordIO format. In this case, Amazon SageMaker wraps each individual S3
          object in a RecordIO record. If the input data is already in RecordIO format, you don't
          need to set this attribute. For more information, see `Create a Dataset Using RecordIO
          <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__ .

          In File mode, leave this field unset or set it to None.

        - **InputMode** *(string) --*

          (Optional) The input mode to use for the data channel in a training job. If you don't set a
          value for ``InputMode`` , Amazon SageMaker uses the value set for ``TrainingInputMode`` .
          Use this parameter to override the ``TrainingInputMode`` setting in a
          AlgorithmSpecification request when you have a channel that needs a different input mode
          from the training job's general setting. To download the data from Amazon Simple Storage
          Service (Amazon S3) to the provisioned ML storage volume, and mount the directory to a
          Docker volume, use ``File`` input mode. To stream data directly from Amazon S3 to the
          container, choose ``Pipe`` input mode.

          To use a model for incremental training, choose ``File`` input model.

        - **ShuffleConfig** *(dict) --*

          A configuration for a shuffle option for input data in a channel. If you use ``S3Prefix``
          for ``S3DataType`` , this shuffles the results of the S3 key prefix matches. If you use
          ``ManifestFile`` , the order of the S3 object references in the ``ManifestFile`` is
          shuffled. If you use ``AugmentedManifestFile`` , the order of the JSON lines in the
          ``AugmentedManifestFile`` is shuffled. The shuffling order is determined using the ``Seed``
          value.

          For Pipe input mode, shuffling is done at the start of every epoch. With large datasets
          this ensures that the order of the training data is different for each epoch, it helps
          reduce bias and possible overfitting. In a multi-node training job when ShuffleConfig is
          combined with ``S3DataDistributionType`` of ``ShardedByS3Key`` , the data is shuffled
          across nodes so that the content sent to a particular node on the first epoch might be sent
          to a different node on the second epoch.

          - **Seed** *(integer) --* **[REQUIRED]**

            Determines the shuffling order in ``ShuffleConfig`` value.

    - **VpcConfig** *(dict) --*

      The  VpcConfig object that specifies the VPC that you want the training jobs that this
      hyperparameter tuning job launches to connect to. Control access to and from your training
      container by configuring the VPC. For more information, see `Protect Training Jobs by Using an
      Amazon Virtual Private Cloud
      <https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html>`__ .

      - **SecurityGroupIds** *(list) --* **[REQUIRED]**

        The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for the VPC
        that is specified in the ``Subnets`` field.

        - *(string) --*

      - **Subnets** *(list) --* **[REQUIRED]**

        The ID of the subnets in the VPC to which you want to connect your training job or model.

        .. note::

          Amazon EC2 P3 accelerated computing instances are not available in the c/d/e availability
          zones of region us-east-1. If you want to create endpoints with P3 instances in VPC mode in
          region us-east-1, create subnets in a/b/f availability zones instead.

        - *(string) --*

    - **OutputDataConfig** *(dict) --* **[REQUIRED]**

      Specifies the path to the Amazon S3 bucket where you store model artifacts from the training
      jobs that the tuning job launches.

      - **KmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the model
        artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be any of the
        following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // KMS Key Alias  ``"alias/ExampleAlias"``

        * // Amazon Resource Name (ARN) of a KMS Key Alias
        ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

        If you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution role
        must include permissions to call ``kms:Encrypt`` . If you don't provide a KMS key ID, Amazon
        SageMaker uses the default KMS key for Amazon S3 for your role's account. Amazon SageMaker
        uses server-side encryption with KMS-managed keys for ``OutputDataConfig`` . If you use a
        bucket policy with an ``s3:PutObject`` permission that only allows objects with server-side
        encryption, set the condition key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` .
        For more information, see `KMS-Managed Encryption Keys
        <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the *Amazon
        Simple Storage Service Developer Guide.*

        The KMS key policy must grant permission to the IAM role that you specify in your
        ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
        requests. For more information, see `Using Key Policies in AWS KMS
        <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
        in the *AWS Key Management Service Developer Guide* .

      - **S3OutputPath** *(string) --* **[REQUIRED]**

        Identifies the S3 path where you want Amazon SageMaker to store the model artifacts. For
        example, ``s3://bucket-name/key-name-prefix`` .

    - **ResourceConfig** *(dict) --* **[REQUIRED]**

      The resources, including the compute instances and storage volumes, to use for the training
      jobs that the tuning job launches.

      Storage volumes store model artifacts and incremental states. Training algorithms might also
      use storage volumes for scratch space. If you want Amazon SageMaker to use the storage volume
      to store the training data, choose ``File`` as the ``TrainingInputMode`` in the algorithm
      specification. For distributed training algorithms, specify an instance count greater than 1.

      - **InstanceType** *(string) --* **[REQUIRED]**

        The ML compute instance type.

      - **InstanceCount** *(integer) --* **[REQUIRED]**

        The number of ML compute instances to use. For distributed training, provide a value greater
        than 1.

      - **VolumeSizeInGB** *(integer) --* **[REQUIRED]**

        The size of the ML storage volume that you want to provision.

        ML storage volumes store model artifacts and incremental states. Training algorithms might
        also use the ML storage volume for scratch space. If you want to store the training data in
        the ML storage volume, choose ``File`` as the ``TrainingInputMode`` in the algorithm
        specification.

        You must specify sufficient ML storage for your scenario.

        .. note::

          Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

        .. note::

          Certain Nitro-based instances include local storage with a fixed total size, dependent on
          the instance type. When using these instances for training, Amazon SageMaker mounts the
          local instance storage instead of Amazon EBS gp2 storage. You can't request a
          ``VolumeSizeInGB`` greater than the total size of the local instance storage.

          For a list of instance types that support local instance storage, including the total size
          per instance type, see `Instance Store Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
          .

      - **VolumeKmsKeyId** *(string) --*

        The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume attached to
        the ML compute instance(s) that run the training job.

        .. note::

          Certain Nitro-based instances include local storage, dependent on the instance type. Local
          storage volumes are encrypted using a hardware module on the instance. You can't request a
          ``VolumeKmsKeyId`` when using an instance type with local storage.

          For a list of instance types that support local instance storage, see `Instance Store
          Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
          .

          For more information about local instance storage encryption, see `SSD Instance Store
          Volumes <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

        The ``VolumeKmsKeyId`` can be in any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

    - **StoppingCondition** *(dict) --* **[REQUIRED]**

      Specifies a limit to how long a model hyperparameter training job can run. It also specifies
      how long you are willing to wait for a managed spot training job to complete. When the job
      reaches the a limit, Amazon SageMaker ends the training job. Use this API to cap model training
      costs.

      - **MaxRuntimeInSeconds** *(integer) --*

        The maximum length of time, in seconds, that the training or compilation job can run. If job
        does not complete during this time, Amazon SageMaker ends the job. If value is not specified,
        default value is 1 day. The maximum value is 28 days.

      - **MaxWaitTimeInSeconds** *(integer) --*

        The maximum length of time, in seconds, how long you are willing to wait for a managed spot
        training job to complete. It is the amount of time spent waiting for Spot capacity plus the
        amount of time the training job runs. It must be equal to or greater than
        ``MaxRuntimeInSeconds`` .

    - **EnableNetworkIsolation** *(boolean) --*

      Isolates the training container. No inbound or outbound network calls can be made, except for
      calls between peers within a training cluster for distributed training. If network isolation is
      used for training jobs that are configured to use a VPC, Amazon SageMaker downloads and uploads
      customer data and model artifacts through the specified VPC, but the training container does
      not have network access.

      .. note::

        The Semantic Segmentation built-in algorithm does not support network isolation.

    - **EnableInterContainerTrafficEncryption** *(boolean) --*

      To encrypt all communications between ML compute instances in distributed training, choose
      ``True`` . Encryption provides greater security for distributed training, but training might
      take longer. How long it takes depends on the amount of communication between compute
      instances, especially if you use a deep learning algorithm in distributed training.

    - **EnableManagedSpotTraining** *(boolean) --*

      A Boolean indicating whether managed spot training is enabled (``True`` ) or not (``False`` ).

    - **CheckpointConfig** *(dict) --*

      Contains information about the output location for managed spot training checkpoint data.

      - **S3Uri** *(string) --* **[REQUIRED]**

        Identifies the S3 path where you want Amazon SageMaker to store checkpoints. For example,
        ``s3://bucket-name/key-name-prefix`` .

      - **LocalPath** *(string) --*

        (Optional) The local directory where checkpoints are written. The default directory is
        ``/opt/ml/checkpoints/`` .
    """


_ClientCreateHyperParameterTuningJobWarmStartConfigParentHyperParameterTuningJobsTypeDef = TypedDict(
    "_ClientCreateHyperParameterTuningJobWarmStartConfigParentHyperParameterTuningJobsTypeDef",
    {"HyperParameterTuningJobName": str},
    total=False,
)


class ClientCreateHyperParameterTuningJobWarmStartConfigParentHyperParameterTuningJobsTypeDef(
    _ClientCreateHyperParameterTuningJobWarmStartConfigParentHyperParameterTuningJobsTypeDef
):
    """
    Type definition for `ClientCreateHyperParameterTuningJobWarmStartConfig` `ParentHyperParameterTuningJobs`

    A previously completed or stopped hyperparameter tuning job to be used as a starting point
    for a new hyperparameter tuning job.

    - **HyperParameterTuningJobName** *(string) --*

      The name of the hyperparameter tuning job to be used as a starting point for a new
      hyperparameter tuning job.
    """


_ClientCreateHyperParameterTuningJobWarmStartConfigTypeDef = TypedDict(
    "_ClientCreateHyperParameterTuningJobWarmStartConfigTypeDef",
    {
        "ParentHyperParameterTuningJobs": List[
            ClientCreateHyperParameterTuningJobWarmStartConfigParentHyperParameterTuningJobsTypeDef
        ],
        "WarmStartType": str,
    },
)


class ClientCreateHyperParameterTuningJobWarmStartConfigTypeDef(
    _ClientCreateHyperParameterTuningJobWarmStartConfigTypeDef
):
    """
    Type definition for `ClientCreateHyperParameterTuningJob` `WarmStartConfig`

    Specifies the configuration for starting the hyperparameter tuning job using one or more previous
    tuning jobs as a starting point. The results of previous tuning jobs are used to inform which
    combinations of hyperparameters to search over in the new tuning job.

    All training jobs launched by the new hyperparameter tuning job are evaluated by using the
    objective metric. If you specify ``IDENTICAL_DATA_AND_ALGORITHM`` as the ``WarmStartType`` value
    for the warm start configuration, the training job that performs the best in the new tuning job
    is compared to the best training jobs from the parent tuning jobs. From these, the training job
    that performs the best as measured by the objective metric is returned as the overall best
    training job.

    .. note::

      All training jobs launched by parent hyperparameter tuning jobs and the new hyperparameter
      tuning jobs count against the limit of training jobs for the tuning job.

    - **ParentHyperParameterTuningJobs** *(list) --* **[REQUIRED]**

      An array of hyperparameter tuning jobs that are used as the starting point for the new
      hyperparameter tuning job. For more information about warm starting a hyperparameter tuning
      job, see `Using a Previous Hyperparameter Tuning Job as a Starting Point
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-warm-start.html>`__ .

      Hyperparameter tuning jobs created before October 1, 2018 cannot be used as parent jobs for
      warm start tuning jobs.

      - *(dict) --*

        A previously completed or stopped hyperparameter tuning job to be used as a starting point
        for a new hyperparameter tuning job.

        - **HyperParameterTuningJobName** *(string) --*

          The name of the hyperparameter tuning job to be used as a starting point for a new
          hyperparameter tuning job.

    - **WarmStartType** *(string) --* **[REQUIRED]**

      Specifies one of the following:

        IDENTICAL_DATA_AND_ALGORITHM

      The new hyperparameter tuning job uses the same input data and training image as the parent
      tuning jobs. You can change the hyperparameter ranges to search and the maximum number of
      training jobs that the hyperparameter tuning job launches. You cannot use a new version of the
      training algorithm, unless the changes in the new version do not affect the algorithm itself.
      For example, changes that improve logging or adding support for a different data format are
      allowed. You can also change hyperparameters from tunable to static, and from static to
      tunable, but the total number of static plus tunable hyperparameters must remain the same as it
      is in all parent jobs. The objective metric for the new tuning job must be the same as for all
      parent jobs.

        TRANSFER_LEARNING

      The new hyperparameter tuning job can include input data, hyperparameter ranges, maximum number
      of concurrent training jobs, and maximum number of training jobs that are different than those
      of its parent hyperparameter tuning jobs. The training image can also be a different version
      from the version used in the parent hyperparameter tuning job. You can also change
      hyperparameters from tunable to static, and from static to tunable, but the total number of
      static plus tunable hyperparameters must remain the same as it is in all parent jobs. The
      objective metric for the new tuning job must be the same as for all parent jobs.
    """


_ClientCreateLabelingJobHumanTaskConfigAnnotationConsolidationConfigTypeDef = TypedDict(
    "_ClientCreateLabelingJobHumanTaskConfigAnnotationConsolidationConfigTypeDef",
    {"AnnotationConsolidationLambdaArn": str},
)


class ClientCreateLabelingJobHumanTaskConfigAnnotationConsolidationConfigTypeDef(
    _ClientCreateLabelingJobHumanTaskConfigAnnotationConsolidationConfigTypeDef
):
    """
    Type definition for `ClientCreateLabelingJobHumanTaskConfig` `AnnotationConsolidationConfig`

    Configures how labels are consolidated across human workers.

    - **AnnotationConsolidationLambdaArn** *(string) --* **[REQUIRED]**

      The Amazon Resource Name (ARN) of a Lambda function implements the logic for annotation
      consolidation.

      For the built-in bounding box, image classification, semantic segmentation, and text
      classification task types, Amazon SageMaker Ground Truth provides the following Lambda
      functions:

      * *Bounding box* - Finds the most similar boxes from different workers based on the Jaccard
      index of the boxes.  ``arn:aws:lambda:us-east-1:432418664414:function:ACS-BoundingBox``
      ``arn:aws:lambda:us-east-2:266458841044:function:ACS-BoundingBox``
      ``arn:aws:lambda:us-west-2:081040173940:function:ACS-BoundingBox``
      ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-BoundingBox``
      ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-BoundingBox``
      ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-BoundingBox``
      ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-BoundingBox``
      ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-BoundingBox``
      ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-BoundingBox``
      ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-BoundingBox``
      ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-BoundingBox``
      ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-BoundingBox``

      * *Image classification* - Uses a variant of the Expectation Maximization approach to
      estimate the true class of an image based on annotations from individual workers.
      ``arn:aws:lambda:us-east-1:432418664414:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:us-east-2:266458841044:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:us-west-2:081040173940:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-ImageMultiClass``

      * *Semantic segmentation* - Treats each pixel in an image as a multi-class classification and
      treats pixel annotations from workers as "votes" for the correct label.
      ``arn:aws:lambda:us-east-1:432418664414:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:us-east-2:266458841044:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:us-west-2:081040173940:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-SemanticSegmentation``

      * *Text classification* - Uses a variant of the Expectation Maximization approach to estimate
      the true class of text based on annotations from individual workers.
      ``arn:aws:lambda:us-east-1:432418664414:function:ACS-TextMultiClass``
      ``arn:aws:lambda:us-east-2:266458841044:function:ACS-TextMultiClass``
      ``arn:aws:lambda:us-west-2:081040173940:function:ACS-TextMultiClass``
      ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-TextMultiClass``
      ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-TextMultiClass``
      ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-TextMultiClass``
      ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-TextMultiClass``
      ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-TextMultiClass``
      ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-TextMultiClass``
      ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-TextMultiClass``
      ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-TextMultiClass``
      ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-TextMultiClass``

      * *Named entity eecognition* - Groups similar selections and calculates aggregate boundaries,
      resolving to most-assigned label.
      ``arn:aws:lambda:us-east-1:432418664414:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:us-east-2:266458841044:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:us-west-2:081040173940:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-NamedEntityRecognition``

      For more information, see `Annotation Consolidation
      <https://docs.aws.amazon.com/sagemaker/latest/dg/sms-annotation-consolidation.html>`__ .
    """


_ClientCreateLabelingJobHumanTaskConfigPublicWorkforceTaskPriceAmountInUsdTypeDef = TypedDict(
    "_ClientCreateLabelingJobHumanTaskConfigPublicWorkforceTaskPriceAmountInUsdTypeDef",
    {"Dollars": int, "Cents": int, "TenthFractionsOfACent": int},
    total=False,
)


class ClientCreateLabelingJobHumanTaskConfigPublicWorkforceTaskPriceAmountInUsdTypeDef(
    _ClientCreateLabelingJobHumanTaskConfigPublicWorkforceTaskPriceAmountInUsdTypeDef
):
    """
    Type definition for `ClientCreateLabelingJobHumanTaskConfigPublicWorkforceTaskPrice` `AmountInUsd`

    Defines the amount of money paid to an Amazon Mechanical Turk worker in United States dollars.

    - **Dollars** *(integer) --*

      The whole number of dollars in the amount.

    - **Cents** *(integer) --*

      The fractional portion, in cents, of the amount.

    - **TenthFractionsOfACent** *(integer) --*

      Fractions of a cent, in tenths.
    """


_ClientCreateLabelingJobHumanTaskConfigPublicWorkforceTaskPriceTypeDef = TypedDict(
    "_ClientCreateLabelingJobHumanTaskConfigPublicWorkforceTaskPriceTypeDef",
    {
        "AmountInUsd": ClientCreateLabelingJobHumanTaskConfigPublicWorkforceTaskPriceAmountInUsdTypeDef
    },
    total=False,
)


class ClientCreateLabelingJobHumanTaskConfigPublicWorkforceTaskPriceTypeDef(
    _ClientCreateLabelingJobHumanTaskConfigPublicWorkforceTaskPriceTypeDef
):
    """
    Type definition for `ClientCreateLabelingJobHumanTaskConfig` `PublicWorkforceTaskPrice`

    The price that you pay for each task performed by an Amazon Mechanical Turk worker.

    - **AmountInUsd** *(dict) --*

      Defines the amount of money paid to an Amazon Mechanical Turk worker in United States dollars.

      - **Dollars** *(integer) --*

        The whole number of dollars in the amount.

      - **Cents** *(integer) --*

        The fractional portion, in cents, of the amount.

      - **TenthFractionsOfACent** *(integer) --*

        Fractions of a cent, in tenths.
    """


_ClientCreateLabelingJobHumanTaskConfigUiConfigTypeDef = TypedDict(
    "_ClientCreateLabelingJobHumanTaskConfigUiConfigTypeDef", {"UiTemplateS3Uri": str}
)


class ClientCreateLabelingJobHumanTaskConfigUiConfigTypeDef(
    _ClientCreateLabelingJobHumanTaskConfigUiConfigTypeDef
):
    """
    Type definition for `ClientCreateLabelingJobHumanTaskConfig` `UiConfig`

    Information about the user interface that workers use to complete the labeling task.

    - **UiTemplateS3Uri** *(string) --* **[REQUIRED]**

      The Amazon S3 bucket location of the UI template. For more information about the contents of
      a UI template, see `Creating Your Custom Labeling Task Template
      <https://docs.aws.amazon.com/sagemaker/latest/dg/sms-custom-templates-step2.html>`__ .
    """


_RequiredClientCreateLabelingJobHumanTaskConfigTypeDef = TypedDict(
    "_RequiredClientCreateLabelingJobHumanTaskConfigTypeDef",
    {
        "WorkteamArn": str,
        "UiConfig": ClientCreateLabelingJobHumanTaskConfigUiConfigTypeDef,
        "PreHumanTaskLambdaArn": str,
        "TaskTitle": str,
        "TaskDescription": str,
        "NumberOfHumanWorkersPerDataObject": int,
        "TaskTimeLimitInSeconds": int,
        "AnnotationConsolidationConfig": ClientCreateLabelingJobHumanTaskConfigAnnotationConsolidationConfigTypeDef,
    },
)
_OptionalClientCreateLabelingJobHumanTaskConfigTypeDef = TypedDict(
    "_OptionalClientCreateLabelingJobHumanTaskConfigTypeDef",
    {
        "TaskKeywords": List[str],
        "TaskAvailabilityLifetimeInSeconds": int,
        "MaxConcurrentTaskCount": int,
        "PublicWorkforceTaskPrice": ClientCreateLabelingJobHumanTaskConfigPublicWorkforceTaskPriceTypeDef,
    },
    total=False,
)


class ClientCreateLabelingJobHumanTaskConfigTypeDef(
    _RequiredClientCreateLabelingJobHumanTaskConfigTypeDef,
    _OptionalClientCreateLabelingJobHumanTaskConfigTypeDef,
):
    """
    Type definition for `ClientCreateLabelingJob` `HumanTaskConfig`

    Configures the information required for human workers to complete a labeling task.

    - **WorkteamArn** *(string) --* **[REQUIRED]**

      The Amazon Resource Name (ARN) of the work team assigned to complete the tasks.

    - **UiConfig** *(dict) --* **[REQUIRED]**

      Information about the user interface that workers use to complete the labeling task.

      - **UiTemplateS3Uri** *(string) --* **[REQUIRED]**

        The Amazon S3 bucket location of the UI template. For more information about the contents of
        a UI template, see `Creating Your Custom Labeling Task Template
        <https://docs.aws.amazon.com/sagemaker/latest/dg/sms-custom-templates-step2.html>`__ .

    - **PreHumanTaskLambdaArn** *(string) --* **[REQUIRED]**

      The Amazon Resource Name (ARN) of a Lambda function that is run before a data object is sent to
      a human worker. Use this function to provide input to a custom labeling job.

      For the built-in bounding box, image classification, semantic segmentation, and text
      classification task types, Amazon SageMaker Ground Truth provides the following Lambda
      functions:

       **US East (Northern Virginia) (us-east-1):**

      * ``arn:aws:lambda:us-east-1:432418664414:function:PRE-BoundingBox``

      * ``arn:aws:lambda:us-east-1:432418664414:function:PRE-ImageMultiClass``

      * ``arn:aws:lambda:us-east-1:432418664414:function:PRE-SemanticSegmentation``

      * ``arn:aws:lambda:us-east-1:432418664414:function:PRE-TextMultiClass``

      * ``arn:aws:lambda:us-east-1:432418664414:function:PRE-NamedEntityRecognition``

       **US East (Ohio) (us-east-2):**

      * ``arn:aws:lambda:us-east-2:266458841044:function:PRE-BoundingBox``

      * ``arn:aws:lambda:us-east-2:266458841044:function:PRE-ImageMultiClass``

      * ``arn:aws:lambda:us-east-2:266458841044:function:PRE-SemanticSegmentation``

      * ``arn:aws:lambda:us-east-2:266458841044:function:PRE-TextMultiClass``

      * ``arn:aws:lambda:us-east-2:266458841044:function:PRE-NamedEntityRecognition``

       **US West (Oregon) (us-west-2):**

      * ``arn:aws:lambda:us-west-2:081040173940:function:PRE-BoundingBox``

      * ``arn:aws:lambda:us-west-2:081040173940:function:PRE-ImageMultiClass``

      * ``arn:aws:lambda:us-west-2:081040173940:function:PRE-SemanticSegmentation``

      * ``arn:aws:lambda:us-west-2:081040173940:function:PRE-TextMultiClass``

      * ``arn:aws:lambda:us-west-2:081040173940:function:PRE-NamedEntityRecognition``

       **Canada (Central) (ca-central-1):**

      * ``arn:awslambda:ca-central-1:918755190332:function:PRE-BoundingBox``

      * ``arn:awslambda:ca-central-1:918755190332:function:PRE-ImageMultiClass``

      * ``arn:awslambda:ca-central-1:918755190332:function:PRE-SemanticSegmentation``

      * ``arn:awslambda:ca-central-1:918755190332:function:PRE-TextMultiClass``

      * ``arn:awslambda:ca-central-1:918755190332:function:PRE-NamedEntityRecognition``

       **EU (Ireland) (eu-west-1):**

      * ``arn:aws:lambda:eu-west-1:568282634449:function:PRE-BoundingBox``

      * ``arn:aws:lambda:eu-west-1:568282634449:function:PRE-ImageMultiClass``

      * ``arn:aws:lambda:eu-west-1:568282634449:function:PRE-SemanticSegmentation``

      * ``arn:aws:lambda:eu-west-1:568282634449:function:PRE-TextMultiClass``

      * ``arn:aws:lambda:eu-west-1:568282634449:function:PRE-NamedEntityRecognition``

       **EU (London) (eu-west-2):**

      * ``arn:awslambda:eu-west-2:487402164563:function:PRE-BoundingBox``

      * ``arn:awslambda:eu-west-2:487402164563:function:PRE-ImageMultiClass``

      * ``arn:awslambda:eu-west-2:487402164563:function:PRE-SemanticSegmentation``

      * ``arn:awslambda:eu-west-2:487402164563:function:PRE-TextMultiClass``

      * ``arn:awslambda:eu-west-2:487402164563:function:PRE-NamedEntityRecognition``

       **EU Frankfurt (eu-central-1):**

      * ``arn:awslambda:eu-central-1:203001061592:function:PRE-BoundingBox``

      * ``arn:awslambda:eu-central-1:203001061592:function:PRE-ImageMultiClass``

      * ``arn:awslambda:eu-central-1:203001061592:function:PRE-SemanticSegmentation``

      * ``arn:awslambda:eu-central-1:203001061592:function:PRE-TextMultiClass``

      * ``arn:awslambda:eu-central-1:203001061592:function:PRE-NamedEntityRecognition``

       **Asia Pacific (Tokyo) (ap-northeast-1):**

      * ``arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-BoundingBox``

      * ``arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-ImageMultiClass``

      * ``arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-SemanticSegmentation``

      * ``arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-TextMultiClass``

      * ``arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-NamedEntityRecognition``

       **Asia Pacific (Seoul) (ap-northeast-2):**

      * ``arn:awslambda:ap-northeast-2:845288260483:function:PRE-BoundingBox``

      * ``arn:awslambda:ap-northeast-2:845288260483:function:PRE-ImageMultiClass``

      * ``arn:awslambda:ap-northeast-2:845288260483:function:PRE-SemanticSegmentation``

      * ``arn:awslambda:ap-northeast-2:845288260483:function:PRE-TextMultiClass``

      * ``arn:awslambda:ap-northeast-2:845288260483:function:PRE-NamedEntityRecognition``

       **Asia Pacific (Mumbai) (ap-south-1):**

      * ``arn:awslambda:ap-south-1:565803892007:function:PRE-BoundingBox``

      * ``arn:awslambda:ap-south-1:565803892007:function:PRE-ImageMultiClass``

      * ``arn:awslambda:ap-south-1:565803892007:function:PRE-SemanticSegmentation``

      * ``arn:awslambda:ap-south-1:565803892007:function:PRE-TextMultiClass``

      * ``arn:awslambda:ap-south-1:565803892007:function:PRE-NamedEntityRecognition``

       **Asia Pacific (Singapore) (ap-southeast-1):**

      * ``arn:awslambda:ap-southeast-1:377565633583:function:PRE-BoundingBox``

      * ``arn:awslambda:ap-southeast-1:377565633583:function:PRE-ImageMultiClass``

      * ``arn:awslambda:ap-southeast-1:377565633583:function:PRE-SemanticSegmentation``

      * ``arn:awslambda:ap-southeast-1:377565633583:function:PRE-TextMultiClass``

      * ``arn:awslambda:ap-southeast-1:377565633583:function:PRE-NamedEntityRecognition``

       **Asia Pacific (Sydney) (ap-southeast-2):**

      * ``arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-BoundingBox``

      * ``arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-ImageMultiClass``

      * ``arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-SemanticSegmentation``

      * ``arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-TextMultiClass``

      * ``arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-NamedEntityRecognition``

    - **TaskKeywords** *(list) --*

      Keywords used to describe the task so that workers on Amazon Mechanical Turk can discover the
      task.

      - *(string) --*

    - **TaskTitle** *(string) --* **[REQUIRED]**

      A title for the task for your human workers.

    - **TaskDescription** *(string) --* **[REQUIRED]**

      A description of the task for your human workers.

    - **NumberOfHumanWorkersPerDataObject** *(integer) --* **[REQUIRED]**

      The number of human workers that will label an object.

    - **TaskTimeLimitInSeconds** *(integer) --* **[REQUIRED]**

      The amount of time that a worker has to complete a task.

    - **TaskAvailabilityLifetimeInSeconds** *(integer) --*

      The length of time that a task remains available for labeling by human workers. **If you choose
      the Amazon Mechanical Turk workforce, the maximum is 12 hours (43200)** . For private and
      vendor workforces, the maximum is as listed.

    - **MaxConcurrentTaskCount** *(integer) --*

      Defines the maximum number of data objects that can be labeled by human workers at the same
      time. Each object may have more than one worker at one time.

    - **AnnotationConsolidationConfig** *(dict) --* **[REQUIRED]**

      Configures how labels are consolidated across human workers.

      - **AnnotationConsolidationLambdaArn** *(string) --* **[REQUIRED]**

        The Amazon Resource Name (ARN) of a Lambda function implements the logic for annotation
        consolidation.

        For the built-in bounding box, image classification, semantic segmentation, and text
        classification task types, Amazon SageMaker Ground Truth provides the following Lambda
        functions:

        * *Bounding box* - Finds the most similar boxes from different workers based on the Jaccard
        index of the boxes.  ``arn:aws:lambda:us-east-1:432418664414:function:ACS-BoundingBox``
        ``arn:aws:lambda:us-east-2:266458841044:function:ACS-BoundingBox``
        ``arn:aws:lambda:us-west-2:081040173940:function:ACS-BoundingBox``
        ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-BoundingBox``
        ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-BoundingBox``
        ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-BoundingBox``
        ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-BoundingBox``
        ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-BoundingBox``
        ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-BoundingBox``
        ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-BoundingBox``
        ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-BoundingBox``
        ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-BoundingBox``

        * *Image classification* - Uses a variant of the Expectation Maximization approach to
        estimate the true class of an image based on annotations from individual workers.
        ``arn:aws:lambda:us-east-1:432418664414:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:us-east-2:266458841044:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:us-west-2:081040173940:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-ImageMultiClass``

        * *Semantic segmentation* - Treats each pixel in an image as a multi-class classification and
        treats pixel annotations from workers as "votes" for the correct label.
        ``arn:aws:lambda:us-east-1:432418664414:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:us-east-2:266458841044:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:us-west-2:081040173940:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-SemanticSegmentation``

        * *Text classification* - Uses a variant of the Expectation Maximization approach to estimate
        the true class of text based on annotations from individual workers.
        ``arn:aws:lambda:us-east-1:432418664414:function:ACS-TextMultiClass``
        ``arn:aws:lambda:us-east-2:266458841044:function:ACS-TextMultiClass``
        ``arn:aws:lambda:us-west-2:081040173940:function:ACS-TextMultiClass``
        ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-TextMultiClass``
        ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-TextMultiClass``
        ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-TextMultiClass``
        ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-TextMultiClass``
        ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-TextMultiClass``
        ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-TextMultiClass``
        ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-TextMultiClass``
        ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-TextMultiClass``
        ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-TextMultiClass``

        * *Named entity eecognition* - Groups similar selections and calculates aggregate boundaries,
        resolving to most-assigned label.
        ``arn:aws:lambda:us-east-1:432418664414:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:us-east-2:266458841044:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:us-west-2:081040173940:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-NamedEntityRecognition``

        For more information, see `Annotation Consolidation
        <https://docs.aws.amazon.com/sagemaker/latest/dg/sms-annotation-consolidation.html>`__ .

    - **PublicWorkforceTaskPrice** *(dict) --*

      The price that you pay for each task performed by an Amazon Mechanical Turk worker.

      - **AmountInUsd** *(dict) --*

        Defines the amount of money paid to an Amazon Mechanical Turk worker in United States dollars.

        - **Dollars** *(integer) --*

          The whole number of dollars in the amount.

        - **Cents** *(integer) --*

          The fractional portion, in cents, of the amount.

        - **TenthFractionsOfACent** *(integer) --*

          Fractions of a cent, in tenths.
    """


_ClientCreateLabelingJobInputConfigDataAttributesTypeDef = TypedDict(
    "_ClientCreateLabelingJobInputConfigDataAttributesTypeDef",
    {"ContentClassifiers": List[str]},
    total=False,
)


class ClientCreateLabelingJobInputConfigDataAttributesTypeDef(
    _ClientCreateLabelingJobInputConfigDataAttributesTypeDef
):
    """
    Type definition for `ClientCreateLabelingJobInputConfig` `DataAttributes`

    Attributes of the data specified by the customer.

    - **ContentClassifiers** *(list) --*

      Declares that your content is free of personally identifiable information or adult content.
      Amazon SageMaker may restrict the Amazon Mechanical Turk workers that can view your task
      based on this information.

      - *(string) --*
    """


_ClientCreateLabelingJobInputConfigDataSourceS3DataSourceTypeDef = TypedDict(
    "_ClientCreateLabelingJobInputConfigDataSourceS3DataSourceTypeDef",
    {"ManifestS3Uri": str},
)


class ClientCreateLabelingJobInputConfigDataSourceS3DataSourceTypeDef(
    _ClientCreateLabelingJobInputConfigDataSourceS3DataSourceTypeDef
):
    """
    Type definition for `ClientCreateLabelingJobInputConfigDataSource` `S3DataSource`

    The Amazon S3 location of the input data objects.

    - **ManifestS3Uri** *(string) --* **[REQUIRED]**

      The Amazon S3 location of the manifest file that describes the input data objects.
    """


_ClientCreateLabelingJobInputConfigDataSourceTypeDef = TypedDict(
    "_ClientCreateLabelingJobInputConfigDataSourceTypeDef",
    {"S3DataSource": ClientCreateLabelingJobInputConfigDataSourceS3DataSourceTypeDef},
)


class ClientCreateLabelingJobInputConfigDataSourceTypeDef(
    _ClientCreateLabelingJobInputConfigDataSourceTypeDef
):
    """
    Type definition for `ClientCreateLabelingJobInputConfig` `DataSource`

    The location of the input data.

    - **S3DataSource** *(dict) --* **[REQUIRED]**

      The Amazon S3 location of the input data objects.

      - **ManifestS3Uri** *(string) --* **[REQUIRED]**

        The Amazon S3 location of the manifest file that describes the input data objects.
    """


_RequiredClientCreateLabelingJobInputConfigTypeDef = TypedDict(
    "_RequiredClientCreateLabelingJobInputConfigTypeDef",
    {"DataSource": ClientCreateLabelingJobInputConfigDataSourceTypeDef},
)
_OptionalClientCreateLabelingJobInputConfigTypeDef = TypedDict(
    "_OptionalClientCreateLabelingJobInputConfigTypeDef",
    {"DataAttributes": ClientCreateLabelingJobInputConfigDataAttributesTypeDef},
    total=False,
)


class ClientCreateLabelingJobInputConfigTypeDef(
    _RequiredClientCreateLabelingJobInputConfigTypeDef,
    _OptionalClientCreateLabelingJobInputConfigTypeDef,
):
    """
    Type definition for `ClientCreateLabelingJob` `InputConfig`

    Input data for the labeling job, such as the Amazon S3 location of the data objects and the
    location of the manifest file that describes the data objects.

    - **DataSource** *(dict) --* **[REQUIRED]**

      The location of the input data.

      - **S3DataSource** *(dict) --* **[REQUIRED]**

        The Amazon S3 location of the input data objects.

        - **ManifestS3Uri** *(string) --* **[REQUIRED]**

          The Amazon S3 location of the manifest file that describes the input data objects.

    - **DataAttributes** *(dict) --*

      Attributes of the data specified by the customer.

      - **ContentClassifiers** *(list) --*

        Declares that your content is free of personally identifiable information or adult content.
        Amazon SageMaker may restrict the Amazon Mechanical Turk workers that can view your task
        based on this information.

        - *(string) --*
    """


_ClientCreateLabelingJobLabelingJobAlgorithmsConfigLabelingJobResourceConfigTypeDef = TypedDict(
    "_ClientCreateLabelingJobLabelingJobAlgorithmsConfigLabelingJobResourceConfigTypeDef",
    {"VolumeKmsKeyId": str},
    total=False,
)


class ClientCreateLabelingJobLabelingJobAlgorithmsConfigLabelingJobResourceConfigTypeDef(
    _ClientCreateLabelingJobLabelingJobAlgorithmsConfigLabelingJobResourceConfigTypeDef
):
    """
    Type definition for `ClientCreateLabelingJobLabelingJobAlgorithmsConfig` `LabelingJobResourceConfig`

    Provides configuration information for a labeling job.

    - **VolumeKmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data on
      the storage volume attached to the ML compute instance(s) that run the training job. The
      ``VolumeKmsKeyId`` can be any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_RequiredClientCreateLabelingJobLabelingJobAlgorithmsConfigTypeDef = TypedDict(
    "_RequiredClientCreateLabelingJobLabelingJobAlgorithmsConfigTypeDef",
    {"LabelingJobAlgorithmSpecificationArn": str},
)
_OptionalClientCreateLabelingJobLabelingJobAlgorithmsConfigTypeDef = TypedDict(
    "_OptionalClientCreateLabelingJobLabelingJobAlgorithmsConfigTypeDef",
    {
        "InitialActiveLearningModelArn": str,
        "LabelingJobResourceConfig": ClientCreateLabelingJobLabelingJobAlgorithmsConfigLabelingJobResourceConfigTypeDef,
    },
    total=False,
)


class ClientCreateLabelingJobLabelingJobAlgorithmsConfigTypeDef(
    _RequiredClientCreateLabelingJobLabelingJobAlgorithmsConfigTypeDef,
    _OptionalClientCreateLabelingJobLabelingJobAlgorithmsConfigTypeDef,
):
    """
    Type definition for `ClientCreateLabelingJob` `LabelingJobAlgorithmsConfig`

    Configures the information required to perform automated data labeling.

    - **LabelingJobAlgorithmSpecificationArn** *(string) --* **[REQUIRED]**

      Specifies the Amazon Resource Name (ARN) of the algorithm used for auto-labeling. You must
      select one of the following ARNs:

      * *Image classification*    ``arn:aws:sagemaker:*region*
      :027400017018:labeling-job-algorithm-specification/image-classification``

      * *Text classification*    ``arn:aws:sagemaker:*region*
      :027400017018:labeling-job-algorithm-specification/text-classification``

      * *Object detection*    ``arn:aws:sagemaker:*region*
      :027400017018:labeling-job-algorithm-specification/object-detection``

      * *Semantic Segmentation*    ``arn:aws:sagemaker:*region*
      :027400017018:labeling-job-algorithm-specification/semantic-segmentation``

    - **InitialActiveLearningModelArn** *(string) --*

      At the end of an auto-label job Amazon SageMaker Ground Truth sends the Amazon Resource Nam
      (ARN) of the final model used for auto-labeling. You can use this model as the starting point
      for subsequent similar jobs by providing the ARN of the model here.

    - **LabelingJobResourceConfig** *(dict) --*

      Provides configuration information for a labeling job.

      - **VolumeKmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data on
        the storage volume attached to the ML compute instance(s) that run the training job. The
        ``VolumeKmsKeyId`` can be any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_RequiredClientCreateLabelingJobOutputConfigTypeDef = TypedDict(
    "_RequiredClientCreateLabelingJobOutputConfigTypeDef", {"S3OutputPath": str}
)
_OptionalClientCreateLabelingJobOutputConfigTypeDef = TypedDict(
    "_OptionalClientCreateLabelingJobOutputConfigTypeDef",
    {"KmsKeyId": str},
    total=False,
)


class ClientCreateLabelingJobOutputConfigTypeDef(
    _RequiredClientCreateLabelingJobOutputConfigTypeDef,
    _OptionalClientCreateLabelingJobOutputConfigTypeDef,
):
    """
    Type definition for `ClientCreateLabelingJob` `OutputConfig`

    The location of the output data and the AWS Key Management Service key ID for the key used to
    encrypt the output data, if any.

    - **S3OutputPath** *(string) --* **[REQUIRED]**

      The Amazon S3 location to write output data.

    - **KmsKeyId** *(string) --*

      The AWS Key Management Service ID of the key used to encrypt the output data, if any.

      If you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution role
      must include permissions to call ``kms:Encrypt`` . If you don't provide a KMS key ID, Amazon
      SageMaker uses the default KMS key for Amazon S3 for your role's account. Amazon SageMaker uses
      server-side encryption with KMS-managed keys for ``LabelingJobOutputConfig`` . If you use a
      bucket policy with an ``s3:PutObject`` permission that only allows objects with server-side
      encryption, set the condition key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For
      more information, see `KMS-Managed Encryption Keys
      <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the *Amazon
      Simple Storage Service Developer Guide.*

      The KMS key policy must grant permission to the IAM role that you specify in your
      ``CreateLabelingJob`` request. For more information, see `Using Key Policies in AWS KMS
      <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the *AWS Key
      Management Service Developer Guide* .
    """


_ClientCreateLabelingJobResponseTypeDef = TypedDict(
    "_ClientCreateLabelingJobResponseTypeDef", {"LabelingJobArn": str}, total=False
)


class ClientCreateLabelingJobResponseTypeDef(_ClientCreateLabelingJobResponseTypeDef):
    """
    Type definition for `ClientCreateLabelingJob` `Response`

    - **LabelingJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the labeling job. You use this ARN to identify the labeling
      job.
    """


_ClientCreateLabelingJobStoppingConditionsTypeDef = TypedDict(
    "_ClientCreateLabelingJobStoppingConditionsTypeDef",
    {"MaxHumanLabeledObjectCount": int, "MaxPercentageOfInputDatasetLabeled": int},
    total=False,
)


class ClientCreateLabelingJobStoppingConditionsTypeDef(
    _ClientCreateLabelingJobStoppingConditionsTypeDef
):
    """
    Type definition for `ClientCreateLabelingJob` `StoppingConditions`

    A set of conditions for stopping the labeling job. If any of the conditions are met, the job is
    automatically stopped. You can use these conditions to control the cost of data labeling.

    - **MaxHumanLabeledObjectCount** *(integer) --*

      The maximum number of objects that can be labeled by human workers.

    - **MaxPercentageOfInputDatasetLabeled** *(integer) --*

      The maximum number of input data objects that should be labeled.
    """


_ClientCreateLabelingJobTagsTypeDef = TypedDict(
    "_ClientCreateLabelingJobTagsTypeDef", {"Key": str, "Value": str}
)


class ClientCreateLabelingJobTagsTypeDef(_ClientCreateLabelingJobTagsTypeDef):
    """
    Type definition for `ClientCreateLabelingJob` `Tags`

    Describes a tag.

    - **Key** *(string) --* **[REQUIRED]**

      The tag key.

    - **Value** *(string) --* **[REQUIRED]**

      The tag value.
    """


_ClientCreateModelContainersTypeDef = TypedDict(
    "_ClientCreateModelContainersTypeDef",
    {
        "ContainerHostname": str,
        "Image": str,
        "Mode": str,
        "ModelDataUrl": str,
        "Environment": Dict[str, str],
        "ModelPackageName": str,
    },
    total=False,
)


class ClientCreateModelContainersTypeDef(_ClientCreateModelContainersTypeDef):
    """
    Type definition for `ClientCreateModel` `Containers`

    Describes the container, as part of model definition.

    - **ContainerHostname** *(string) --*

      This parameter is ignored for models that contain only a ``PrimaryContainer`` .

      When a ``ContainerDefinition`` is part of an inference pipeline, the value of ths parameter
      uniquely identifies the container for the purposes of logging and metrics. For information,
      see `Use Logs and Metrics to Monitor an Inference Pipeline
      <https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipeline-logs-metrics.html>`__ .
      If you don't specify a value for this parameter for a ``ContainerDefinition`` that is part of
      an inference pipeline, a unique name is automatically assigned based on the position of the
      ``ContainerDefinition`` in the pipeline. If you specify a value for the ``ContainerHostName``
      for any ``ContainerDefinition`` that is part of an inference pipeline, you must specify a
      value for the ``ContainerHostName`` parameter of every ``ContainerDefinition`` in that
      pipeline.

    - **Image** *(string) --*

      The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored. If you
      are using your own custom algorithm instead of an algorithm provided by Amazon SageMaker, the
      inference code must meet Amazon SageMaker requirements. Amazon SageMaker supports both
      ``registry/repository[:tag]`` and ``registry/repository[@digest]`` image path formats. For
      more information, see `Using Your Own Algorithms with Amazon SageMaker
      <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__

    - **Mode** *(string) --*

      Specifies whether the container hosts a single model or multiple models.

    - **ModelDataUrl** *(string) --*

      The S3 path where the model artifacts, which result from model training, are stored. This
      path must point to a single gzip compressed tar archive (.tar.gz suffix). The S3 path is
      required for Amazon SageMaker built-in algorithms, but not if you use your own algorithms.
      For more information on built-in algorithms, see `Common Parameters
      <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
      .

      If you provide a value for this parameter, Amazon SageMaker uses AWS Security Token Service
      to download model artifacts from the S3 path you provide. AWS STS is activated in your IAM
      user account by default. If you previously deactivated AWS STS for a region, you need to
      reactivate AWS STS for that region. For more information, see `Activating and Deactivating
      AWS STS in an AWS Region
      <https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_enable-regions.html>`__
      in the *AWS Identity and Access Management User Guide* .

      .. warning::

        If you use a built-in algorithm to create a model, Amazon SageMaker requires that you
        provide a S3 path to the model artifacts in ``ModelDataUrl`` .

    - **Environment** *(dict) --*

      The environment variables to set in the Docker container. Each key and value in the
      ``Environment`` string to string map can have length of up to 1024. We support up to 16
      entries in the map.

      - *(string) --*

        - *(string) --*

    - **ModelPackageName** *(string) --*

      The name or Amazon Resource Name (ARN) of the model package to use to create the model.
    """


_RequiredClientCreateModelPackageInferenceSpecificationContainersTypeDef = TypedDict(
    "_RequiredClientCreateModelPackageInferenceSpecificationContainersTypeDef",
    {"Image": str},
)
_OptionalClientCreateModelPackageInferenceSpecificationContainersTypeDef = TypedDict(
    "_OptionalClientCreateModelPackageInferenceSpecificationContainersTypeDef",
    {
        "ContainerHostname": str,
        "ImageDigest": str,
        "ModelDataUrl": str,
        "ProductId": str,
    },
    total=False,
)


class ClientCreateModelPackageInferenceSpecificationContainersTypeDef(
    _RequiredClientCreateModelPackageInferenceSpecificationContainersTypeDef,
    _OptionalClientCreateModelPackageInferenceSpecificationContainersTypeDef,
):
    """
    Type definition for `ClientCreateModelPackageInferenceSpecification` `Containers`

    Describes the Docker container for the model package.

    - **ContainerHostname** *(string) --*

      The DNS host name for the Docker container.

    - **Image** *(string) --* **[REQUIRED]**

      The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.

      If you are using your own custom algorithm instead of an algorithm provided by Amazon
      SageMaker, the inference code must meet Amazon SageMaker requirements. Amazon SageMaker
      supports both ``registry/repository[:tag]`` and ``registry/repository[@digest]`` image path
      formats. For more information, see `Using Your Own Algorithms with Amazon SageMaker
      <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

    - **ImageDigest** *(string) --*

      An MD5 hash of the training algorithm that identifies the Docker image used for training.

    - **ModelDataUrl** *(string) --*

      The Amazon S3 path where the model artifacts, which result from model training, are stored.
      This path must point to a single ``gzip`` compressed tar archive (``.tar.gz`` suffix).

    - **ProductId** *(string) --*

      The AWS Marketplace product ID of the model package.
    """


_ClientCreateModelPackageInferenceSpecificationTypeDef = TypedDict(
    "_ClientCreateModelPackageInferenceSpecificationTypeDef",
    {
        "Containers": List[
            ClientCreateModelPackageInferenceSpecificationContainersTypeDef
        ],
        "SupportedTransformInstanceTypes": List[str],
        "SupportedRealtimeInferenceInstanceTypes": List[str],
        "SupportedContentTypes": List[str],
        "SupportedResponseMIMETypes": List[str],
    },
)


class ClientCreateModelPackageInferenceSpecificationTypeDef(
    _ClientCreateModelPackageInferenceSpecificationTypeDef
):
    """
    Type definition for `ClientCreateModelPackage` `InferenceSpecification`

    Specifies details about inference jobs that can be run with models based on this model package,
    including the following:

    * The Amazon ECR paths of containers that contain the inference code and model artifacts.

    * The instance types that the model package supports for transform jobs and real-time endpoints
    used for inference.

    * The input and output content formats that the model package supports for inference.

    - **Containers** *(list) --* **[REQUIRED]**

      The Amazon ECR registry path of the Docker image that contains the inference code.

      - *(dict) --*

        Describes the Docker container for the model package.

        - **ContainerHostname** *(string) --*

          The DNS host name for the Docker container.

        - **Image** *(string) --* **[REQUIRED]**

          The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.

          If you are using your own custom algorithm instead of an algorithm provided by Amazon
          SageMaker, the inference code must meet Amazon SageMaker requirements. Amazon SageMaker
          supports both ``registry/repository[:tag]`` and ``registry/repository[@digest]`` image path
          formats. For more information, see `Using Your Own Algorithms with Amazon SageMaker
          <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

        - **ImageDigest** *(string) --*

          An MD5 hash of the training algorithm that identifies the Docker image used for training.

        - **ModelDataUrl** *(string) --*

          The Amazon S3 path where the model artifacts, which result from model training, are stored.
          This path must point to a single ``gzip`` compressed tar archive (``.tar.gz`` suffix).

        - **ProductId** *(string) --*

          The AWS Marketplace product ID of the model package.

    - **SupportedTransformInstanceTypes** *(list) --* **[REQUIRED]**

      A list of the instance types on which a transformation job can be run or on which an endpoint
      can be deployed.

      - *(string) --*

    - **SupportedRealtimeInferenceInstanceTypes** *(list) --* **[REQUIRED]**

      A list of the instance types that are used to generate inferences in real-time.

      - *(string) --*

    - **SupportedContentTypes** *(list) --* **[REQUIRED]**

      The supported MIME types for the input data.

      - *(string) --*

    - **SupportedResponseMIMETypes** *(list) --* **[REQUIRED]**

      The supported MIME types for the output data.

      - *(string) --*
    """


_ClientCreateModelPackageResponseTypeDef = TypedDict(
    "_ClientCreateModelPackageResponseTypeDef", {"ModelPackageArn": str}, total=False
)


class ClientCreateModelPackageResponseTypeDef(_ClientCreateModelPackageResponseTypeDef):
    """
    Type definition for `ClientCreateModelPackage` `Response`

    - **ModelPackageArn** *(string) --*

      The Amazon Resource Name (ARN) of the new model package.
    """


_RequiredClientCreateModelPackageSourceAlgorithmSpecificationSourceAlgorithmsTypeDef = TypedDict(
    "_RequiredClientCreateModelPackageSourceAlgorithmSpecificationSourceAlgorithmsTypeDef",
    {"AlgorithmName": str},
)
_OptionalClientCreateModelPackageSourceAlgorithmSpecificationSourceAlgorithmsTypeDef = TypedDict(
    "_OptionalClientCreateModelPackageSourceAlgorithmSpecificationSourceAlgorithmsTypeDef",
    {"ModelDataUrl": str},
    total=False,
)


class ClientCreateModelPackageSourceAlgorithmSpecificationSourceAlgorithmsTypeDef(
    _RequiredClientCreateModelPackageSourceAlgorithmSpecificationSourceAlgorithmsTypeDef,
    _OptionalClientCreateModelPackageSourceAlgorithmSpecificationSourceAlgorithmsTypeDef,
):
    """
    Type definition for `ClientCreateModelPackageSourceAlgorithmSpecification` `SourceAlgorithms`

    Specifies an algorithm that was used to create the model package. The algorithm must be
    either an algorithm resource in your Amazon SageMaker account or an algorithm in AWS
    Marketplace that you are subscribed to.

    - **ModelDataUrl** *(string) --*

      The Amazon S3 path where the model artifacts, which result from model training, are stored.
      This path must point to a single ``gzip`` compressed tar archive (``.tar.gz`` suffix).

    - **AlgorithmName** *(string) --* **[REQUIRED]**

      The name of an algorithm that was used to create the model package. The algorithm must be
      either an algorithm resource in your Amazon SageMaker account or an algorithm in AWS
      Marketplace that you are subscribed to.
    """


_ClientCreateModelPackageSourceAlgorithmSpecificationTypeDef = TypedDict(
    "_ClientCreateModelPackageSourceAlgorithmSpecificationTypeDef",
    {
        "SourceAlgorithms": List[
            ClientCreateModelPackageSourceAlgorithmSpecificationSourceAlgorithmsTypeDef
        ]
    },
)


class ClientCreateModelPackageSourceAlgorithmSpecificationTypeDef(
    _ClientCreateModelPackageSourceAlgorithmSpecificationTypeDef
):
    """
    Type definition for `ClientCreateModelPackage` `SourceAlgorithmSpecification`

    Details about the algorithm that was used to create the model package.

    - **SourceAlgorithms** *(list) --* **[REQUIRED]**

      A list of the algorithms that were used to create a model package.

      - *(dict) --*

        Specifies an algorithm that was used to create the model package. The algorithm must be
        either an algorithm resource in your Amazon SageMaker account or an algorithm in AWS
        Marketplace that you are subscribed to.

        - **ModelDataUrl** *(string) --*

          The Amazon S3 path where the model artifacts, which result from model training, are stored.
          This path must point to a single ``gzip`` compressed tar archive (``.tar.gz`` suffix).

        - **AlgorithmName** *(string) --* **[REQUIRED]**

          The name of an algorithm that was used to create the model package. The algorithm must be
          either an algorithm resource in your Amazon SageMaker account or an algorithm in AWS
          Marketplace that you are subscribed to.
    """


_ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef = TypedDict(
    "_ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef",
    {"S3DataType": str, "S3Uri": str},
)


class ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef(
    _ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef
):
    """
    Type definition for `ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSource` `S3DataSource`

    The S3 location of the data source that is associated with a channel.

    - **S3DataType** *(string) --* **[REQUIRED]**

      If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
      SageMaker uses all objects with the specified key name prefix for batch transform.

      If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
      file containing a list of object keys that you want Amazon SageMaker to use for
      batch transform.

      The following values are compatible: ``ManifestFile`` , ``S3Prefix``

      The following value is not compatible: ``AugmentedManifestFile``

    - **S3Uri** *(string) --* **[REQUIRED]**

      Depending on the value specified for the ``S3DataType`` , identifies either a key
      name prefix or a manifest. For example:

      * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

      * A manifest might look like this: ``s3://bucketname/example.manifest``   The
      manifest is an S3 object which is a JSON file with the following format:   ``[
      {"prefix": "s3://customer_bucket/some/prefix/"},``
      ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``    ``...``
      ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the following
      ``s3Uris`` :   ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
      ``S3Uris`` in this manifest constitutes the input data for the channel for this
      datasource. The object that each ``S3Uris`` points to must be readable by the IAM
      role that Amazon SageMaker uses to perform tasks on your behalf.
    """


_ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef = TypedDict(
    "_ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef",
    {
        "S3DataSource": ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef
    },
)


class ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef(
    _ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef
):
    """
    Type definition for `ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInput` `DataSource`

    Describes the location of the channel data, which is, the S3 location of the input data
    that the model can consume.

    - **S3DataSource** *(dict) --* **[REQUIRED]**

      The S3 location of the data source that is associated with a channel.

      - **S3DataType** *(string) --* **[REQUIRED]**

        If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
        SageMaker uses all objects with the specified key name prefix for batch transform.

        If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
        file containing a list of object keys that you want Amazon SageMaker to use for
        batch transform.

        The following values are compatible: ``ManifestFile`` , ``S3Prefix``

        The following value is not compatible: ``AugmentedManifestFile``

      - **S3Uri** *(string) --* **[REQUIRED]**

        Depending on the value specified for the ``S3DataType`` , identifies either a key
        name prefix or a manifest. For example:

        * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

        * A manifest might look like this: ``s3://bucketname/example.manifest``   The
        manifest is an S3 object which is a JSON file with the following format:   ``[
        {"prefix": "s3://customer_bucket/some/prefix/"},``
        ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``    ``...``
        ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the following
        ``s3Uris`` :   ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
        ``S3Uris`` in this manifest constitutes the input data for the channel for this
        datasource. The object that each ``S3Uris`` points to must be readable by the IAM
        role that Amazon SageMaker uses to perform tasks on your behalf.
    """


_RequiredClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef = TypedDict(
    "_RequiredClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef",
    {
        "DataSource": ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef
    },
)
_OptionalClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef = TypedDict(
    "_OptionalClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef",
    {"ContentType": str, "CompressionType": str, "SplitType": str},
    total=False,
)


class ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef(
    _RequiredClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef,
    _OptionalClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef,
):
    """
    Type definition for `ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinition` `TransformInput`

    A description of the input source and the way the transform job consumes it.

    - **DataSource** *(dict) --* **[REQUIRED]**

      Describes the location of the channel data, which is, the S3 location of the input data
      that the model can consume.

      - **S3DataSource** *(dict) --* **[REQUIRED]**

        The S3 location of the data source that is associated with a channel.

        - **S3DataType** *(string) --* **[REQUIRED]**

          If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
          SageMaker uses all objects with the specified key name prefix for batch transform.

          If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
          file containing a list of object keys that you want Amazon SageMaker to use for
          batch transform.

          The following values are compatible: ``ManifestFile`` , ``S3Prefix``

          The following value is not compatible: ``AugmentedManifestFile``

        - **S3Uri** *(string) --* **[REQUIRED]**

          Depending on the value specified for the ``S3DataType`` , identifies either a key
          name prefix or a manifest. For example:

          * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

          * A manifest might look like this: ``s3://bucketname/example.manifest``   The
          manifest is an S3 object which is a JSON file with the following format:   ``[
          {"prefix": "s3://customer_bucket/some/prefix/"},``
          ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``    ``...``
          ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the following
          ``s3Uris`` :   ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
          ``S3Uris`` in this manifest constitutes the input data for the channel for this
          datasource. The object that each ``S3Uris`` points to must be readable by the IAM
          role that Amazon SageMaker uses to perform tasks on your behalf.

    - **ContentType** *(string) --*

      The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker uses
      the MIME type with each http call to transfer data to the transform job.

    - **CompressionType** *(string) --*

      If your transform data is compressed, specify the compression type. Amazon SageMaker
      automatically decompresses the data for the transform job accordingly. The default
      value is ``None`` .

    - **SplitType** *(string) --*

      The method to use to split the transform job's data files into smaller batches.
      Splitting is necessary when the total size of each object is too large to fit in a
      single request. You can also use data splitting to improve performance by processing
      multiple concurrent mini-batches. The default value for ``SplitType`` is ``None`` ,
      which indicates that input data files are not split, and request payloads contain the
      entire contents of an input object. Set the value of this parameter to ``Line`` to
      split records on a newline character boundary. ``SplitType`` also supports a number of
      record-oriented binary data formats.

      When splitting is enabled, the size of a mini-batch depends on the values of the
      ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
      ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
      records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
      ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records in
      each request.

      .. note::

        Some data formats represent a record as a binary payload wrapped with extra padding
        bytes. When splitting is applied to a binary data format, padding is removed if the
        value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is not removed if the
        value of ``BatchStrategy`` is set to ``MultiRecord`` .

        For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
        <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For more
        information about ``TFRecord`` , see `Consuming TFRecord data
        <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
        TensorFlow documentation.
    """


_RequiredClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef = TypedDict(
    "_RequiredClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef",
    {"S3OutputPath": str},
)
_OptionalClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef = TypedDict(
    "_OptionalClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef",
    {"Accept": str, "AssembleWith": str, "KmsKeyId": str},
    total=False,
)


class ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef(
    _RequiredClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef,
    _OptionalClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef,
):
    """
    Type definition for `ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinition` `TransformOutput`

    Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
    from the transform job.

    - **S3OutputPath** *(string) --* **[REQUIRED]**

      The Amazon S3 path where you want Amazon SageMaker to store the results of the
      transform job. For example, ``s3://bucket-name/key-name-prefix`` .

      For every S3 object used as input for the transform job, batch transform stores the
      transformed data with an .``out`` suffix in a corresponding subfolder in the location
      in the output prefix. For example, for the input data stored at
      ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores the
      transformed data at
      ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
      transform doesn't upload partially processed objects. For an input S3 object that
      contains multiple records, it creates an .``out`` file only if the transform job
      succeeds on the entire file. When the input contains multiple S3 objects, the batch
      transform job processes the listed S3 objects and uploads only the output for
      successfully processed objects. If any object fails in the transform job batch
      transform marks the job as failed to prompt investigation.

    - **Accept** *(string) --*

      The MIME type used to specify the output data. Amazon SageMaker uses the MIME type with
      each http call to transfer data from the transform job.

    - **AssembleWith** *(string) --*

      Defines how to assemble the results of the transform job as a single S3 object. Choose
      a format that is most convenient to you. To concatenate the results in binary format,
      specify ``None`` . To add a newline character at the end of every transformed record,
      specify ``Line`` .

    - **KmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
      model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be
      any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // KMS Key Alias  ``"alias/ExampleAlias"``

      * // Amazon Resource Name (ARN) of a KMS Key Alias
      ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

      If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon
      S3 for your role's account. For more information, see `KMS-Managed Encryption Keys
      <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
      *Amazon Simple Storage Service Developer Guide.*

      The KMS key policy must grant permission to the IAM role that you specify in your
      CreateModel request. For more information, see `Using Key Policies in AWS KMS
      <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the *AWS
      Key Management Service Developer Guide* .
    """


_RequiredClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef = TypedDict(
    "_RequiredClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef",
    {"InstanceType": str, "InstanceCount": int},
)
_OptionalClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef = TypedDict(
    "_OptionalClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef",
    {"VolumeKmsKeyId": str},
    total=False,
)


class ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef(
    _RequiredClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef,
    _OptionalClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef,
):
    """
    Type definition for `ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinition` `TransformResources`

    Identifies the ML compute instances for the transform job.

    - **InstanceType** *(string) --* **[REQUIRED]**

      The ML compute instance type for the transform job. If you are using built-in
      algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge or
      ``ml.m5.large`` instance types.

    - **InstanceCount** *(integer) --* **[REQUIRED]**

      The number of ML compute instances to use in the transform job. For distributed
      transform jobs, specify a value greater than 1. The default value is ``1`` .

    - **VolumeKmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data
      on the storage volume attached to the ML compute instance(s) that run the batch
      transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_RequiredClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef = TypedDict(
    "_RequiredClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef",
    {
        "TransformInput": ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef,
        "TransformOutput": ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef,
        "TransformResources": ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef,
    },
)
_OptionalClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef = TypedDict(
    "_OptionalClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef",
    {
        "MaxConcurrentTransforms": int,
        "MaxPayloadInMB": int,
        "BatchStrategy": str,
        "Environment": Dict[str, str],
    },
    total=False,
)


class ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef(
    _RequiredClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef,
    _OptionalClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef,
):
    """
    Type definition for `ClientCreateModelPackageValidationSpecificationValidationProfiles` `TransformJobDefinition`

    The ``TransformJobDefinition`` object that describes the transform job used for the
    validation of the model package.

    - **MaxConcurrentTransforms** *(integer) --*

      The maximum number of parallel requests that can be sent to each instance in a transform
      job. The default value is 1.

    - **MaxPayloadInMB** *(integer) --*

      The maximum payload size allowed, in MB. A payload is the data portion of a record
      (without metadata).

    - **BatchStrategy** *(string) --*

      A string that determines the number of records included in a single mini-batch.

       ``SingleRecord`` means only one record is used per mini-batch. ``MultiRecord`` means a
       mini-batch is set to contain as many records that can fit within the ``MaxPayloadInMB``
       limit.

    - **Environment** *(dict) --*

      The environment variables to set in the Docker container. We support up to 16 key and
      values entries in the map.

      - *(string) --*

        - *(string) --*

    - **TransformInput** *(dict) --* **[REQUIRED]**

      A description of the input source and the way the transform job consumes it.

      - **DataSource** *(dict) --* **[REQUIRED]**

        Describes the location of the channel data, which is, the S3 location of the input data
        that the model can consume.

        - **S3DataSource** *(dict) --* **[REQUIRED]**

          The S3 location of the data source that is associated with a channel.

          - **S3DataType** *(string) --* **[REQUIRED]**

            If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
            SageMaker uses all objects with the specified key name prefix for batch transform.

            If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
            file containing a list of object keys that you want Amazon SageMaker to use for
            batch transform.

            The following values are compatible: ``ManifestFile`` , ``S3Prefix``

            The following value is not compatible: ``AugmentedManifestFile``

          - **S3Uri** *(string) --* **[REQUIRED]**

            Depending on the value specified for the ``S3DataType`` , identifies either a key
            name prefix or a manifest. For example:

            * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

            * A manifest might look like this: ``s3://bucketname/example.manifest``   The
            manifest is an S3 object which is a JSON file with the following format:   ``[
            {"prefix": "s3://customer_bucket/some/prefix/"},``
            ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``    ``...``
            ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the following
            ``s3Uris`` :   ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
            ``S3Uris`` in this manifest constitutes the input data for the channel for this
            datasource. The object that each ``S3Uris`` points to must be readable by the IAM
            role that Amazon SageMaker uses to perform tasks on your behalf.

      - **ContentType** *(string) --*

        The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker uses
        the MIME type with each http call to transfer data to the transform job.

      - **CompressionType** *(string) --*

        If your transform data is compressed, specify the compression type. Amazon SageMaker
        automatically decompresses the data for the transform job accordingly. The default
        value is ``None`` .

      - **SplitType** *(string) --*

        The method to use to split the transform job's data files into smaller batches.
        Splitting is necessary when the total size of each object is too large to fit in a
        single request. You can also use data splitting to improve performance by processing
        multiple concurrent mini-batches. The default value for ``SplitType`` is ``None`` ,
        which indicates that input data files are not split, and request payloads contain the
        entire contents of an input object. Set the value of this parameter to ``Line`` to
        split records on a newline character boundary. ``SplitType`` also supports a number of
        record-oriented binary data formats.

        When splitting is enabled, the size of a mini-batch depends on the values of the
        ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
        ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
        records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
        ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records in
        each request.

        .. note::

          Some data formats represent a record as a binary payload wrapped with extra padding
          bytes. When splitting is applied to a binary data format, padding is removed if the
          value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is not removed if the
          value of ``BatchStrategy`` is set to ``MultiRecord`` .

          For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
          <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For more
          information about ``TFRecord`` , see `Consuming TFRecord data
          <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
          TensorFlow documentation.

    - **TransformOutput** *(dict) --* **[REQUIRED]**

      Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
      from the transform job.

      - **S3OutputPath** *(string) --* **[REQUIRED]**

        The Amazon S3 path where you want Amazon SageMaker to store the results of the
        transform job. For example, ``s3://bucket-name/key-name-prefix`` .

        For every S3 object used as input for the transform job, batch transform stores the
        transformed data with an .``out`` suffix in a corresponding subfolder in the location
        in the output prefix. For example, for the input data stored at
        ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores the
        transformed data at
        ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
        transform doesn't upload partially processed objects. For an input S3 object that
        contains multiple records, it creates an .``out`` file only if the transform job
        succeeds on the entire file. When the input contains multiple S3 objects, the batch
        transform job processes the listed S3 objects and uploads only the output for
        successfully processed objects. If any object fails in the transform job batch
        transform marks the job as failed to prompt investigation.

      - **Accept** *(string) --*

        The MIME type used to specify the output data. Amazon SageMaker uses the MIME type with
        each http call to transfer data from the transform job.

      - **AssembleWith** *(string) --*

        Defines how to assemble the results of the transform job as a single S3 object. Choose
        a format that is most convenient to you. To concatenate the results in binary format,
        specify ``None`` . To add a newline character at the end of every transformed record,
        specify ``Line`` .

      - **KmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
        model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be
        any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // KMS Key Alias  ``"alias/ExampleAlias"``

        * // Amazon Resource Name (ARN) of a KMS Key Alias
        ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

        If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon
        S3 for your role's account. For more information, see `KMS-Managed Encryption Keys
        <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
        *Amazon Simple Storage Service Developer Guide.*

        The KMS key policy must grant permission to the IAM role that you specify in your
        CreateModel request. For more information, see `Using Key Policies in AWS KMS
        <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the *AWS
        Key Management Service Developer Guide* .

    - **TransformResources** *(dict) --* **[REQUIRED]**

      Identifies the ML compute instances for the transform job.

      - **InstanceType** *(string) --* **[REQUIRED]**

        The ML compute instance type for the transform job. If you are using built-in
        algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge or
        ``ml.m5.large`` instance types.

      - **InstanceCount** *(integer) --* **[REQUIRED]**

        The number of ML compute instances to use in the transform job. For distributed
        transform jobs, specify a value greater than 1. The default value is ``1`` .

      - **VolumeKmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data
        on the storage volume attached to the ML compute instance(s) that run the batch
        transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientCreateModelPackageValidationSpecificationValidationProfilesTypeDef = TypedDict(
    "_ClientCreateModelPackageValidationSpecificationValidationProfilesTypeDef",
    {
        "ProfileName": str,
        "TransformJobDefinition": ClientCreateModelPackageValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef,
    },
)


class ClientCreateModelPackageValidationSpecificationValidationProfilesTypeDef(
    _ClientCreateModelPackageValidationSpecificationValidationProfilesTypeDef
):
    """
    Type definition for `ClientCreateModelPackageValidationSpecification` `ValidationProfiles`

    Contains data, such as the inputs and targeted instance types that are used in the process of
    validating the model package.

    The data provided in the validation profile is made available to your buyers on AWS
    Marketplace.

    - **ProfileName** *(string) --* **[REQUIRED]**

      The name of the profile for the model package.

    - **TransformJobDefinition** *(dict) --* **[REQUIRED]**

      The ``TransformJobDefinition`` object that describes the transform job used for the
      validation of the model package.

      - **MaxConcurrentTransforms** *(integer) --*

        The maximum number of parallel requests that can be sent to each instance in a transform
        job. The default value is 1.

      - **MaxPayloadInMB** *(integer) --*

        The maximum payload size allowed, in MB. A payload is the data portion of a record
        (without metadata).

      - **BatchStrategy** *(string) --*

        A string that determines the number of records included in a single mini-batch.

         ``SingleRecord`` means only one record is used per mini-batch. ``MultiRecord`` means a
         mini-batch is set to contain as many records that can fit within the ``MaxPayloadInMB``
         limit.

      - **Environment** *(dict) --*

        The environment variables to set in the Docker container. We support up to 16 key and
        values entries in the map.

        - *(string) --*

          - *(string) --*

      - **TransformInput** *(dict) --* **[REQUIRED]**

        A description of the input source and the way the transform job consumes it.

        - **DataSource** *(dict) --* **[REQUIRED]**

          Describes the location of the channel data, which is, the S3 location of the input data
          that the model can consume.

          - **S3DataSource** *(dict) --* **[REQUIRED]**

            The S3 location of the data source that is associated with a channel.

            - **S3DataType** *(string) --* **[REQUIRED]**

              If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
              SageMaker uses all objects with the specified key name prefix for batch transform.

              If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
              file containing a list of object keys that you want Amazon SageMaker to use for
              batch transform.

              The following values are compatible: ``ManifestFile`` , ``S3Prefix``

              The following value is not compatible: ``AugmentedManifestFile``

            - **S3Uri** *(string) --* **[REQUIRED]**

              Depending on the value specified for the ``S3DataType`` , identifies either a key
              name prefix or a manifest. For example:

              * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

              * A manifest might look like this: ``s3://bucketname/example.manifest``   The
              manifest is an S3 object which is a JSON file with the following format:   ``[
              {"prefix": "s3://customer_bucket/some/prefix/"},``
              ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``    ``...``
              ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the following
              ``s3Uris`` :   ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
              ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
              ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
              ``S3Uris`` in this manifest constitutes the input data for the channel for this
              datasource. The object that each ``S3Uris`` points to must be readable by the IAM
              role that Amazon SageMaker uses to perform tasks on your behalf.

        - **ContentType** *(string) --*

          The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker uses
          the MIME type with each http call to transfer data to the transform job.

        - **CompressionType** *(string) --*

          If your transform data is compressed, specify the compression type. Amazon SageMaker
          automatically decompresses the data for the transform job accordingly. The default
          value is ``None`` .

        - **SplitType** *(string) --*

          The method to use to split the transform job's data files into smaller batches.
          Splitting is necessary when the total size of each object is too large to fit in a
          single request. You can also use data splitting to improve performance by processing
          multiple concurrent mini-batches. The default value for ``SplitType`` is ``None`` ,
          which indicates that input data files are not split, and request payloads contain the
          entire contents of an input object. Set the value of this parameter to ``Line`` to
          split records on a newline character boundary. ``SplitType`` also supports a number of
          record-oriented binary data formats.

          When splitting is enabled, the size of a mini-batch depends on the values of the
          ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
          ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
          records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
          ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records in
          each request.

          .. note::

            Some data formats represent a record as a binary payload wrapped with extra padding
            bytes. When splitting is applied to a binary data format, padding is removed if the
            value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is not removed if the
            value of ``BatchStrategy`` is set to ``MultiRecord`` .

            For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
            <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For more
            information about ``TFRecord`` , see `Consuming TFRecord data
            <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
            TensorFlow documentation.

      - **TransformOutput** *(dict) --* **[REQUIRED]**

        Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
        from the transform job.

        - **S3OutputPath** *(string) --* **[REQUIRED]**

          The Amazon S3 path where you want Amazon SageMaker to store the results of the
          transform job. For example, ``s3://bucket-name/key-name-prefix`` .

          For every S3 object used as input for the transform job, batch transform stores the
          transformed data with an .``out`` suffix in a corresponding subfolder in the location
          in the output prefix. For example, for the input data stored at
          ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores the
          transformed data at
          ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
          transform doesn't upload partially processed objects. For an input S3 object that
          contains multiple records, it creates an .``out`` file only if the transform job
          succeeds on the entire file. When the input contains multiple S3 objects, the batch
          transform job processes the listed S3 objects and uploads only the output for
          successfully processed objects. If any object fails in the transform job batch
          transform marks the job as failed to prompt investigation.

        - **Accept** *(string) --*

          The MIME type used to specify the output data. Amazon SageMaker uses the MIME type with
          each http call to transfer data from the transform job.

        - **AssembleWith** *(string) --*

          Defines how to assemble the results of the transform job as a single S3 object. Choose
          a format that is most convenient to you. To concatenate the results in binary format,
          specify ``None`` . To add a newline character at the end of every transformed record,
          specify ``Line`` .

        - **KmsKeyId** *(string) --*

          The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
          model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be
          any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // KMS Key Alias  ``"alias/ExampleAlias"``

          * // Amazon Resource Name (ARN) of a KMS Key Alias
          ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

          If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon
          S3 for your role's account. For more information, see `KMS-Managed Encryption Keys
          <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
          *Amazon Simple Storage Service Developer Guide.*

          The KMS key policy must grant permission to the IAM role that you specify in your
          CreateModel request. For more information, see `Using Key Policies in AWS KMS
          <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the *AWS
          Key Management Service Developer Guide* .

      - **TransformResources** *(dict) --* **[REQUIRED]**

        Identifies the ML compute instances for the transform job.

        - **InstanceType** *(string) --* **[REQUIRED]**

          The ML compute instance type for the transform job. If you are using built-in
          algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge or
          ``ml.m5.large`` instance types.

        - **InstanceCount** *(integer) --* **[REQUIRED]**

          The number of ML compute instances to use in the transform job. For distributed
          transform jobs, specify a value greater than 1. The default value is ``1`` .

        - **VolumeKmsKeyId** *(string) --*

          The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data
          on the storage volume attached to the ML compute instance(s) that run the batch
          transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientCreateModelPackageValidationSpecificationTypeDef = TypedDict(
    "_ClientCreateModelPackageValidationSpecificationTypeDef",
    {
        "ValidationRole": str,
        "ValidationProfiles": List[
            ClientCreateModelPackageValidationSpecificationValidationProfilesTypeDef
        ],
    },
)


class ClientCreateModelPackageValidationSpecificationTypeDef(
    _ClientCreateModelPackageValidationSpecificationTypeDef
):
    """
    Type definition for `ClientCreateModelPackage` `ValidationSpecification`

    Specifies configurations for one or more transform jobs that Amazon SageMaker runs to test the
    model package.

    - **ValidationRole** *(string) --* **[REQUIRED]**

      The IAM roles to be used for the validation of the model package.

    - **ValidationProfiles** *(list) --* **[REQUIRED]**

      An array of ``ModelPackageValidationProfile`` objects, each of which specifies a batch
      transform job that Amazon SageMaker runs to validate your model package.

      - *(dict) --*

        Contains data, such as the inputs and targeted instance types that are used in the process of
        validating the model package.

        The data provided in the validation profile is made available to your buyers on AWS
        Marketplace.

        - **ProfileName** *(string) --* **[REQUIRED]**

          The name of the profile for the model package.

        - **TransformJobDefinition** *(dict) --* **[REQUIRED]**

          The ``TransformJobDefinition`` object that describes the transform job used for the
          validation of the model package.

          - **MaxConcurrentTransforms** *(integer) --*

            The maximum number of parallel requests that can be sent to each instance in a transform
            job. The default value is 1.

          - **MaxPayloadInMB** *(integer) --*

            The maximum payload size allowed, in MB. A payload is the data portion of a record
            (without metadata).

          - **BatchStrategy** *(string) --*

            A string that determines the number of records included in a single mini-batch.

             ``SingleRecord`` means only one record is used per mini-batch. ``MultiRecord`` means a
             mini-batch is set to contain as many records that can fit within the ``MaxPayloadInMB``
             limit.

          - **Environment** *(dict) --*

            The environment variables to set in the Docker container. We support up to 16 key and
            values entries in the map.

            - *(string) --*

              - *(string) --*

          - **TransformInput** *(dict) --* **[REQUIRED]**

            A description of the input source and the way the transform job consumes it.

            - **DataSource** *(dict) --* **[REQUIRED]**

              Describes the location of the channel data, which is, the S3 location of the input data
              that the model can consume.

              - **S3DataSource** *(dict) --* **[REQUIRED]**

                The S3 location of the data source that is associated with a channel.

                - **S3DataType** *(string) --* **[REQUIRED]**

                  If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
                  SageMaker uses all objects with the specified key name prefix for batch transform.

                  If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
                  file containing a list of object keys that you want Amazon SageMaker to use for
                  batch transform.

                  The following values are compatible: ``ManifestFile`` , ``S3Prefix``

                  The following value is not compatible: ``AugmentedManifestFile``

                - **S3Uri** *(string) --* **[REQUIRED]**

                  Depending on the value specified for the ``S3DataType`` , identifies either a key
                  name prefix or a manifest. For example:

                  * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

                  * A manifest might look like this: ``s3://bucketname/example.manifest``   The
                  manifest is an S3 object which is a JSON file with the following format:   ``[
                  {"prefix": "s3://customer_bucket/some/prefix/"},``
                  ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``    ``...``
                  ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the following
                  ``s3Uris`` :   ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                  ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                  ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
                  ``S3Uris`` in this manifest constitutes the input data for the channel for this
                  datasource. The object that each ``S3Uris`` points to must be readable by the IAM
                  role that Amazon SageMaker uses to perform tasks on your behalf.

            - **ContentType** *(string) --*

              The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker uses
              the MIME type with each http call to transfer data to the transform job.

            - **CompressionType** *(string) --*

              If your transform data is compressed, specify the compression type. Amazon SageMaker
              automatically decompresses the data for the transform job accordingly. The default
              value is ``None`` .

            - **SplitType** *(string) --*

              The method to use to split the transform job's data files into smaller batches.
              Splitting is necessary when the total size of each object is too large to fit in a
              single request. You can also use data splitting to improve performance by processing
              multiple concurrent mini-batches. The default value for ``SplitType`` is ``None`` ,
              which indicates that input data files are not split, and request payloads contain the
              entire contents of an input object. Set the value of this parameter to ``Line`` to
              split records on a newline character boundary. ``SplitType`` also supports a number of
              record-oriented binary data formats.

              When splitting is enabled, the size of a mini-batch depends on the values of the
              ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
              ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
              records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
              ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records in
              each request.

              .. note::

                Some data formats represent a record as a binary payload wrapped with extra padding
                bytes. When splitting is applied to a binary data format, padding is removed if the
                value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is not removed if the
                value of ``BatchStrategy`` is set to ``MultiRecord`` .

                For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
                <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For more
                information about ``TFRecord`` , see `Consuming TFRecord data
                <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
                TensorFlow documentation.

          - **TransformOutput** *(dict) --* **[REQUIRED]**

            Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
            from the transform job.

            - **S3OutputPath** *(string) --* **[REQUIRED]**

              The Amazon S3 path where you want Amazon SageMaker to store the results of the
              transform job. For example, ``s3://bucket-name/key-name-prefix`` .

              For every S3 object used as input for the transform job, batch transform stores the
              transformed data with an .``out`` suffix in a corresponding subfolder in the location
              in the output prefix. For example, for the input data stored at
              ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores the
              transformed data at
              ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
              transform doesn't upload partially processed objects. For an input S3 object that
              contains multiple records, it creates an .``out`` file only if the transform job
              succeeds on the entire file. When the input contains multiple S3 objects, the batch
              transform job processes the listed S3 objects and uploads only the output for
              successfully processed objects. If any object fails in the transform job batch
              transform marks the job as failed to prompt investigation.

            - **Accept** *(string) --*

              The MIME type used to specify the output data. Amazon SageMaker uses the MIME type with
              each http call to transfer data from the transform job.

            - **AssembleWith** *(string) --*

              Defines how to assemble the results of the transform job as a single S3 object. Choose
              a format that is most convenient to you. To concatenate the results in binary format,
              specify ``None`` . To add a newline character at the end of every transformed record,
              specify ``Line`` .

            - **KmsKeyId** *(string) --*

              The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
              model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be
              any of the following formats:

              * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // Amazon Resource Name (ARN) of a KMS Key
              ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // KMS Key Alias  ``"alias/ExampleAlias"``

              * // Amazon Resource Name (ARN) of a KMS Key Alias
              ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

              If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon
              S3 for your role's account. For more information, see `KMS-Managed Encryption Keys
              <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
              *Amazon Simple Storage Service Developer Guide.*

              The KMS key policy must grant permission to the IAM role that you specify in your
              CreateModel request. For more information, see `Using Key Policies in AWS KMS
              <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the *AWS
              Key Management Service Developer Guide* .

          - **TransformResources** *(dict) --* **[REQUIRED]**

            Identifies the ML compute instances for the transform job.

            - **InstanceType** *(string) --* **[REQUIRED]**

              The ML compute instance type for the transform job. If you are using built-in
              algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge or
              ``ml.m5.large`` instance types.

            - **InstanceCount** *(integer) --* **[REQUIRED]**

              The number of ML compute instances to use in the transform job. For distributed
              transform jobs, specify a value greater than 1. The default value is ``1`` .

            - **VolumeKmsKeyId** *(string) --*

              The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data
              on the storage volume attached to the ML compute instance(s) that run the batch
              transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

              * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // Amazon Resource Name (ARN) of a KMS Key
              ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientCreateModelPrimaryContainerTypeDef = TypedDict(
    "_ClientCreateModelPrimaryContainerTypeDef",
    {
        "ContainerHostname": str,
        "Image": str,
        "Mode": str,
        "ModelDataUrl": str,
        "Environment": Dict[str, str],
        "ModelPackageName": str,
    },
    total=False,
)


class ClientCreateModelPrimaryContainerTypeDef(
    _ClientCreateModelPrimaryContainerTypeDef
):
    """
    Type definition for `ClientCreateModel` `PrimaryContainer`

    The location of the primary docker image containing inference code, associated artifacts, and
    custom environment map that the inference code uses when the model is deployed for predictions.

    - **ContainerHostname** *(string) --*

      This parameter is ignored for models that contain only a ``PrimaryContainer`` .

      When a ``ContainerDefinition`` is part of an inference pipeline, the value of ths parameter
      uniquely identifies the container for the purposes of logging and metrics. For information, see
      `Use Logs and Metrics to Monitor an Inference Pipeline
      <https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipeline-logs-metrics.html>`__ . If
      you don't specify a value for this parameter for a ``ContainerDefinition`` that is part of an
      inference pipeline, a unique name is automatically assigned based on the position of the
      ``ContainerDefinition`` in the pipeline. If you specify a value for the ``ContainerHostName``
      for any ``ContainerDefinition`` that is part of an inference pipeline, you must specify a value
      for the ``ContainerHostName`` parameter of every ``ContainerDefinition`` in that pipeline.

    - **Image** *(string) --*

      The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored. If you are
      using your own custom algorithm instead of an algorithm provided by Amazon SageMaker, the
      inference code must meet Amazon SageMaker requirements. Amazon SageMaker supports both
      ``registry/repository[:tag]`` and ``registry/repository[@digest]`` image path formats. For more
      information, see `Using Your Own Algorithms with Amazon SageMaker
      <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__

    - **Mode** *(string) --*

      Specifies whether the container hosts a single model or multiple models.

    - **ModelDataUrl** *(string) --*

      The S3 path where the model artifacts, which result from model training, are stored. This path
      must point to a single gzip compressed tar archive (.tar.gz suffix). The S3 path is required
      for Amazon SageMaker built-in algorithms, but not if you use your own algorithms. For more
      information on built-in algorithms, see `Common Parameters
      <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__ .

      If you provide a value for this parameter, Amazon SageMaker uses AWS Security Token Service to
      download model artifacts from the S3 path you provide. AWS STS is activated in your IAM user
      account by default. If you previously deactivated AWS STS for a region, you need to reactivate
      AWS STS for that region. For more information, see `Activating and Deactivating AWS STS in an
      AWS Region
      <https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_enable-regions.html>`__
      in the *AWS Identity and Access Management User Guide* .

      .. warning::

        If you use a built-in algorithm to create a model, Amazon SageMaker requires that you provide
        a S3 path to the model artifacts in ``ModelDataUrl`` .

    - **Environment** *(dict) --*

      The environment variables to set in the Docker container. Each key and value in the
      ``Environment`` string to string map can have length of up to 1024. We support up to 16 entries
      in the map.

      - *(string) --*

        - *(string) --*

    - **ModelPackageName** *(string) --*

      The name or Amazon Resource Name (ARN) of the model package to use to create the model.
    """


_ClientCreateModelResponseTypeDef = TypedDict(
    "_ClientCreateModelResponseTypeDef", {"ModelArn": str}, total=False
)


class ClientCreateModelResponseTypeDef(_ClientCreateModelResponseTypeDef):
    """
    Type definition for `ClientCreateModel` `Response`

    - **ModelArn** *(string) --*

      The ARN of the model created in Amazon SageMaker.
    """


_ClientCreateModelTagsTypeDef = TypedDict(
    "_ClientCreateModelTagsTypeDef", {"Key": str, "Value": str}
)


class ClientCreateModelTagsTypeDef(_ClientCreateModelTagsTypeDef):
    """
    Type definition for `ClientCreateModel` `Tags`

    Describes a tag.

    - **Key** *(string) --* **[REQUIRED]**

      The tag key.

    - **Value** *(string) --* **[REQUIRED]**

      The tag value.
    """


_ClientCreateModelVpcConfigTypeDef = TypedDict(
    "_ClientCreateModelVpcConfigTypeDef",
    {"SecurityGroupIds": List[str], "Subnets": List[str]},
)


class ClientCreateModelVpcConfigTypeDef(_ClientCreateModelVpcConfigTypeDef):
    """
    Type definition for `ClientCreateModel` `VpcConfig`

    A `VpcConfig <https://docs.aws.amazon.com/sagemaker/latest/dg/API_VpcConfig.html>`__ object that
    specifies the VPC that you want your model to connect to. Control access to and from your model
    container by configuring the VPC. ``VpcConfig`` is used in hosting services and in batch
    transform. For more information, see `Protect Endpoints by Using an Amazon Virtual Private Cloud
    <https://docs.aws.amazon.com/sagemaker/latest/dg/host-vpc.html>`__ and `Protect Data in Batch
    Transform Jobs by Using an Amazon Virtual Private Cloud
    <https://docs.aws.amazon.com/sagemaker/latest/dg/batch-vpc.html>`__ .

    - **SecurityGroupIds** *(list) --* **[REQUIRED]**

      The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for the VPC
      that is specified in the ``Subnets`` field.

      - *(string) --*

    - **Subnets** *(list) --* **[REQUIRED]**

      The ID of the subnets in the VPC to which you want to connect your training job or model.

      .. note::

        Amazon EC2 P3 accelerated computing instances are not available in the c/d/e availability
        zones of region us-east-1. If you want to create endpoints with P3 instances in VPC mode in
        region us-east-1, create subnets in a/b/f availability zones instead.

      - *(string) --*
    """


_ClientCreateNotebookInstanceLifecycleConfigOnCreateTypeDef = TypedDict(
    "_ClientCreateNotebookInstanceLifecycleConfigOnCreateTypeDef",
    {"Content": str},
    total=False,
)


class ClientCreateNotebookInstanceLifecycleConfigOnCreateTypeDef(
    _ClientCreateNotebookInstanceLifecycleConfigOnCreateTypeDef
):
    """
    Type definition for `ClientCreateNotebookInstanceLifecycleConfig` `OnCreate`

    Contains the notebook instance lifecycle configuration script.

    Each lifecycle configuration script has a limit of 16384 characters.

    The value of the ``$PATH`` environment variable that is available to both scripts is
    ``/sbin:bin:/usr/sbin:/usr/bin`` .

    View CloudWatch Logs for notebook instance lifecycle configurations in log group
    ``/aws/sagemaker/NotebookInstances`` in log stream
    ``[notebook-instance-name]/[LifecycleConfigHook]`` .

    Lifecycle configuration scripts cannot run for longer than 5 minutes. If a script runs for
    longer than 5 minutes, it fails and the notebook instance is not created or started.

    For information about notebook instance lifestyle configurations, see `Step 2.1\\: (Optional)
    Customize a Notebook Instance
    <https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html>`__ .

    - **Content** *(string) --*

      A base64-encoded string that contains a shell script for a notebook instance lifecycle
      configuration.
    """


_ClientCreateNotebookInstanceLifecycleConfigOnStartTypeDef = TypedDict(
    "_ClientCreateNotebookInstanceLifecycleConfigOnStartTypeDef",
    {"Content": str},
    total=False,
)


class ClientCreateNotebookInstanceLifecycleConfigOnStartTypeDef(
    _ClientCreateNotebookInstanceLifecycleConfigOnStartTypeDef
):
    """
    Type definition for `ClientCreateNotebookInstanceLifecycleConfig` `OnStart`

    Contains the notebook instance lifecycle configuration script.

    Each lifecycle configuration script has a limit of 16384 characters.

    The value of the ``$PATH`` environment variable that is available to both scripts is
    ``/sbin:bin:/usr/sbin:/usr/bin`` .

    View CloudWatch Logs for notebook instance lifecycle configurations in log group
    ``/aws/sagemaker/NotebookInstances`` in log stream
    ``[notebook-instance-name]/[LifecycleConfigHook]`` .

    Lifecycle configuration scripts cannot run for longer than 5 minutes. If a script runs for
    longer than 5 minutes, it fails and the notebook instance is not created or started.

    For information about notebook instance lifestyle configurations, see `Step 2.1\\: (Optional)
    Customize a Notebook Instance
    <https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html>`__ .

    - **Content** *(string) --*

      A base64-encoded string that contains a shell script for a notebook instance lifecycle
      configuration.
    """


_ClientCreateNotebookInstanceLifecycleConfigResponseTypeDef = TypedDict(
    "_ClientCreateNotebookInstanceLifecycleConfigResponseTypeDef",
    {"NotebookInstanceLifecycleConfigArn": str},
    total=False,
)


class ClientCreateNotebookInstanceLifecycleConfigResponseTypeDef(
    _ClientCreateNotebookInstanceLifecycleConfigResponseTypeDef
):
    """
    Type definition for `ClientCreateNotebookInstanceLifecycleConfig` `Response`

    - **NotebookInstanceLifecycleConfigArn** *(string) --*

      The Amazon Resource Name (ARN) of the lifecycle configuration.
    """


_ClientCreateNotebookInstanceResponseTypeDef = TypedDict(
    "_ClientCreateNotebookInstanceResponseTypeDef",
    {"NotebookInstanceArn": str},
    total=False,
)


class ClientCreateNotebookInstanceResponseTypeDef(
    _ClientCreateNotebookInstanceResponseTypeDef
):
    """
    Type definition for `ClientCreateNotebookInstance` `Response`

    - **NotebookInstanceArn** *(string) --*

      The Amazon Resource Name (ARN) of the notebook instance.
    """


_ClientCreateNotebookInstanceTagsTypeDef = TypedDict(
    "_ClientCreateNotebookInstanceTagsTypeDef", {"Key": str, "Value": str}
)


class ClientCreateNotebookInstanceTagsTypeDef(_ClientCreateNotebookInstanceTagsTypeDef):
    """
    Type definition for `ClientCreateNotebookInstance` `Tags`

    Describes a tag.

    - **Key** *(string) --* **[REQUIRED]**

      The tag key.

    - **Value** *(string) --* **[REQUIRED]**

      The tag value.
    """


_ClientCreatePresignedNotebookInstanceUrlResponseTypeDef = TypedDict(
    "_ClientCreatePresignedNotebookInstanceUrlResponseTypeDef",
    {"AuthorizedUrl": str},
    total=False,
)


class ClientCreatePresignedNotebookInstanceUrlResponseTypeDef(
    _ClientCreatePresignedNotebookInstanceUrlResponseTypeDef
):
    """
    Type definition for `ClientCreatePresignedNotebookInstanceUrl` `Response`

    - **AuthorizedUrl** *(string) --*

      A JSON object that contains the URL string.
    """


_ClientCreateTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef = TypedDict(
    "_ClientCreateTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef",
    {"Name": str, "Regex": str},
)


class ClientCreateTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef(
    _ClientCreateTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef
):
    """
    Type definition for `ClientCreateTrainingJobAlgorithmSpecification` `MetricDefinitions`

    Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` . Amazon
    SageMakerhyperparameter tuning captures all defined metrics. You specify one metric that a
    hyperparameter tuning job uses as its objective metric to choose the best training job.

    - **Name** *(string) --* **[REQUIRED]**

      The name of the metric.

    - **Regex** *(string) --* **[REQUIRED]**

      A regular expression that searches the output of a training job and gets the value of the
      metric. For more information about using regular expressions to define metrics, see
      `Defining Objective Metrics
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
      .
    """


_RequiredClientCreateTrainingJobAlgorithmSpecificationTypeDef = TypedDict(
    "_RequiredClientCreateTrainingJobAlgorithmSpecificationTypeDef",
    {"TrainingInputMode": str},
)
_OptionalClientCreateTrainingJobAlgorithmSpecificationTypeDef = TypedDict(
    "_OptionalClientCreateTrainingJobAlgorithmSpecificationTypeDef",
    {
        "TrainingImage": str,
        "AlgorithmName": str,
        "MetricDefinitions": List[
            ClientCreateTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef
        ],
    },
    total=False,
)


class ClientCreateTrainingJobAlgorithmSpecificationTypeDef(
    _RequiredClientCreateTrainingJobAlgorithmSpecificationTypeDef,
    _OptionalClientCreateTrainingJobAlgorithmSpecificationTypeDef,
):
    """
    Type definition for `ClientCreateTrainingJob` `AlgorithmSpecification`

    The registry path of the Docker image that contains the training algorithm and algorithm-specific
    metadata, including the input mode. For more information about algorithms provided by Amazon
    SageMaker, see `Algorithms <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ . For
    information about providing your own algorithms, see `Using Your Own Algorithms with Amazon
    SageMaker <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

    - **TrainingImage** *(string) --*

      The registry path of the Docker image that contains the training algorithm. For information
      about docker registry paths for built-in algorithms, see `Algorithms Provided by Amazon
      SageMaker\\: Common Parameters
      <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
      . Amazon SageMaker supports both ``registry/repository[:tag]`` and
      ``registry/repository[@digest]`` image path formats. For more information, see `Using Your Own
      Algorithms with Amazon SageMaker
      <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

    - **AlgorithmName** *(string) --*

      The name of the algorithm resource to use for the training job. This must be an algorithm
      resource that you created or subscribe to on AWS Marketplace. If you specify a value for this
      parameter, you can't specify a value for ``TrainingImage`` .

    - **TrainingInputMode** *(string) --* **[REQUIRED]**

      The input mode that the algorithm supports. For the input modes that Amazon SageMaker
      algorithms support, see `Algorithms
      <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ . If an algorithm supports the
      ``File`` input mode, Amazon SageMaker downloads the training data from S3 to the provisioned ML
      storage Volume, and mounts the directory to docker volume for training container. If an
      algorithm supports the ``Pipe`` input mode, Amazon SageMaker streams data directly from S3 to
      the container.

      In File mode, make sure you provision ML storage volume with sufficient capacity to accommodate
      the data download from S3. In addition to the training data, the ML storage volume also stores
      the output model. The algorithm container use ML storage volume to also store intermediate
      information, if any.

      For distributed algorithms using File mode, training data is distributed uniformly, and your
      training duration is predictable if the input data objects size is approximately same. Amazon
      SageMaker does not split the files any further for model training. If the object sizes are
      skewed, training won't be optimal as the data distribution is also skewed where one host in a
      training cluster is overloaded, thus becoming bottleneck in training.

    - **MetricDefinitions** *(list) --*

      A list of metric definition objects. Each object specifies the metric name and regular
      expressions used to parse algorithm logs. Amazon SageMaker publishes each metric to Amazon
      CloudWatch.

      - *(dict) --*

        Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` . Amazon
        SageMakerhyperparameter tuning captures all defined metrics. You specify one metric that a
        hyperparameter tuning job uses as its objective metric to choose the best training job.

        - **Name** *(string) --* **[REQUIRED]**

          The name of the metric.

        - **Regex** *(string) --* **[REQUIRED]**

          A regular expression that searches the output of a training job and gets the value of the
          metric. For more information about using regular expressions to define metrics, see
          `Defining Objective Metrics
          <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
          .
    """


_RequiredClientCreateTrainingJobCheckpointConfigTypeDef = TypedDict(
    "_RequiredClientCreateTrainingJobCheckpointConfigTypeDef", {"S3Uri": str}
)
_OptionalClientCreateTrainingJobCheckpointConfigTypeDef = TypedDict(
    "_OptionalClientCreateTrainingJobCheckpointConfigTypeDef",
    {"LocalPath": str},
    total=False,
)


class ClientCreateTrainingJobCheckpointConfigTypeDef(
    _RequiredClientCreateTrainingJobCheckpointConfigTypeDef,
    _OptionalClientCreateTrainingJobCheckpointConfigTypeDef,
):
    """
    Type definition for `ClientCreateTrainingJob` `CheckpointConfig`

    Contains information about the output location for managed spot training checkpoint data.

    - **S3Uri** *(string) --* **[REQUIRED]**

      Identifies the S3 path where you want Amazon SageMaker to store checkpoints. For example,
      ``s3://bucket-name/key-name-prefix`` .

    - **LocalPath** *(string) --*

      (Optional) The local directory where checkpoints are written. The default directory is
      ``/opt/ml/checkpoints/`` .
    """


_ClientCreateTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef = TypedDict(
    "_ClientCreateTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef",
    {
        "FileSystemId": str,
        "FileSystemAccessMode": str,
        "FileSystemType": str,
        "DirectoryPath": str,
    },
)


class ClientCreateTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef(
    _ClientCreateTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef
):
    """
    Type definition for `ClientCreateTrainingJobInputDataConfigDataSource` `FileSystemDataSource`

    The file system that is associated with a channel.

    - **FileSystemId** *(string) --* **[REQUIRED]**

      The file system id.

    - **FileSystemAccessMode** *(string) --* **[REQUIRED]**

      The access mode of the mount of the directory associated with the channel. A directory
      can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

    - **FileSystemType** *(string) --* **[REQUIRED]**

      The file system type.

    - **DirectoryPath** *(string) --* **[REQUIRED]**

      The full path to the directory to associate with the channel.
    """


_RequiredClientCreateTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef = TypedDict(
    "_RequiredClientCreateTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef",
    {"S3DataType": str, "S3Uri": str},
)
_OptionalClientCreateTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef = TypedDict(
    "_OptionalClientCreateTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef",
    {"S3DataDistributionType": str, "AttributeNames": List[str]},
    total=False,
)


class ClientCreateTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef(
    _RequiredClientCreateTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef,
    _OptionalClientCreateTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef,
):
    """
    Type definition for `ClientCreateTrainingJobInputDataConfigDataSource` `S3DataSource`

    The S3 location of the data source that is associated with a channel.

    - **S3DataType** *(string) --* **[REQUIRED]**

      If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker
      uses all objects that match the specified key name prefix for model training.

      If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest file
      containing a list of object keys that you want Amazon SageMaker to use for model training.

      If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an augmented
      manifest file in JSON lines format. This file contains the data you want to use for model
      training. ``AugmentedManifestFile`` can only be used if the Channel's input mode is
      ``Pipe`` .

    - **S3Uri** *(string) --* **[REQUIRED]**

      Depending on the value specified for the ``S3DataType`` , identifies either a key name
      prefix or a manifest. For example:

      * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

      * A manifest might look like this: ``s3://bucketname/example.manifest``   The manifest is
      an S3 object which is a JSON file with the following format:  The preceding JSON matches
      the following ``s3Uris`` :   ``[ {"prefix": "s3://customer_bucket/some/prefix/"},``
      ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``    ``...``
      ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the following
      ``s3Uris`` :   ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
      ``s3uris`` in this manifest is the input data for the channel for this datasource. The
      object that each ``s3uris`` points to must be readable by the IAM role that Amazon
      SageMaker uses to perform tasks on your behalf.

    - **S3DataDistributionType** *(string) --*

      If you want Amazon SageMaker to replicate the entire dataset on each ML compute instance
      that is launched for model training, specify ``FullyReplicated`` .

      If you want Amazon SageMaker to replicate a subset of data on each ML compute instance
      that is launched for model training, specify ``ShardedByS3Key`` . If there are *n* ML
      compute instances launched for a training job, each instance gets approximately 1/*n* of
      the number of S3 objects. In this case, model training on each machine uses only the
      subset of training data.

      Don't choose more ML compute instances for training than available S3 objects. If you do,
      some nodes won't get any data and you will pay for nodes that aren't getting any training
      data. This applies in both File and Pipe modes. Keep this in mind when developing
      algorithms.

      In distributed training, where you use multiple ML compute EC2 instances, you might
      choose ``ShardedByS3Key`` . If the algorithm requires copying training data to the ML
      storage volume (when ``TrainingInputMode`` is set to ``File`` ), this copies 1/*n* of the
      number of objects.

    - **AttributeNames** *(list) --*

      A list of one or more attribute names to use that are found in a specified augmented
      manifest file.

      - *(string) --*
    """


_ClientCreateTrainingJobInputDataConfigDataSourceTypeDef = TypedDict(
    "_ClientCreateTrainingJobInputDataConfigDataSourceTypeDef",
    {
        "S3DataSource": ClientCreateTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef,
        "FileSystemDataSource": ClientCreateTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef,
    },
    total=False,
)


class ClientCreateTrainingJobInputDataConfigDataSourceTypeDef(
    _ClientCreateTrainingJobInputDataConfigDataSourceTypeDef
):
    """
    Type definition for `ClientCreateTrainingJobInputDataConfig` `DataSource`

    The location of the channel data.

    - **S3DataSource** *(dict) --*

      The S3 location of the data source that is associated with a channel.

      - **S3DataType** *(string) --* **[REQUIRED]**

        If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker
        uses all objects that match the specified key name prefix for model training.

        If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest file
        containing a list of object keys that you want Amazon SageMaker to use for model training.

        If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an augmented
        manifest file in JSON lines format. This file contains the data you want to use for model
        training. ``AugmentedManifestFile`` can only be used if the Channel's input mode is
        ``Pipe`` .

      - **S3Uri** *(string) --* **[REQUIRED]**

        Depending on the value specified for the ``S3DataType`` , identifies either a key name
        prefix or a manifest. For example:

        * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

        * A manifest might look like this: ``s3://bucketname/example.manifest``   The manifest is
        an S3 object which is a JSON file with the following format:  The preceding JSON matches
        the following ``s3Uris`` :   ``[ {"prefix": "s3://customer_bucket/some/prefix/"},``
        ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``    ``...``
        ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the following
        ``s3Uris`` :   ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
        ``s3uris`` in this manifest is the input data for the channel for this datasource. The
        object that each ``s3uris`` points to must be readable by the IAM role that Amazon
        SageMaker uses to perform tasks on your behalf.

      - **S3DataDistributionType** *(string) --*

        If you want Amazon SageMaker to replicate the entire dataset on each ML compute instance
        that is launched for model training, specify ``FullyReplicated`` .

        If you want Amazon SageMaker to replicate a subset of data on each ML compute instance
        that is launched for model training, specify ``ShardedByS3Key`` . If there are *n* ML
        compute instances launched for a training job, each instance gets approximately 1/*n* of
        the number of S3 objects. In this case, model training on each machine uses only the
        subset of training data.

        Don't choose more ML compute instances for training than available S3 objects. If you do,
        some nodes won't get any data and you will pay for nodes that aren't getting any training
        data. This applies in both File and Pipe modes. Keep this in mind when developing
        algorithms.

        In distributed training, where you use multiple ML compute EC2 instances, you might
        choose ``ShardedByS3Key`` . If the algorithm requires copying training data to the ML
        storage volume (when ``TrainingInputMode`` is set to ``File`` ), this copies 1/*n* of the
        number of objects.

      - **AttributeNames** *(list) --*

        A list of one or more attribute names to use that are found in a specified augmented
        manifest file.

        - *(string) --*

    - **FileSystemDataSource** *(dict) --*

      The file system that is associated with a channel.

      - **FileSystemId** *(string) --* **[REQUIRED]**

        The file system id.

      - **FileSystemAccessMode** *(string) --* **[REQUIRED]**

        The access mode of the mount of the directory associated with the channel. A directory
        can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

      - **FileSystemType** *(string) --* **[REQUIRED]**

        The file system type.

      - **DirectoryPath** *(string) --* **[REQUIRED]**

        The full path to the directory to associate with the channel.
    """


_ClientCreateTrainingJobInputDataConfigShuffleConfigTypeDef = TypedDict(
    "_ClientCreateTrainingJobInputDataConfigShuffleConfigTypeDef", {"Seed": int}
)


class ClientCreateTrainingJobInputDataConfigShuffleConfigTypeDef(
    _ClientCreateTrainingJobInputDataConfigShuffleConfigTypeDef
):
    """
    Type definition for `ClientCreateTrainingJobInputDataConfig` `ShuffleConfig`

    A configuration for a shuffle option for input data in a channel. If you use ``S3Prefix`` for
    ``S3DataType`` , this shuffles the results of the S3 key prefix matches. If you use
    ``ManifestFile`` , the order of the S3 object references in the ``ManifestFile`` is shuffled.
    If you use ``AugmentedManifestFile`` , the order of the JSON lines in the
    ``AugmentedManifestFile`` is shuffled. The shuffling order is determined using the ``Seed``
    value.

    For Pipe input mode, shuffling is done at the start of every epoch. With large datasets this
    ensures that the order of the training data is different for each epoch, it helps reduce bias
    and possible overfitting. In a multi-node training job when ShuffleConfig is combined with
    ``S3DataDistributionType`` of ``ShardedByS3Key`` , the data is shuffled across nodes so that
    the content sent to a particular node on the first epoch might be sent to a different node on
    the second epoch.

    - **Seed** *(integer) --* **[REQUIRED]**

      Determines the shuffling order in ``ShuffleConfig`` value.
    """


_RequiredClientCreateTrainingJobInputDataConfigTypeDef = TypedDict(
    "_RequiredClientCreateTrainingJobInputDataConfigTypeDef",
    {
        "ChannelName": str,
        "DataSource": ClientCreateTrainingJobInputDataConfigDataSourceTypeDef,
    },
)
_OptionalClientCreateTrainingJobInputDataConfigTypeDef = TypedDict(
    "_OptionalClientCreateTrainingJobInputDataConfigTypeDef",
    {
        "ContentType": str,
        "CompressionType": str,
        "RecordWrapperType": str,
        "InputMode": str,
        "ShuffleConfig": ClientCreateTrainingJobInputDataConfigShuffleConfigTypeDef,
    },
    total=False,
)


class ClientCreateTrainingJobInputDataConfigTypeDef(
    _RequiredClientCreateTrainingJobInputDataConfigTypeDef,
    _OptionalClientCreateTrainingJobInputDataConfigTypeDef,
):
    """
    Type definition for `ClientCreateTrainingJob` `InputDataConfig`

    A channel is a named input source that training algorithms can consume.

    - **ChannelName** *(string) --* **[REQUIRED]**

      The name of the channel.

    - **DataSource** *(dict) --* **[REQUIRED]**

      The location of the channel data.

      - **S3DataSource** *(dict) --*

        The S3 location of the data source that is associated with a channel.

        - **S3DataType** *(string) --* **[REQUIRED]**

          If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker
          uses all objects that match the specified key name prefix for model training.

          If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest file
          containing a list of object keys that you want Amazon SageMaker to use for model training.

          If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an augmented
          manifest file in JSON lines format. This file contains the data you want to use for model
          training. ``AugmentedManifestFile`` can only be used if the Channel's input mode is
          ``Pipe`` .

        - **S3Uri** *(string) --* **[REQUIRED]**

          Depending on the value specified for the ``S3DataType`` , identifies either a key name
          prefix or a manifest. For example:

          * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

          * A manifest might look like this: ``s3://bucketname/example.manifest``   The manifest is
          an S3 object which is a JSON file with the following format:  The preceding JSON matches
          the following ``s3Uris`` :   ``[ {"prefix": "s3://customer_bucket/some/prefix/"},``
          ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``    ``...``
          ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the following
          ``s3Uris`` :   ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
          ``s3uris`` in this manifest is the input data for the channel for this datasource. The
          object that each ``s3uris`` points to must be readable by the IAM role that Amazon
          SageMaker uses to perform tasks on your behalf.

        - **S3DataDistributionType** *(string) --*

          If you want Amazon SageMaker to replicate the entire dataset on each ML compute instance
          that is launched for model training, specify ``FullyReplicated`` .

          If you want Amazon SageMaker to replicate a subset of data on each ML compute instance
          that is launched for model training, specify ``ShardedByS3Key`` . If there are *n* ML
          compute instances launched for a training job, each instance gets approximately 1/*n* of
          the number of S3 objects. In this case, model training on each machine uses only the
          subset of training data.

          Don't choose more ML compute instances for training than available S3 objects. If you do,
          some nodes won't get any data and you will pay for nodes that aren't getting any training
          data. This applies in both File and Pipe modes. Keep this in mind when developing
          algorithms.

          In distributed training, where you use multiple ML compute EC2 instances, you might
          choose ``ShardedByS3Key`` . If the algorithm requires copying training data to the ML
          storage volume (when ``TrainingInputMode`` is set to ``File`` ), this copies 1/*n* of the
          number of objects.

        - **AttributeNames** *(list) --*

          A list of one or more attribute names to use that are found in a specified augmented
          manifest file.

          - *(string) --*

      - **FileSystemDataSource** *(dict) --*

        The file system that is associated with a channel.

        - **FileSystemId** *(string) --* **[REQUIRED]**

          The file system id.

        - **FileSystemAccessMode** *(string) --* **[REQUIRED]**

          The access mode of the mount of the directory associated with the channel. A directory
          can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

        - **FileSystemType** *(string) --* **[REQUIRED]**

          The file system type.

        - **DirectoryPath** *(string) --* **[REQUIRED]**

          The full path to the directory to associate with the channel.

    - **ContentType** *(string) --*

      The MIME type of the data.

    - **CompressionType** *(string) --*

      If training data is compressed, the compression type. The default value is ``None`` .
      ``CompressionType`` is used only in Pipe input mode. In File mode, leave this field unset or
      set it to None.

    - **RecordWrapperType** *(string) --*

      Specify RecordIO as the value when input data is in raw format but the training algorithm
      requires the RecordIO format. In this case, Amazon SageMaker wraps each individual S3 object
      in a RecordIO record. If the input data is already in RecordIO format, you don't need to set
      this attribute. For more information, see `Create a Dataset Using RecordIO
      <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__ .

      In File mode, leave this field unset or set it to None.

    - **InputMode** *(string) --*

      (Optional) The input mode to use for the data channel in a training job. If you don't set a
      value for ``InputMode`` , Amazon SageMaker uses the value set for ``TrainingInputMode`` . Use
      this parameter to override the ``TrainingInputMode`` setting in a  AlgorithmSpecification
      request when you have a channel that needs a different input mode from the training job's
      general setting. To download the data from Amazon Simple Storage Service (Amazon S3) to the
      provisioned ML storage volume, and mount the directory to a Docker volume, use ``File`` input
      mode. To stream data directly from Amazon S3 to the container, choose ``Pipe`` input mode.

      To use a model for incremental training, choose ``File`` input model.

    - **ShuffleConfig** *(dict) --*

      A configuration for a shuffle option for input data in a channel. If you use ``S3Prefix`` for
      ``S3DataType`` , this shuffles the results of the S3 key prefix matches. If you use
      ``ManifestFile`` , the order of the S3 object references in the ``ManifestFile`` is shuffled.
      If you use ``AugmentedManifestFile`` , the order of the JSON lines in the
      ``AugmentedManifestFile`` is shuffled. The shuffling order is determined using the ``Seed``
      value.

      For Pipe input mode, shuffling is done at the start of every epoch. With large datasets this
      ensures that the order of the training data is different for each epoch, it helps reduce bias
      and possible overfitting. In a multi-node training job when ShuffleConfig is combined with
      ``S3DataDistributionType`` of ``ShardedByS3Key`` , the data is shuffled across nodes so that
      the content sent to a particular node on the first epoch might be sent to a different node on
      the second epoch.

      - **Seed** *(integer) --* **[REQUIRED]**

        Determines the shuffling order in ``ShuffleConfig`` value.
    """


_RequiredClientCreateTrainingJobOutputDataConfigTypeDef = TypedDict(
    "_RequiredClientCreateTrainingJobOutputDataConfigTypeDef", {"S3OutputPath": str}
)
_OptionalClientCreateTrainingJobOutputDataConfigTypeDef = TypedDict(
    "_OptionalClientCreateTrainingJobOutputDataConfigTypeDef",
    {"KmsKeyId": str},
    total=False,
)


class ClientCreateTrainingJobOutputDataConfigTypeDef(
    _RequiredClientCreateTrainingJobOutputDataConfigTypeDef,
    _OptionalClientCreateTrainingJobOutputDataConfigTypeDef,
):
    """
    Type definition for `ClientCreateTrainingJob` `OutputDataConfig`

    Specifies the path to the S3 location where you want to store model artifacts. Amazon SageMaker
    creates subfolders for the artifacts.

    - **KmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the model
      artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be any of the
      following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // KMS Key Alias  ``"alias/ExampleAlias"``

      * // Amazon Resource Name (ARN) of a KMS Key Alias
      ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

      If you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution role
      must include permissions to call ``kms:Encrypt`` . If you don't provide a KMS key ID, Amazon
      SageMaker uses the default KMS key for Amazon S3 for your role's account. Amazon SageMaker uses
      server-side encryption with KMS-managed keys for ``OutputDataConfig`` . If you use a bucket
      policy with an ``s3:PutObject`` permission that only allows objects with server-side
      encryption, set the condition key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For
      more information, see `KMS-Managed Encryption Keys
      <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the *Amazon
      Simple Storage Service Developer Guide.*

      The KMS key policy must grant permission to the IAM role that you specify in your
      ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob`` requests.
      For more information, see `Using Key Policies in AWS KMS
      <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
      in the *AWS Key Management Service Developer Guide* .

    - **S3OutputPath** *(string) --* **[REQUIRED]**

      Identifies the S3 path where you want Amazon SageMaker to store the model artifacts. For
      example, ``s3://bucket-name/key-name-prefix`` .
    """


_RequiredClientCreateTrainingJobResourceConfigTypeDef = TypedDict(
    "_RequiredClientCreateTrainingJobResourceConfigTypeDef",
    {"InstanceType": str, "InstanceCount": int, "VolumeSizeInGB": int},
)
_OptionalClientCreateTrainingJobResourceConfigTypeDef = TypedDict(
    "_OptionalClientCreateTrainingJobResourceConfigTypeDef",
    {"VolumeKmsKeyId": str},
    total=False,
)


class ClientCreateTrainingJobResourceConfigTypeDef(
    _RequiredClientCreateTrainingJobResourceConfigTypeDef,
    _OptionalClientCreateTrainingJobResourceConfigTypeDef,
):
    """
    Type definition for `ClientCreateTrainingJob` `ResourceConfig`

    The resources, including the ML compute instances and ML storage volumes, to use for model
    training.

    ML storage volumes store model artifacts and incremental states. Training algorithms might also
    use ML storage volumes for scratch space. If you want Amazon SageMaker to use the ML storage
    volume to store the training data, choose ``File`` as the ``TrainingInputMode`` in the algorithm
    specification. For distributed training algorithms, specify an instance count greater than 1.

    - **InstanceType** *(string) --* **[REQUIRED]**

      The ML compute instance type.

    - **InstanceCount** *(integer) --* **[REQUIRED]**

      The number of ML compute instances to use. For distributed training, provide a value greater
      than 1.

    - **VolumeSizeInGB** *(integer) --* **[REQUIRED]**

      The size of the ML storage volume that you want to provision.

      ML storage volumes store model artifacts and incremental states. Training algorithms might also
      use the ML storage volume for scratch space. If you want to store the training data in the ML
      storage volume, choose ``File`` as the ``TrainingInputMode`` in the algorithm specification.

      You must specify sufficient ML storage for your scenario.

      .. note::

        Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

      .. note::

        Certain Nitro-based instances include local storage with a fixed total size, dependent on the
        instance type. When using these instances for training, Amazon SageMaker mounts the local
        instance storage instead of Amazon EBS gp2 storage. You can't request a ``VolumeSizeInGB``
        greater than the total size of the local instance storage.

        For a list of instance types that support local instance storage, including the total size
        per instance type, see `Instance Store Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
        .

    - **VolumeKmsKeyId** *(string) --*

      The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume attached to
      the ML compute instance(s) that run the training job.

      .. note::

        Certain Nitro-based instances include local storage, dependent on the instance type. Local
        storage volumes are encrypted using a hardware module on the instance. You can't request a
        ``VolumeKmsKeyId`` when using an instance type with local storage.

        For a list of instance types that support local instance storage, see `Instance Store Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
        .

        For more information about local instance storage encryption, see `SSD Instance Store Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

      The ``VolumeKmsKeyId`` can be in any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientCreateTrainingJobResponseTypeDef = TypedDict(
    "_ClientCreateTrainingJobResponseTypeDef", {"TrainingJobArn": str}, total=False
)


class ClientCreateTrainingJobResponseTypeDef(_ClientCreateTrainingJobResponseTypeDef):
    """
    Type definition for `ClientCreateTrainingJob` `Response`

    - **TrainingJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the training job.
    """


_ClientCreateTrainingJobStoppingConditionTypeDef = TypedDict(
    "_ClientCreateTrainingJobStoppingConditionTypeDef",
    {"MaxRuntimeInSeconds": int, "MaxWaitTimeInSeconds": int},
    total=False,
)


class ClientCreateTrainingJobStoppingConditionTypeDef(
    _ClientCreateTrainingJobStoppingConditionTypeDef
):
    """
    Type definition for `ClientCreateTrainingJob` `StoppingCondition`

    Specifies a limit to how long a model training job can run. When the job reaches the time limit,
    Amazon SageMaker ends the training job. Use this API to cap model training costs.

    To stop a job, Amazon SageMaker sends the algorithm the ``SIGTERM`` signal, which delays job
    termination for 120 seconds. Algorithms can use this 120-second window to save the model
    artifacts, so the results of training are not lost.

    - **MaxRuntimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, that the training or compilation job can run. If job
      does not complete during this time, Amazon SageMaker ends the job. If value is not specified,
      default value is 1 day. The maximum value is 28 days.

    - **MaxWaitTimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, how long you are willing to wait for a managed spot
      training job to complete. It is the amount of time spent waiting for Spot capacity plus the
      amount of time the training job runs. It must be equal to or greater than
      ``MaxRuntimeInSeconds`` .
    """


_ClientCreateTrainingJobTagsTypeDef = TypedDict(
    "_ClientCreateTrainingJobTagsTypeDef", {"Key": str, "Value": str}
)


class ClientCreateTrainingJobTagsTypeDef(_ClientCreateTrainingJobTagsTypeDef):
    """
    Type definition for `ClientCreateTrainingJob` `Tags`

    Describes a tag.

    - **Key** *(string) --* **[REQUIRED]**

      The tag key.

    - **Value** *(string) --* **[REQUIRED]**

      The tag value.
    """


_ClientCreateTrainingJobVpcConfigTypeDef = TypedDict(
    "_ClientCreateTrainingJobVpcConfigTypeDef",
    {"SecurityGroupIds": List[str], "Subnets": List[str]},
)


class ClientCreateTrainingJobVpcConfigTypeDef(_ClientCreateTrainingJobVpcConfigTypeDef):
    """
    Type definition for `ClientCreateTrainingJob` `VpcConfig`

    A  VpcConfig object that specifies the VPC that you want your training job to connect to. Control
    access to and from your training container by configuring the VPC. For more information, see
    `Protect Training Jobs by Using an Amazon Virtual Private Cloud
    <https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html>`__ .

    - **SecurityGroupIds** *(list) --* **[REQUIRED]**

      The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for the VPC
      that is specified in the ``Subnets`` field.

      - *(string) --*

    - **Subnets** *(list) --* **[REQUIRED]**

      The ID of the subnets in the VPC to which you want to connect your training job or model.

      .. note::

        Amazon EC2 P3 accelerated computing instances are not available in the c/d/e availability
        zones of region us-east-1. If you want to create endpoints with P3 instances in VPC mode in
        region us-east-1, create subnets in a/b/f availability zones instead.

      - *(string) --*
    """


_ClientCreateTransformJobDataProcessingTypeDef = TypedDict(
    "_ClientCreateTransformJobDataProcessingTypeDef",
    {"InputFilter": str, "OutputFilter": str, "JoinSource": str},
    total=False,
)


class ClientCreateTransformJobDataProcessingTypeDef(
    _ClientCreateTransformJobDataProcessingTypeDef
):
    """
    Type definition for `ClientCreateTransformJob` `DataProcessing`

    The data structure used to specify the data to be used for inference in a batch transform job and
    to associate the data that is relevant to the prediction results in the output. The input filter
    provided allows you to exclude input data that is not needed for inference in a batch transform
    job. The output filter provided allows you to include input data relevant to interpreting the
    predictions in the output from the job. For more information, see `Associate Prediction Results
    with their Corresponding Input Records
    <https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html>`__ .

    - **InputFilter** *(string) --*

      A `JSONPath
      <https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html#data-processing-operators>`__
      expression used to select a portion of the input data to pass to the algorithm. Use the
      ``InputFilter`` parameter to exclude fields, such as an ID column, from the input. If you want
      Amazon SageMaker to pass the entire input dataset to the algorithm, accept the default value
      ``$`` .

      Examples: ``"$"`` , ``"$[1:]"`` , ``"$.features"``

    - **OutputFilter** *(string) --*

      A `JSONPath
      <https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html#data-processing-operators>`__
      expression used to select a portion of the joined dataset to save in the output file for a
      batch transform job. If you want Amazon SageMaker to store the entire input dataset in the
      output file, leave the default value, ``$`` . If you specify indexes that aren't within the
      dimension size of the joined dataset, you get an error.

      Examples: ``"$"`` , ``"$[0,5:]"`` , ``"$['id','SageMakerOutput']"``

    - **JoinSource** *(string) --*

      Specifies the source of the data to join with the transformed data. The valid values are
      ``None`` and ``Input`` . The default value is ``None`` , which specifies not to join the input
      with the transformed data. If you want the batch transform job to join the original input data
      with the transformed data, set ``JoinSource`` to ``Input`` .

      For JSON or JSONLines objects, such as a JSON array, Amazon SageMaker adds the transformed data
      to the input JSON object in an attribute called ``SageMakerOutput`` . The joined result for
      JSON must be a key-value pair object. If the input is not a key-value pair object, Amazon
      SageMaker creates a new JSON file. In the new JSON file, and the input data is stored under the
      ``SageMakerInput`` key and the results are stored in ``SageMakerOutput`` .

      For CSV files, Amazon SageMaker combines the transformed data with the input data at the end of
      the input data and stores it in the output file. The joined data has the joined input data
      followed by the transformed data and the output is a CSV file.
    """


_ClientCreateTransformJobResponseTypeDef = TypedDict(
    "_ClientCreateTransformJobResponseTypeDef", {"TransformJobArn": str}, total=False
)


class ClientCreateTransformJobResponseTypeDef(_ClientCreateTransformJobResponseTypeDef):
    """
    Type definition for `ClientCreateTransformJob` `Response`

    - **TransformJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the transform job.
    """


_ClientCreateTransformJobTagsTypeDef = TypedDict(
    "_ClientCreateTransformJobTagsTypeDef", {"Key": str, "Value": str}
)


class ClientCreateTransformJobTagsTypeDef(_ClientCreateTransformJobTagsTypeDef):
    """
    Type definition for `ClientCreateTransformJob` `Tags`

    Describes a tag.

    - **Key** *(string) --* **[REQUIRED]**

      The tag key.

    - **Value** *(string) --* **[REQUIRED]**

      The tag value.
    """


_ClientCreateTransformJobTransformInputDataSourceS3DataSourceTypeDef = TypedDict(
    "_ClientCreateTransformJobTransformInputDataSourceS3DataSourceTypeDef",
    {"S3DataType": str, "S3Uri": str},
)


class ClientCreateTransformJobTransformInputDataSourceS3DataSourceTypeDef(
    _ClientCreateTransformJobTransformInputDataSourceS3DataSourceTypeDef
):
    """
    Type definition for `ClientCreateTransformJobTransformInputDataSource` `S3DataSource`

    The S3 location of the data source that is associated with a channel.

    - **S3DataType** *(string) --* **[REQUIRED]**

      If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker uses
      all objects with the specified key name prefix for batch transform.

      If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest file
      containing a list of object keys that you want Amazon SageMaker to use for batch transform.

      The following values are compatible: ``ManifestFile`` , ``S3Prefix``

      The following value is not compatible: ``AugmentedManifestFile``

    - **S3Uri** *(string) --* **[REQUIRED]**

      Depending on the value specified for the ``S3DataType`` , identifies either a key name
      prefix or a manifest. For example:

      * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

      * A manifest might look like this: ``s3://bucketname/example.manifest``   The manifest is
      an S3 object which is a JSON file with the following format:   ``[ {"prefix":
      "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
      ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``    ``]``   The
      preceding JSON matches the following ``s3Uris`` :
      ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
      ``S3Uris`` in this manifest constitutes the input data for the channel for this datasource.
      The object that each ``S3Uris`` points to must be readable by the IAM role that Amazon
      SageMaker uses to perform tasks on your behalf.
    """


_ClientCreateTransformJobTransformInputDataSourceTypeDef = TypedDict(
    "_ClientCreateTransformJobTransformInputDataSourceTypeDef",
    {
        "S3DataSource": ClientCreateTransformJobTransformInputDataSourceS3DataSourceTypeDef
    },
)


class ClientCreateTransformJobTransformInputDataSourceTypeDef(
    _ClientCreateTransformJobTransformInputDataSourceTypeDef
):
    """
    Type definition for `ClientCreateTransformJobTransformInput` `DataSource`

    Describes the location of the channel data, which is, the S3 location of the input data that
    the model can consume.

    - **S3DataSource** *(dict) --* **[REQUIRED]**

      The S3 location of the data source that is associated with a channel.

      - **S3DataType** *(string) --* **[REQUIRED]**

        If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker uses
        all objects with the specified key name prefix for batch transform.

        If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest file
        containing a list of object keys that you want Amazon SageMaker to use for batch transform.

        The following values are compatible: ``ManifestFile`` , ``S3Prefix``

        The following value is not compatible: ``AugmentedManifestFile``

      - **S3Uri** *(string) --* **[REQUIRED]**

        Depending on the value specified for the ``S3DataType`` , identifies either a key name
        prefix or a manifest. For example:

        * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

        * A manifest might look like this: ``s3://bucketname/example.manifest``   The manifest is
        an S3 object which is a JSON file with the following format:   ``[ {"prefix":
        "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
        ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``    ``]``   The
        preceding JSON matches the following ``s3Uris`` :
        ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
        ``S3Uris`` in this manifest constitutes the input data for the channel for this datasource.
        The object that each ``S3Uris`` points to must be readable by the IAM role that Amazon
        SageMaker uses to perform tasks on your behalf.
    """


_RequiredClientCreateTransformJobTransformInputTypeDef = TypedDict(
    "_RequiredClientCreateTransformJobTransformInputTypeDef",
    {"DataSource": ClientCreateTransformJobTransformInputDataSourceTypeDef},
)
_OptionalClientCreateTransformJobTransformInputTypeDef = TypedDict(
    "_OptionalClientCreateTransformJobTransformInputTypeDef",
    {"ContentType": str, "CompressionType": str, "SplitType": str},
    total=False,
)


class ClientCreateTransformJobTransformInputTypeDef(
    _RequiredClientCreateTransformJobTransformInputTypeDef,
    _OptionalClientCreateTransformJobTransformInputTypeDef,
):
    """
    Type definition for `ClientCreateTransformJob` `TransformInput`

    Describes the input source and the way the transform job consumes it.

    - **DataSource** *(dict) --* **[REQUIRED]**

      Describes the location of the channel data, which is, the S3 location of the input data that
      the model can consume.

      - **S3DataSource** *(dict) --* **[REQUIRED]**

        The S3 location of the data source that is associated with a channel.

        - **S3DataType** *(string) --* **[REQUIRED]**

          If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker uses
          all objects with the specified key name prefix for batch transform.

          If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest file
          containing a list of object keys that you want Amazon SageMaker to use for batch transform.

          The following values are compatible: ``ManifestFile`` , ``S3Prefix``

          The following value is not compatible: ``AugmentedManifestFile``

        - **S3Uri** *(string) --* **[REQUIRED]**

          Depending on the value specified for the ``S3DataType`` , identifies either a key name
          prefix or a manifest. For example:

          * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

          * A manifest might look like this: ``s3://bucketname/example.manifest``   The manifest is
          an S3 object which is a JSON file with the following format:   ``[ {"prefix":
          "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
          ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``    ``]``   The
          preceding JSON matches the following ``s3Uris`` :
          ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
          ``S3Uris`` in this manifest constitutes the input data for the channel for this datasource.
          The object that each ``S3Uris`` points to must be readable by the IAM role that Amazon
          SageMaker uses to perform tasks on your behalf.

    - **ContentType** *(string) --*

      The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker uses the
      MIME type with each http call to transfer data to the transform job.

    - **CompressionType** *(string) --*

      If your transform data is compressed, specify the compression type. Amazon SageMaker
      automatically decompresses the data for the transform job accordingly. The default value is
      ``None`` .

    - **SplitType** *(string) --*

      The method to use to split the transform job's data files into smaller batches. Splitting is
      necessary when the total size of each object is too large to fit in a single request. You can
      also use data splitting to improve performance by processing multiple concurrent mini-batches.
      The default value for ``SplitType`` is ``None`` , which indicates that input data files are not
      split, and request payloads contain the entire contents of an input object. Set the value of
      this parameter to ``Line`` to split records on a newline character boundary. ``SplitType`` also
      supports a number of record-oriented binary data formats.

      When splitting is enabled, the size of a mini-batch depends on the values of the
      ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of ``BatchStrategy`` is
      ``MultiRecord`` , Amazon SageMaker sends the maximum number of records in each request, up to
      the ``MaxPayloadInMB`` limit. If the value of ``BatchStrategy`` is ``SingleRecord`` , Amazon
      SageMaker sends individual records in each request.

      .. note::

        Some data formats represent a record as a binary payload wrapped with extra padding bytes.
        When splitting is applied to a binary data format, padding is removed if the value of
        ``BatchStrategy`` is set to ``SingleRecord`` . Padding is not removed if the value of
        ``BatchStrategy`` is set to ``MultiRecord`` .

        For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
        <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For more
        information about ``TFRecord`` , see `Consuming TFRecord data
        <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the TensorFlow
        documentation.
    """


_RequiredClientCreateTransformJobTransformOutputTypeDef = TypedDict(
    "_RequiredClientCreateTransformJobTransformOutputTypeDef", {"S3OutputPath": str}
)
_OptionalClientCreateTransformJobTransformOutputTypeDef = TypedDict(
    "_OptionalClientCreateTransformJobTransformOutputTypeDef",
    {"Accept": str, "AssembleWith": str, "KmsKeyId": str},
    total=False,
)


class ClientCreateTransformJobTransformOutputTypeDef(
    _RequiredClientCreateTransformJobTransformOutputTypeDef,
    _OptionalClientCreateTransformJobTransformOutputTypeDef,
):
    """
    Type definition for `ClientCreateTransformJob` `TransformOutput`

    Describes the results of the transform job.

    - **S3OutputPath** *(string) --* **[REQUIRED]**

      The Amazon S3 path where you want Amazon SageMaker to store the results of the transform job.
      For example, ``s3://bucket-name/key-name-prefix`` .

      For every S3 object used as input for the transform job, batch transform stores the transformed
      data with an .``out`` suffix in a corresponding subfolder in the location in the output prefix.
      For example, for the input data stored at
      ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores the
      transformed data at ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` .
      Batch transform doesn't upload partially processed objects. For an input S3 object that
      contains multiple records, it creates an .``out`` file only if the transform job succeeds on
      the entire file. When the input contains multiple S3 objects, the batch transform job processes
      the listed S3 objects and uploads only the output for successfully processed objects. If any
      object fails in the transform job batch transform marks the job as failed to prompt
      investigation.

    - **Accept** *(string) --*

      The MIME type used to specify the output data. Amazon SageMaker uses the MIME type with each
      http call to transfer data from the transform job.

    - **AssembleWith** *(string) --*

      Defines how to assemble the results of the transform job as a single S3 object. Choose a format
      that is most convenient to you. To concatenate the results in binary format, specify ``None`` .
      To add a newline character at the end of every transformed record, specify ``Line`` .

    - **KmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the model
      artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be any of the
      following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // KMS Key Alias  ``"alias/ExampleAlias"``

      * // Amazon Resource Name (ARN) of a KMS Key Alias
      ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

      If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3 for
      your role's account. For more information, see `KMS-Managed Encryption Keys
      <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the *Amazon
      Simple Storage Service Developer Guide.*

      The KMS key policy must grant permission to the IAM role that you specify in your  CreateModel
      request. For more information, see `Using Key Policies in AWS KMS
      <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the *AWS Key
      Management Service Developer Guide* .
    """


_RequiredClientCreateTransformJobTransformResourcesTypeDef = TypedDict(
    "_RequiredClientCreateTransformJobTransformResourcesTypeDef",
    {"InstanceType": str, "InstanceCount": int},
)
_OptionalClientCreateTransformJobTransformResourcesTypeDef = TypedDict(
    "_OptionalClientCreateTransformJobTransformResourcesTypeDef",
    {"VolumeKmsKeyId": str},
    total=False,
)


class ClientCreateTransformJobTransformResourcesTypeDef(
    _RequiredClientCreateTransformJobTransformResourcesTypeDef,
    _OptionalClientCreateTransformJobTransformResourcesTypeDef,
):
    """
    Type definition for `ClientCreateTransformJob` `TransformResources`

    Describes the resources, including ML instance types and ML instance count, to use for the
    transform job.

    - **InstanceType** *(string) --* **[REQUIRED]**

      The ML compute instance type for the transform job. If you are using built-in algorithms to
      transform moderately sized datasets, we recommend using ml.m4.xlarge or ``ml.m5.large``
      instance types.

    - **InstanceCount** *(integer) --* **[REQUIRED]**

      The number of ML compute instances to use in the transform job. For distributed transform jobs,
      specify a value greater than 1. The default value is ``1`` .

    - **VolumeKmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data on the
      storage volume attached to the ML compute instance(s) that run the batch transform job. The
      ``VolumeKmsKeyId`` can be any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientCreateWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef = TypedDict(
    "_ClientCreateWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef",
    {"UserPool": str, "UserGroup": str, "ClientId": str},
)


class ClientCreateWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef(
    _ClientCreateWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef
):
    """
    Type definition for `ClientCreateWorkteamMemberDefinitions` `CognitoMemberDefinition`

    The Amazon Cognito user group that is part of the work team.

    - **UserPool** *(string) --* **[REQUIRED]**

      An identifier for a user pool. The user pool must be in the same region as the service that
      you are calling.

    - **UserGroup** *(string) --* **[REQUIRED]**

      An identifier for a user group.

    - **ClientId** *(string) --* **[REQUIRED]**

      An identifier for an application client. You must create the app client ID using Amazon
      Cognito.
    """


_ClientCreateWorkteamMemberDefinitionsTypeDef = TypedDict(
    "_ClientCreateWorkteamMemberDefinitionsTypeDef",
    {
        "CognitoMemberDefinition": ClientCreateWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef
    },
    total=False,
)


class ClientCreateWorkteamMemberDefinitionsTypeDef(
    _ClientCreateWorkteamMemberDefinitionsTypeDef
):
    """
    Type definition for `ClientCreateWorkteam` `MemberDefinitions`

    Defines the Amazon Cognito user group that is part of a work team.

    - **CognitoMemberDefinition** *(dict) --*

      The Amazon Cognito user group that is part of the work team.

      - **UserPool** *(string) --* **[REQUIRED]**

        An identifier for a user pool. The user pool must be in the same region as the service that
        you are calling.

      - **UserGroup** *(string) --* **[REQUIRED]**

        An identifier for a user group.

      - **ClientId** *(string) --* **[REQUIRED]**

        An identifier for an application client. You must create the app client ID using Amazon
        Cognito.
    """


_ClientCreateWorkteamNotificationConfigurationTypeDef = TypedDict(
    "_ClientCreateWorkteamNotificationConfigurationTypeDef",
    {"NotificationTopicArn": str},
    total=False,
)


class ClientCreateWorkteamNotificationConfigurationTypeDef(
    _ClientCreateWorkteamNotificationConfigurationTypeDef
):
    """
    Type definition for `ClientCreateWorkteam` `NotificationConfiguration`

    Configures notification of workers regarding available or expiring work items.

    - **NotificationTopicArn** *(string) --*

      The ARN for the SNS topic to which notifications should be published.
    """


_ClientCreateWorkteamResponseTypeDef = TypedDict(
    "_ClientCreateWorkteamResponseTypeDef", {"WorkteamArn": str}, total=False
)


class ClientCreateWorkteamResponseTypeDef(_ClientCreateWorkteamResponseTypeDef):
    """
    Type definition for `ClientCreateWorkteam` `Response`

    - **WorkteamArn** *(string) --*

      The Amazon Resource Name (ARN) of the work team. You can use this ARN to identify the work
      team.
    """


_ClientCreateWorkteamTagsTypeDef = TypedDict(
    "_ClientCreateWorkteamTagsTypeDef", {"Key": str, "Value": str}
)


class ClientCreateWorkteamTagsTypeDef(_ClientCreateWorkteamTagsTypeDef):
    """
    Type definition for `ClientCreateWorkteam` `Tags`

    Describes a tag.

    - **Key** *(string) --* **[REQUIRED]**

      The tag key.

    - **Value** *(string) --* **[REQUIRED]**

      The tag value.
    """


_ClientDeleteWorkteamResponseTypeDef = TypedDict(
    "_ClientDeleteWorkteamResponseTypeDef", {"Success": bool}, total=False
)


class ClientDeleteWorkteamResponseTypeDef(_ClientDeleteWorkteamResponseTypeDef):
    """
    Type definition for `ClientDeleteWorkteam` `Response`

    - **Success** *(boolean) --*

      Returns ``true`` if the work team was successfully deleted; otherwise, returns ``false`` .
    """


_ClientDescribeAlgorithmResponseAlgorithmStatusDetailsImageScanStatusesTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseAlgorithmStatusDetailsImageScanStatusesTypeDef",
    {"Name": str, "Status": str, "FailureReason": str},
    total=False,
)


class ClientDescribeAlgorithmResponseAlgorithmStatusDetailsImageScanStatusesTypeDef(
    _ClientDescribeAlgorithmResponseAlgorithmStatusDetailsImageScanStatusesTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseAlgorithmStatusDetails` `ImageScanStatuses`

    Represents the overall status of an algorithm.

    - **Name** *(string) --*

      The name of the algorithm for which the overall status is being reported.

    - **Status** *(string) --*

      The current status.

    - **FailureReason** *(string) --*

      if the overall status is ``Failed`` , the reason for the failure.
    """


_ClientDescribeAlgorithmResponseAlgorithmStatusDetailsValidationStatusesTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseAlgorithmStatusDetailsValidationStatusesTypeDef",
    {"Name": str, "Status": str, "FailureReason": str},
    total=False,
)


class ClientDescribeAlgorithmResponseAlgorithmStatusDetailsValidationStatusesTypeDef(
    _ClientDescribeAlgorithmResponseAlgorithmStatusDetailsValidationStatusesTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseAlgorithmStatusDetails` `ValidationStatuses`

    Represents the overall status of an algorithm.

    - **Name** *(string) --*

      The name of the algorithm for which the overall status is being reported.

    - **Status** *(string) --*

      The current status.

    - **FailureReason** *(string) --*

      if the overall status is ``Failed`` , the reason for the failure.
    """


_ClientDescribeAlgorithmResponseAlgorithmStatusDetailsTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseAlgorithmStatusDetailsTypeDef",
    {
        "ValidationStatuses": List[
            ClientDescribeAlgorithmResponseAlgorithmStatusDetailsValidationStatusesTypeDef
        ],
        "ImageScanStatuses": List[
            ClientDescribeAlgorithmResponseAlgorithmStatusDetailsImageScanStatusesTypeDef
        ],
    },
    total=False,
)


class ClientDescribeAlgorithmResponseAlgorithmStatusDetailsTypeDef(
    _ClientDescribeAlgorithmResponseAlgorithmStatusDetailsTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponse` `AlgorithmStatusDetails`

    Details about the current status of the algorithm.

    - **ValidationStatuses** *(list) --*

      The status of algorithm validation.

      - *(dict) --*

        Represents the overall status of an algorithm.

        - **Name** *(string) --*

          The name of the algorithm for which the overall status is being reported.

        - **Status** *(string) --*

          The current status.

        - **FailureReason** *(string) --*

          if the overall status is ``Failed`` , the reason for the failure.

    - **ImageScanStatuses** *(list) --*

      The status of the scan of the algorithm's Docker image container.

      - *(dict) --*

        Represents the overall status of an algorithm.

        - **Name** *(string) --*

          The name of the algorithm for which the overall status is being reported.

        - **Status** *(string) --*

          The current status.

        - **FailureReason** *(string) --*

          if the overall status is ``Failed`` , the reason for the failure.
    """


_ClientDescribeAlgorithmResponseInferenceSpecificationContainersTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseInferenceSpecificationContainersTypeDef",
    {
        "ContainerHostname": str,
        "Image": str,
        "ImageDigest": str,
        "ModelDataUrl": str,
        "ProductId": str,
    },
    total=False,
)


class ClientDescribeAlgorithmResponseInferenceSpecificationContainersTypeDef(
    _ClientDescribeAlgorithmResponseInferenceSpecificationContainersTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseInferenceSpecification` `Containers`

    Describes the Docker container for the model package.

    - **ContainerHostname** *(string) --*

      The DNS host name for the Docker container.

    - **Image** *(string) --*

      The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.

      If you are using your own custom algorithm instead of an algorithm provided by Amazon
      SageMaker, the inference code must meet Amazon SageMaker requirements. Amazon SageMaker
      supports both ``registry/repository[:tag]`` and ``registry/repository[@digest]`` image
      path formats. For more information, see `Using Your Own Algorithms with Amazon
      SageMaker <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

    - **ImageDigest** *(string) --*

      An MD5 hash of the training algorithm that identifies the Docker image used for
      training.

    - **ModelDataUrl** *(string) --*

      The Amazon S3 path where the model artifacts, which result from model training, are
      stored. This path must point to a single ``gzip`` compressed tar archive (``.tar.gz``
      suffix).

    - **ProductId** *(string) --*

      The AWS Marketplace product ID of the model package.
    """


_ClientDescribeAlgorithmResponseInferenceSpecificationTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseInferenceSpecificationTypeDef",
    {
        "Containers": List[
            ClientDescribeAlgorithmResponseInferenceSpecificationContainersTypeDef
        ],
        "SupportedTransformInstanceTypes": List[str],
        "SupportedRealtimeInferenceInstanceTypes": List[str],
        "SupportedContentTypes": List[str],
        "SupportedResponseMIMETypes": List[str],
    },
    total=False,
)


class ClientDescribeAlgorithmResponseInferenceSpecificationTypeDef(
    _ClientDescribeAlgorithmResponseInferenceSpecificationTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponse` `InferenceSpecification`

    Details about inference jobs that the algorithm runs.

    - **Containers** *(list) --*

      The Amazon ECR registry path of the Docker image that contains the inference code.

      - *(dict) --*

        Describes the Docker container for the model package.

        - **ContainerHostname** *(string) --*

          The DNS host name for the Docker container.

        - **Image** *(string) --*

          The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.

          If you are using your own custom algorithm instead of an algorithm provided by Amazon
          SageMaker, the inference code must meet Amazon SageMaker requirements. Amazon SageMaker
          supports both ``registry/repository[:tag]`` and ``registry/repository[@digest]`` image
          path formats. For more information, see `Using Your Own Algorithms with Amazon
          SageMaker <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

        - **ImageDigest** *(string) --*

          An MD5 hash of the training algorithm that identifies the Docker image used for
          training.

        - **ModelDataUrl** *(string) --*

          The Amazon S3 path where the model artifacts, which result from model training, are
          stored. This path must point to a single ``gzip`` compressed tar archive (``.tar.gz``
          suffix).

        - **ProductId** *(string) --*

          The AWS Marketplace product ID of the model package.

    - **SupportedTransformInstanceTypes** *(list) --*

      A list of the instance types on which a transformation job can be run or on which an
      endpoint can be deployed.

      - *(string) --*

    - **SupportedRealtimeInferenceInstanceTypes** *(list) --*

      A list of the instance types that are used to generate inferences in real-time.

      - *(string) --*

    - **SupportedContentTypes** *(list) --*

      The supported MIME types for the input data.

      - *(string) --*

    - **SupportedResponseMIMETypes** *(list) --*

      The supported MIME types for the output data.

      - *(string) --*
    """


_ClientDescribeAlgorithmResponseTrainingSpecificationMetricDefinitionsTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseTrainingSpecificationMetricDefinitionsTypeDef",
    {"Name": str, "Regex": str},
    total=False,
)


class ClientDescribeAlgorithmResponseTrainingSpecificationMetricDefinitionsTypeDef(
    _ClientDescribeAlgorithmResponseTrainingSpecificationMetricDefinitionsTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseTrainingSpecification` `MetricDefinitions`

    Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
    Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
    metric that a hyperparameter tuning job uses as its objective metric to choose the best
    training job.

    - **Name** *(string) --*

      The name of the metric.

    - **Regex** *(string) --*

      A regular expression that searches the output of a training job and gets the value of
      the metric. For more information about using regular expressions to define metrics, see
      `Defining Objective Metrics
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
      .
    """


_ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeCategoricalParameterRangeSpecificationTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeCategoricalParameterRangeSpecificationTypeDef",
    {"Values": List[str]},
    total=False,
)


class ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeCategoricalParameterRangeSpecificationTypeDef(
    _ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeCategoricalParameterRangeSpecificationTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRange` `CategoricalParameterRangeSpecification`

    A ``CategoricalParameterRangeSpecification`` object that defines the possible values
    for a categorical hyperparameter.

    - **Values** *(list) --*

      The allowed categories for the hyperparameter.

      - *(string) --*
    """


_ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeContinuousParameterRangeSpecificationTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeContinuousParameterRangeSpecificationTypeDef",
    {"MinValue": str, "MaxValue": str},
    total=False,
)


class ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeContinuousParameterRangeSpecificationTypeDef(
    _ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeContinuousParameterRangeSpecificationTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRange` `ContinuousParameterRangeSpecification`

    A ``ContinuousParameterRangeSpecification`` object that defines the possible values
    for a continuous hyperparameter.

    - **MinValue** *(string) --*

      The minimum floating-point value allowed.

    - **MaxValue** *(string) --*

      The maximum floating-point value allowed.
    """


_ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeIntegerParameterRangeSpecificationTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeIntegerParameterRangeSpecificationTypeDef",
    {"MinValue": str, "MaxValue": str},
    total=False,
)


class ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeIntegerParameterRangeSpecificationTypeDef(
    _ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeIntegerParameterRangeSpecificationTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRange` `IntegerParameterRangeSpecification`

    A ``IntegerParameterRangeSpecification`` object that defines the possible values for
    an integer hyperparameter.

    - **MinValue** *(string) --*

      The minimum integer value allowed.

    - **MaxValue** *(string) --*

      The maximum integer value allowed.
    """


_ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeTypeDef",
    {
        "IntegerParameterRangeSpecification": ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeIntegerParameterRangeSpecificationTypeDef,
        "ContinuousParameterRangeSpecification": ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeContinuousParameterRangeSpecificationTypeDef,
        "CategoricalParameterRangeSpecification": ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeCategoricalParameterRangeSpecificationTypeDef,
    },
    total=False,
)


class ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeTypeDef(
    _ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParameters` `Range`

    The allowed range for this hyperparameter.

    - **IntegerParameterRangeSpecification** *(dict) --*

      A ``IntegerParameterRangeSpecification`` object that defines the possible values for
      an integer hyperparameter.

      - **MinValue** *(string) --*

        The minimum integer value allowed.

      - **MaxValue** *(string) --*

        The maximum integer value allowed.

    - **ContinuousParameterRangeSpecification** *(dict) --*

      A ``ContinuousParameterRangeSpecification`` object that defines the possible values
      for a continuous hyperparameter.

      - **MinValue** *(string) --*

        The minimum floating-point value allowed.

      - **MaxValue** *(string) --*

        The maximum floating-point value allowed.

    - **CategoricalParameterRangeSpecification** *(dict) --*

      A ``CategoricalParameterRangeSpecification`` object that defines the possible values
      for a categorical hyperparameter.

      - **Values** *(list) --*

        The allowed categories for the hyperparameter.

        - *(string) --*
    """


_ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersTypeDef",
    {
        "Name": str,
        "Description": str,
        "Type": str,
        "Range": ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersRangeTypeDef,
        "IsTunable": bool,
        "IsRequired": bool,
        "DefaultValue": str,
    },
    total=False,
)


class ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersTypeDef(
    _ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseTrainingSpecification` `SupportedHyperParameters`

    Defines a hyperparameter to be used by an algorithm.

    - **Name** *(string) --*

      The name of this hyperparameter. The name must be unique.

    - **Description** *(string) --*

      A brief description of the hyperparameter.

    - **Type** *(string) --*

      The type of this hyperparameter. The valid types are ``Integer`` , ``Continuous`` ,
      ``Categorical`` , and ``FreeText`` .

    - **Range** *(dict) --*

      The allowed range for this hyperparameter.

      - **IntegerParameterRangeSpecification** *(dict) --*

        A ``IntegerParameterRangeSpecification`` object that defines the possible values for
        an integer hyperparameter.

        - **MinValue** *(string) --*

          The minimum integer value allowed.

        - **MaxValue** *(string) --*

          The maximum integer value allowed.

      - **ContinuousParameterRangeSpecification** *(dict) --*

        A ``ContinuousParameterRangeSpecification`` object that defines the possible values
        for a continuous hyperparameter.

        - **MinValue** *(string) --*

          The minimum floating-point value allowed.

        - **MaxValue** *(string) --*

          The maximum floating-point value allowed.

      - **CategoricalParameterRangeSpecification** *(dict) --*

        A ``CategoricalParameterRangeSpecification`` object that defines the possible values
        for a categorical hyperparameter.

        - **Values** *(list) --*

          The allowed categories for the hyperparameter.

          - *(string) --*

    - **IsTunable** *(boolean) --*

      Indicates whether this hyperparameter is tunable in a hyperparameter tuning job.

    - **IsRequired** *(boolean) --*

      Indicates whether this hyperparameter is required.

    - **DefaultValue** *(string) --*

      The default value for this hyperparameter. If a default value is specified, a
      hyperparameter cannot be required.
    """


_ClientDescribeAlgorithmResponseTrainingSpecificationSupportedTuningJobObjectiveMetricsTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseTrainingSpecificationSupportedTuningJobObjectiveMetricsTypeDef",
    {"Type": str, "MetricName": str},
    total=False,
)


class ClientDescribeAlgorithmResponseTrainingSpecificationSupportedTuningJobObjectiveMetricsTypeDef(
    _ClientDescribeAlgorithmResponseTrainingSpecificationSupportedTuningJobObjectiveMetricsTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseTrainingSpecification` `SupportedTuningJobObjectiveMetrics`

    Defines the objective metric for a hyperparameter tuning job. Hyperparameter tuning uses
    the value of this metric to evaluate the training jobs it launches, and returns the
    training job that results in either the highest or lowest value for this metric,
    depending on the value you specify for the ``Type`` parameter.

    - **Type** *(string) --*

      Whether to minimize or maximize the objective metric.

    - **MetricName** *(string) --*

      The name of the metric to use for the objective metric.
    """


_ClientDescribeAlgorithmResponseTrainingSpecificationTrainingChannelsTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseTrainingSpecificationTrainingChannelsTypeDef",
    {
        "Name": str,
        "Description": str,
        "IsRequired": bool,
        "SupportedContentTypes": List[str],
        "SupportedCompressionTypes": List[str],
        "SupportedInputModes": List[str],
    },
    total=False,
)


class ClientDescribeAlgorithmResponseTrainingSpecificationTrainingChannelsTypeDef(
    _ClientDescribeAlgorithmResponseTrainingSpecificationTrainingChannelsTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseTrainingSpecification` `TrainingChannels`

    Defines a named input source, called a channel, to be used by an algorithm.

    - **Name** *(string) --*

      The name of the channel.

    - **Description** *(string) --*

      A brief description of the channel.

    - **IsRequired** *(boolean) --*

      Indicates whether the channel is required by the algorithm.

    - **SupportedContentTypes** *(list) --*

      The supported MIME types for the data.

      - *(string) --*

    - **SupportedCompressionTypes** *(list) --*

      The allowed compression types, if data compression is used.

      - *(string) --*

    - **SupportedInputModes** *(list) --*

      The allowed input mode, either FILE or PIPE.

      In FILE mode, Amazon SageMaker copies the data from the input source onto the local
      Amazon Elastic Block Store (Amazon EBS) volumes before starting your training
      algorithm. This is the most commonly used input mode.

      In PIPE mode, Amazon SageMaker streams input data from the source directly to your
      algorithm without using the EBS volume.

      - *(string) --*
    """


_ClientDescribeAlgorithmResponseTrainingSpecificationTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseTrainingSpecificationTypeDef",
    {
        "TrainingImage": str,
        "TrainingImageDigest": str,
        "SupportedHyperParameters": List[
            ClientDescribeAlgorithmResponseTrainingSpecificationSupportedHyperParametersTypeDef
        ],
        "SupportedTrainingInstanceTypes": List[str],
        "SupportsDistributedTraining": bool,
        "MetricDefinitions": List[
            ClientDescribeAlgorithmResponseTrainingSpecificationMetricDefinitionsTypeDef
        ],
        "TrainingChannels": List[
            ClientDescribeAlgorithmResponseTrainingSpecificationTrainingChannelsTypeDef
        ],
        "SupportedTuningJobObjectiveMetrics": List[
            ClientDescribeAlgorithmResponseTrainingSpecificationSupportedTuningJobObjectiveMetricsTypeDef
        ],
    },
    total=False,
)


class ClientDescribeAlgorithmResponseTrainingSpecificationTypeDef(
    _ClientDescribeAlgorithmResponseTrainingSpecificationTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponse` `TrainingSpecification`

    Details about training jobs run by this algorithm.

    - **TrainingImage** *(string) --*

      The Amazon ECR registry path of the Docker image that contains the training algorithm.

    - **TrainingImageDigest** *(string) --*

      An MD5 hash of the training algorithm that identifies the Docker image used for training.

    - **SupportedHyperParameters** *(list) --*

      A list of the ``HyperParameterSpecification`` objects, that define the supported
      hyperparameters. This is required if the algorithm supports automatic model tuning.>

      - *(dict) --*

        Defines a hyperparameter to be used by an algorithm.

        - **Name** *(string) --*

          The name of this hyperparameter. The name must be unique.

        - **Description** *(string) --*

          A brief description of the hyperparameter.

        - **Type** *(string) --*

          The type of this hyperparameter. The valid types are ``Integer`` , ``Continuous`` ,
          ``Categorical`` , and ``FreeText`` .

        - **Range** *(dict) --*

          The allowed range for this hyperparameter.

          - **IntegerParameterRangeSpecification** *(dict) --*

            A ``IntegerParameterRangeSpecification`` object that defines the possible values for
            an integer hyperparameter.

            - **MinValue** *(string) --*

              The minimum integer value allowed.

            - **MaxValue** *(string) --*

              The maximum integer value allowed.

          - **ContinuousParameterRangeSpecification** *(dict) --*

            A ``ContinuousParameterRangeSpecification`` object that defines the possible values
            for a continuous hyperparameter.

            - **MinValue** *(string) --*

              The minimum floating-point value allowed.

            - **MaxValue** *(string) --*

              The maximum floating-point value allowed.

          - **CategoricalParameterRangeSpecification** *(dict) --*

            A ``CategoricalParameterRangeSpecification`` object that defines the possible values
            for a categorical hyperparameter.

            - **Values** *(list) --*

              The allowed categories for the hyperparameter.

              - *(string) --*

        - **IsTunable** *(boolean) --*

          Indicates whether this hyperparameter is tunable in a hyperparameter tuning job.

        - **IsRequired** *(boolean) --*

          Indicates whether this hyperparameter is required.

        - **DefaultValue** *(string) --*

          The default value for this hyperparameter. If a default value is specified, a
          hyperparameter cannot be required.

    - **SupportedTrainingInstanceTypes** *(list) --*

      A list of the instance types that this algorithm can use for training.

      - *(string) --*

    - **SupportsDistributedTraining** *(boolean) --*

      Indicates whether the algorithm supports distributed training. If set to false, buyers
      cant request more than one instance during training.

    - **MetricDefinitions** *(list) --*

      A list of ``MetricDefinition`` objects, which are used for parsing metrics generated by the
      algorithm.

      - *(dict) --*

        Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
        Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
        metric that a hyperparameter tuning job uses as its objective metric to choose the best
        training job.

        - **Name** *(string) --*

          The name of the metric.

        - **Regex** *(string) --*

          A regular expression that searches the output of a training job and gets the value of
          the metric. For more information about using regular expressions to define metrics, see
          `Defining Objective Metrics
          <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
          .

    - **TrainingChannels** *(list) --*

      A list of ``ChannelSpecification`` objects, which specify the input sources to be used by
      the algorithm.

      - *(dict) --*

        Defines a named input source, called a channel, to be used by an algorithm.

        - **Name** *(string) --*

          The name of the channel.

        - **Description** *(string) --*

          A brief description of the channel.

        - **IsRequired** *(boolean) --*

          Indicates whether the channel is required by the algorithm.

        - **SupportedContentTypes** *(list) --*

          The supported MIME types for the data.

          - *(string) --*

        - **SupportedCompressionTypes** *(list) --*

          The allowed compression types, if data compression is used.

          - *(string) --*

        - **SupportedInputModes** *(list) --*

          The allowed input mode, either FILE or PIPE.

          In FILE mode, Amazon SageMaker copies the data from the input source onto the local
          Amazon Elastic Block Store (Amazon EBS) volumes before starting your training
          algorithm. This is the most commonly used input mode.

          In PIPE mode, Amazon SageMaker streams input data from the source directly to your
          algorithm without using the EBS volume.

          - *(string) --*

    - **SupportedTuningJobObjectiveMetrics** *(list) --*

      A list of the metrics that the algorithm emits that can be used as the objective metric in
      a hyperparameter tuning job.

      - *(dict) --*

        Defines the objective metric for a hyperparameter tuning job. Hyperparameter tuning uses
        the value of this metric to evaluate the training jobs it launches, and returns the
        training job that results in either the highest or lowest value for this metric,
        depending on the value you specify for the ``Type`` parameter.

        - **Type** *(string) --*

          Whether to minimize or maximize the objective metric.

        - **MetricName** *(string) --*

          The name of the metric to use for the objective metric.
    """


_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef",
    {
        "FileSystemId": str,
        "FileSystemAccessMode": str,
        "FileSystemType": str,
        "DirectoryPath": str,
    },
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSource` `FileSystemDataSource`

    The file system that is associated with a channel.

    - **FileSystemId** *(string) --*

      The file system id.

    - **FileSystemAccessMode** *(string) --*

      The access mode of the mount of the directory associated with the channel. A
      directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
      mode.

    - **FileSystemType** *(string) --*

      The file system type.

    - **DirectoryPath** *(string) --*

      The full path to the directory to associate with the channel.
    """


_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef",
    {
        "S3DataType": str,
        "S3Uri": str,
        "S3DataDistributionType": str,
        "AttributeNames": List[str],
    },
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSource` `S3DataSource`

    The S3 location of the data source that is associated with a channel.

    - **S3DataType** *(string) --*

      If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
      SageMaker uses all objects that match the specified key name prefix for model
      training.

      If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
      manifest file containing a list of object keys that you want Amazon SageMaker
      to use for model training.

      If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is
      an augmented manifest file in JSON lines format. This file contains the data
      you want to use for model training. ``AugmentedManifestFile`` can only be
      used if the Channel's input mode is ``Pipe`` .

    - **S3Uri** *(string) --*

      Depending on the value specified for the ``S3DataType`` , identifies either a
      key name prefix or a manifest. For example:

      * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

      * A manifest might look like this: ``s3://bucketname/example.manifest``   The
      manifest is an S3 object which is a JSON file with the following format:  The
      preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
      "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
         ``"relative/path/custdata-2",``    ``...``
         ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the
         following ``s3Uris`` :
         ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
         ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The
          complete set of ``s3uris`` in this manifest is the input data for the
          channel for this datasource. The object that each ``s3uris`` points to
          must be readable by the IAM role that Amazon SageMaker uses to perform
          tasks on your behalf.

    - **S3DataDistributionType** *(string) --*

      If you want Amazon SageMaker to replicate the entire dataset on each ML
      compute instance that is launched for model training, specify
      ``FullyReplicated`` .

      If you want Amazon SageMaker to replicate a subset of data on each ML compute
      instance that is launched for model training, specify ``ShardedByS3Key`` . If
      there are *n* ML compute instances launched for a training job, each instance
      gets approximately 1/*n* of the number of S3 objects. In this case, model
      training on each machine uses only the subset of training data.

      Don't choose more ML compute instances for training than available S3
      objects. If you do, some nodes won't get any data and you will pay for nodes
      that aren't getting any training data. This applies in both File and Pipe
      modes. Keep this in mind when developing algorithms.

      In distributed training, where you use multiple ML compute EC2 instances, you
      might choose ``ShardedByS3Key`` . If the algorithm requires copying training
      data to the ML storage volume (when ``TrainingInputMode`` is set to ``File``
      ), this copies 1/*n* of the number of objects.

    - **AttributeNames** *(list) --*

      A list of one or more attribute names to use that are found in a specified
      augmented manifest file.

      - *(string) --*
    """


_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceTypeDef",
    {
        "S3DataSource": ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef,
        "FileSystemDataSource": ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef,
    },
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfig` `DataSource`

    The location of the channel data.

    - **S3DataSource** *(dict) --*

      The S3 location of the data source that is associated with a channel.

      - **S3DataType** *(string) --*

        If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
        SageMaker uses all objects that match the specified key name prefix for model
        training.

        If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
        manifest file containing a list of object keys that you want Amazon SageMaker
        to use for model training.

        If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is
        an augmented manifest file in JSON lines format. This file contains the data
        you want to use for model training. ``AugmentedManifestFile`` can only be
        used if the Channel's input mode is ``Pipe`` .

      - **S3Uri** *(string) --*

        Depending on the value specified for the ``S3DataType`` , identifies either a
        key name prefix or a manifest. For example:

        * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

        * A manifest might look like this: ``s3://bucketname/example.manifest``   The
        manifest is an S3 object which is a JSON file with the following format:  The
        preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
        "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
           ``"relative/path/custdata-2",``    ``...``
           ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the
           following ``s3Uris`` :
           ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
           ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The
            complete set of ``s3uris`` in this manifest is the input data for the
            channel for this datasource. The object that each ``s3uris`` points to
            must be readable by the IAM role that Amazon SageMaker uses to perform
            tasks on your behalf.

      - **S3DataDistributionType** *(string) --*

        If you want Amazon SageMaker to replicate the entire dataset on each ML
        compute instance that is launched for model training, specify
        ``FullyReplicated`` .

        If you want Amazon SageMaker to replicate a subset of data on each ML compute
        instance that is launched for model training, specify ``ShardedByS3Key`` . If
        there are *n* ML compute instances launched for a training job, each instance
        gets approximately 1/*n* of the number of S3 objects. In this case, model
        training on each machine uses only the subset of training data.

        Don't choose more ML compute instances for training than available S3
        objects. If you do, some nodes won't get any data and you will pay for nodes
        that aren't getting any training data. This applies in both File and Pipe
        modes. Keep this in mind when developing algorithms.

        In distributed training, where you use multiple ML compute EC2 instances, you
        might choose ``ShardedByS3Key`` . If the algorithm requires copying training
        data to the ML storage volume (when ``TrainingInputMode`` is set to ``File``
        ), this copies 1/*n* of the number of objects.

      - **AttributeNames** *(list) --*

        A list of one or more attribute names to use that are found in a specified
        augmented manifest file.

        - *(string) --*

    - **FileSystemDataSource** *(dict) --*

      The file system that is associated with a channel.

      - **FileSystemId** *(string) --*

        The file system id.

      - **FileSystemAccessMode** *(string) --*

        The access mode of the mount of the directory associated with the channel. A
        directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
        mode.

      - **FileSystemType** *(string) --*

        The file system type.

      - **DirectoryPath** *(string) --*

        The full path to the directory to associate with the channel.
    """


_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef",
    {"Seed": int},
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfig` `ShuffleConfig`

    A configuration for a shuffle option for input data in a channel. If you use
    ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
    matches. If you use ``ManifestFile`` , the order of the S3 object references in
    the ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the
    order of the JSON lines in the ``AugmentedManifestFile`` is shuffled. The
    shuffling order is determined using the ``Seed`` value.

    For Pipe input mode, shuffling is done at the start of every epoch. With large
    datasets this ensures that the order of the training data is different for each
    epoch, it helps reduce bias and possible overfitting. In a multi-node training
    job when ShuffleConfig is combined with ``S3DataDistributionType`` of
    ``ShardedByS3Key`` , the data is shuffled across nodes so that the content sent
    to a particular node on the first epoch might be sent to a different node on the
    second epoch.

    - **Seed** *(integer) --*

      Determines the shuffling order in ``ShuffleConfig`` value.
    """


_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigTypeDef",
    {
        "ChannelName": str,
        "DataSource": ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigDataSourceTypeDef,
        "ContentType": str,
        "CompressionType": str,
        "RecordWrapperType": str,
        "InputMode": str,
        "ShuffleConfig": ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef,
    },
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinition` `InputDataConfig`

    A channel is a named input source that training algorithms can consume.

    - **ChannelName** *(string) --*

      The name of the channel.

    - **DataSource** *(dict) --*

      The location of the channel data.

      - **S3DataSource** *(dict) --*

        The S3 location of the data source that is associated with a channel.

        - **S3DataType** *(string) --*

          If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
          SageMaker uses all objects that match the specified key name prefix for model
          training.

          If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
          manifest file containing a list of object keys that you want Amazon SageMaker
          to use for model training.

          If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is
          an augmented manifest file in JSON lines format. This file contains the data
          you want to use for model training. ``AugmentedManifestFile`` can only be
          used if the Channel's input mode is ``Pipe`` .

        - **S3Uri** *(string) --*

          Depending on the value specified for the ``S3DataType`` , identifies either a
          key name prefix or a manifest. For example:

          * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

          * A manifest might look like this: ``s3://bucketname/example.manifest``   The
          manifest is an S3 object which is a JSON file with the following format:  The
          preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
          "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
             ``"relative/path/custdata-2",``    ``...``
             ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the
             following ``s3Uris`` :
             ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
             ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
              ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The
              complete set of ``s3uris`` in this manifest is the input data for the
              channel for this datasource. The object that each ``s3uris`` points to
              must be readable by the IAM role that Amazon SageMaker uses to perform
              tasks on your behalf.

        - **S3DataDistributionType** *(string) --*

          If you want Amazon SageMaker to replicate the entire dataset on each ML
          compute instance that is launched for model training, specify
          ``FullyReplicated`` .

          If you want Amazon SageMaker to replicate a subset of data on each ML compute
          instance that is launched for model training, specify ``ShardedByS3Key`` . If
          there are *n* ML compute instances launched for a training job, each instance
          gets approximately 1/*n* of the number of S3 objects. In this case, model
          training on each machine uses only the subset of training data.

          Don't choose more ML compute instances for training than available S3
          objects. If you do, some nodes won't get any data and you will pay for nodes
          that aren't getting any training data. This applies in both File and Pipe
          modes. Keep this in mind when developing algorithms.

          In distributed training, where you use multiple ML compute EC2 instances, you
          might choose ``ShardedByS3Key`` . If the algorithm requires copying training
          data to the ML storage volume (when ``TrainingInputMode`` is set to ``File``
          ), this copies 1/*n* of the number of objects.

        - **AttributeNames** *(list) --*

          A list of one or more attribute names to use that are found in a specified
          augmented manifest file.

          - *(string) --*

      - **FileSystemDataSource** *(dict) --*

        The file system that is associated with a channel.

        - **FileSystemId** *(string) --*

          The file system id.

        - **FileSystemAccessMode** *(string) --*

          The access mode of the mount of the directory associated with the channel. A
          directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
          mode.

        - **FileSystemType** *(string) --*

          The file system type.

        - **DirectoryPath** *(string) --*

          The full path to the directory to associate with the channel.

    - **ContentType** *(string) --*

      The MIME type of the data.

    - **CompressionType** *(string) --*

      If training data is compressed, the compression type. The default value is
      ``None`` . ``CompressionType`` is used only in Pipe input mode. In File mode,
      leave this field unset or set it to None.

    - **RecordWrapperType** *(string) --*

      Specify RecordIO as the value when input data is in raw format but the training
      algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
      individual S3 object in a RecordIO record. If the input data is already in
      RecordIO format, you don't need to set this attribute. For more information, see
      `Create a Dataset Using RecordIO
      <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
      .

      In File mode, leave this field unset or set it to None.

    - **InputMode** *(string) --*

      (Optional) The input mode to use for the data channel in a training job. If you
      don't set a value for ``InputMode`` , Amazon SageMaker uses the value set for
      ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
      setting in a  AlgorithmSpecification request when you have a channel that needs a
      different input mode from the training job's general setting. To download the
      data from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage
      volume, and mount the directory to a Docker volume, use ``File`` input mode. To
      stream data directly from Amazon S3 to the container, choose ``Pipe`` input mode.

      To use a model for incremental training, choose ``File`` input model.

    - **ShuffleConfig** *(dict) --*

      A configuration for a shuffle option for input data in a channel. If you use
      ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
      matches. If you use ``ManifestFile`` , the order of the S3 object references in
      the ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the
      order of the JSON lines in the ``AugmentedManifestFile`` is shuffled. The
      shuffling order is determined using the ``Seed`` value.

      For Pipe input mode, shuffling is done at the start of every epoch. With large
      datasets this ensures that the order of the training data is different for each
      epoch, it helps reduce bias and possible overfitting. In a multi-node training
      job when ShuffleConfig is combined with ``S3DataDistributionType`` of
      ``ShardedByS3Key`` , the data is shuffled across nodes so that the content sent
      to a particular node on the first epoch might be sent to a different node on the
      second epoch.

      - **Seed** *(integer) --*

        Determines the shuffling order in ``ShuffleConfig`` value.
    """


_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionOutputDataConfigTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionOutputDataConfigTypeDef",
    {"KmsKeyId": str, "S3OutputPath": str},
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionOutputDataConfigTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionOutputDataConfigTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinition` `OutputDataConfig`

    the path to the S3 bucket where you want to store model artifacts. Amazon SageMaker
    creates subfolders for the artifacts.

    - **KmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
      the model artifacts at rest using Amazon S3 server-side encryption. The
      ``KmsKeyId`` can be any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // KMS Key Alias  ``"alias/ExampleAlias"``

      * // Amazon Resource Name (ARN) of a KMS Key Alias
      ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

      If you use a KMS key ID or an alias of your master key, the Amazon SageMaker
      execution role must include permissions to call ``kms:Encrypt`` . If you don't
      provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3 for
      your role's account. Amazon SageMaker uses server-side encryption with KMS-managed
      keys for ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject``
      permission that only allows objects with server-side encryption, set the condition
      key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information,
      see `KMS-Managed Encryption Keys
      <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
      *Amazon Simple Storage Service Developer Guide.*

      The KMS key policy must grant permission to the IAM role that you specify in your
      ``CreateTrainingJob`` , ``CreateTransformJob`` , or
      ``CreateHyperParameterTuningJob`` requests. For more information, see `Using Key
      Policies in AWS KMS
      <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
      in the *AWS Key Management Service Developer Guide* .

    - **S3OutputPath** *(string) --*

      Identifies the S3 path where you want Amazon SageMaker to store the model
      artifacts. For example, ``s3://bucket-name/key-name-prefix`` .
    """


_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionResourceConfigTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionResourceConfigTypeDef",
    {
        "InstanceType": str,
        "InstanceCount": int,
        "VolumeSizeInGB": int,
        "VolumeKmsKeyId": str,
    },
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionResourceConfigTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionResourceConfigTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinition` `ResourceConfig`

    The resources, including the ML compute instances and ML storage volumes, to use for
    model training.

    - **InstanceType** *(string) --*

      The ML compute instance type.

    - **InstanceCount** *(integer) --*

      The number of ML compute instances to use. For distributed training, provide a
      value greater than 1.

    - **VolumeSizeInGB** *(integer) --*

      The size of the ML storage volume that you want to provision.

      ML storage volumes store model artifacts and incremental states. Training
      algorithms might also use the ML storage volume for scratch space. If you want to
      store the training data in the ML storage volume, choose ``File`` as the
      ``TrainingInputMode`` in the algorithm specification.

      You must specify sufficient ML storage for your scenario.

      .. note::

        Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume
        type.

      .. note::

        Certain Nitro-based instances include local storage with a fixed total size,
        dependent on the instance type. When using these instances for training, Amazon
        SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage.
        You can't request a ``VolumeSizeInGB`` greater than the total size of the local
        instance storage.

        For a list of instance types that support local instance storage, including the
        total size per instance type, see `Instance Store Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
        .

    - **VolumeKmsKeyId** *(string) --*

      The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
      attached to the ML compute instance(s) that run the training job.

      .. note::

        Certain Nitro-based instances include local storage, dependent on the instance
        type. Local storage volumes are encrypted using a hardware module on the
        instance. You can't request a ``VolumeKmsKeyId`` when using an instance type with
        local storage.

        For a list of instance types that support local instance storage, see `Instance
        Store Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
        .

        For more information about local instance storage encryption, see `SSD Instance
        Store Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

      The ``VolumeKmsKeyId`` can be in any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionStoppingConditionTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionStoppingConditionTypeDef",
    {"MaxRuntimeInSeconds": int, "MaxWaitTimeInSeconds": int},
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionStoppingConditionTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionStoppingConditionTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinition` `StoppingCondition`

    Specifies a limit to how long a model training job can run. When the job reaches the
    time limit, Amazon SageMaker ends the training job. Use this API to cap model
    training costs.

    To stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays
    job termination for 120 seconds. Algorithms can use this 120-second window to save
    the model artifacts.

    - **MaxRuntimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, that the training or compilation job can
      run. If job does not complete during this time, Amazon SageMaker ends the job. If
      value is not specified, default value is 1 day. The maximum value is 28 days.

    - **MaxWaitTimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, how long you are willing to wait for a
      managed spot training job to complete. It is the amount of time spent waiting for
      Spot capacity plus the amount of time the training job runs. It must be equal to or
      greater than ``MaxRuntimeInSeconds`` .
    """


_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionTypeDef",
    {
        "TrainingInputMode": str,
        "HyperParameters": Dict[str, str],
        "InputDataConfig": List[
            ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionInputDataConfigTypeDef
        ],
        "OutputDataConfig": ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionOutputDataConfigTypeDef,
        "ResourceConfig": ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionResourceConfigTypeDef,
        "StoppingCondition": ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionStoppingConditionTypeDef,
    },
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseValidationSpecificationValidationProfiles` `TrainingJobDefinition`

    The ``TrainingJobDefinition`` object that describes the training job that Amazon
    SageMaker runs to validate your algorithm.

    - **TrainingInputMode** *(string) --*

      The input mode used by the algorithm for the training job. For the input modes that
      Amazon SageMaker algorithms support, see `Algorithms
      <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ .

      If an algorithm supports the ``File`` input mode, Amazon SageMaker downloads the
      training data from S3 to the provisioned ML storage Volume, and mounts the directory
      to docker volume for training container. If an algorithm supports the ``Pipe`` input
      mode, Amazon SageMaker streams data directly from S3 to the container.

    - **HyperParameters** *(dict) --*

      The hyperparameters used for the training job.

      - *(string) --*

        - *(string) --*

    - **InputDataConfig** *(list) --*

      An array of ``Channel`` objects, each of which specifies an input source.

      - *(dict) --*

        A channel is a named input source that training algorithms can consume.

        - **ChannelName** *(string) --*

          The name of the channel.

        - **DataSource** *(dict) --*

          The location of the channel data.

          - **S3DataSource** *(dict) --*

            The S3 location of the data source that is associated with a channel.

            - **S3DataType** *(string) --*

              If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
              SageMaker uses all objects that match the specified key name prefix for model
              training.

              If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
              manifest file containing a list of object keys that you want Amazon SageMaker
              to use for model training.

              If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is
              an augmented manifest file in JSON lines format. This file contains the data
              you want to use for model training. ``AugmentedManifestFile`` can only be
              used if the Channel's input mode is ``Pipe`` .

            - **S3Uri** *(string) --*

              Depending on the value specified for the ``S3DataType`` , identifies either a
              key name prefix or a manifest. For example:

              * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

              * A manifest might look like this: ``s3://bucketname/example.manifest``   The
              manifest is an S3 object which is a JSON file with the following format:  The
              preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
              "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
                 ``"relative/path/custdata-2",``    ``...``
                 ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the
                 following ``s3Uris`` :
                 ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                 ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                  ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The
                  complete set of ``s3uris`` in this manifest is the input data for the
                  channel for this datasource. The object that each ``s3uris`` points to
                  must be readable by the IAM role that Amazon SageMaker uses to perform
                  tasks on your behalf.

            - **S3DataDistributionType** *(string) --*

              If you want Amazon SageMaker to replicate the entire dataset on each ML
              compute instance that is launched for model training, specify
              ``FullyReplicated`` .

              If you want Amazon SageMaker to replicate a subset of data on each ML compute
              instance that is launched for model training, specify ``ShardedByS3Key`` . If
              there are *n* ML compute instances launched for a training job, each instance
              gets approximately 1/*n* of the number of S3 objects. In this case, model
              training on each machine uses only the subset of training data.

              Don't choose more ML compute instances for training than available S3
              objects. If you do, some nodes won't get any data and you will pay for nodes
              that aren't getting any training data. This applies in both File and Pipe
              modes. Keep this in mind when developing algorithms.

              In distributed training, where you use multiple ML compute EC2 instances, you
              might choose ``ShardedByS3Key`` . If the algorithm requires copying training
              data to the ML storage volume (when ``TrainingInputMode`` is set to ``File``
              ), this copies 1/*n* of the number of objects.

            - **AttributeNames** *(list) --*

              A list of one or more attribute names to use that are found in a specified
              augmented manifest file.

              - *(string) --*

          - **FileSystemDataSource** *(dict) --*

            The file system that is associated with a channel.

            - **FileSystemId** *(string) --*

              The file system id.

            - **FileSystemAccessMode** *(string) --*

              The access mode of the mount of the directory associated with the channel. A
              directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
              mode.

            - **FileSystemType** *(string) --*

              The file system type.

            - **DirectoryPath** *(string) --*

              The full path to the directory to associate with the channel.

        - **ContentType** *(string) --*

          The MIME type of the data.

        - **CompressionType** *(string) --*

          If training data is compressed, the compression type. The default value is
          ``None`` . ``CompressionType`` is used only in Pipe input mode. In File mode,
          leave this field unset or set it to None.

        - **RecordWrapperType** *(string) --*

          Specify RecordIO as the value when input data is in raw format but the training
          algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
          individual S3 object in a RecordIO record. If the input data is already in
          RecordIO format, you don't need to set this attribute. For more information, see
          `Create a Dataset Using RecordIO
          <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
          .

          In File mode, leave this field unset or set it to None.

        - **InputMode** *(string) --*

          (Optional) The input mode to use for the data channel in a training job. If you
          don't set a value for ``InputMode`` , Amazon SageMaker uses the value set for
          ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
          setting in a  AlgorithmSpecification request when you have a channel that needs a
          different input mode from the training job's general setting. To download the
          data from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage
          volume, and mount the directory to a Docker volume, use ``File`` input mode. To
          stream data directly from Amazon S3 to the container, choose ``Pipe`` input mode.

          To use a model for incremental training, choose ``File`` input model.

        - **ShuffleConfig** *(dict) --*

          A configuration for a shuffle option for input data in a channel. If you use
          ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
          matches. If you use ``ManifestFile`` , the order of the S3 object references in
          the ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the
          order of the JSON lines in the ``AugmentedManifestFile`` is shuffled. The
          shuffling order is determined using the ``Seed`` value.

          For Pipe input mode, shuffling is done at the start of every epoch. With large
          datasets this ensures that the order of the training data is different for each
          epoch, it helps reduce bias and possible overfitting. In a multi-node training
          job when ShuffleConfig is combined with ``S3DataDistributionType`` of
          ``ShardedByS3Key`` , the data is shuffled across nodes so that the content sent
          to a particular node on the first epoch might be sent to a different node on the
          second epoch.

          - **Seed** *(integer) --*

            Determines the shuffling order in ``ShuffleConfig`` value.

    - **OutputDataConfig** *(dict) --*

      the path to the S3 bucket where you want to store model artifacts. Amazon SageMaker
      creates subfolders for the artifacts.

      - **KmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
        the model artifacts at rest using Amazon S3 server-side encryption. The
        ``KmsKeyId`` can be any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // KMS Key Alias  ``"alias/ExampleAlias"``

        * // Amazon Resource Name (ARN) of a KMS Key Alias
        ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

        If you use a KMS key ID or an alias of your master key, the Amazon SageMaker
        execution role must include permissions to call ``kms:Encrypt`` . If you don't
        provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3 for
        your role's account. Amazon SageMaker uses server-side encryption with KMS-managed
        keys for ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject``
        permission that only allows objects with server-side encryption, set the condition
        key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information,
        see `KMS-Managed Encryption Keys
        <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
        *Amazon Simple Storage Service Developer Guide.*

        The KMS key policy must grant permission to the IAM role that you specify in your
        ``CreateTrainingJob`` , ``CreateTransformJob`` , or
        ``CreateHyperParameterTuningJob`` requests. For more information, see `Using Key
        Policies in AWS KMS
        <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
        in the *AWS Key Management Service Developer Guide* .

      - **S3OutputPath** *(string) --*

        Identifies the S3 path where you want Amazon SageMaker to store the model
        artifacts. For example, ``s3://bucket-name/key-name-prefix`` .

    - **ResourceConfig** *(dict) --*

      The resources, including the ML compute instances and ML storage volumes, to use for
      model training.

      - **InstanceType** *(string) --*

        The ML compute instance type.

      - **InstanceCount** *(integer) --*

        The number of ML compute instances to use. For distributed training, provide a
        value greater than 1.

      - **VolumeSizeInGB** *(integer) --*

        The size of the ML storage volume that you want to provision.

        ML storage volumes store model artifacts and incremental states. Training
        algorithms might also use the ML storage volume for scratch space. If you want to
        store the training data in the ML storage volume, choose ``File`` as the
        ``TrainingInputMode`` in the algorithm specification.

        You must specify sufficient ML storage for your scenario.

        .. note::

          Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume
          type.

        .. note::

          Certain Nitro-based instances include local storage with a fixed total size,
          dependent on the instance type. When using these instances for training, Amazon
          SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage.
          You can't request a ``VolumeSizeInGB`` greater than the total size of the local
          instance storage.

          For a list of instance types that support local instance storage, including the
          total size per instance type, see `Instance Store Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
          .

      - **VolumeKmsKeyId** *(string) --*

        The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
        attached to the ML compute instance(s) that run the training job.

        .. note::

          Certain Nitro-based instances include local storage, dependent on the instance
          type. Local storage volumes are encrypted using a hardware module on the
          instance. You can't request a ``VolumeKmsKeyId`` when using an instance type with
          local storage.

          For a list of instance types that support local instance storage, see `Instance
          Store Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
          .

          For more information about local instance storage encryption, see `SSD Instance
          Store Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

        The ``VolumeKmsKeyId`` can be in any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

    - **StoppingCondition** *(dict) --*

      Specifies a limit to how long a model training job can run. When the job reaches the
      time limit, Amazon SageMaker ends the training job. Use this API to cap model
      training costs.

      To stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays
      job termination for 120 seconds. Algorithms can use this 120-second window to save
      the model artifacts.

      - **MaxRuntimeInSeconds** *(integer) --*

        The maximum length of time, in seconds, that the training or compilation job can
        run. If job does not complete during this time, Amazon SageMaker ends the job. If
        value is not specified, default value is 1 day. The maximum value is 28 days.

      - **MaxWaitTimeInSeconds** *(integer) --*

        The maximum length of time, in seconds, how long you are willing to wait for a
        managed spot training job to complete. It is the amount of time spent waiting for
        Spot capacity plus the amount of time the training job runs. It must be equal to or
        greater than ``MaxRuntimeInSeconds`` .
    """


_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef",
    {"S3DataType": str, "S3Uri": str},
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSource` `S3DataSource`

    The S3 location of the data source that is associated with a channel.

    - **S3DataType** *(string) --*

      If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
      SageMaker uses all objects with the specified key name prefix for batch
      transform.

      If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
      manifest file containing a list of object keys that you want Amazon SageMaker
      to use for batch transform.

      The following values are compatible: ``ManifestFile`` , ``S3Prefix``

      The following value is not compatible: ``AugmentedManifestFile``

    - **S3Uri** *(string) --*

      Depending on the value specified for the ``S3DataType`` , identifies either a
      key name prefix or a manifest. For example:

      * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

      * A manifest might look like this: ``s3://bucketname/example.manifest``   The
      manifest is an S3 object which is a JSON file with the following format:   ``[
      {"prefix": "s3://customer_bucket/some/prefix/"},``
      ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``
      ``...``    ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches
      the following ``s3Uris`` :
      ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
      set of ``S3Uris`` in this manifest constitutes the input data for the channel
      for this datasource. The object that each ``S3Uris`` points to must be readable
      by the IAM role that Amazon SageMaker uses to perform tasks on your behalf.
    """


_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef",
    {
        "S3DataSource": ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef
    },
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInput` `DataSource`

    Describes the location of the channel data, which is, the S3 location of the input
    data that the model can consume.

    - **S3DataSource** *(dict) --*

      The S3 location of the data source that is associated with a channel.

      - **S3DataType** *(string) --*

        If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
        SageMaker uses all objects with the specified key name prefix for batch
        transform.

        If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
        manifest file containing a list of object keys that you want Amazon SageMaker
        to use for batch transform.

        The following values are compatible: ``ManifestFile`` , ``S3Prefix``

        The following value is not compatible: ``AugmentedManifestFile``

      - **S3Uri** *(string) --*

        Depending on the value specified for the ``S3DataType`` , identifies either a
        key name prefix or a manifest. For example:

        * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

        * A manifest might look like this: ``s3://bucketname/example.manifest``   The
        manifest is an S3 object which is a JSON file with the following format:   ``[
        {"prefix": "s3://customer_bucket/some/prefix/"},``
        ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``
        ``...``    ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches
        the following ``s3Uris`` :
        ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
        set of ``S3Uris`` in this manifest constitutes the input data for the channel
        for this datasource. The object that each ``S3Uris`` points to must be readable
        by the IAM role that Amazon SageMaker uses to perform tasks on your behalf.
    """


_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef",
    {
        "DataSource": ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef,
        "ContentType": str,
        "CompressionType": str,
        "SplitType": str,
    },
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinition` `TransformInput`

    A description of the input source and the way the transform job consumes it.

    - **DataSource** *(dict) --*

      Describes the location of the channel data, which is, the S3 location of the input
      data that the model can consume.

      - **S3DataSource** *(dict) --*

        The S3 location of the data source that is associated with a channel.

        - **S3DataType** *(string) --*

          If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
          SageMaker uses all objects with the specified key name prefix for batch
          transform.

          If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
          manifest file containing a list of object keys that you want Amazon SageMaker
          to use for batch transform.

          The following values are compatible: ``ManifestFile`` , ``S3Prefix``

          The following value is not compatible: ``AugmentedManifestFile``

        - **S3Uri** *(string) --*

          Depending on the value specified for the ``S3DataType`` , identifies either a
          key name prefix or a manifest. For example:

          * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

          * A manifest might look like this: ``s3://bucketname/example.manifest``   The
          manifest is an S3 object which is a JSON file with the following format:   ``[
          {"prefix": "s3://customer_bucket/some/prefix/"},``
          ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``
          ``...``    ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches
          the following ``s3Uris`` :
          ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
          set of ``S3Uris`` in this manifest constitutes the input data for the channel
          for this datasource. The object that each ``S3Uris`` points to must be readable
          by the IAM role that Amazon SageMaker uses to perform tasks on your behalf.

    - **ContentType** *(string) --*

      The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker
      uses the MIME type with each http call to transfer data to the transform job.

    - **CompressionType** *(string) --*

      If your transform data is compressed, specify the compression type. Amazon
      SageMaker automatically decompresses the data for the transform job accordingly.
      The default value is ``None`` .

    - **SplitType** *(string) --*

      The method to use to split the transform job's data files into smaller batches.
      Splitting is necessary when the total size of each object is too large to fit in a
      single request. You can also use data splitting to improve performance by
      processing multiple concurrent mini-batches. The default value for ``SplitType`` is
      ``None`` , which indicates that input data files are not split, and request
      payloads contain the entire contents of an input object. Set the value of this
      parameter to ``Line`` to split records on a newline character boundary.
      ``SplitType`` also supports a number of record-oriented binary data formats.

      When splitting is enabled, the size of a mini-batch depends on the values of the
      ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
      ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
      records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
      ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records
      in each request.

      .. note::

        Some data formats represent a record as a binary payload wrapped with extra
        padding bytes. When splitting is applied to a binary data format, padding is
        removed if the value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is
        not removed if the value of ``BatchStrategy`` is set to ``MultiRecord`` .

        For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
        <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For
        more information about ``TFRecord`` , see `Consuming TFRecord data
        <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
        TensorFlow documentation.
    """


_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef",
    {"S3OutputPath": str, "Accept": str, "AssembleWith": str, "KmsKeyId": str},
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinition` `TransformOutput`

    Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
    from the transform job.

    - **S3OutputPath** *(string) --*

      The Amazon S3 path where you want Amazon SageMaker to store the results of the
      transform job. For example, ``s3://bucket-name/key-name-prefix`` .

      For every S3 object used as input for the transform job, batch transform stores the
      transformed data with an .``out`` suffix in a corresponding subfolder in the
      location in the output prefix. For example, for the input data stored at
      ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores
      the transformed data at
      ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
      transform doesn't upload partially processed objects. For an input S3 object that
      contains multiple records, it creates an .``out`` file only if the transform job
      succeeds on the entire file. When the input contains multiple S3 objects, the batch
      transform job processes the listed S3 objects and uploads only the output for
      successfully processed objects. If any object fails in the transform job batch
      transform marks the job as failed to prompt investigation.

    - **Accept** *(string) --*

      The MIME type used to specify the output data. Amazon SageMaker uses the MIME type
      with each http call to transfer data from the transform job.

    - **AssembleWith** *(string) --*

      Defines how to assemble the results of the transform job as a single S3 object.
      Choose a format that is most convenient to you. To concatenate the results in
      binary format, specify ``None`` . To add a newline character at the end of every
      transformed record, specify ``Line`` .

    - **KmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
      the model artifacts at rest using Amazon S3 server-side encryption. The
      ``KmsKeyId`` can be any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // KMS Key Alias  ``"alias/ExampleAlias"``

      * // Amazon Resource Name (ARN) of a KMS Key Alias
      ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

      If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for
      Amazon S3 for your role's account. For more information, see `KMS-Managed
      Encryption Keys
      <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
      *Amazon Simple Storage Service Developer Guide.*

      The KMS key policy must grant permission to the IAM role that you specify in your
      CreateModel request. For more information, see `Using Key Policies in AWS KMS
      <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the
      *AWS Key Management Service Developer Guide* .
    """


_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef",
    {"InstanceType": str, "InstanceCount": int, "VolumeKmsKeyId": str},
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinition` `TransformResources`

    Identifies the ML compute instances for the transform job.

    - **InstanceType** *(string) --*

      The ML compute instance type for the transform job. If you are using built-in
      algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge
      or ``ml.m5.large`` instance types.

    - **InstanceCount** *(integer) --*

      The number of ML compute instances to use in the transform job. For distributed
      transform jobs, specify a value greater than 1. The default value is ``1`` .

    - **VolumeKmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
      data on the storage volume attached to the ML compute instance(s) that run the
      batch transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef",
    {
        "MaxConcurrentTransforms": int,
        "MaxPayloadInMB": int,
        "BatchStrategy": str,
        "Environment": Dict[str, str],
        "TransformInput": ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef,
        "TransformOutput": ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef,
        "TransformResources": ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef,
    },
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseValidationSpecificationValidationProfiles` `TransformJobDefinition`

    The ``TransformJobDefinition`` object that describes the transform job that Amazon
    SageMaker runs to validate your algorithm.

    - **MaxConcurrentTransforms** *(integer) --*

      The maximum number of parallel requests that can be sent to each instance in a
      transform job. The default value is 1.

    - **MaxPayloadInMB** *(integer) --*

      The maximum payload size allowed, in MB. A payload is the data portion of a record
      (without metadata).

    - **BatchStrategy** *(string) --*

      A string that determines the number of records included in a single mini-batch.

       ``SingleRecord`` means only one record is used per mini-batch. ``MultiRecord`` means
       a mini-batch is set to contain as many records that can fit within the
       ``MaxPayloadInMB`` limit.

    - **Environment** *(dict) --*

      The environment variables to set in the Docker container. We support up to 16 key and
      values entries in the map.

      - *(string) --*

        - *(string) --*

    - **TransformInput** *(dict) --*

      A description of the input source and the way the transform job consumes it.

      - **DataSource** *(dict) --*

        Describes the location of the channel data, which is, the S3 location of the input
        data that the model can consume.

        - **S3DataSource** *(dict) --*

          The S3 location of the data source that is associated with a channel.

          - **S3DataType** *(string) --*

            If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
            SageMaker uses all objects with the specified key name prefix for batch
            transform.

            If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
            manifest file containing a list of object keys that you want Amazon SageMaker
            to use for batch transform.

            The following values are compatible: ``ManifestFile`` , ``S3Prefix``

            The following value is not compatible: ``AugmentedManifestFile``

          - **S3Uri** *(string) --*

            Depending on the value specified for the ``S3DataType`` , identifies either a
            key name prefix or a manifest. For example:

            * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

            * A manifest might look like this: ``s3://bucketname/example.manifest``   The
            manifest is an S3 object which is a JSON file with the following format:   ``[
            {"prefix": "s3://customer_bucket/some/prefix/"},``
            ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``
            ``...``    ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches
            the following ``s3Uris`` :
            ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
            set of ``S3Uris`` in this manifest constitutes the input data for the channel
            for this datasource. The object that each ``S3Uris`` points to must be readable
            by the IAM role that Amazon SageMaker uses to perform tasks on your behalf.

      - **ContentType** *(string) --*

        The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker
        uses the MIME type with each http call to transfer data to the transform job.

      - **CompressionType** *(string) --*

        If your transform data is compressed, specify the compression type. Amazon
        SageMaker automatically decompresses the data for the transform job accordingly.
        The default value is ``None`` .

      - **SplitType** *(string) --*

        The method to use to split the transform job's data files into smaller batches.
        Splitting is necessary when the total size of each object is too large to fit in a
        single request. You can also use data splitting to improve performance by
        processing multiple concurrent mini-batches. The default value for ``SplitType`` is
        ``None`` , which indicates that input data files are not split, and request
        payloads contain the entire contents of an input object. Set the value of this
        parameter to ``Line`` to split records on a newline character boundary.
        ``SplitType`` also supports a number of record-oriented binary data formats.

        When splitting is enabled, the size of a mini-batch depends on the values of the
        ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
        ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
        records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
        ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records
        in each request.

        .. note::

          Some data formats represent a record as a binary payload wrapped with extra
          padding bytes. When splitting is applied to a binary data format, padding is
          removed if the value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is
          not removed if the value of ``BatchStrategy`` is set to ``MultiRecord`` .

          For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
          <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For
          more information about ``TFRecord`` , see `Consuming TFRecord data
          <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
          TensorFlow documentation.

    - **TransformOutput** *(dict) --*

      Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
      from the transform job.

      - **S3OutputPath** *(string) --*

        The Amazon S3 path where you want Amazon SageMaker to store the results of the
        transform job. For example, ``s3://bucket-name/key-name-prefix`` .

        For every S3 object used as input for the transform job, batch transform stores the
        transformed data with an .``out`` suffix in a corresponding subfolder in the
        location in the output prefix. For example, for the input data stored at
        ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores
        the transformed data at
        ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
        transform doesn't upload partially processed objects. For an input S3 object that
        contains multiple records, it creates an .``out`` file only if the transform job
        succeeds on the entire file. When the input contains multiple S3 objects, the batch
        transform job processes the listed S3 objects and uploads only the output for
        successfully processed objects. If any object fails in the transform job batch
        transform marks the job as failed to prompt investigation.

      - **Accept** *(string) --*

        The MIME type used to specify the output data. Amazon SageMaker uses the MIME type
        with each http call to transfer data from the transform job.

      - **AssembleWith** *(string) --*

        Defines how to assemble the results of the transform job as a single S3 object.
        Choose a format that is most convenient to you. To concatenate the results in
        binary format, specify ``None`` . To add a newline character at the end of every
        transformed record, specify ``Line`` .

      - **KmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
        the model artifacts at rest using Amazon S3 server-side encryption. The
        ``KmsKeyId`` can be any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // KMS Key Alias  ``"alias/ExampleAlias"``

        * // Amazon Resource Name (ARN) of a KMS Key Alias
        ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

        If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for
        Amazon S3 for your role's account. For more information, see `KMS-Managed
        Encryption Keys
        <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
        *Amazon Simple Storage Service Developer Guide.*

        The KMS key policy must grant permission to the IAM role that you specify in your
        CreateModel request. For more information, see `Using Key Policies in AWS KMS
        <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the
        *AWS Key Management Service Developer Guide* .

    - **TransformResources** *(dict) --*

      Identifies the ML compute instances for the transform job.

      - **InstanceType** *(string) --*

        The ML compute instance type for the transform job. If you are using built-in
        algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge
        or ``ml.m5.large`` instance types.

      - **InstanceCount** *(integer) --*

        The number of ML compute instances to use in the transform job. For distributed
        transform jobs, specify a value greater than 1. The default value is ``1`` .

      - **VolumeKmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
        data on the storage volume attached to the ML compute instance(s) that run the
        batch transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTypeDef",
    {
        "ProfileName": str,
        "TrainingJobDefinition": ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTrainingJobDefinitionTypeDef,
        "TransformJobDefinition": ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef,
    },
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponseValidationSpecification` `ValidationProfiles`

    Defines a training job and a batch transform job that Amazon SageMaker runs to validate
    your algorithm.

    The data provided in the validation profile is made available to your buyers on AWS
    Marketplace.

    - **ProfileName** *(string) --*

      The name of the profile for the algorithm. The name must have 1 to 63 characters. Valid
      characters are a-z, A-Z, 0-9, and - (hyphen).

    - **TrainingJobDefinition** *(dict) --*

      The ``TrainingJobDefinition`` object that describes the training job that Amazon
      SageMaker runs to validate your algorithm.

      - **TrainingInputMode** *(string) --*

        The input mode used by the algorithm for the training job. For the input modes that
        Amazon SageMaker algorithms support, see `Algorithms
        <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ .

        If an algorithm supports the ``File`` input mode, Amazon SageMaker downloads the
        training data from S3 to the provisioned ML storage Volume, and mounts the directory
        to docker volume for training container. If an algorithm supports the ``Pipe`` input
        mode, Amazon SageMaker streams data directly from S3 to the container.

      - **HyperParameters** *(dict) --*

        The hyperparameters used for the training job.

        - *(string) --*

          - *(string) --*

      - **InputDataConfig** *(list) --*

        An array of ``Channel`` objects, each of which specifies an input source.

        - *(dict) --*

          A channel is a named input source that training algorithms can consume.

          - **ChannelName** *(string) --*

            The name of the channel.

          - **DataSource** *(dict) --*

            The location of the channel data.

            - **S3DataSource** *(dict) --*

              The S3 location of the data source that is associated with a channel.

              - **S3DataType** *(string) --*

                If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
                SageMaker uses all objects that match the specified key name prefix for model
                training.

                If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
                manifest file containing a list of object keys that you want Amazon SageMaker
                to use for model training.

                If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is
                an augmented manifest file in JSON lines format. This file contains the data
                you want to use for model training. ``AugmentedManifestFile`` can only be
                used if the Channel's input mode is ``Pipe`` .

              - **S3Uri** *(string) --*

                Depending on the value specified for the ``S3DataType`` , identifies either a
                key name prefix or a manifest. For example:

                * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

                * A manifest might look like this: ``s3://bucketname/example.manifest``   The
                manifest is an S3 object which is a JSON file with the following format:  The
                preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
                "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
                   ``"relative/path/custdata-2",``    ``...``
                   ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the
                   following ``s3Uris`` :
                   ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                   ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                    ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The
                    complete set of ``s3uris`` in this manifest is the input data for the
                    channel for this datasource. The object that each ``s3uris`` points to
                    must be readable by the IAM role that Amazon SageMaker uses to perform
                    tasks on your behalf.

              - **S3DataDistributionType** *(string) --*

                If you want Amazon SageMaker to replicate the entire dataset on each ML
                compute instance that is launched for model training, specify
                ``FullyReplicated`` .

                If you want Amazon SageMaker to replicate a subset of data on each ML compute
                instance that is launched for model training, specify ``ShardedByS3Key`` . If
                there are *n* ML compute instances launched for a training job, each instance
                gets approximately 1/*n* of the number of S3 objects. In this case, model
                training on each machine uses only the subset of training data.

                Don't choose more ML compute instances for training than available S3
                objects. If you do, some nodes won't get any data and you will pay for nodes
                that aren't getting any training data. This applies in both File and Pipe
                modes. Keep this in mind when developing algorithms.

                In distributed training, where you use multiple ML compute EC2 instances, you
                might choose ``ShardedByS3Key`` . If the algorithm requires copying training
                data to the ML storage volume (when ``TrainingInputMode`` is set to ``File``
                ), this copies 1/*n* of the number of objects.

              - **AttributeNames** *(list) --*

                A list of one or more attribute names to use that are found in a specified
                augmented manifest file.

                - *(string) --*

            - **FileSystemDataSource** *(dict) --*

              The file system that is associated with a channel.

              - **FileSystemId** *(string) --*

                The file system id.

              - **FileSystemAccessMode** *(string) --*

                The access mode of the mount of the directory associated with the channel. A
                directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
                mode.

              - **FileSystemType** *(string) --*

                The file system type.

              - **DirectoryPath** *(string) --*

                The full path to the directory to associate with the channel.

          - **ContentType** *(string) --*

            The MIME type of the data.

          - **CompressionType** *(string) --*

            If training data is compressed, the compression type. The default value is
            ``None`` . ``CompressionType`` is used only in Pipe input mode. In File mode,
            leave this field unset or set it to None.

          - **RecordWrapperType** *(string) --*

            Specify RecordIO as the value when input data is in raw format but the training
            algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
            individual S3 object in a RecordIO record. If the input data is already in
            RecordIO format, you don't need to set this attribute. For more information, see
            `Create a Dataset Using RecordIO
            <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
            .

            In File mode, leave this field unset or set it to None.

          - **InputMode** *(string) --*

            (Optional) The input mode to use for the data channel in a training job. If you
            don't set a value for ``InputMode`` , Amazon SageMaker uses the value set for
            ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
            setting in a  AlgorithmSpecification request when you have a channel that needs a
            different input mode from the training job's general setting. To download the
            data from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage
            volume, and mount the directory to a Docker volume, use ``File`` input mode. To
            stream data directly from Amazon S3 to the container, choose ``Pipe`` input mode.

            To use a model for incremental training, choose ``File`` input model.

          - **ShuffleConfig** *(dict) --*

            A configuration for a shuffle option for input data in a channel. If you use
            ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
            matches. If you use ``ManifestFile`` , the order of the S3 object references in
            the ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the
            order of the JSON lines in the ``AugmentedManifestFile`` is shuffled. The
            shuffling order is determined using the ``Seed`` value.

            For Pipe input mode, shuffling is done at the start of every epoch. With large
            datasets this ensures that the order of the training data is different for each
            epoch, it helps reduce bias and possible overfitting. In a multi-node training
            job when ShuffleConfig is combined with ``S3DataDistributionType`` of
            ``ShardedByS3Key`` , the data is shuffled across nodes so that the content sent
            to a particular node on the first epoch might be sent to a different node on the
            second epoch.

            - **Seed** *(integer) --*

              Determines the shuffling order in ``ShuffleConfig`` value.

      - **OutputDataConfig** *(dict) --*

        the path to the S3 bucket where you want to store model artifacts. Amazon SageMaker
        creates subfolders for the artifacts.

        - **KmsKeyId** *(string) --*

          The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
          the model artifacts at rest using Amazon S3 server-side encryption. The
          ``KmsKeyId`` can be any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // KMS Key Alias  ``"alias/ExampleAlias"``

          * // Amazon Resource Name (ARN) of a KMS Key Alias
          ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

          If you use a KMS key ID or an alias of your master key, the Amazon SageMaker
          execution role must include permissions to call ``kms:Encrypt`` . If you don't
          provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3 for
          your role's account. Amazon SageMaker uses server-side encryption with KMS-managed
          keys for ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject``
          permission that only allows objects with server-side encryption, set the condition
          key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information,
          see `KMS-Managed Encryption Keys
          <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
          *Amazon Simple Storage Service Developer Guide.*

          The KMS key policy must grant permission to the IAM role that you specify in your
          ``CreateTrainingJob`` , ``CreateTransformJob`` , or
          ``CreateHyperParameterTuningJob`` requests. For more information, see `Using Key
          Policies in AWS KMS
          <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
          in the *AWS Key Management Service Developer Guide* .

        - **S3OutputPath** *(string) --*

          Identifies the S3 path where you want Amazon SageMaker to store the model
          artifacts. For example, ``s3://bucket-name/key-name-prefix`` .

      - **ResourceConfig** *(dict) --*

        The resources, including the ML compute instances and ML storage volumes, to use for
        model training.

        - **InstanceType** *(string) --*

          The ML compute instance type.

        - **InstanceCount** *(integer) --*

          The number of ML compute instances to use. For distributed training, provide a
          value greater than 1.

        - **VolumeSizeInGB** *(integer) --*

          The size of the ML storage volume that you want to provision.

          ML storage volumes store model artifacts and incremental states. Training
          algorithms might also use the ML storage volume for scratch space. If you want to
          store the training data in the ML storage volume, choose ``File`` as the
          ``TrainingInputMode`` in the algorithm specification.

          You must specify sufficient ML storage for your scenario.

          .. note::

            Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume
            type.

          .. note::

            Certain Nitro-based instances include local storage with a fixed total size,
            dependent on the instance type. When using these instances for training, Amazon
            SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage.
            You can't request a ``VolumeSizeInGB`` greater than the total size of the local
            instance storage.

            For a list of instance types that support local instance storage, including the
            total size per instance type, see `Instance Store Volumes
            <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
            .

        - **VolumeKmsKeyId** *(string) --*

          The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
          attached to the ML compute instance(s) that run the training job.

          .. note::

            Certain Nitro-based instances include local storage, dependent on the instance
            type. Local storage volumes are encrypted using a hardware module on the
            instance. You can't request a ``VolumeKmsKeyId`` when using an instance type with
            local storage.

            For a list of instance types that support local instance storage, see `Instance
            Store Volumes
            <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
            .

            For more information about local instance storage encryption, see `SSD Instance
            Store Volumes
            <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

          The ``VolumeKmsKeyId`` can be in any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      - **StoppingCondition** *(dict) --*

        Specifies a limit to how long a model training job can run. When the job reaches the
        time limit, Amazon SageMaker ends the training job. Use this API to cap model
        training costs.

        To stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays
        job termination for 120 seconds. Algorithms can use this 120-second window to save
        the model artifacts.

        - **MaxRuntimeInSeconds** *(integer) --*

          The maximum length of time, in seconds, that the training or compilation job can
          run. If job does not complete during this time, Amazon SageMaker ends the job. If
          value is not specified, default value is 1 day. The maximum value is 28 days.

        - **MaxWaitTimeInSeconds** *(integer) --*

          The maximum length of time, in seconds, how long you are willing to wait for a
          managed spot training job to complete. It is the amount of time spent waiting for
          Spot capacity plus the amount of time the training job runs. It must be equal to or
          greater than ``MaxRuntimeInSeconds`` .

    - **TransformJobDefinition** *(dict) --*

      The ``TransformJobDefinition`` object that describes the transform job that Amazon
      SageMaker runs to validate your algorithm.

      - **MaxConcurrentTransforms** *(integer) --*

        The maximum number of parallel requests that can be sent to each instance in a
        transform job. The default value is 1.

      - **MaxPayloadInMB** *(integer) --*

        The maximum payload size allowed, in MB. A payload is the data portion of a record
        (without metadata).

      - **BatchStrategy** *(string) --*

        A string that determines the number of records included in a single mini-batch.

         ``SingleRecord`` means only one record is used per mini-batch. ``MultiRecord`` means
         a mini-batch is set to contain as many records that can fit within the
         ``MaxPayloadInMB`` limit.

      - **Environment** *(dict) --*

        The environment variables to set in the Docker container. We support up to 16 key and
        values entries in the map.

        - *(string) --*

          - *(string) --*

      - **TransformInput** *(dict) --*

        A description of the input source and the way the transform job consumes it.

        - **DataSource** *(dict) --*

          Describes the location of the channel data, which is, the S3 location of the input
          data that the model can consume.

          - **S3DataSource** *(dict) --*

            The S3 location of the data source that is associated with a channel.

            - **S3DataType** *(string) --*

              If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
              SageMaker uses all objects with the specified key name prefix for batch
              transform.

              If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
              manifest file containing a list of object keys that you want Amazon SageMaker
              to use for batch transform.

              The following values are compatible: ``ManifestFile`` , ``S3Prefix``

              The following value is not compatible: ``AugmentedManifestFile``

            - **S3Uri** *(string) --*

              Depending on the value specified for the ``S3DataType`` , identifies either a
              key name prefix or a manifest. For example:

              * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

              * A manifest might look like this: ``s3://bucketname/example.manifest``   The
              manifest is an S3 object which is a JSON file with the following format:   ``[
              {"prefix": "s3://customer_bucket/some/prefix/"},``
              ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``
              ``...``    ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches
              the following ``s3Uris`` :
              ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
              ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
              ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
              set of ``S3Uris`` in this manifest constitutes the input data for the channel
              for this datasource. The object that each ``S3Uris`` points to must be readable
              by the IAM role that Amazon SageMaker uses to perform tasks on your behalf.

        - **ContentType** *(string) --*

          The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker
          uses the MIME type with each http call to transfer data to the transform job.

        - **CompressionType** *(string) --*

          If your transform data is compressed, specify the compression type. Amazon
          SageMaker automatically decompresses the data for the transform job accordingly.
          The default value is ``None`` .

        - **SplitType** *(string) --*

          The method to use to split the transform job's data files into smaller batches.
          Splitting is necessary when the total size of each object is too large to fit in a
          single request. You can also use data splitting to improve performance by
          processing multiple concurrent mini-batches. The default value for ``SplitType`` is
          ``None`` , which indicates that input data files are not split, and request
          payloads contain the entire contents of an input object. Set the value of this
          parameter to ``Line`` to split records on a newline character boundary.
          ``SplitType`` also supports a number of record-oriented binary data formats.

          When splitting is enabled, the size of a mini-batch depends on the values of the
          ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
          ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
          records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
          ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records
          in each request.

          .. note::

            Some data formats represent a record as a binary payload wrapped with extra
            padding bytes. When splitting is applied to a binary data format, padding is
            removed if the value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is
            not removed if the value of ``BatchStrategy`` is set to ``MultiRecord`` .

            For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
            <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For
            more information about ``TFRecord`` , see `Consuming TFRecord data
            <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
            TensorFlow documentation.

      - **TransformOutput** *(dict) --*

        Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
        from the transform job.

        - **S3OutputPath** *(string) --*

          The Amazon S3 path where you want Amazon SageMaker to store the results of the
          transform job. For example, ``s3://bucket-name/key-name-prefix`` .

          For every S3 object used as input for the transform job, batch transform stores the
          transformed data with an .``out`` suffix in a corresponding subfolder in the
          location in the output prefix. For example, for the input data stored at
          ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores
          the transformed data at
          ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
          transform doesn't upload partially processed objects. For an input S3 object that
          contains multiple records, it creates an .``out`` file only if the transform job
          succeeds on the entire file. When the input contains multiple S3 objects, the batch
          transform job processes the listed S3 objects and uploads only the output for
          successfully processed objects. If any object fails in the transform job batch
          transform marks the job as failed to prompt investigation.

        - **Accept** *(string) --*

          The MIME type used to specify the output data. Amazon SageMaker uses the MIME type
          with each http call to transfer data from the transform job.

        - **AssembleWith** *(string) --*

          Defines how to assemble the results of the transform job as a single S3 object.
          Choose a format that is most convenient to you. To concatenate the results in
          binary format, specify ``None`` . To add a newline character at the end of every
          transformed record, specify ``Line`` .

        - **KmsKeyId** *(string) --*

          The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
          the model artifacts at rest using Amazon S3 server-side encryption. The
          ``KmsKeyId`` can be any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // KMS Key Alias  ``"alias/ExampleAlias"``

          * // Amazon Resource Name (ARN) of a KMS Key Alias
          ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

          If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for
          Amazon S3 for your role's account. For more information, see `KMS-Managed
          Encryption Keys
          <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
          *Amazon Simple Storage Service Developer Guide.*

          The KMS key policy must grant permission to the IAM role that you specify in your
          CreateModel request. For more information, see `Using Key Policies in AWS KMS
          <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the
          *AWS Key Management Service Developer Guide* .

      - **TransformResources** *(dict) --*

        Identifies the ML compute instances for the transform job.

        - **InstanceType** *(string) --*

          The ML compute instance type for the transform job. If you are using built-in
          algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge
          or ``ml.m5.large`` instance types.

        - **InstanceCount** *(integer) --*

          The number of ML compute instances to use in the transform job. For distributed
          transform jobs, specify a value greater than 1. The default value is ``1`` .

        - **VolumeKmsKeyId** *(string) --*

          The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
          data on the storage volume attached to the ML compute instance(s) that run the
          batch transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientDescribeAlgorithmResponseValidationSpecificationTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseValidationSpecificationTypeDef",
    {
        "ValidationRole": str,
        "ValidationProfiles": List[
            ClientDescribeAlgorithmResponseValidationSpecificationValidationProfilesTypeDef
        ],
    },
    total=False,
)


class ClientDescribeAlgorithmResponseValidationSpecificationTypeDef(
    _ClientDescribeAlgorithmResponseValidationSpecificationTypeDef
):
    """
    Type definition for `ClientDescribeAlgorithmResponse` `ValidationSpecification`

    Details about configurations for one or more training jobs that Amazon SageMaker runs to test
    the algorithm.

    - **ValidationRole** *(string) --*

      The IAM roles that Amazon SageMaker uses to run the training jobs.

    - **ValidationProfiles** *(list) --*

      An array of ``AlgorithmValidationProfile`` objects, each of which specifies a training job
      and batch transform job that Amazon SageMaker runs to validate your algorithm.

      - *(dict) --*

        Defines a training job and a batch transform job that Amazon SageMaker runs to validate
        your algorithm.

        The data provided in the validation profile is made available to your buyers on AWS
        Marketplace.

        - **ProfileName** *(string) --*

          The name of the profile for the algorithm. The name must have 1 to 63 characters. Valid
          characters are a-z, A-Z, 0-9, and - (hyphen).

        - **TrainingJobDefinition** *(dict) --*

          The ``TrainingJobDefinition`` object that describes the training job that Amazon
          SageMaker runs to validate your algorithm.

          - **TrainingInputMode** *(string) --*

            The input mode used by the algorithm for the training job. For the input modes that
            Amazon SageMaker algorithms support, see `Algorithms
            <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ .

            If an algorithm supports the ``File`` input mode, Amazon SageMaker downloads the
            training data from S3 to the provisioned ML storage Volume, and mounts the directory
            to docker volume for training container. If an algorithm supports the ``Pipe`` input
            mode, Amazon SageMaker streams data directly from S3 to the container.

          - **HyperParameters** *(dict) --*

            The hyperparameters used for the training job.

            - *(string) --*

              - *(string) --*

          - **InputDataConfig** *(list) --*

            An array of ``Channel`` objects, each of which specifies an input source.

            - *(dict) --*

              A channel is a named input source that training algorithms can consume.

              - **ChannelName** *(string) --*

                The name of the channel.

              - **DataSource** *(dict) --*

                The location of the channel data.

                - **S3DataSource** *(dict) --*

                  The S3 location of the data source that is associated with a channel.

                  - **S3DataType** *(string) --*

                    If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
                    SageMaker uses all objects that match the specified key name prefix for model
                    training.

                    If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
                    manifest file containing a list of object keys that you want Amazon SageMaker
                    to use for model training.

                    If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is
                    an augmented manifest file in JSON lines format. This file contains the data
                    you want to use for model training. ``AugmentedManifestFile`` can only be
                    used if the Channel's input mode is ``Pipe`` .

                  - **S3Uri** *(string) --*

                    Depending on the value specified for the ``S3DataType`` , identifies either a
                    key name prefix or a manifest. For example:

                    * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

                    * A manifest might look like this: ``s3://bucketname/example.manifest``   The
                    manifest is an S3 object which is a JSON file with the following format:  The
                    preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
                    "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
                       ``"relative/path/custdata-2",``    ``...``
                       ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the
                       following ``s3Uris`` :
                       ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                       ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                        ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The
                        complete set of ``s3uris`` in this manifest is the input data for the
                        channel for this datasource. The object that each ``s3uris`` points to
                        must be readable by the IAM role that Amazon SageMaker uses to perform
                        tasks on your behalf.

                  - **S3DataDistributionType** *(string) --*

                    If you want Amazon SageMaker to replicate the entire dataset on each ML
                    compute instance that is launched for model training, specify
                    ``FullyReplicated`` .

                    If you want Amazon SageMaker to replicate a subset of data on each ML compute
                    instance that is launched for model training, specify ``ShardedByS3Key`` . If
                    there are *n* ML compute instances launched for a training job, each instance
                    gets approximately 1/*n* of the number of S3 objects. In this case, model
                    training on each machine uses only the subset of training data.

                    Don't choose more ML compute instances for training than available S3
                    objects. If you do, some nodes won't get any data and you will pay for nodes
                    that aren't getting any training data. This applies in both File and Pipe
                    modes. Keep this in mind when developing algorithms.

                    In distributed training, where you use multiple ML compute EC2 instances, you
                    might choose ``ShardedByS3Key`` . If the algorithm requires copying training
                    data to the ML storage volume (when ``TrainingInputMode`` is set to ``File``
                    ), this copies 1/*n* of the number of objects.

                  - **AttributeNames** *(list) --*

                    A list of one or more attribute names to use that are found in a specified
                    augmented manifest file.

                    - *(string) --*

                - **FileSystemDataSource** *(dict) --*

                  The file system that is associated with a channel.

                  - **FileSystemId** *(string) --*

                    The file system id.

                  - **FileSystemAccessMode** *(string) --*

                    The access mode of the mount of the directory associated with the channel. A
                    directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
                    mode.

                  - **FileSystemType** *(string) --*

                    The file system type.

                  - **DirectoryPath** *(string) --*

                    The full path to the directory to associate with the channel.

              - **ContentType** *(string) --*

                The MIME type of the data.

              - **CompressionType** *(string) --*

                If training data is compressed, the compression type. The default value is
                ``None`` . ``CompressionType`` is used only in Pipe input mode. In File mode,
                leave this field unset or set it to None.

              - **RecordWrapperType** *(string) --*

                Specify RecordIO as the value when input data is in raw format but the training
                algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
                individual S3 object in a RecordIO record. If the input data is already in
                RecordIO format, you don't need to set this attribute. For more information, see
                `Create a Dataset Using RecordIO
                <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
                .

                In File mode, leave this field unset or set it to None.

              - **InputMode** *(string) --*

                (Optional) The input mode to use for the data channel in a training job. If you
                don't set a value for ``InputMode`` , Amazon SageMaker uses the value set for
                ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
                setting in a  AlgorithmSpecification request when you have a channel that needs a
                different input mode from the training job's general setting. To download the
                data from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage
                volume, and mount the directory to a Docker volume, use ``File`` input mode. To
                stream data directly from Amazon S3 to the container, choose ``Pipe`` input mode.

                To use a model for incremental training, choose ``File`` input model.

              - **ShuffleConfig** *(dict) --*

                A configuration for a shuffle option for input data in a channel. If you use
                ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
                matches. If you use ``ManifestFile`` , the order of the S3 object references in
                the ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the
                order of the JSON lines in the ``AugmentedManifestFile`` is shuffled. The
                shuffling order is determined using the ``Seed`` value.

                For Pipe input mode, shuffling is done at the start of every epoch. With large
                datasets this ensures that the order of the training data is different for each
                epoch, it helps reduce bias and possible overfitting. In a multi-node training
                job when ShuffleConfig is combined with ``S3DataDistributionType`` of
                ``ShardedByS3Key`` , the data is shuffled across nodes so that the content sent
                to a particular node on the first epoch might be sent to a different node on the
                second epoch.

                - **Seed** *(integer) --*

                  Determines the shuffling order in ``ShuffleConfig`` value.

          - **OutputDataConfig** *(dict) --*

            the path to the S3 bucket where you want to store model artifacts. Amazon SageMaker
            creates subfolders for the artifacts.

            - **KmsKeyId** *(string) --*

              The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
              the model artifacts at rest using Amazon S3 server-side encryption. The
              ``KmsKeyId`` can be any of the following formats:

              * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // Amazon Resource Name (ARN) of a KMS Key
              ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // KMS Key Alias  ``"alias/ExampleAlias"``

              * // Amazon Resource Name (ARN) of a KMS Key Alias
              ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

              If you use a KMS key ID or an alias of your master key, the Amazon SageMaker
              execution role must include permissions to call ``kms:Encrypt`` . If you don't
              provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3 for
              your role's account. Amazon SageMaker uses server-side encryption with KMS-managed
              keys for ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject``
              permission that only allows objects with server-side encryption, set the condition
              key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information,
              see `KMS-Managed Encryption Keys
              <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
              *Amazon Simple Storage Service Developer Guide.*

              The KMS key policy must grant permission to the IAM role that you specify in your
              ``CreateTrainingJob`` , ``CreateTransformJob`` , or
              ``CreateHyperParameterTuningJob`` requests. For more information, see `Using Key
              Policies in AWS KMS
              <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
              in the *AWS Key Management Service Developer Guide* .

            - **S3OutputPath** *(string) --*

              Identifies the S3 path where you want Amazon SageMaker to store the model
              artifacts. For example, ``s3://bucket-name/key-name-prefix`` .

          - **ResourceConfig** *(dict) --*

            The resources, including the ML compute instances and ML storage volumes, to use for
            model training.

            - **InstanceType** *(string) --*

              The ML compute instance type.

            - **InstanceCount** *(integer) --*

              The number of ML compute instances to use. For distributed training, provide a
              value greater than 1.

            - **VolumeSizeInGB** *(integer) --*

              The size of the ML storage volume that you want to provision.

              ML storage volumes store model artifacts and incremental states. Training
              algorithms might also use the ML storage volume for scratch space. If you want to
              store the training data in the ML storage volume, choose ``File`` as the
              ``TrainingInputMode`` in the algorithm specification.

              You must specify sufficient ML storage for your scenario.

              .. note::

                Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume
                type.

              .. note::

                Certain Nitro-based instances include local storage with a fixed total size,
                dependent on the instance type. When using these instances for training, Amazon
                SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage.
                You can't request a ``VolumeSizeInGB`` greater than the total size of the local
                instance storage.

                For a list of instance types that support local instance storage, including the
                total size per instance type, see `Instance Store Volumes
                <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
                .

            - **VolumeKmsKeyId** *(string) --*

              The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
              attached to the ML compute instance(s) that run the training job.

              .. note::

                Certain Nitro-based instances include local storage, dependent on the instance
                type. Local storage volumes are encrypted using a hardware module on the
                instance. You can't request a ``VolumeKmsKeyId`` when using an instance type with
                local storage.

                For a list of instance types that support local instance storage, see `Instance
                Store Volumes
                <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
                .

                For more information about local instance storage encryption, see `SSD Instance
                Store Volumes
                <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

              The ``VolumeKmsKeyId`` can be in any of the following formats:

              * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // Amazon Resource Name (ARN) of a KMS Key
              ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

          - **StoppingCondition** *(dict) --*

            Specifies a limit to how long a model training job can run. When the job reaches the
            time limit, Amazon SageMaker ends the training job. Use this API to cap model
            training costs.

            To stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays
            job termination for 120 seconds. Algorithms can use this 120-second window to save
            the model artifacts.

            - **MaxRuntimeInSeconds** *(integer) --*

              The maximum length of time, in seconds, that the training or compilation job can
              run. If job does not complete during this time, Amazon SageMaker ends the job. If
              value is not specified, default value is 1 day. The maximum value is 28 days.

            - **MaxWaitTimeInSeconds** *(integer) --*

              The maximum length of time, in seconds, how long you are willing to wait for a
              managed spot training job to complete. It is the amount of time spent waiting for
              Spot capacity plus the amount of time the training job runs. It must be equal to or
              greater than ``MaxRuntimeInSeconds`` .

        - **TransformJobDefinition** *(dict) --*

          The ``TransformJobDefinition`` object that describes the transform job that Amazon
          SageMaker runs to validate your algorithm.

          - **MaxConcurrentTransforms** *(integer) --*

            The maximum number of parallel requests that can be sent to each instance in a
            transform job. The default value is 1.

          - **MaxPayloadInMB** *(integer) --*

            The maximum payload size allowed, in MB. A payload is the data portion of a record
            (without metadata).

          - **BatchStrategy** *(string) --*

            A string that determines the number of records included in a single mini-batch.

             ``SingleRecord`` means only one record is used per mini-batch. ``MultiRecord`` means
             a mini-batch is set to contain as many records that can fit within the
             ``MaxPayloadInMB`` limit.

          - **Environment** *(dict) --*

            The environment variables to set in the Docker container. We support up to 16 key and
            values entries in the map.

            - *(string) --*

              - *(string) --*

          - **TransformInput** *(dict) --*

            A description of the input source and the way the transform job consumes it.

            - **DataSource** *(dict) --*

              Describes the location of the channel data, which is, the S3 location of the input
              data that the model can consume.

              - **S3DataSource** *(dict) --*

                The S3 location of the data source that is associated with a channel.

                - **S3DataType** *(string) --*

                  If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
                  SageMaker uses all objects with the specified key name prefix for batch
                  transform.

                  If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
                  manifest file containing a list of object keys that you want Amazon SageMaker
                  to use for batch transform.

                  The following values are compatible: ``ManifestFile`` , ``S3Prefix``

                  The following value is not compatible: ``AugmentedManifestFile``

                - **S3Uri** *(string) --*

                  Depending on the value specified for the ``S3DataType`` , identifies either a
                  key name prefix or a manifest. For example:

                  * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

                  * A manifest might look like this: ``s3://bucketname/example.manifest``   The
                  manifest is an S3 object which is a JSON file with the following format:   ``[
                  {"prefix": "s3://customer_bucket/some/prefix/"},``
                  ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``
                  ``...``    ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches
                  the following ``s3Uris`` :
                  ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                  ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                  ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
                  set of ``S3Uris`` in this manifest constitutes the input data for the channel
                  for this datasource. The object that each ``S3Uris`` points to must be readable
                  by the IAM role that Amazon SageMaker uses to perform tasks on your behalf.

            - **ContentType** *(string) --*

              The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker
              uses the MIME type with each http call to transfer data to the transform job.

            - **CompressionType** *(string) --*

              If your transform data is compressed, specify the compression type. Amazon
              SageMaker automatically decompresses the data for the transform job accordingly.
              The default value is ``None`` .

            - **SplitType** *(string) --*

              The method to use to split the transform job's data files into smaller batches.
              Splitting is necessary when the total size of each object is too large to fit in a
              single request. You can also use data splitting to improve performance by
              processing multiple concurrent mini-batches. The default value for ``SplitType`` is
              ``None`` , which indicates that input data files are not split, and request
              payloads contain the entire contents of an input object. Set the value of this
              parameter to ``Line`` to split records on a newline character boundary.
              ``SplitType`` also supports a number of record-oriented binary data formats.

              When splitting is enabled, the size of a mini-batch depends on the values of the
              ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
              ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
              records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
              ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records
              in each request.

              .. note::

                Some data formats represent a record as a binary payload wrapped with extra
                padding bytes. When splitting is applied to a binary data format, padding is
                removed if the value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is
                not removed if the value of ``BatchStrategy`` is set to ``MultiRecord`` .

                For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
                <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For
                more information about ``TFRecord`` , see `Consuming TFRecord data
                <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
                TensorFlow documentation.

          - **TransformOutput** *(dict) --*

            Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
            from the transform job.

            - **S3OutputPath** *(string) --*

              The Amazon S3 path where you want Amazon SageMaker to store the results of the
              transform job. For example, ``s3://bucket-name/key-name-prefix`` .

              For every S3 object used as input for the transform job, batch transform stores the
              transformed data with an .``out`` suffix in a corresponding subfolder in the
              location in the output prefix. For example, for the input data stored at
              ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores
              the transformed data at
              ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
              transform doesn't upload partially processed objects. For an input S3 object that
              contains multiple records, it creates an .``out`` file only if the transform job
              succeeds on the entire file. When the input contains multiple S3 objects, the batch
              transform job processes the listed S3 objects and uploads only the output for
              successfully processed objects. If any object fails in the transform job batch
              transform marks the job as failed to prompt investigation.

            - **Accept** *(string) --*

              The MIME type used to specify the output data. Amazon SageMaker uses the MIME type
              with each http call to transfer data from the transform job.

            - **AssembleWith** *(string) --*

              Defines how to assemble the results of the transform job as a single S3 object.
              Choose a format that is most convenient to you. To concatenate the results in
              binary format, specify ``None`` . To add a newline character at the end of every
              transformed record, specify ``Line`` .

            - **KmsKeyId** *(string) --*

              The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
              the model artifacts at rest using Amazon S3 server-side encryption. The
              ``KmsKeyId`` can be any of the following formats:

              * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // Amazon Resource Name (ARN) of a KMS Key
              ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // KMS Key Alias  ``"alias/ExampleAlias"``

              * // Amazon Resource Name (ARN) of a KMS Key Alias
              ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

              If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for
              Amazon S3 for your role's account. For more information, see `KMS-Managed
              Encryption Keys
              <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
              *Amazon Simple Storage Service Developer Guide.*

              The KMS key policy must grant permission to the IAM role that you specify in your
              CreateModel request. For more information, see `Using Key Policies in AWS KMS
              <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the
              *AWS Key Management Service Developer Guide* .

          - **TransformResources** *(dict) --*

            Identifies the ML compute instances for the transform job.

            - **InstanceType** *(string) --*

              The ML compute instance type for the transform job. If you are using built-in
              algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge
              or ``ml.m5.large`` instance types.

            - **InstanceCount** *(integer) --*

              The number of ML compute instances to use in the transform job. For distributed
              transform jobs, specify a value greater than 1. The default value is ``1`` .

            - **VolumeKmsKeyId** *(string) --*

              The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
              data on the storage volume attached to the ML compute instance(s) that run the
              batch transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

              * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // Amazon Resource Name (ARN) of a KMS Key
              ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientDescribeAlgorithmResponseTypeDef = TypedDict(
    "_ClientDescribeAlgorithmResponseTypeDef",
    {
        "AlgorithmName": str,
        "AlgorithmArn": str,
        "AlgorithmDescription": str,
        "CreationTime": datetime,
        "TrainingSpecification": ClientDescribeAlgorithmResponseTrainingSpecificationTypeDef,
        "InferenceSpecification": ClientDescribeAlgorithmResponseInferenceSpecificationTypeDef,
        "ValidationSpecification": ClientDescribeAlgorithmResponseValidationSpecificationTypeDef,
        "AlgorithmStatus": str,
        "AlgorithmStatusDetails": ClientDescribeAlgorithmResponseAlgorithmStatusDetailsTypeDef,
        "ProductId": str,
        "CertifyForMarketplace": bool,
    },
    total=False,
)


class ClientDescribeAlgorithmResponseTypeDef(_ClientDescribeAlgorithmResponseTypeDef):
    """
    Type definition for `ClientDescribeAlgorithm` `Response`

    - **AlgorithmName** *(string) --*

      The name of the algorithm being described.

    - **AlgorithmArn** *(string) --*

      The Amazon Resource Name (ARN) of the algorithm.

    - **AlgorithmDescription** *(string) --*

      A brief summary about the algorithm.

    - **CreationTime** *(datetime) --*

      A timestamp specifying when the algorithm was created.

    - **TrainingSpecification** *(dict) --*

      Details about training jobs run by this algorithm.

      - **TrainingImage** *(string) --*

        The Amazon ECR registry path of the Docker image that contains the training algorithm.

      - **TrainingImageDigest** *(string) --*

        An MD5 hash of the training algorithm that identifies the Docker image used for training.

      - **SupportedHyperParameters** *(list) --*

        A list of the ``HyperParameterSpecification`` objects, that define the supported
        hyperparameters. This is required if the algorithm supports automatic model tuning.>

        - *(dict) --*

          Defines a hyperparameter to be used by an algorithm.

          - **Name** *(string) --*

            The name of this hyperparameter. The name must be unique.

          - **Description** *(string) --*

            A brief description of the hyperparameter.

          - **Type** *(string) --*

            The type of this hyperparameter. The valid types are ``Integer`` , ``Continuous`` ,
            ``Categorical`` , and ``FreeText`` .

          - **Range** *(dict) --*

            The allowed range for this hyperparameter.

            - **IntegerParameterRangeSpecification** *(dict) --*

              A ``IntegerParameterRangeSpecification`` object that defines the possible values for
              an integer hyperparameter.

              - **MinValue** *(string) --*

                The minimum integer value allowed.

              - **MaxValue** *(string) --*

                The maximum integer value allowed.

            - **ContinuousParameterRangeSpecification** *(dict) --*

              A ``ContinuousParameterRangeSpecification`` object that defines the possible values
              for a continuous hyperparameter.

              - **MinValue** *(string) --*

                The minimum floating-point value allowed.

              - **MaxValue** *(string) --*

                The maximum floating-point value allowed.

            - **CategoricalParameterRangeSpecification** *(dict) --*

              A ``CategoricalParameterRangeSpecification`` object that defines the possible values
              for a categorical hyperparameter.

              - **Values** *(list) --*

                The allowed categories for the hyperparameter.

                - *(string) --*

          - **IsTunable** *(boolean) --*

            Indicates whether this hyperparameter is tunable in a hyperparameter tuning job.

          - **IsRequired** *(boolean) --*

            Indicates whether this hyperparameter is required.

          - **DefaultValue** *(string) --*

            The default value for this hyperparameter. If a default value is specified, a
            hyperparameter cannot be required.

      - **SupportedTrainingInstanceTypes** *(list) --*

        A list of the instance types that this algorithm can use for training.

        - *(string) --*

      - **SupportsDistributedTraining** *(boolean) --*

        Indicates whether the algorithm supports distributed training. If set to false, buyers
        cant request more than one instance during training.

      - **MetricDefinitions** *(list) --*

        A list of ``MetricDefinition`` objects, which are used for parsing metrics generated by the
        algorithm.

        - *(dict) --*

          Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
          Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
          metric that a hyperparameter tuning job uses as its objective metric to choose the best
          training job.

          - **Name** *(string) --*

            The name of the metric.

          - **Regex** *(string) --*

            A regular expression that searches the output of a training job and gets the value of
            the metric. For more information about using regular expressions to define metrics, see
            `Defining Objective Metrics
            <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
            .

      - **TrainingChannels** *(list) --*

        A list of ``ChannelSpecification`` objects, which specify the input sources to be used by
        the algorithm.

        - *(dict) --*

          Defines a named input source, called a channel, to be used by an algorithm.

          - **Name** *(string) --*

            The name of the channel.

          - **Description** *(string) --*

            A brief description of the channel.

          - **IsRequired** *(boolean) --*

            Indicates whether the channel is required by the algorithm.

          - **SupportedContentTypes** *(list) --*

            The supported MIME types for the data.

            - *(string) --*

          - **SupportedCompressionTypes** *(list) --*

            The allowed compression types, if data compression is used.

            - *(string) --*

          - **SupportedInputModes** *(list) --*

            The allowed input mode, either FILE or PIPE.

            In FILE mode, Amazon SageMaker copies the data from the input source onto the local
            Amazon Elastic Block Store (Amazon EBS) volumes before starting your training
            algorithm. This is the most commonly used input mode.

            In PIPE mode, Amazon SageMaker streams input data from the source directly to your
            algorithm without using the EBS volume.

            - *(string) --*

      - **SupportedTuningJobObjectiveMetrics** *(list) --*

        A list of the metrics that the algorithm emits that can be used as the objective metric in
        a hyperparameter tuning job.

        - *(dict) --*

          Defines the objective metric for a hyperparameter tuning job. Hyperparameter tuning uses
          the value of this metric to evaluate the training jobs it launches, and returns the
          training job that results in either the highest or lowest value for this metric,
          depending on the value you specify for the ``Type`` parameter.

          - **Type** *(string) --*

            Whether to minimize or maximize the objective metric.

          - **MetricName** *(string) --*

            The name of the metric to use for the objective metric.

    - **InferenceSpecification** *(dict) --*

      Details about inference jobs that the algorithm runs.

      - **Containers** *(list) --*

        The Amazon ECR registry path of the Docker image that contains the inference code.

        - *(dict) --*

          Describes the Docker container for the model package.

          - **ContainerHostname** *(string) --*

            The DNS host name for the Docker container.

          - **Image** *(string) --*

            The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.

            If you are using your own custom algorithm instead of an algorithm provided by Amazon
            SageMaker, the inference code must meet Amazon SageMaker requirements. Amazon SageMaker
            supports both ``registry/repository[:tag]`` and ``registry/repository[@digest]`` image
            path formats. For more information, see `Using Your Own Algorithms with Amazon
            SageMaker <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

          - **ImageDigest** *(string) --*

            An MD5 hash of the training algorithm that identifies the Docker image used for
            training.

          - **ModelDataUrl** *(string) --*

            The Amazon S3 path where the model artifacts, which result from model training, are
            stored. This path must point to a single ``gzip`` compressed tar archive (``.tar.gz``
            suffix).

          - **ProductId** *(string) --*

            The AWS Marketplace product ID of the model package.

      - **SupportedTransformInstanceTypes** *(list) --*

        A list of the instance types on which a transformation job can be run or on which an
        endpoint can be deployed.

        - *(string) --*

      - **SupportedRealtimeInferenceInstanceTypes** *(list) --*

        A list of the instance types that are used to generate inferences in real-time.

        - *(string) --*

      - **SupportedContentTypes** *(list) --*

        The supported MIME types for the input data.

        - *(string) --*

      - **SupportedResponseMIMETypes** *(list) --*

        The supported MIME types for the output data.

        - *(string) --*

    - **ValidationSpecification** *(dict) --*

      Details about configurations for one or more training jobs that Amazon SageMaker runs to test
      the algorithm.

      - **ValidationRole** *(string) --*

        The IAM roles that Amazon SageMaker uses to run the training jobs.

      - **ValidationProfiles** *(list) --*

        An array of ``AlgorithmValidationProfile`` objects, each of which specifies a training job
        and batch transform job that Amazon SageMaker runs to validate your algorithm.

        - *(dict) --*

          Defines a training job and a batch transform job that Amazon SageMaker runs to validate
          your algorithm.

          The data provided in the validation profile is made available to your buyers on AWS
          Marketplace.

          - **ProfileName** *(string) --*

            The name of the profile for the algorithm. The name must have 1 to 63 characters. Valid
            characters are a-z, A-Z, 0-9, and - (hyphen).

          - **TrainingJobDefinition** *(dict) --*

            The ``TrainingJobDefinition`` object that describes the training job that Amazon
            SageMaker runs to validate your algorithm.

            - **TrainingInputMode** *(string) --*

              The input mode used by the algorithm for the training job. For the input modes that
              Amazon SageMaker algorithms support, see `Algorithms
              <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ .

              If an algorithm supports the ``File`` input mode, Amazon SageMaker downloads the
              training data from S3 to the provisioned ML storage Volume, and mounts the directory
              to docker volume for training container. If an algorithm supports the ``Pipe`` input
              mode, Amazon SageMaker streams data directly from S3 to the container.

            - **HyperParameters** *(dict) --*

              The hyperparameters used for the training job.

              - *(string) --*

                - *(string) --*

            - **InputDataConfig** *(list) --*

              An array of ``Channel`` objects, each of which specifies an input source.

              - *(dict) --*

                A channel is a named input source that training algorithms can consume.

                - **ChannelName** *(string) --*

                  The name of the channel.

                - **DataSource** *(dict) --*

                  The location of the channel data.

                  - **S3DataSource** *(dict) --*

                    The S3 location of the data source that is associated with a channel.

                    - **S3DataType** *(string) --*

                      If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
                      SageMaker uses all objects that match the specified key name prefix for model
                      training.

                      If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
                      manifest file containing a list of object keys that you want Amazon SageMaker
                      to use for model training.

                      If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is
                      an augmented manifest file in JSON lines format. This file contains the data
                      you want to use for model training. ``AugmentedManifestFile`` can only be
                      used if the Channel's input mode is ``Pipe`` .

                    - **S3Uri** *(string) --*

                      Depending on the value specified for the ``S3DataType`` , identifies either a
                      key name prefix or a manifest. For example:

                      * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

                      * A manifest might look like this: ``s3://bucketname/example.manifest``   The
                      manifest is an S3 object which is a JSON file with the following format:  The
                      preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
                      "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
                         ``"relative/path/custdata-2",``    ``...``
                         ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches the
                         following ``s3Uris`` :
                         ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                         ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                          ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The
                          complete set of ``s3uris`` in this manifest is the input data for the
                          channel for this datasource. The object that each ``s3uris`` points to
                          must be readable by the IAM role that Amazon SageMaker uses to perform
                          tasks on your behalf.

                    - **S3DataDistributionType** *(string) --*

                      If you want Amazon SageMaker to replicate the entire dataset on each ML
                      compute instance that is launched for model training, specify
                      ``FullyReplicated`` .

                      If you want Amazon SageMaker to replicate a subset of data on each ML compute
                      instance that is launched for model training, specify ``ShardedByS3Key`` . If
                      there are *n* ML compute instances launched for a training job, each instance
                      gets approximately 1/*n* of the number of S3 objects. In this case, model
                      training on each machine uses only the subset of training data.

                      Don't choose more ML compute instances for training than available S3
                      objects. If you do, some nodes won't get any data and you will pay for nodes
                      that aren't getting any training data. This applies in both File and Pipe
                      modes. Keep this in mind when developing algorithms.

                      In distributed training, where you use multiple ML compute EC2 instances, you
                      might choose ``ShardedByS3Key`` . If the algorithm requires copying training
                      data to the ML storage volume (when ``TrainingInputMode`` is set to ``File``
                      ), this copies 1/*n* of the number of objects.

                    - **AttributeNames** *(list) --*

                      A list of one or more attribute names to use that are found in a specified
                      augmented manifest file.

                      - *(string) --*

                  - **FileSystemDataSource** *(dict) --*

                    The file system that is associated with a channel.

                    - **FileSystemId** *(string) --*

                      The file system id.

                    - **FileSystemAccessMode** *(string) --*

                      The access mode of the mount of the directory associated with the channel. A
                      directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
                      mode.

                    - **FileSystemType** *(string) --*

                      The file system type.

                    - **DirectoryPath** *(string) --*

                      The full path to the directory to associate with the channel.

                - **ContentType** *(string) --*

                  The MIME type of the data.

                - **CompressionType** *(string) --*

                  If training data is compressed, the compression type. The default value is
                  ``None`` . ``CompressionType`` is used only in Pipe input mode. In File mode,
                  leave this field unset or set it to None.

                - **RecordWrapperType** *(string) --*

                  Specify RecordIO as the value when input data is in raw format but the training
                  algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
                  individual S3 object in a RecordIO record. If the input data is already in
                  RecordIO format, you don't need to set this attribute. For more information, see
                  `Create a Dataset Using RecordIO
                  <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
                  .

                  In File mode, leave this field unset or set it to None.

                - **InputMode** *(string) --*

                  (Optional) The input mode to use for the data channel in a training job. If you
                  don't set a value for ``InputMode`` , Amazon SageMaker uses the value set for
                  ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
                  setting in a  AlgorithmSpecification request when you have a channel that needs a
                  different input mode from the training job's general setting. To download the
                  data from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage
                  volume, and mount the directory to a Docker volume, use ``File`` input mode. To
                  stream data directly from Amazon S3 to the container, choose ``Pipe`` input mode.

                  To use a model for incremental training, choose ``File`` input model.

                - **ShuffleConfig** *(dict) --*

                  A configuration for a shuffle option for input data in a channel. If you use
                  ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
                  matches. If you use ``ManifestFile`` , the order of the S3 object references in
                  the ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the
                  order of the JSON lines in the ``AugmentedManifestFile`` is shuffled. The
                  shuffling order is determined using the ``Seed`` value.

                  For Pipe input mode, shuffling is done at the start of every epoch. With large
                  datasets this ensures that the order of the training data is different for each
                  epoch, it helps reduce bias and possible overfitting. In a multi-node training
                  job when ShuffleConfig is combined with ``S3DataDistributionType`` of
                  ``ShardedByS3Key`` , the data is shuffled across nodes so that the content sent
                  to a particular node on the first epoch might be sent to a different node on the
                  second epoch.

                  - **Seed** *(integer) --*

                    Determines the shuffling order in ``ShuffleConfig`` value.

            - **OutputDataConfig** *(dict) --*

              the path to the S3 bucket where you want to store model artifacts. Amazon SageMaker
              creates subfolders for the artifacts.

              - **KmsKeyId** *(string) --*

                The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
                the model artifacts at rest using Amazon S3 server-side encryption. The
                ``KmsKeyId`` can be any of the following formats:

                * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

                * // Amazon Resource Name (ARN) of a KMS Key
                ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

                * // KMS Key Alias  ``"alias/ExampleAlias"``

                * // Amazon Resource Name (ARN) of a KMS Key Alias
                ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

                If you use a KMS key ID or an alias of your master key, the Amazon SageMaker
                execution role must include permissions to call ``kms:Encrypt`` . If you don't
                provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3 for
                your role's account. Amazon SageMaker uses server-side encryption with KMS-managed
                keys for ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject``
                permission that only allows objects with server-side encryption, set the condition
                key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information,
                see `KMS-Managed Encryption Keys
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
                *Amazon Simple Storage Service Developer Guide.*

                The KMS key policy must grant permission to the IAM role that you specify in your
                ``CreateTrainingJob`` , ``CreateTransformJob`` , or
                ``CreateHyperParameterTuningJob`` requests. For more information, see `Using Key
                Policies in AWS KMS
                <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
                in the *AWS Key Management Service Developer Guide* .

              - **S3OutputPath** *(string) --*

                Identifies the S3 path where you want Amazon SageMaker to store the model
                artifacts. For example, ``s3://bucket-name/key-name-prefix`` .

            - **ResourceConfig** *(dict) --*

              The resources, including the ML compute instances and ML storage volumes, to use for
              model training.

              - **InstanceType** *(string) --*

                The ML compute instance type.

              - **InstanceCount** *(integer) --*

                The number of ML compute instances to use. For distributed training, provide a
                value greater than 1.

              - **VolumeSizeInGB** *(integer) --*

                The size of the ML storage volume that you want to provision.

                ML storage volumes store model artifacts and incremental states. Training
                algorithms might also use the ML storage volume for scratch space. If you want to
                store the training data in the ML storage volume, choose ``File`` as the
                ``TrainingInputMode`` in the algorithm specification.

                You must specify sufficient ML storage for your scenario.

                .. note::

                  Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume
                  type.

                .. note::

                  Certain Nitro-based instances include local storage with a fixed total size,
                  dependent on the instance type. When using these instances for training, Amazon
                  SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage.
                  You can't request a ``VolumeSizeInGB`` greater than the total size of the local
                  instance storage.

                  For a list of instance types that support local instance storage, including the
                  total size per instance type, see `Instance Store Volumes
                  <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
                  .

              - **VolumeKmsKeyId** *(string) --*

                The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
                attached to the ML compute instance(s) that run the training job.

                .. note::

                  Certain Nitro-based instances include local storage, dependent on the instance
                  type. Local storage volumes are encrypted using a hardware module on the
                  instance. You can't request a ``VolumeKmsKeyId`` when using an instance type with
                  local storage.

                  For a list of instance types that support local instance storage, see `Instance
                  Store Volumes
                  <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
                  .

                  For more information about local instance storage encryption, see `SSD Instance
                  Store Volumes
                  <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

                The ``VolumeKmsKeyId`` can be in any of the following formats:

                * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

                * // Amazon Resource Name (ARN) of a KMS Key
                ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

            - **StoppingCondition** *(dict) --*

              Specifies a limit to how long a model training job can run. When the job reaches the
              time limit, Amazon SageMaker ends the training job. Use this API to cap model
              training costs.

              To stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays
              job termination for 120 seconds. Algorithms can use this 120-second window to save
              the model artifacts.

              - **MaxRuntimeInSeconds** *(integer) --*

                The maximum length of time, in seconds, that the training or compilation job can
                run. If job does not complete during this time, Amazon SageMaker ends the job. If
                value is not specified, default value is 1 day. The maximum value is 28 days.

              - **MaxWaitTimeInSeconds** *(integer) --*

                The maximum length of time, in seconds, how long you are willing to wait for a
                managed spot training job to complete. It is the amount of time spent waiting for
                Spot capacity plus the amount of time the training job runs. It must be equal to or
                greater than ``MaxRuntimeInSeconds`` .

          - **TransformJobDefinition** *(dict) --*

            The ``TransformJobDefinition`` object that describes the transform job that Amazon
            SageMaker runs to validate your algorithm.

            - **MaxConcurrentTransforms** *(integer) --*

              The maximum number of parallel requests that can be sent to each instance in a
              transform job. The default value is 1.

            - **MaxPayloadInMB** *(integer) --*

              The maximum payload size allowed, in MB. A payload is the data portion of a record
              (without metadata).

            - **BatchStrategy** *(string) --*

              A string that determines the number of records included in a single mini-batch.

               ``SingleRecord`` means only one record is used per mini-batch. ``MultiRecord`` means
               a mini-batch is set to contain as many records that can fit within the
               ``MaxPayloadInMB`` limit.

            - **Environment** *(dict) --*

              The environment variables to set in the Docker container. We support up to 16 key and
              values entries in the map.

              - *(string) --*

                - *(string) --*

            - **TransformInput** *(dict) --*

              A description of the input source and the way the transform job consumes it.

              - **DataSource** *(dict) --*

                Describes the location of the channel data, which is, the S3 location of the input
                data that the model can consume.

                - **S3DataSource** *(dict) --*

                  The S3 location of the data source that is associated with a channel.

                  - **S3DataType** *(string) --*

                    If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
                    SageMaker uses all objects with the specified key name prefix for batch
                    transform.

                    If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
                    manifest file containing a list of object keys that you want Amazon SageMaker
                    to use for batch transform.

                    The following values are compatible: ``ManifestFile`` , ``S3Prefix``

                    The following value is not compatible: ``AugmentedManifestFile``

                  - **S3Uri** *(string) --*

                    Depending on the value specified for the ``S3DataType`` , identifies either a
                    key name prefix or a manifest. For example:

                    * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

                    * A manifest might look like this: ``s3://bucketname/example.manifest``   The
                    manifest is an S3 object which is a JSON file with the following format:   ``[
                    {"prefix": "s3://customer_bucket/some/prefix/"},``
                    ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``
                    ``...``    ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches
                    the following ``s3Uris`` :
                    ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                    ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                    ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
                    set of ``S3Uris`` in this manifest constitutes the input data for the channel
                    for this datasource. The object that each ``S3Uris`` points to must be readable
                    by the IAM role that Amazon SageMaker uses to perform tasks on your behalf.

              - **ContentType** *(string) --*

                The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker
                uses the MIME type with each http call to transfer data to the transform job.

              - **CompressionType** *(string) --*

                If your transform data is compressed, specify the compression type. Amazon
                SageMaker automatically decompresses the data for the transform job accordingly.
                The default value is ``None`` .

              - **SplitType** *(string) --*

                The method to use to split the transform job's data files into smaller batches.
                Splitting is necessary when the total size of each object is too large to fit in a
                single request. You can also use data splitting to improve performance by
                processing multiple concurrent mini-batches. The default value for ``SplitType`` is
                ``None`` , which indicates that input data files are not split, and request
                payloads contain the entire contents of an input object. Set the value of this
                parameter to ``Line`` to split records on a newline character boundary.
                ``SplitType`` also supports a number of record-oriented binary data formats.

                When splitting is enabled, the size of a mini-batch depends on the values of the
                ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
                ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
                records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
                ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records
                in each request.

                .. note::

                  Some data formats represent a record as a binary payload wrapped with extra
                  padding bytes. When splitting is applied to a binary data format, padding is
                  removed if the value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is
                  not removed if the value of ``BatchStrategy`` is set to ``MultiRecord`` .

                  For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
                  <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For
                  more information about ``TFRecord`` , see `Consuming TFRecord data
                  <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
                  TensorFlow documentation.

            - **TransformOutput** *(dict) --*

              Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
              from the transform job.

              - **S3OutputPath** *(string) --*

                The Amazon S3 path where you want Amazon SageMaker to store the results of the
                transform job. For example, ``s3://bucket-name/key-name-prefix`` .

                For every S3 object used as input for the transform job, batch transform stores the
                transformed data with an .``out`` suffix in a corresponding subfolder in the
                location in the output prefix. For example, for the input data stored at
                ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores
                the transformed data at
                ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
                transform doesn't upload partially processed objects. For an input S3 object that
                contains multiple records, it creates an .``out`` file only if the transform job
                succeeds on the entire file. When the input contains multiple S3 objects, the batch
                transform job processes the listed S3 objects and uploads only the output for
                successfully processed objects. If any object fails in the transform job batch
                transform marks the job as failed to prompt investigation.

              - **Accept** *(string) --*

                The MIME type used to specify the output data. Amazon SageMaker uses the MIME type
                with each http call to transfer data from the transform job.

              - **AssembleWith** *(string) --*

                Defines how to assemble the results of the transform job as a single S3 object.
                Choose a format that is most convenient to you. To concatenate the results in
                binary format, specify ``None`` . To add a newline character at the end of every
                transformed record, specify ``Line`` .

              - **KmsKeyId** *(string) --*

                The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
                the model artifacts at rest using Amazon S3 server-side encryption. The
                ``KmsKeyId`` can be any of the following formats:

                * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

                * // Amazon Resource Name (ARN) of a KMS Key
                ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

                * // KMS Key Alias  ``"alias/ExampleAlias"``

                * // Amazon Resource Name (ARN) of a KMS Key Alias
                ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

                If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for
                Amazon S3 for your role's account. For more information, see `KMS-Managed
                Encryption Keys
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
                *Amazon Simple Storage Service Developer Guide.*

                The KMS key policy must grant permission to the IAM role that you specify in your
                CreateModel request. For more information, see `Using Key Policies in AWS KMS
                <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the
                *AWS Key Management Service Developer Guide* .

            - **TransformResources** *(dict) --*

              Identifies the ML compute instances for the transform job.

              - **InstanceType** *(string) --*

                The ML compute instance type for the transform job. If you are using built-in
                algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge
                or ``ml.m5.large`` instance types.

              - **InstanceCount** *(integer) --*

                The number of ML compute instances to use in the transform job. For distributed
                transform jobs, specify a value greater than 1. The default value is ``1`` .

              - **VolumeKmsKeyId** *(string) --*

                The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
                data on the storage volume attached to the ML compute instance(s) that run the
                batch transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

                * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

                * // Amazon Resource Name (ARN) of a KMS Key
                ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

    - **AlgorithmStatus** *(string) --*

      The current status of the algorithm.

    - **AlgorithmStatusDetails** *(dict) --*

      Details about the current status of the algorithm.

      - **ValidationStatuses** *(list) --*

        The status of algorithm validation.

        - *(dict) --*

          Represents the overall status of an algorithm.

          - **Name** *(string) --*

            The name of the algorithm for which the overall status is being reported.

          - **Status** *(string) --*

            The current status.

          - **FailureReason** *(string) --*

            if the overall status is ``Failed`` , the reason for the failure.

      - **ImageScanStatuses** *(list) --*

        The status of the scan of the algorithm's Docker image container.

        - *(dict) --*

          Represents the overall status of an algorithm.

          - **Name** *(string) --*

            The name of the algorithm for which the overall status is being reported.

          - **Status** *(string) --*

            The current status.

          - **FailureReason** *(string) --*

            if the overall status is ``Failed`` , the reason for the failure.

    - **ProductId** *(string) --*

      The product identifier of the algorithm.

    - **CertifyForMarketplace** *(boolean) --*

      Whether the algorithm is certified to be listed in AWS Marketplace.
    """


_ClientDescribeCodeRepositoryResponseGitConfigTypeDef = TypedDict(
    "_ClientDescribeCodeRepositoryResponseGitConfigTypeDef",
    {"RepositoryUrl": str, "Branch": str, "SecretArn": str},
    total=False,
)


class ClientDescribeCodeRepositoryResponseGitConfigTypeDef(
    _ClientDescribeCodeRepositoryResponseGitConfigTypeDef
):
    """
    Type definition for `ClientDescribeCodeRepositoryResponse` `GitConfig`

    Configuration details about the repository, including the URL where the repository is
    located, the default branch, and the Amazon Resource Name (ARN) of the AWS Secrets Manager
    secret that contains the credentials used to access the repository.

    - **RepositoryUrl** *(string) --*

      The URL where the Git repository is located.

    - **Branch** *(string) --*

      The default branch for the Git repository.

    - **SecretArn** *(string) --*

      The Amazon Resource Name (ARN) of the AWS Secrets Manager secret that contains the
      credentials used to access the git repository. The secret must have a staging label of
      ``AWSCURRENT`` and must be in the following format:

       ``{"username": *UserName* , "password": *Password* }``
    """


_ClientDescribeCodeRepositoryResponseTypeDef = TypedDict(
    "_ClientDescribeCodeRepositoryResponseTypeDef",
    {
        "CodeRepositoryName": str,
        "CodeRepositoryArn": str,
        "CreationTime": datetime,
        "LastModifiedTime": datetime,
        "GitConfig": ClientDescribeCodeRepositoryResponseGitConfigTypeDef,
    },
    total=False,
)


class ClientDescribeCodeRepositoryResponseTypeDef(
    _ClientDescribeCodeRepositoryResponseTypeDef
):
    """
    Type definition for `ClientDescribeCodeRepository` `Response`

    - **CodeRepositoryName** *(string) --*

      The name of the Git repository.

    - **CodeRepositoryArn** *(string) --*

      The Amazon Resource Name (ARN) of the Git repository.

    - **CreationTime** *(datetime) --*

      The date and time that the repository was created.

    - **LastModifiedTime** *(datetime) --*

      The date and time that the repository was last changed.

    - **GitConfig** *(dict) --*

      Configuration details about the repository, including the URL where the repository is
      located, the default branch, and the Amazon Resource Name (ARN) of the AWS Secrets Manager
      secret that contains the credentials used to access the repository.

      - **RepositoryUrl** *(string) --*

        The URL where the Git repository is located.

      - **Branch** *(string) --*

        The default branch for the Git repository.

      - **SecretArn** *(string) --*

        The Amazon Resource Name (ARN) of the AWS Secrets Manager secret that contains the
        credentials used to access the git repository. The secret must have a staging label of
        ``AWSCURRENT`` and must be in the following format:

         ``{"username": *UserName* , "password": *Password* }``
    """


_ClientDescribeCompilationJobResponseInputConfigTypeDef = TypedDict(
    "_ClientDescribeCompilationJobResponseInputConfigTypeDef",
    {"S3Uri": str, "DataInputConfig": str, "Framework": str},
    total=False,
)


class ClientDescribeCompilationJobResponseInputConfigTypeDef(
    _ClientDescribeCompilationJobResponseInputConfigTypeDef
):
    """
    Type definition for `ClientDescribeCompilationJobResponse` `InputConfig`

    Information about the location in Amazon S3 of the input model artifacts, the name and shape
    of the expected data inputs, and the framework in which the model was trained.

    - **S3Uri** *(string) --*

      The S3 path where the model artifacts, which result from model training, are stored. This
      path must point to a single gzip compressed tar archive (.tar.gz suffix).

    - **DataInputConfig** *(string) --*

      Specifies the name and shape of the expected data inputs for your trained model with a JSON
      dictionary form. The data inputs are  InputConfig$Framework specific.

      * ``TensorFlow`` : You must specify the name and shape (NHWC format) of the expected data
      inputs using a dictionary format for your trained model. The dictionary formats required
      for the console and CLI are different.

        * Examples for one input:

          * If using the console, ``{"input":[1,1024,1024,3]}``

          * If using the CLI, ``{\\"input\\":[1,1024,1024,3]}``

        * Examples for two inputs:

          * If using the console, ``{"data1": [1,28,28,1], "data2":[1,28,28,1]}``

          * If using the CLI, ``{\\"data1\\": [1,28,28,1], \\"data2\\":[1,28,28,1]}``

      * ``MXNET/ONNX`` : You must specify the name and shape (NCHW format) of the expected data
      inputs in order using a dictionary format for your trained model. The dictionary formats
      required for the console and CLI are different.

        * Examples for one input:

          * If using the console, ``{"data":[1,3,1024,1024]}``

          * If using the CLI, ``{\\"data\\":[1,3,1024,1024]}``

        * Examples for two inputs:

          * If using the console, ``{"var1": [1,1,28,28], "var2":[1,1,28,28]}``

          * If using the CLI, ``{\\"var1\\": [1,1,28,28], \\"var2\\":[1,1,28,28]}``

      * ``PyTorch`` : You can either specify the name and shape (NCHW format) of expected data
      inputs in order using a dictionary format for your trained model or you can specify the
      shape only using a list format. The dictionary formats required for the console and CLI are
      different. The list formats for the console and CLI are the same.

        * Examples for one input in dictionary format:

          * If using the console, ``{"input0":[1,3,224,224]}``

          * If using the CLI, ``{\\"input0\\":[1,3,224,224]}``

        * Example for one input in list format: ``[[1,3,224,224]]``

        * Examples for two inputs in dictionary format:

          * If using the console, ``{"input0":[1,3,224,224], "input1":[1,3,224,224]}``

          * If using the CLI, ``{\\"input0\\":[1,3,224,224], \\"input1\\":[1,3,224,224]}``

        * Example for two inputs in list format: ``[[1,3,224,224], [1,3,224,224]]``

      * ``XGBOOST`` : input data name and shape are not needed.

    - **Framework** *(string) --*

      Identifies the framework in which the model was trained. For example: TENSORFLOW.
    """


_ClientDescribeCompilationJobResponseModelArtifactsTypeDef = TypedDict(
    "_ClientDescribeCompilationJobResponseModelArtifactsTypeDef",
    {"S3ModelArtifacts": str},
    total=False,
)


class ClientDescribeCompilationJobResponseModelArtifactsTypeDef(
    _ClientDescribeCompilationJobResponseModelArtifactsTypeDef
):
    """
    Type definition for `ClientDescribeCompilationJobResponse` `ModelArtifacts`

    Information about the location in Amazon S3 that has been configured for storing the model
    artifacts used in the compilation job.

    - **S3ModelArtifacts** *(string) --*

      The path of the S3 object that contains the model artifacts. For example,
      ``s3://bucket-name/keynameprefix/model.tar.gz`` .
    """


_ClientDescribeCompilationJobResponseOutputConfigTypeDef = TypedDict(
    "_ClientDescribeCompilationJobResponseOutputConfigTypeDef",
    {"S3OutputLocation": str, "TargetDevice": str},
    total=False,
)


class ClientDescribeCompilationJobResponseOutputConfigTypeDef(
    _ClientDescribeCompilationJobResponseOutputConfigTypeDef
):
    """
    Type definition for `ClientDescribeCompilationJobResponse` `OutputConfig`

    Information about the output location for the compiled model and the target device that the
    model runs on.

    - **S3OutputLocation** *(string) --*

      Identifies the S3 path where you want Amazon SageMaker to store the model artifacts. For
      example, s3://bucket-name/key-name-prefix.

    - **TargetDevice** *(string) --*

      Identifies the device that you want to run your model on after it has been compiled. For
      example: ml_c5.
    """


_ClientDescribeCompilationJobResponseStoppingConditionTypeDef = TypedDict(
    "_ClientDescribeCompilationJobResponseStoppingConditionTypeDef",
    {"MaxRuntimeInSeconds": int, "MaxWaitTimeInSeconds": int},
    total=False,
)


class ClientDescribeCompilationJobResponseStoppingConditionTypeDef(
    _ClientDescribeCompilationJobResponseStoppingConditionTypeDef
):
    """
    Type definition for `ClientDescribeCompilationJobResponse` `StoppingCondition`

    Specifies a limit to how long a model compilation job can run. When the job reaches the time
    limit, Amazon SageMaker ends the compilation job. Use this API to cap model training costs.

    - **MaxRuntimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, that the training or compilation job can run. If
      job does not complete during this time, Amazon SageMaker ends the job. If value is not
      specified, default value is 1 day. The maximum value is 28 days.

    - **MaxWaitTimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, how long you are willing to wait for a managed spot
      training job to complete. It is the amount of time spent waiting for Spot capacity plus the
      amount of time the training job runs. It must be equal to or greater than
      ``MaxRuntimeInSeconds`` .
    """


_ClientDescribeCompilationJobResponseTypeDef = TypedDict(
    "_ClientDescribeCompilationJobResponseTypeDef",
    {
        "CompilationJobName": str,
        "CompilationJobArn": str,
        "CompilationJobStatus": str,
        "CompilationStartTime": datetime,
        "CompilationEndTime": datetime,
        "StoppingCondition": ClientDescribeCompilationJobResponseStoppingConditionTypeDef,
        "CreationTime": datetime,
        "LastModifiedTime": datetime,
        "FailureReason": str,
        "ModelArtifacts": ClientDescribeCompilationJobResponseModelArtifactsTypeDef,
        "RoleArn": str,
        "InputConfig": ClientDescribeCompilationJobResponseInputConfigTypeDef,
        "OutputConfig": ClientDescribeCompilationJobResponseOutputConfigTypeDef,
    },
    total=False,
)


class ClientDescribeCompilationJobResponseTypeDef(
    _ClientDescribeCompilationJobResponseTypeDef
):
    """
    Type definition for `ClientDescribeCompilationJob` `Response`

    - **CompilationJobName** *(string) --*

      The name of the model compilation job.

    - **CompilationJobArn** *(string) --*

      The Amazon Resource Name (ARN) of an IAM role that Amazon SageMaker assumes to perform the
      model compilation job.

    - **CompilationJobStatus** *(string) --*

      The status of the model compilation job.

    - **CompilationStartTime** *(datetime) --*

      The time when the model compilation job started the ``CompilationJob`` instances.

      You are billed for the time between this timestamp and the timestamp in the
      DescribeCompilationJobResponse$CompilationEndTime field. In Amazon CloudWatch Logs, the start
      time might be later than this time. That's because it takes time to download the compilation
      job, which depends on the size of the compilation job container.

    - **CompilationEndTime** *(datetime) --*

      The time when the model compilation job on a compilation job instance ended. For a successful
      or stopped job, this is when the job's model artifacts have finished uploading. For a failed
      job, this is when Amazon SageMaker detected that the job failed.

    - **StoppingCondition** *(dict) --*

      Specifies a limit to how long a model compilation job can run. When the job reaches the time
      limit, Amazon SageMaker ends the compilation job. Use this API to cap model training costs.

      - **MaxRuntimeInSeconds** *(integer) --*

        The maximum length of time, in seconds, that the training or compilation job can run. If
        job does not complete during this time, Amazon SageMaker ends the job. If value is not
        specified, default value is 1 day. The maximum value is 28 days.

      - **MaxWaitTimeInSeconds** *(integer) --*

        The maximum length of time, in seconds, how long you are willing to wait for a managed spot
        training job to complete. It is the amount of time spent waiting for Spot capacity plus the
        amount of time the training job runs. It must be equal to or greater than
        ``MaxRuntimeInSeconds`` .

    - **CreationTime** *(datetime) --*

      The time that the model compilation job was created.

    - **LastModifiedTime** *(datetime) --*

      The time that the status of the model compilation job was last modified.

    - **FailureReason** *(string) --*

      If a model compilation job failed, the reason it failed.

    - **ModelArtifacts** *(dict) --*

      Information about the location in Amazon S3 that has been configured for storing the model
      artifacts used in the compilation job.

      - **S3ModelArtifacts** *(string) --*

        The path of the S3 object that contains the model artifacts. For example,
        ``s3://bucket-name/keynameprefix/model.tar.gz`` .

    - **RoleArn** *(string) --*

      The Amazon Resource Name (ARN) of the model compilation job.

    - **InputConfig** *(dict) --*

      Information about the location in Amazon S3 of the input model artifacts, the name and shape
      of the expected data inputs, and the framework in which the model was trained.

      - **S3Uri** *(string) --*

        The S3 path where the model artifacts, which result from model training, are stored. This
        path must point to a single gzip compressed tar archive (.tar.gz suffix).

      - **DataInputConfig** *(string) --*

        Specifies the name and shape of the expected data inputs for your trained model with a JSON
        dictionary form. The data inputs are  InputConfig$Framework specific.

        * ``TensorFlow`` : You must specify the name and shape (NHWC format) of the expected data
        inputs using a dictionary format for your trained model. The dictionary formats required
        for the console and CLI are different.

          * Examples for one input:

            * If using the console, ``{"input":[1,1024,1024,3]}``

            * If using the CLI, ``{\\"input\\":[1,1024,1024,3]}``

          * Examples for two inputs:

            * If using the console, ``{"data1": [1,28,28,1], "data2":[1,28,28,1]}``

            * If using the CLI, ``{\\"data1\\": [1,28,28,1], \\"data2\\":[1,28,28,1]}``

        * ``MXNET/ONNX`` : You must specify the name and shape (NCHW format) of the expected data
        inputs in order using a dictionary format for your trained model. The dictionary formats
        required for the console and CLI are different.

          * Examples for one input:

            * If using the console, ``{"data":[1,3,1024,1024]}``

            * If using the CLI, ``{\\"data\\":[1,3,1024,1024]}``

          * Examples for two inputs:

            * If using the console, ``{"var1": [1,1,28,28], "var2":[1,1,28,28]}``

            * If using the CLI, ``{\\"var1\\": [1,1,28,28], \\"var2\\":[1,1,28,28]}``

        * ``PyTorch`` : You can either specify the name and shape (NCHW format) of expected data
        inputs in order using a dictionary format for your trained model or you can specify the
        shape only using a list format. The dictionary formats required for the console and CLI are
        different. The list formats for the console and CLI are the same.

          * Examples for one input in dictionary format:

            * If using the console, ``{"input0":[1,3,224,224]}``

            * If using the CLI, ``{\\"input0\\":[1,3,224,224]}``

          * Example for one input in list format: ``[[1,3,224,224]]``

          * Examples for two inputs in dictionary format:

            * If using the console, ``{"input0":[1,3,224,224], "input1":[1,3,224,224]}``

            * If using the CLI, ``{\\"input0\\":[1,3,224,224], \\"input1\\":[1,3,224,224]}``

          * Example for two inputs in list format: ``[[1,3,224,224], [1,3,224,224]]``

        * ``XGBOOST`` : input data name and shape are not needed.

      - **Framework** *(string) --*

        Identifies the framework in which the model was trained. For example: TENSORFLOW.

    - **OutputConfig** *(dict) --*

      Information about the output location for the compiled model and the target device that the
      model runs on.

      - **S3OutputLocation** *(string) --*

        Identifies the S3 path where you want Amazon SageMaker to store the model artifacts. For
        example, s3://bucket-name/key-name-prefix.

      - **TargetDevice** *(string) --*

        Identifies the device that you want to run your model on after it has been compiled. For
        example: ml_c5.
    """


_ClientDescribeEndpointConfigResponseProductionVariantsTypeDef = TypedDict(
    "_ClientDescribeEndpointConfigResponseProductionVariantsTypeDef",
    {
        "VariantName": str,
        "ModelName": str,
        "InitialInstanceCount": int,
        "InstanceType": str,
        "InitialVariantWeight": float,
        "AcceleratorType": str,
    },
    total=False,
)


class ClientDescribeEndpointConfigResponseProductionVariantsTypeDef(
    _ClientDescribeEndpointConfigResponseProductionVariantsTypeDef
):
    """
    Type definition for `ClientDescribeEndpointConfigResponse` `ProductionVariants`

    Identifies a model that you want to host and the resources to deploy for hosting it. If you
    are deploying multiple models, tell Amazon SageMaker how to distribute traffic among the
    models by specifying variant weights.

    - **VariantName** *(string) --*

      The name of the production variant.

    - **ModelName** *(string) --*

      The name of the model that you want to host. This is the name that you specified when
      creating the model.

    - **InitialInstanceCount** *(integer) --*

      Number of instances to launch initially.

    - **InstanceType** *(string) --*

      The ML compute instance type.

    - **InitialVariantWeight** *(float) --*

      Determines initial traffic distribution among all of the models that you specify in the
      endpoint configuration. The traffic to a production variant is determined by the ratio of
      the ``VariantWeight`` to the sum of all ``VariantWeight`` values across all
      ProductionVariants. If unspecified, it defaults to 1.0.

    - **AcceleratorType** *(string) --*

      The size of the Elastic Inference (EI) instance to use for the production variant. EI
      instances provide on-demand GPU computing for inference. For more information, see `Using
      Elastic Inference in Amazon SageMaker
      <https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html>`__ .
    """


_ClientDescribeEndpointConfigResponseTypeDef = TypedDict(
    "_ClientDescribeEndpointConfigResponseTypeDef",
    {
        "EndpointConfigName": str,
        "EndpointConfigArn": str,
        "ProductionVariants": List[
            ClientDescribeEndpointConfigResponseProductionVariantsTypeDef
        ],
        "KmsKeyId": str,
        "CreationTime": datetime,
    },
    total=False,
)


class ClientDescribeEndpointConfigResponseTypeDef(
    _ClientDescribeEndpointConfigResponseTypeDef
):
    """
    Type definition for `ClientDescribeEndpointConfig` `Response`

    - **EndpointConfigName** *(string) --*

      Name of the Amazon SageMaker endpoint configuration.

    - **EndpointConfigArn** *(string) --*

      The Amazon Resource Name (ARN) of the endpoint configuration.

    - **ProductionVariants** *(list) --*

      An array of ``ProductionVariant`` objects, one for each model that you want to host at this
      endpoint.

      - *(dict) --*

        Identifies a model that you want to host and the resources to deploy for hosting it. If you
        are deploying multiple models, tell Amazon SageMaker how to distribute traffic among the
        models by specifying variant weights.

        - **VariantName** *(string) --*

          The name of the production variant.

        - **ModelName** *(string) --*

          The name of the model that you want to host. This is the name that you specified when
          creating the model.

        - **InitialInstanceCount** *(integer) --*

          Number of instances to launch initially.

        - **InstanceType** *(string) --*

          The ML compute instance type.

        - **InitialVariantWeight** *(float) --*

          Determines initial traffic distribution among all of the models that you specify in the
          endpoint configuration. The traffic to a production variant is determined by the ratio of
          the ``VariantWeight`` to the sum of all ``VariantWeight`` values across all
          ProductionVariants. If unspecified, it defaults to 1.0.

        - **AcceleratorType** *(string) --*

          The size of the Elastic Inference (EI) instance to use for the production variant. EI
          instances provide on-demand GPU computing for inference. For more information, see `Using
          Elastic Inference in Amazon SageMaker
          <https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html>`__ .

    - **KmsKeyId** *(string) --*

      AWS KMS key ID Amazon SageMaker uses to encrypt data when storing it on the ML storage volume
      attached to the instance.

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the endpoint configuration was created.
    """


_ClientDescribeEndpointResponseProductionVariantsDeployedImagesTypeDef = TypedDict(
    "_ClientDescribeEndpointResponseProductionVariantsDeployedImagesTypeDef",
    {"SpecifiedImage": str, "ResolvedImage": str, "ResolutionTime": datetime},
    total=False,
)


class ClientDescribeEndpointResponseProductionVariantsDeployedImagesTypeDef(
    _ClientDescribeEndpointResponseProductionVariantsDeployedImagesTypeDef
):
    """
    Type definition for `ClientDescribeEndpointResponseProductionVariants` `DeployedImages`

    Gets the Amazon EC2 Container Registry path of the docker image of the model that is
    hosted in this  ProductionVariant .

    If you used the ``registry/repository[:tag]`` form to specify the image path of the
    primary container when you created the model hosted in this ``ProductionVariant`` , the
    path resolves to a path of the form ``registry/repository[@digest]`` . A digest is a
    hash value that identifies a specific version of an image. For information about Amazon
    ECR paths, see `Pulling an Image
    <https://docs.aws.amazon.com/AmazonECR/latest/userguide/docker-pull-ecr-image.html>`__
    in the *Amazon ECR User Guide* .

    - **SpecifiedImage** *(string) --*

      The image path you specified when you created the model.

    - **ResolvedImage** *(string) --*

      The specific digest path of the image hosted in this ``ProductionVariant`` .

    - **ResolutionTime** *(datetime) --*

      The date and time when the image path for the model resolved to the ``ResolvedImage``
    """


_ClientDescribeEndpointResponseProductionVariantsTypeDef = TypedDict(
    "_ClientDescribeEndpointResponseProductionVariantsTypeDef",
    {
        "VariantName": str,
        "DeployedImages": List[
            ClientDescribeEndpointResponseProductionVariantsDeployedImagesTypeDef
        ],
        "CurrentWeight": float,
        "DesiredWeight": float,
        "CurrentInstanceCount": int,
        "DesiredInstanceCount": int,
    },
    total=False,
)


class ClientDescribeEndpointResponseProductionVariantsTypeDef(
    _ClientDescribeEndpointResponseProductionVariantsTypeDef
):
    """
    Type definition for `ClientDescribeEndpointResponse` `ProductionVariants`

    Describes weight and capacities for a production variant associated with an endpoint. If
    you sent a request to the ``UpdateEndpointWeightsAndCapacities`` API and the endpoint
    status is ``Updating`` , you get different desired and current values.

    - **VariantName** *(string) --*

      The name of the variant.

    - **DeployedImages** *(list) --*

      An array of ``DeployedImage`` objects that specify the Amazon EC2 Container Registry
      paths of the inference images deployed on instances of this ``ProductionVariant`` .

      - *(dict) --*

        Gets the Amazon EC2 Container Registry path of the docker image of the model that is
        hosted in this  ProductionVariant .

        If you used the ``registry/repository[:tag]`` form to specify the image path of the
        primary container when you created the model hosted in this ``ProductionVariant`` , the
        path resolves to a path of the form ``registry/repository[@digest]`` . A digest is a
        hash value that identifies a specific version of an image. For information about Amazon
        ECR paths, see `Pulling an Image
        <https://docs.aws.amazon.com/AmazonECR/latest/userguide/docker-pull-ecr-image.html>`__
        in the *Amazon ECR User Guide* .

        - **SpecifiedImage** *(string) --*

          The image path you specified when you created the model.

        - **ResolvedImage** *(string) --*

          The specific digest path of the image hosted in this ``ProductionVariant`` .

        - **ResolutionTime** *(datetime) --*

          The date and time when the image path for the model resolved to the ``ResolvedImage``

    - **CurrentWeight** *(float) --*

      The weight associated with the variant.

    - **DesiredWeight** *(float) --*

      The requested weight, as specified in the ``UpdateEndpointWeightsAndCapacities`` request.

    - **CurrentInstanceCount** *(integer) --*

      The number of instances associated with the variant.

    - **DesiredInstanceCount** *(integer) --*

      The number of instances requested in the ``UpdateEndpointWeightsAndCapacities`` request.
    """


_ClientDescribeEndpointResponseTypeDef = TypedDict(
    "_ClientDescribeEndpointResponseTypeDef",
    {
        "EndpointName": str,
        "EndpointArn": str,
        "EndpointConfigName": str,
        "ProductionVariants": List[
            ClientDescribeEndpointResponseProductionVariantsTypeDef
        ],
        "EndpointStatus": str,
        "FailureReason": str,
        "CreationTime": datetime,
        "LastModifiedTime": datetime,
    },
    total=False,
)


class ClientDescribeEndpointResponseTypeDef(_ClientDescribeEndpointResponseTypeDef):
    """
    Type definition for `ClientDescribeEndpoint` `Response`

    - **EndpointName** *(string) --*

      Name of the endpoint.

    - **EndpointArn** *(string) --*

      The Amazon Resource Name (ARN) of the endpoint.

    - **EndpointConfigName** *(string) --*

      The name of the endpoint configuration associated with this endpoint.

    - **ProductionVariants** *(list) --*

      An array of  ProductionVariantSummary objects, one for each model hosted behind this endpoint.

      - *(dict) --*

        Describes weight and capacities for a production variant associated with an endpoint. If
        you sent a request to the ``UpdateEndpointWeightsAndCapacities`` API and the endpoint
        status is ``Updating`` , you get different desired and current values.

        - **VariantName** *(string) --*

          The name of the variant.

        - **DeployedImages** *(list) --*

          An array of ``DeployedImage`` objects that specify the Amazon EC2 Container Registry
          paths of the inference images deployed on instances of this ``ProductionVariant`` .

          - *(dict) --*

            Gets the Amazon EC2 Container Registry path of the docker image of the model that is
            hosted in this  ProductionVariant .

            If you used the ``registry/repository[:tag]`` form to specify the image path of the
            primary container when you created the model hosted in this ``ProductionVariant`` , the
            path resolves to a path of the form ``registry/repository[@digest]`` . A digest is a
            hash value that identifies a specific version of an image. For information about Amazon
            ECR paths, see `Pulling an Image
            <https://docs.aws.amazon.com/AmazonECR/latest/userguide/docker-pull-ecr-image.html>`__
            in the *Amazon ECR User Guide* .

            - **SpecifiedImage** *(string) --*

              The image path you specified when you created the model.

            - **ResolvedImage** *(string) --*

              The specific digest path of the image hosted in this ``ProductionVariant`` .

            - **ResolutionTime** *(datetime) --*

              The date and time when the image path for the model resolved to the ``ResolvedImage``

        - **CurrentWeight** *(float) --*

          The weight associated with the variant.

        - **DesiredWeight** *(float) --*

          The requested weight, as specified in the ``UpdateEndpointWeightsAndCapacities`` request.

        - **CurrentInstanceCount** *(integer) --*

          The number of instances associated with the variant.

        - **DesiredInstanceCount** *(integer) --*

          The number of instances requested in the ``UpdateEndpointWeightsAndCapacities`` request.

    - **EndpointStatus** *(string) --*

      The status of the endpoint.

      * ``OutOfService`` : Endpoint is not available to take incoming requests.

      * ``Creating`` :  CreateEndpoint is executing.

      * ``Updating`` :  UpdateEndpoint or  UpdateEndpointWeightsAndCapacities is executing.

      * ``SystemUpdating`` : Endpoint is undergoing maintenance and cannot be updated or deleted or
      re-scaled until it has completed. This maintenance operation does not change any
      customer-specified values such as VPC config, KMS encryption, model, instance type, or
      instance count.

      * ``RollingBack`` : Endpoint fails to scale up or down or change its variant weight and is in
      the process of rolling back to its previous configuration. Once the rollback completes,
      endpoint returns to an ``InService`` status. This transitional status only applies to an
      endpoint that has autoscaling enabled and is undergoing variant weight or capacity changes as
      part of an  UpdateEndpointWeightsAndCapacities call or when the
      UpdateEndpointWeightsAndCapacities operation is called explicitly.

      * ``InService`` : Endpoint is available to process incoming requests.

      * ``Deleting`` :  DeleteEndpoint is executing.

      * ``Failed`` : Endpoint could not be created, updated, or re-scaled. Use
      DescribeEndpointOutput$FailureReason for information about the failure.  DeleteEndpoint is
      the only operation that can be performed on a failed endpoint.

    - **FailureReason** *(string) --*

      If the status of the endpoint is ``Failed`` , the reason why it failed.

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the endpoint was created.

    - **LastModifiedTime** *(datetime) --*

      A timestamp that shows when the endpoint was last modified.
    """


_ClientDescribeHyperParameterTuningJobResponseBestTrainingJobFinalHyperParameterTuningJobObjectiveMetricTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseBestTrainingJobFinalHyperParameterTuningJobObjectiveMetricTypeDef",
    {"Type": str, "MetricName": str, "Value": float},
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseBestTrainingJobFinalHyperParameterTuningJobObjectiveMetricTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseBestTrainingJobFinalHyperParameterTuningJobObjectiveMetricTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseBestTrainingJob` `FinalHyperParameterTuningJobObjectiveMetric`

    The  FinalHyperParameterTuningJobObjectiveMetric object that specifies the value of the
    objective metric of the tuning job that launched this training job.

    - **Type** *(string) --*

      Whether to minimize or maximize the objective metric. Valid values are Minimize and
      Maximize.

    - **MetricName** *(string) --*

      The name of the objective metric.

    - **Value** *(float) --*

      The value of the objective metric.
    """


_ClientDescribeHyperParameterTuningJobResponseBestTrainingJobTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseBestTrainingJobTypeDef",
    {
        "TrainingJobName": str,
        "TrainingJobArn": str,
        "TuningJobName": str,
        "CreationTime": datetime,
        "TrainingStartTime": datetime,
        "TrainingEndTime": datetime,
        "TrainingJobStatus": str,
        "TunedHyperParameters": Dict[str, str],
        "FailureReason": str,
        "FinalHyperParameterTuningJobObjectiveMetric": ClientDescribeHyperParameterTuningJobResponseBestTrainingJobFinalHyperParameterTuningJobObjectiveMetricTypeDef,
        "ObjectiveStatus": str,
    },
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseBestTrainingJobTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseBestTrainingJobTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponse` `BestTrainingJob`

    A  TrainingJobSummary object that describes the training job that completed with the best
    current  HyperParameterTuningJobObjective .

    - **TrainingJobName** *(string) --*

      The name of the training job.

    - **TrainingJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the training job.

    - **TuningJobName** *(string) --*

      The HyperParameter tuning job that launched the training job.

    - **CreationTime** *(datetime) --*

      The date and time that the training job was created.

    - **TrainingStartTime** *(datetime) --*

      The date and time that the training job started.

    - **TrainingEndTime** *(datetime) --*

      Specifies the time when the training job ends on training instances. You are billed for the
      time interval between the value of ``TrainingStartTime`` and this time. For successful jobs
      and stopped jobs, this is the time after model artifacts are uploaded. For failed jobs,
      this is the time when Amazon SageMaker detects a job failure.

    - **TrainingJobStatus** *(string) --*

      The status of the training job.

    - **TunedHyperParameters** *(dict) --*

      A list of the hyperparameters for which you specified ranges to search.

      - *(string) --*

        - *(string) --*

    - **FailureReason** *(string) --*

      The reason that the training job failed.

    - **FinalHyperParameterTuningJobObjectiveMetric** *(dict) --*

      The  FinalHyperParameterTuningJobObjectiveMetric object that specifies the value of the
      objective metric of the tuning job that launched this training job.

      - **Type** *(string) --*

        Whether to minimize or maximize the objective metric. Valid values are Minimize and
        Maximize.

      - **MetricName** *(string) --*

        The name of the objective metric.

      - **Value** *(float) --*

        The value of the objective metric.

    - **ObjectiveStatus** *(string) --*

      The status of the objective metric for the training job:

      * Succeeded: The final objective metric for the training job was evaluated by the
      hyperparameter tuning job and used in the hyperparameter tuning process.

      * Pending: The training job is in progress and evaluation of its final objective metric is
      pending.

      * Failed: The final objective metric for the training job was not evaluated, and was not
      used in the hyperparameter tuning process. This typically occurs when the training job
      failed or did not emit an objective metric.
    """


_ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigHyperParameterTuningJobObjectiveTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigHyperParameterTuningJobObjectiveTypeDef",
    {"Type": str, "MetricName": str},
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigHyperParameterTuningJobObjectiveTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigHyperParameterTuningJobObjectiveTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfig` `HyperParameterTuningJobObjective`

    The  HyperParameterTuningJobObjective object that specifies the objective metric for this
    tuning job.

    - **Type** *(string) --*

      Whether to minimize or maximize the objective metric.

    - **MetricName** *(string) --*

      The name of the metric to use for the objective metric.
    """


_ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesCategoricalParameterRangesTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesCategoricalParameterRangesTypeDef",
    {"Name": str, "Values": List[str]},
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesCategoricalParameterRangesTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesCategoricalParameterRangesTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRanges` `CategoricalParameterRanges`

    A list of categorical hyperparameters to tune.

    - **Name** *(string) --*

      The name of the categorical hyperparameter to tune.

    - **Values** *(list) --*

      A list of the categories for the hyperparameter.

      - *(string) --*
    """


_ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesContinuousParameterRangesTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesContinuousParameterRangesTypeDef",
    {"Name": str, "MinValue": str, "MaxValue": str, "ScalingType": str},
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesContinuousParameterRangesTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesContinuousParameterRangesTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRanges` `ContinuousParameterRanges`

    A list of continuous hyperparameters to tune.

    - **Name** *(string) --*

      The name of the continuous hyperparameter to tune.

    - **MinValue** *(string) --*

      The minimum value for the hyperparameter. The tuning job uses floating-point values
      between this value and ``MaxValue`` for tuning.

    - **MaxValue** *(string) --*

      The maximum value for the hyperparameter. The tuning job uses floating-point values
      between ``MinValue`` value and this value for tuning.

    - **ScalingType** *(string) --*

      The scale that hyperparameter tuning uses to search the hyperparameter range. For
      information about choosing a hyperparameter scale, see `Hyperparameter Scaling
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html#scaling-type>`__
      . One of the following values:

        Auto

      Amazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.

        Linear

      Hyperparameter tuning searches the values in the hyperparameter range by using a
      linear scale.

        Logarithmic

      Hyperparameter tuning searches the values in the hyperparameter range by using a
      logarithmic scale.

      Logarithmic scaling works only for ranges that have only values greater than 0.

        ReverseLogarithmic

      Hyperparameter tuning searches the values in the hyperparameter range by using a
      reverse logarithmic scale.

      Reverse logarithmic scaling works only for ranges that are entirely within the range
      0<=x<1.0.
    """


_ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesIntegerParameterRangesTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesIntegerParameterRangesTypeDef",
    {"Name": str, "MinValue": str, "MaxValue": str, "ScalingType": str},
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesIntegerParameterRangesTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesIntegerParameterRangesTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRanges` `IntegerParameterRanges`

    For a hyperparameter of the integer type, specifies the range that a hyperparameter
    tuning job searches.

    - **Name** *(string) --*

      The name of the hyperparameter to search.

    - **MinValue** *(string) --*

      The minimum value of the hyperparameter to search.

    - **MaxValue** *(string) --*

      The maximum value of the hyperparameter to search.

    - **ScalingType** *(string) --*

      The scale that hyperparameter tuning uses to search the hyperparameter range. For
      information about choosing a hyperparameter scale, see `Hyperparameter Scaling
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html#scaling-type>`__
      . One of the following values:

        Auto

      Amazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.

        Linear

      Hyperparameter tuning searches the values in the hyperparameter range by using a
      linear scale.

        Logarithmic

      Hyperparameter tuning searches the values in the hyperparameter range by using a
      logarithmic scale.

      Logarithmic scaling works only for ranges that have only values greater than 0.
    """


_ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesTypeDef",
    {
        "IntegerParameterRanges": List[
            ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesIntegerParameterRangesTypeDef
        ],
        "ContinuousParameterRanges": List[
            ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesContinuousParameterRangesTypeDef
        ],
        "CategoricalParameterRanges": List[
            ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesCategoricalParameterRangesTypeDef
        ],
    },
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfig` `ParameterRanges`

    The  ParameterRanges object that specifies the ranges of hyperparameters that this tuning
    job searches.

    - **IntegerParameterRanges** *(list) --*

      The array of  IntegerParameterRange objects that specify ranges of integer
      hyperparameters that a hyperparameter tuning job searches.

      - *(dict) --*

        For a hyperparameter of the integer type, specifies the range that a hyperparameter
        tuning job searches.

        - **Name** *(string) --*

          The name of the hyperparameter to search.

        - **MinValue** *(string) --*

          The minimum value of the hyperparameter to search.

        - **MaxValue** *(string) --*

          The maximum value of the hyperparameter to search.

        - **ScalingType** *(string) --*

          The scale that hyperparameter tuning uses to search the hyperparameter range. For
          information about choosing a hyperparameter scale, see `Hyperparameter Scaling
          <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html#scaling-type>`__
          . One of the following values:

            Auto

          Amazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.

            Linear

          Hyperparameter tuning searches the values in the hyperparameter range by using a
          linear scale.

            Logarithmic

          Hyperparameter tuning searches the values in the hyperparameter range by using a
          logarithmic scale.

          Logarithmic scaling works only for ranges that have only values greater than 0.

    - **ContinuousParameterRanges** *(list) --*

      The array of  ContinuousParameterRange objects that specify ranges of continuous
      hyperparameters that a hyperparameter tuning job searches.

      - *(dict) --*

        A list of continuous hyperparameters to tune.

        - **Name** *(string) --*

          The name of the continuous hyperparameter to tune.

        - **MinValue** *(string) --*

          The minimum value for the hyperparameter. The tuning job uses floating-point values
          between this value and ``MaxValue`` for tuning.

        - **MaxValue** *(string) --*

          The maximum value for the hyperparameter. The tuning job uses floating-point values
          between ``MinValue`` value and this value for tuning.

        - **ScalingType** *(string) --*

          The scale that hyperparameter tuning uses to search the hyperparameter range. For
          information about choosing a hyperparameter scale, see `Hyperparameter Scaling
          <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html#scaling-type>`__
          . One of the following values:

            Auto

          Amazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.

            Linear

          Hyperparameter tuning searches the values in the hyperparameter range by using a
          linear scale.

            Logarithmic

          Hyperparameter tuning searches the values in the hyperparameter range by using a
          logarithmic scale.

          Logarithmic scaling works only for ranges that have only values greater than 0.

            ReverseLogarithmic

          Hyperparameter tuning searches the values in the hyperparameter range by using a
          reverse logarithmic scale.

          Reverse logarithmic scaling works only for ranges that are entirely within the range
          0<=x<1.0.

    - **CategoricalParameterRanges** *(list) --*

      The array of  CategoricalParameterRange objects that specify ranges of categorical
      hyperparameters that a hyperparameter tuning job searches.

      - *(dict) --*

        A list of categorical hyperparameters to tune.

        - **Name** *(string) --*

          The name of the categorical hyperparameter to tune.

        - **Values** *(list) --*

          A list of the categories for the hyperparameter.

          - *(string) --*
    """


_ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigResourceLimitsTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigResourceLimitsTypeDef",
    {"MaxNumberOfTrainingJobs": int, "MaxParallelTrainingJobs": int},
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigResourceLimitsTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigResourceLimitsTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfig` `ResourceLimits`

    The  ResourceLimits object that specifies the maximum number of training jobs and parallel
    training jobs for this tuning job.

    - **MaxNumberOfTrainingJobs** *(integer) --*

      The maximum number of training jobs that a hyperparameter tuning job can launch.

    - **MaxParallelTrainingJobs** *(integer) --*

      The maximum number of concurrent training jobs that a hyperparameter tuning job can
      launch.
    """


_ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigTypeDef",
    {
        "Strategy": str,
        "HyperParameterTuningJobObjective": ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigHyperParameterTuningJobObjectiveTypeDef,
        "ResourceLimits": ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigResourceLimitsTypeDef,
        "ParameterRanges": ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigParameterRangesTypeDef,
        "TrainingJobEarlyStoppingType": str,
    },
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponse` `HyperParameterTuningJobConfig`

    The  HyperParameterTuningJobConfig object that specifies the configuration of the tuning job.

    - **Strategy** *(string) --*

      Specifies how hyperparameter tuning chooses the combinations of hyperparameter values to
      use for the training job it launches. To use the Bayesian search stategy, set this to
      ``Bayesian`` . To randomly search, set it to ``Random`` . For information about search
      strategies, see `How Hyperparameter Tuning Works
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html>`__
      .

    - **HyperParameterTuningJobObjective** *(dict) --*

      The  HyperParameterTuningJobObjective object that specifies the objective metric for this
      tuning job.

      - **Type** *(string) --*

        Whether to minimize or maximize the objective metric.

      - **MetricName** *(string) --*

        The name of the metric to use for the objective metric.

    - **ResourceLimits** *(dict) --*

      The  ResourceLimits object that specifies the maximum number of training jobs and parallel
      training jobs for this tuning job.

      - **MaxNumberOfTrainingJobs** *(integer) --*

        The maximum number of training jobs that a hyperparameter tuning job can launch.

      - **MaxParallelTrainingJobs** *(integer) --*

        The maximum number of concurrent training jobs that a hyperparameter tuning job can
        launch.

    - **ParameterRanges** *(dict) --*

      The  ParameterRanges object that specifies the ranges of hyperparameters that this tuning
      job searches.

      - **IntegerParameterRanges** *(list) --*

        The array of  IntegerParameterRange objects that specify ranges of integer
        hyperparameters that a hyperparameter tuning job searches.

        - *(dict) --*

          For a hyperparameter of the integer type, specifies the range that a hyperparameter
          tuning job searches.

          - **Name** *(string) --*

            The name of the hyperparameter to search.

          - **MinValue** *(string) --*

            The minimum value of the hyperparameter to search.

          - **MaxValue** *(string) --*

            The maximum value of the hyperparameter to search.

          - **ScalingType** *(string) --*

            The scale that hyperparameter tuning uses to search the hyperparameter range. For
            information about choosing a hyperparameter scale, see `Hyperparameter Scaling
            <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html#scaling-type>`__
            . One of the following values:

              Auto

            Amazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.

              Linear

            Hyperparameter tuning searches the values in the hyperparameter range by using a
            linear scale.

              Logarithmic

            Hyperparameter tuning searches the values in the hyperparameter range by using a
            logarithmic scale.

            Logarithmic scaling works only for ranges that have only values greater than 0.

      - **ContinuousParameterRanges** *(list) --*

        The array of  ContinuousParameterRange objects that specify ranges of continuous
        hyperparameters that a hyperparameter tuning job searches.

        - *(dict) --*

          A list of continuous hyperparameters to tune.

          - **Name** *(string) --*

            The name of the continuous hyperparameter to tune.

          - **MinValue** *(string) --*

            The minimum value for the hyperparameter. The tuning job uses floating-point values
            between this value and ``MaxValue`` for tuning.

          - **MaxValue** *(string) --*

            The maximum value for the hyperparameter. The tuning job uses floating-point values
            between ``MinValue`` value and this value for tuning.

          - **ScalingType** *(string) --*

            The scale that hyperparameter tuning uses to search the hyperparameter range. For
            information about choosing a hyperparameter scale, see `Hyperparameter Scaling
            <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html#scaling-type>`__
            . One of the following values:

              Auto

            Amazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.

              Linear

            Hyperparameter tuning searches the values in the hyperparameter range by using a
            linear scale.

              Logarithmic

            Hyperparameter tuning searches the values in the hyperparameter range by using a
            logarithmic scale.

            Logarithmic scaling works only for ranges that have only values greater than 0.

              ReverseLogarithmic

            Hyperparameter tuning searches the values in the hyperparameter range by using a
            reverse logarithmic scale.

            Reverse logarithmic scaling works only for ranges that are entirely within the range
            0<=x<1.0.

      - **CategoricalParameterRanges** *(list) --*

        The array of  CategoricalParameterRange objects that specify ranges of categorical
        hyperparameters that a hyperparameter tuning job searches.

        - *(dict) --*

          A list of categorical hyperparameters to tune.

          - **Name** *(string) --*

            The name of the categorical hyperparameter to tune.

          - **Values** *(list) --*

            A list of the categories for the hyperparameter.

            - *(string) --*

    - **TrainingJobEarlyStoppingType** *(string) --*

      Specifies whether to use early stopping for training jobs launched by the hyperparameter
      tuning job. This can be one of the following values (the default value is ``OFF`` ):

        OFF

      Training jobs launched by the hyperparameter tuning job do not use early stopping.

        AUTO

      Amazon SageMaker stops training jobs launched by the hyperparameter tuning job when they
      are unlikely to perform better than previously completed training jobs. For more
      information, see `Stop Training Jobs Early
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-early-stopping.html>`__
      .
    """


_ClientDescribeHyperParameterTuningJobResponseObjectiveStatusCountersTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseObjectiveStatusCountersTypeDef",
    {"Succeeded": int, "Pending": int, "Failed": int},
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseObjectiveStatusCountersTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseObjectiveStatusCountersTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponse` `ObjectiveStatusCounters`

    The  ObjectiveStatusCounters object that specifies the number of training jobs, categorized
    by the status of their final objective metric, that this tuning job launched.

    - **Succeeded** *(integer) --*

      The number of training jobs whose final objective metric was evaluated by the
      hyperparameter tuning job and used in the hyperparameter tuning process.

    - **Pending** *(integer) --*

      The number of training jobs that are in progress and pending evaluation of their final
      objective metric.

    - **Failed** *(integer) --*

      The number of training jobs whose final objective metric was not evaluated and used in the
      hyperparameter tuning process. This typically occurs when the training job failed or did
      not emit an objective metric.
    """


_ClientDescribeHyperParameterTuningJobResponseOverallBestTrainingJobFinalHyperParameterTuningJobObjectiveMetricTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseOverallBestTrainingJobFinalHyperParameterTuningJobObjectiveMetricTypeDef",
    {"Type": str, "MetricName": str, "Value": float},
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseOverallBestTrainingJobFinalHyperParameterTuningJobObjectiveMetricTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseOverallBestTrainingJobFinalHyperParameterTuningJobObjectiveMetricTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseOverallBestTrainingJob` `FinalHyperParameterTuningJobObjectiveMetric`

    The  FinalHyperParameterTuningJobObjectiveMetric object that specifies the value of the
    objective metric of the tuning job that launched this training job.

    - **Type** *(string) --*

      Whether to minimize or maximize the objective metric. Valid values are Minimize and
      Maximize.

    - **MetricName** *(string) --*

      The name of the objective metric.

    - **Value** *(float) --*

      The value of the objective metric.
    """


_ClientDescribeHyperParameterTuningJobResponseOverallBestTrainingJobTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseOverallBestTrainingJobTypeDef",
    {
        "TrainingJobName": str,
        "TrainingJobArn": str,
        "TuningJobName": str,
        "CreationTime": datetime,
        "TrainingStartTime": datetime,
        "TrainingEndTime": datetime,
        "TrainingJobStatus": str,
        "TunedHyperParameters": Dict[str, str],
        "FailureReason": str,
        "FinalHyperParameterTuningJobObjectiveMetric": ClientDescribeHyperParameterTuningJobResponseOverallBestTrainingJobFinalHyperParameterTuningJobObjectiveMetricTypeDef,
        "ObjectiveStatus": str,
    },
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseOverallBestTrainingJobTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseOverallBestTrainingJobTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponse` `OverallBestTrainingJob`

    If the hyperparameter tuning job is an warm start tuning job with a ``WarmStartType`` of
    ``IDENTICAL_DATA_AND_ALGORITHM`` , this is the  TrainingJobSummary for the training job with
    the best objective metric value of all training jobs launched by this tuning job and all
    parent jobs specified for the warm start tuning job.

    - **TrainingJobName** *(string) --*

      The name of the training job.

    - **TrainingJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the training job.

    - **TuningJobName** *(string) --*

      The HyperParameter tuning job that launched the training job.

    - **CreationTime** *(datetime) --*

      The date and time that the training job was created.

    - **TrainingStartTime** *(datetime) --*

      The date and time that the training job started.

    - **TrainingEndTime** *(datetime) --*

      Specifies the time when the training job ends on training instances. You are billed for the
      time interval between the value of ``TrainingStartTime`` and this time. For successful jobs
      and stopped jobs, this is the time after model artifacts are uploaded. For failed jobs,
      this is the time when Amazon SageMaker detects a job failure.

    - **TrainingJobStatus** *(string) --*

      The status of the training job.

    - **TunedHyperParameters** *(dict) --*

      A list of the hyperparameters for which you specified ranges to search.

      - *(string) --*

        - *(string) --*

    - **FailureReason** *(string) --*

      The reason that the training job failed.

    - **FinalHyperParameterTuningJobObjectiveMetric** *(dict) --*

      The  FinalHyperParameterTuningJobObjectiveMetric object that specifies the value of the
      objective metric of the tuning job that launched this training job.

      - **Type** *(string) --*

        Whether to minimize or maximize the objective metric. Valid values are Minimize and
        Maximize.

      - **MetricName** *(string) --*

        The name of the objective metric.

      - **Value** *(float) --*

        The value of the objective metric.

    - **ObjectiveStatus** *(string) --*

      The status of the objective metric for the training job:

      * Succeeded: The final objective metric for the training job was evaluated by the
      hyperparameter tuning job and used in the hyperparameter tuning process.

      * Pending: The training job is in progress and evaluation of its final objective metric is
      pending.

      * Failed: The final objective metric for the training job was not evaluated, and was not
      used in the hyperparameter tuning process. This typically occurs when the training job
      failed or did not emit an objective metric.
    """


_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionAlgorithmSpecificationMetricDefinitionsTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionAlgorithmSpecificationMetricDefinitionsTypeDef",
    {"Name": str, "Regex": str},
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionAlgorithmSpecificationMetricDefinitionsTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionAlgorithmSpecificationMetricDefinitionsTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionAlgorithmSpecification` `MetricDefinitions`

    Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
    Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
    metric that a hyperparameter tuning job uses as its objective metric to choose the best
    training job.

    - **Name** *(string) --*

      The name of the metric.

    - **Regex** *(string) --*

      A regular expression that searches the output of a training job and gets the value of
      the metric. For more information about using regular expressions to define metrics,
      see `Defining Objective Metrics
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
      .
    """


_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionAlgorithmSpecificationTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionAlgorithmSpecificationTypeDef",
    {
        "TrainingImage": str,
        "TrainingInputMode": str,
        "AlgorithmName": str,
        "MetricDefinitions": List[
            ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionAlgorithmSpecificationMetricDefinitionsTypeDef
        ],
    },
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionAlgorithmSpecificationTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionAlgorithmSpecificationTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinition` `AlgorithmSpecification`

    The  HyperParameterAlgorithmSpecification object that specifies the resource algorithm to
    use for the training jobs that the tuning job launches.

    - **TrainingImage** *(string) --*

      The registry path of the Docker image that contains the training algorithm. For
      information about Docker registry paths for built-in algorithms, see `Algorithms Provided
      by Amazon SageMaker\\: Common Parameters
      <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
      . Amazon SageMaker supports both ``registry/repository[:tag]`` and
      ``registry/repository[@digest]`` image path formats. For more information, see `Using
      Your Own Algorithms with Amazon SageMaker
      <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

    - **TrainingInputMode** *(string) --*

      The input mode that the algorithm supports: File or Pipe. In File input mode, Amazon
      SageMaker downloads the training data from Amazon S3 to the storage volume that is
      attached to the training instance and mounts the directory to the Docker volume for the
      training container. In Pipe input mode, Amazon SageMaker streams data directly from
      Amazon S3 to the container.

      If you specify File mode, make sure that you provision the storage volume that is
      attached to the training instance with enough capacity to accommodate the training data
      downloaded from Amazon S3, the model artifacts, and intermediate information.

      For more information about input modes, see `Algorithms
      <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ .

    - **AlgorithmName** *(string) --*

      The name of the resource algorithm to use for the hyperparameter tuning job. If you
      specify a value for this parameter, do not specify a value for ``TrainingImage`` .

    - **MetricDefinitions** *(list) --*

      An array of  MetricDefinition objects that specify the metrics that the algorithm emits.

      - *(dict) --*

        Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
        Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
        metric that a hyperparameter tuning job uses as its objective metric to choose the best
        training job.

        - **Name** *(string) --*

          The name of the metric.

        - **Regex** *(string) --*

          A regular expression that searches the output of a training job and gets the value of
          the metric. For more information about using regular expressions to define metrics,
          see `Defining Objective Metrics
          <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
          .
    """


_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionCheckpointConfigTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionCheckpointConfigTypeDef",
    {"S3Uri": str, "LocalPath": str},
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionCheckpointConfigTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionCheckpointConfigTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinition` `CheckpointConfig`

    Contains information about the output location for managed spot training checkpoint data.

    - **S3Uri** *(string) --*

      Identifies the S3 path where you want Amazon SageMaker to store checkpoints. For example,
      ``s3://bucket-name/key-name-prefix`` .

    - **LocalPath** *(string) --*

      (Optional) The local directory where checkpoints are written. The default directory is
      ``/opt/ml/checkpoints/`` .
    """


_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef",
    {
        "FileSystemId": str,
        "FileSystemAccessMode": str,
        "FileSystemType": str,
        "DirectoryPath": str,
    },
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSource` `FileSystemDataSource`

    The file system that is associated with a channel.

    - **FileSystemId** *(string) --*

      The file system id.

    - **FileSystemAccessMode** *(string) --*

      The access mode of the mount of the directory associated with the channel. A
      directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

    - **FileSystemType** *(string) --*

      The file system type.

    - **DirectoryPath** *(string) --*

      The full path to the directory to associate with the channel.
    """


_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef",
    {
        "S3DataType": str,
        "S3Uri": str,
        "S3DataDistributionType": str,
        "AttributeNames": List[str],
    },
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSource` `S3DataSource`

    The S3 location of the data source that is associated with a channel.

    - **S3DataType** *(string) --*

      If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
      SageMaker uses all objects that match the specified key name prefix for model
      training.

      If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
      file containing a list of object keys that you want Amazon SageMaker to use for
      model training.

      If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
      augmented manifest file in JSON lines format. This file contains the data you want
      to use for model training. ``AugmentedManifestFile`` can only be used if the
      Channel's input mode is ``Pipe`` .

    - **S3Uri** *(string) --*

      Depending on the value specified for the ``S3DataType`` , identifies either a key
      name prefix or a manifest. For example:

      * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

      * A manifest might look like this: ``s3://bucketname/example.manifest``   The
      manifest is an S3 object which is a JSON file with the following format:  The
      preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
      "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
      ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
      ``]``   The preceding JSON matches the following ``s3Uris`` :
      ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
      ``s3uris`` in this manifest is the input data for the channel for this datasource.
      The object that each ``s3uris`` points to must be readable by the IAM role that
      Amazon SageMaker uses to perform tasks on your behalf.

    - **S3DataDistributionType** *(string) --*

      If you want Amazon SageMaker to replicate the entire dataset on each ML compute
      instance that is launched for model training, specify ``FullyReplicated`` .

      If you want Amazon SageMaker to replicate a subset of data on each ML compute
      instance that is launched for model training, specify ``ShardedByS3Key`` . If there
      are *n* ML compute instances launched for a training job, each instance gets
      approximately 1/*n* of the number of S3 objects. In this case, model training on
      each machine uses only the subset of training data.

      Don't choose more ML compute instances for training than available S3 objects. If
      you do, some nodes won't get any data and you will pay for nodes that aren't
      getting any training data. This applies in both File and Pipe modes. Keep this in
      mind when developing algorithms.

      In distributed training, where you use multiple ML compute EC2 instances, you might
      choose ``ShardedByS3Key`` . If the algorithm requires copying training data to the
      ML storage volume (when ``TrainingInputMode`` is set to ``File`` ), this copies
      1/*n* of the number of objects.

    - **AttributeNames** *(list) --*

      A list of one or more attribute names to use that are found in a specified
      augmented manifest file.

      - *(string) --*
    """


_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceTypeDef",
    {
        "S3DataSource": ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceS3DataSourceTypeDef,
        "FileSystemDataSource": ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceFileSystemDataSourceTypeDef,
    },
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfig` `DataSource`

    The location of the channel data.

    - **S3DataSource** *(dict) --*

      The S3 location of the data source that is associated with a channel.

      - **S3DataType** *(string) --*

        If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
        SageMaker uses all objects that match the specified key name prefix for model
        training.

        If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
        file containing a list of object keys that you want Amazon SageMaker to use for
        model training.

        If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
        augmented manifest file in JSON lines format. This file contains the data you want
        to use for model training. ``AugmentedManifestFile`` can only be used if the
        Channel's input mode is ``Pipe`` .

      - **S3Uri** *(string) --*

        Depending on the value specified for the ``S3DataType`` , identifies either a key
        name prefix or a manifest. For example:

        * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

        * A manifest might look like this: ``s3://bucketname/example.manifest``   The
        manifest is an S3 object which is a JSON file with the following format:  The
        preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
        "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
        ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
        ``]``   The preceding JSON matches the following ``s3Uris`` :
        ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
        ``s3uris`` in this manifest is the input data for the channel for this datasource.
        The object that each ``s3uris`` points to must be readable by the IAM role that
        Amazon SageMaker uses to perform tasks on your behalf.

      - **S3DataDistributionType** *(string) --*

        If you want Amazon SageMaker to replicate the entire dataset on each ML compute
        instance that is launched for model training, specify ``FullyReplicated`` .

        If you want Amazon SageMaker to replicate a subset of data on each ML compute
        instance that is launched for model training, specify ``ShardedByS3Key`` . If there
        are *n* ML compute instances launched for a training job, each instance gets
        approximately 1/*n* of the number of S3 objects. In this case, model training on
        each machine uses only the subset of training data.

        Don't choose more ML compute instances for training than available S3 objects. If
        you do, some nodes won't get any data and you will pay for nodes that aren't
        getting any training data. This applies in both File and Pipe modes. Keep this in
        mind when developing algorithms.

        In distributed training, where you use multiple ML compute EC2 instances, you might
        choose ``ShardedByS3Key`` . If the algorithm requires copying training data to the
        ML storage volume (when ``TrainingInputMode`` is set to ``File`` ), this copies
        1/*n* of the number of objects.

      - **AttributeNames** *(list) --*

        A list of one or more attribute names to use that are found in a specified
        augmented manifest file.

        - *(string) --*

    - **FileSystemDataSource** *(dict) --*

      The file system that is associated with a channel.

      - **FileSystemId** *(string) --*

        The file system id.

      - **FileSystemAccessMode** *(string) --*

        The access mode of the mount of the directory associated with the channel. A
        directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

      - **FileSystemType** *(string) --*

        The file system type.

      - **DirectoryPath** *(string) --*

        The full path to the directory to associate with the channel.
    """


_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef",
    {"Seed": int},
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfig` `ShuffleConfig`

    A configuration for a shuffle option for input data in a channel. If you use
    ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
    matches. If you use ``ManifestFile`` , the order of the S3 object references in the
    ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of the
    JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
    determined using the ``Seed`` value.

    For Pipe input mode, shuffling is done at the start of every epoch. With large datasets
    this ensures that the order of the training data is different for each epoch, it helps
    reduce bias and possible overfitting. In a multi-node training job when ShuffleConfig
    is combined with ``S3DataDistributionType`` of ``ShardedByS3Key`` , the data is
    shuffled across nodes so that the content sent to a particular node on the first epoch
    might be sent to a different node on the second epoch.

    - **Seed** *(integer) --*

      Determines the shuffling order in ``ShuffleConfig`` value.
    """


_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigTypeDef",
    {
        "ChannelName": str,
        "DataSource": ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigDataSourceTypeDef,
        "ContentType": str,
        "CompressionType": str,
        "RecordWrapperType": str,
        "InputMode": str,
        "ShuffleConfig": ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigShuffleConfigTypeDef,
    },
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinition` `InputDataConfig`

    A channel is a named input source that training algorithms can consume.

    - **ChannelName** *(string) --*

      The name of the channel.

    - **DataSource** *(dict) --*

      The location of the channel data.

      - **S3DataSource** *(dict) --*

        The S3 location of the data source that is associated with a channel.

        - **S3DataType** *(string) --*

          If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
          SageMaker uses all objects that match the specified key name prefix for model
          training.

          If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
          file containing a list of object keys that you want Amazon SageMaker to use for
          model training.

          If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
          augmented manifest file in JSON lines format. This file contains the data you want
          to use for model training. ``AugmentedManifestFile`` can only be used if the
          Channel's input mode is ``Pipe`` .

        - **S3Uri** *(string) --*

          Depending on the value specified for the ``S3DataType`` , identifies either a key
          name prefix or a manifest. For example:

          * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

          * A manifest might look like this: ``s3://bucketname/example.manifest``   The
          manifest is an S3 object which is a JSON file with the following format:  The
          preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
          "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
          ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
          ``]``   The preceding JSON matches the following ``s3Uris`` :
          ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
          ``s3uris`` in this manifest is the input data for the channel for this datasource.
          The object that each ``s3uris`` points to must be readable by the IAM role that
          Amazon SageMaker uses to perform tasks on your behalf.

        - **S3DataDistributionType** *(string) --*

          If you want Amazon SageMaker to replicate the entire dataset on each ML compute
          instance that is launched for model training, specify ``FullyReplicated`` .

          If you want Amazon SageMaker to replicate a subset of data on each ML compute
          instance that is launched for model training, specify ``ShardedByS3Key`` . If there
          are *n* ML compute instances launched for a training job, each instance gets
          approximately 1/*n* of the number of S3 objects. In this case, model training on
          each machine uses only the subset of training data.

          Don't choose more ML compute instances for training than available S3 objects. If
          you do, some nodes won't get any data and you will pay for nodes that aren't
          getting any training data. This applies in both File and Pipe modes. Keep this in
          mind when developing algorithms.

          In distributed training, where you use multiple ML compute EC2 instances, you might
          choose ``ShardedByS3Key`` . If the algorithm requires copying training data to the
          ML storage volume (when ``TrainingInputMode`` is set to ``File`` ), this copies
          1/*n* of the number of objects.

        - **AttributeNames** *(list) --*

          A list of one or more attribute names to use that are found in a specified
          augmented manifest file.

          - *(string) --*

      - **FileSystemDataSource** *(dict) --*

        The file system that is associated with a channel.

        - **FileSystemId** *(string) --*

          The file system id.

        - **FileSystemAccessMode** *(string) --*

          The access mode of the mount of the directory associated with the channel. A
          directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

        - **FileSystemType** *(string) --*

          The file system type.

        - **DirectoryPath** *(string) --*

          The full path to the directory to associate with the channel.

    - **ContentType** *(string) --*

      The MIME type of the data.

    - **CompressionType** *(string) --*

      If training data is compressed, the compression type. The default value is ``None`` .
      ``CompressionType`` is used only in Pipe input mode. In File mode, leave this field
      unset or set it to None.

    - **RecordWrapperType** *(string) --*

      Specify RecordIO as the value when input data is in raw format but the training
      algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
      individual S3 object in a RecordIO record. If the input data is already in RecordIO
      format, you don't need to set this attribute. For more information, see `Create a
      Dataset Using RecordIO
      <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
      .

      In File mode, leave this field unset or set it to None.

    - **InputMode** *(string) --*

      (Optional) The input mode to use for the data channel in a training job. If you don't
      set a value for ``InputMode`` , Amazon SageMaker uses the value set for
      ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
      setting in a  AlgorithmSpecification request when you have a channel that needs a
      different input mode from the training job's general setting. To download the data from
      Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage volume, and
      mount the directory to a Docker volume, use ``File`` input mode. To stream data
      directly from Amazon S3 to the container, choose ``Pipe`` input mode.

      To use a model for incremental training, choose ``File`` input model.

    - **ShuffleConfig** *(dict) --*

      A configuration for a shuffle option for input data in a channel. If you use
      ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
      matches. If you use ``ManifestFile`` , the order of the S3 object references in the
      ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of the
      JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
      determined using the ``Seed`` value.

      For Pipe input mode, shuffling is done at the start of every epoch. With large datasets
      this ensures that the order of the training data is different for each epoch, it helps
      reduce bias and possible overfitting. In a multi-node training job when ShuffleConfig
      is combined with ``S3DataDistributionType`` of ``ShardedByS3Key`` , the data is
      shuffled across nodes so that the content sent to a particular node on the first epoch
      might be sent to a different node on the second epoch.

      - **Seed** *(integer) --*

        Determines the shuffling order in ``ShuffleConfig`` value.
    """


_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionOutputDataConfigTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionOutputDataConfigTypeDef",
    {"KmsKeyId": str, "S3OutputPath": str},
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionOutputDataConfigTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionOutputDataConfigTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinition` `OutputDataConfig`

    Specifies the path to the Amazon S3 bucket where you store model artifacts from the
    training jobs that the tuning job launches.

    - **KmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
      model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be
      any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // KMS Key Alias  ``"alias/ExampleAlias"``

      * // Amazon Resource Name (ARN) of a KMS Key Alias
      ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

      If you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution
      role must include permissions to call ``kms:Encrypt`` . If you don't provide a KMS key
      ID, Amazon SageMaker uses the default KMS key for Amazon S3 for your role's account.
      Amazon SageMaker uses server-side encryption with KMS-managed keys for
      ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject`` permission
      that only allows objects with server-side encryption, set the condition key of
      ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information, see
      `KMS-Managed Encryption Keys
      <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
      *Amazon Simple Storage Service Developer Guide.*

      The KMS key policy must grant permission to the IAM role that you specify in your
      ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
      requests. For more information, see `Using Key Policies in AWS KMS
      <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
      in the *AWS Key Management Service Developer Guide* .

    - **S3OutputPath** *(string) --*

      Identifies the S3 path where you want Amazon SageMaker to store the model artifacts. For
      example, ``s3://bucket-name/key-name-prefix`` .
    """


_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionResourceConfigTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionResourceConfigTypeDef",
    {
        "InstanceType": str,
        "InstanceCount": int,
        "VolumeSizeInGB": int,
        "VolumeKmsKeyId": str,
    },
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionResourceConfigTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionResourceConfigTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinition` `ResourceConfig`

    The resources, including the compute instances and storage volumes, to use for the training
    jobs that the tuning job launches.

    Storage volumes store model artifacts and incremental states. Training algorithms might
    also use storage volumes for scratch space. If you want Amazon SageMaker to use the storage
    volume to store the training data, choose ``File`` as the ``TrainingInputMode`` in the
    algorithm specification. For distributed training algorithms, specify an instance count
    greater than 1.

    - **InstanceType** *(string) --*

      The ML compute instance type.

    - **InstanceCount** *(integer) --*

      The number of ML compute instances to use. For distributed training, provide a value
      greater than 1.

    - **VolumeSizeInGB** *(integer) --*

      The size of the ML storage volume that you want to provision.

      ML storage volumes store model artifacts and incremental states. Training algorithms
      might also use the ML storage volume for scratch space. If you want to store the training
      data in the ML storage volume, choose ``File`` as the ``TrainingInputMode`` in the
      algorithm specification.

      You must specify sufficient ML storage for your scenario.

      .. note::

        Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

      .. note::

        Certain Nitro-based instances include local storage with a fixed total size, dependent
        on the instance type. When using these instances for training, Amazon SageMaker mounts
        the local instance storage instead of Amazon EBS gp2 storage. You can't request a
        ``VolumeSizeInGB`` greater than the total size of the local instance storage.

        For a list of instance types that support local instance storage, including the total
        size per instance type, see `Instance Store Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
        .

    - **VolumeKmsKeyId** *(string) --*

      The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume attached
      to the ML compute instance(s) that run the training job.

      .. note::

        Certain Nitro-based instances include local storage, dependent on the instance type.
        Local storage volumes are encrypted using a hardware module on the instance. You can't
        request a ``VolumeKmsKeyId`` when using an instance type with local storage.

        For a list of instance types that support local instance storage, see `Instance Store
        Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
        .

        For more information about local instance storage encryption, see `SSD Instance Store
        Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

      The ``VolumeKmsKeyId`` can be in any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionStoppingConditionTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionStoppingConditionTypeDef",
    {"MaxRuntimeInSeconds": int, "MaxWaitTimeInSeconds": int},
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionStoppingConditionTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionStoppingConditionTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinition` `StoppingCondition`

    Specifies a limit to how long a model hyperparameter training job can run. It also
    specifies how long you are willing to wait for a managed spot training job to complete.
    When the job reaches the a limit, Amazon SageMaker ends the training job. Use this API to
    cap model training costs.

    - **MaxRuntimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, that the training or compilation job can run. If
      job does not complete during this time, Amazon SageMaker ends the job. If value is not
      specified, default value is 1 day. The maximum value is 28 days.

    - **MaxWaitTimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, how long you are willing to wait for a managed
      spot training job to complete. It is the amount of time spent waiting for Spot capacity
      plus the amount of time the training job runs. It must be equal to or greater than
      ``MaxRuntimeInSeconds`` .
    """


_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionVpcConfigTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionVpcConfigTypeDef",
    {"SecurityGroupIds": List[str], "Subnets": List[str]},
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionVpcConfigTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionVpcConfigTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinition` `VpcConfig`

    The  VpcConfig object that specifies the VPC that you want the training jobs that this
    hyperparameter tuning job launches to connect to. Control access to and from your training
    container by configuring the VPC. For more information, see `Protect Training Jobs by Using
    an Amazon Virtual Private Cloud
    <https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html>`__ .

    - **SecurityGroupIds** *(list) --*

      The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for the
      VPC that is specified in the ``Subnets`` field.

      - *(string) --*

    - **Subnets** *(list) --*

      The ID of the subnets in the VPC to which you want to connect your training job or model.

      .. note::

        Amazon EC2 P3 accelerated computing instances are not available in the c/d/e
        availability zones of region us-east-1. If you want to create endpoints with P3
        instances in VPC mode in region us-east-1, create subnets in a/b/f availability zones
        instead.

      - *(string) --*
    """


_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionTypeDef",
    {
        "StaticHyperParameters": Dict[str, str],
        "AlgorithmSpecification": ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionAlgorithmSpecificationTypeDef,
        "RoleArn": str,
        "InputDataConfig": List[
            ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionInputDataConfigTypeDef
        ],
        "VpcConfig": ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionVpcConfigTypeDef,
        "OutputDataConfig": ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionOutputDataConfigTypeDef,
        "ResourceConfig": ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionResourceConfigTypeDef,
        "StoppingCondition": ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionStoppingConditionTypeDef,
        "EnableNetworkIsolation": bool,
        "EnableInterContainerTrafficEncryption": bool,
        "EnableManagedSpotTraining": bool,
        "CheckpointConfig": ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionCheckpointConfigTypeDef,
    },
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponse` `TrainingJobDefinition`

    The  HyperParameterTrainingJobDefinition object that specifies the definition of the training
    jobs that this tuning job launches.

    - **StaticHyperParameters** *(dict) --*

      Specifies the values of hyperparameters that do not change for the tuning job.

      - *(string) --*

        - *(string) --*

    - **AlgorithmSpecification** *(dict) --*

      The  HyperParameterAlgorithmSpecification object that specifies the resource algorithm to
      use for the training jobs that the tuning job launches.

      - **TrainingImage** *(string) --*

        The registry path of the Docker image that contains the training algorithm. For
        information about Docker registry paths for built-in algorithms, see `Algorithms Provided
        by Amazon SageMaker\\: Common Parameters
        <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
        . Amazon SageMaker supports both ``registry/repository[:tag]`` and
        ``registry/repository[@digest]`` image path formats. For more information, see `Using
        Your Own Algorithms with Amazon SageMaker
        <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

      - **TrainingInputMode** *(string) --*

        The input mode that the algorithm supports: File or Pipe. In File input mode, Amazon
        SageMaker downloads the training data from Amazon S3 to the storage volume that is
        attached to the training instance and mounts the directory to the Docker volume for the
        training container. In Pipe input mode, Amazon SageMaker streams data directly from
        Amazon S3 to the container.

        If you specify File mode, make sure that you provision the storage volume that is
        attached to the training instance with enough capacity to accommodate the training data
        downloaded from Amazon S3, the model artifacts, and intermediate information.

        For more information about input modes, see `Algorithms
        <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ .

      - **AlgorithmName** *(string) --*

        The name of the resource algorithm to use for the hyperparameter tuning job. If you
        specify a value for this parameter, do not specify a value for ``TrainingImage`` .

      - **MetricDefinitions** *(list) --*

        An array of  MetricDefinition objects that specify the metrics that the algorithm emits.

        - *(dict) --*

          Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
          Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
          metric that a hyperparameter tuning job uses as its objective metric to choose the best
          training job.

          - **Name** *(string) --*

            The name of the metric.

          - **Regex** *(string) --*

            A regular expression that searches the output of a training job and gets the value of
            the metric. For more information about using regular expressions to define metrics,
            see `Defining Objective Metrics
            <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
            .

    - **RoleArn** *(string) --*

      The Amazon Resource Name (ARN) of the IAM role associated with the training jobs that the
      tuning job launches.

    - **InputDataConfig** *(list) --*

      An array of  Channel objects that specify the input for the training jobs that the tuning
      job launches.

      - *(dict) --*

        A channel is a named input source that training algorithms can consume.

        - **ChannelName** *(string) --*

          The name of the channel.

        - **DataSource** *(dict) --*

          The location of the channel data.

          - **S3DataSource** *(dict) --*

            The S3 location of the data source that is associated with a channel.

            - **S3DataType** *(string) --*

              If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
              SageMaker uses all objects that match the specified key name prefix for model
              training.

              If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
              file containing a list of object keys that you want Amazon SageMaker to use for
              model training.

              If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
              augmented manifest file in JSON lines format. This file contains the data you want
              to use for model training. ``AugmentedManifestFile`` can only be used if the
              Channel's input mode is ``Pipe`` .

            - **S3Uri** *(string) --*

              Depending on the value specified for the ``S3DataType`` , identifies either a key
              name prefix or a manifest. For example:

              * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

              * A manifest might look like this: ``s3://bucketname/example.manifest``   The
              manifest is an S3 object which is a JSON file with the following format:  The
              preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
              "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
              ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
              ``]``   The preceding JSON matches the following ``s3Uris`` :
              ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
              ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
              ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
              ``s3uris`` in this manifest is the input data for the channel for this datasource.
              The object that each ``s3uris`` points to must be readable by the IAM role that
              Amazon SageMaker uses to perform tasks on your behalf.

            - **S3DataDistributionType** *(string) --*

              If you want Amazon SageMaker to replicate the entire dataset on each ML compute
              instance that is launched for model training, specify ``FullyReplicated`` .

              If you want Amazon SageMaker to replicate a subset of data on each ML compute
              instance that is launched for model training, specify ``ShardedByS3Key`` . If there
              are *n* ML compute instances launched for a training job, each instance gets
              approximately 1/*n* of the number of S3 objects. In this case, model training on
              each machine uses only the subset of training data.

              Don't choose more ML compute instances for training than available S3 objects. If
              you do, some nodes won't get any data and you will pay for nodes that aren't
              getting any training data. This applies in both File and Pipe modes. Keep this in
              mind when developing algorithms.

              In distributed training, where you use multiple ML compute EC2 instances, you might
              choose ``ShardedByS3Key`` . If the algorithm requires copying training data to the
              ML storage volume (when ``TrainingInputMode`` is set to ``File`` ), this copies
              1/*n* of the number of objects.

            - **AttributeNames** *(list) --*

              A list of one or more attribute names to use that are found in a specified
              augmented manifest file.

              - *(string) --*

          - **FileSystemDataSource** *(dict) --*

            The file system that is associated with a channel.

            - **FileSystemId** *(string) --*

              The file system id.

            - **FileSystemAccessMode** *(string) --*

              The access mode of the mount of the directory associated with the channel. A
              directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

            - **FileSystemType** *(string) --*

              The file system type.

            - **DirectoryPath** *(string) --*

              The full path to the directory to associate with the channel.

        - **ContentType** *(string) --*

          The MIME type of the data.

        - **CompressionType** *(string) --*

          If training data is compressed, the compression type. The default value is ``None`` .
          ``CompressionType`` is used only in Pipe input mode. In File mode, leave this field
          unset or set it to None.

        - **RecordWrapperType** *(string) --*

          Specify RecordIO as the value when input data is in raw format but the training
          algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
          individual S3 object in a RecordIO record. If the input data is already in RecordIO
          format, you don't need to set this attribute. For more information, see `Create a
          Dataset Using RecordIO
          <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
          .

          In File mode, leave this field unset or set it to None.

        - **InputMode** *(string) --*

          (Optional) The input mode to use for the data channel in a training job. If you don't
          set a value for ``InputMode`` , Amazon SageMaker uses the value set for
          ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
          setting in a  AlgorithmSpecification request when you have a channel that needs a
          different input mode from the training job's general setting. To download the data from
          Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage volume, and
          mount the directory to a Docker volume, use ``File`` input mode. To stream data
          directly from Amazon S3 to the container, choose ``Pipe`` input mode.

          To use a model for incremental training, choose ``File`` input model.

        - **ShuffleConfig** *(dict) --*

          A configuration for a shuffle option for input data in a channel. If you use
          ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
          matches. If you use ``ManifestFile`` , the order of the S3 object references in the
          ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of the
          JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
          determined using the ``Seed`` value.

          For Pipe input mode, shuffling is done at the start of every epoch. With large datasets
          this ensures that the order of the training data is different for each epoch, it helps
          reduce bias and possible overfitting. In a multi-node training job when ShuffleConfig
          is combined with ``S3DataDistributionType`` of ``ShardedByS3Key`` , the data is
          shuffled across nodes so that the content sent to a particular node on the first epoch
          might be sent to a different node on the second epoch.

          - **Seed** *(integer) --*

            Determines the shuffling order in ``ShuffleConfig`` value.

    - **VpcConfig** *(dict) --*

      The  VpcConfig object that specifies the VPC that you want the training jobs that this
      hyperparameter tuning job launches to connect to. Control access to and from your training
      container by configuring the VPC. For more information, see `Protect Training Jobs by Using
      an Amazon Virtual Private Cloud
      <https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html>`__ .

      - **SecurityGroupIds** *(list) --*

        The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for the
        VPC that is specified in the ``Subnets`` field.

        - *(string) --*

      - **Subnets** *(list) --*

        The ID of the subnets in the VPC to which you want to connect your training job or model.

        .. note::

          Amazon EC2 P3 accelerated computing instances are not available in the c/d/e
          availability zones of region us-east-1. If you want to create endpoints with P3
          instances in VPC mode in region us-east-1, create subnets in a/b/f availability zones
          instead.

        - *(string) --*

    - **OutputDataConfig** *(dict) --*

      Specifies the path to the Amazon S3 bucket where you store model artifacts from the
      training jobs that the tuning job launches.

      - **KmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
        model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be
        any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // KMS Key Alias  ``"alias/ExampleAlias"``

        * // Amazon Resource Name (ARN) of a KMS Key Alias
        ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

        If you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution
        role must include permissions to call ``kms:Encrypt`` . If you don't provide a KMS key
        ID, Amazon SageMaker uses the default KMS key for Amazon S3 for your role's account.
        Amazon SageMaker uses server-side encryption with KMS-managed keys for
        ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject`` permission
        that only allows objects with server-side encryption, set the condition key of
        ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information, see
        `KMS-Managed Encryption Keys
        <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
        *Amazon Simple Storage Service Developer Guide.*

        The KMS key policy must grant permission to the IAM role that you specify in your
        ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
        requests. For more information, see `Using Key Policies in AWS KMS
        <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
        in the *AWS Key Management Service Developer Guide* .

      - **S3OutputPath** *(string) --*

        Identifies the S3 path where you want Amazon SageMaker to store the model artifacts. For
        example, ``s3://bucket-name/key-name-prefix`` .

    - **ResourceConfig** *(dict) --*

      The resources, including the compute instances and storage volumes, to use for the training
      jobs that the tuning job launches.

      Storage volumes store model artifacts and incremental states. Training algorithms might
      also use storage volumes for scratch space. If you want Amazon SageMaker to use the storage
      volume to store the training data, choose ``File`` as the ``TrainingInputMode`` in the
      algorithm specification. For distributed training algorithms, specify an instance count
      greater than 1.

      - **InstanceType** *(string) --*

        The ML compute instance type.

      - **InstanceCount** *(integer) --*

        The number of ML compute instances to use. For distributed training, provide a value
        greater than 1.

      - **VolumeSizeInGB** *(integer) --*

        The size of the ML storage volume that you want to provision.

        ML storage volumes store model artifacts and incremental states. Training algorithms
        might also use the ML storage volume for scratch space. If you want to store the training
        data in the ML storage volume, choose ``File`` as the ``TrainingInputMode`` in the
        algorithm specification.

        You must specify sufficient ML storage for your scenario.

        .. note::

          Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

        .. note::

          Certain Nitro-based instances include local storage with a fixed total size, dependent
          on the instance type. When using these instances for training, Amazon SageMaker mounts
          the local instance storage instead of Amazon EBS gp2 storage. You can't request a
          ``VolumeSizeInGB`` greater than the total size of the local instance storage.

          For a list of instance types that support local instance storage, including the total
          size per instance type, see `Instance Store Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
          .

      - **VolumeKmsKeyId** *(string) --*

        The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume attached
        to the ML compute instance(s) that run the training job.

        .. note::

          Certain Nitro-based instances include local storage, dependent on the instance type.
          Local storage volumes are encrypted using a hardware module on the instance. You can't
          request a ``VolumeKmsKeyId`` when using an instance type with local storage.

          For a list of instance types that support local instance storage, see `Instance Store
          Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
          .

          For more information about local instance storage encryption, see `SSD Instance Store
          Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

        The ``VolumeKmsKeyId`` can be in any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

    - **StoppingCondition** *(dict) --*

      Specifies a limit to how long a model hyperparameter training job can run. It also
      specifies how long you are willing to wait for a managed spot training job to complete.
      When the job reaches the a limit, Amazon SageMaker ends the training job. Use this API to
      cap model training costs.

      - **MaxRuntimeInSeconds** *(integer) --*

        The maximum length of time, in seconds, that the training or compilation job can run. If
        job does not complete during this time, Amazon SageMaker ends the job. If value is not
        specified, default value is 1 day. The maximum value is 28 days.

      - **MaxWaitTimeInSeconds** *(integer) --*

        The maximum length of time, in seconds, how long you are willing to wait for a managed
        spot training job to complete. It is the amount of time spent waiting for Spot capacity
        plus the amount of time the training job runs. It must be equal to or greater than
        ``MaxRuntimeInSeconds`` .

    - **EnableNetworkIsolation** *(boolean) --*

      Isolates the training container. No inbound or outbound network calls can be made, except
      for calls between peers within a training cluster for distributed training. If network
      isolation is used for training jobs that are configured to use a VPC, Amazon SageMaker
      downloads and uploads customer data and model artifacts through the specified VPC, but the
      training container does not have network access.

      .. note::

        The Semantic Segmentation built-in algorithm does not support network isolation.

    - **EnableInterContainerTrafficEncryption** *(boolean) --*

      To encrypt all communications between ML compute instances in distributed training, choose
      ``True`` . Encryption provides greater security for distributed training, but training
      might take longer. How long it takes depends on the amount of communication between compute
      instances, especially if you use a deep learning algorithm in distributed training.

    - **EnableManagedSpotTraining** *(boolean) --*

      A Boolean indicating whether managed spot training is enabled (``True`` ) or not (``False``
      ).

    - **CheckpointConfig** *(dict) --*

      Contains information about the output location for managed spot training checkpoint data.

      - **S3Uri** *(string) --*

        Identifies the S3 path where you want Amazon SageMaker to store checkpoints. For example,
        ``s3://bucket-name/key-name-prefix`` .

      - **LocalPath** *(string) --*

        (Optional) The local directory where checkpoints are written. The default directory is
        ``/opt/ml/checkpoints/`` .
    """


_ClientDescribeHyperParameterTuningJobResponseTrainingJobStatusCountersTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseTrainingJobStatusCountersTypeDef",
    {
        "Completed": int,
        "InProgress": int,
        "RetryableError": int,
        "NonRetryableError": int,
        "Stopped": int,
    },
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseTrainingJobStatusCountersTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseTrainingJobStatusCountersTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponse` `TrainingJobStatusCounters`

    The  TrainingJobStatusCounters object that specifies the number of training jobs, categorized
    by status, that this tuning job launched.

    - **Completed** *(integer) --*

      The number of completed training jobs launched by the hyperparameter tuning job.

    - **InProgress** *(integer) --*

      The number of in-progress training jobs launched by a hyperparameter tuning job.

    - **RetryableError** *(integer) --*

      The number of training jobs that failed, but can be retried. A failed training job can be
      retried only if it failed because an internal service error occurred.

    - **NonRetryableError** *(integer) --*

      The number of training jobs that failed and can't be retried. A failed training job can't
      be retried if it failed because a client error occurred.

    - **Stopped** *(integer) --*

      The number of training jobs launched by a hyperparameter tuning job that were manually
      stopped.
    """


_ClientDescribeHyperParameterTuningJobResponseWarmStartConfigParentHyperParameterTuningJobsTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseWarmStartConfigParentHyperParameterTuningJobsTypeDef",
    {"HyperParameterTuningJobName": str},
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseWarmStartConfigParentHyperParameterTuningJobsTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseWarmStartConfigParentHyperParameterTuningJobsTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponseWarmStartConfig` `ParentHyperParameterTuningJobs`

    A previously completed or stopped hyperparameter tuning job to be used as a starting
    point for a new hyperparameter tuning job.

    - **HyperParameterTuningJobName** *(string) --*

      The name of the hyperparameter tuning job to be used as a starting point for a new
      hyperparameter tuning job.
    """


_ClientDescribeHyperParameterTuningJobResponseWarmStartConfigTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseWarmStartConfigTypeDef",
    {
        "ParentHyperParameterTuningJobs": List[
            ClientDescribeHyperParameterTuningJobResponseWarmStartConfigParentHyperParameterTuningJobsTypeDef
        ],
        "WarmStartType": str,
    },
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseWarmStartConfigTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseWarmStartConfigTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJobResponse` `WarmStartConfig`

    The configuration for starting the hyperparameter parameter tuning job using one or more
    previous tuning jobs as a starting point. The results of previous tuning jobs are used to
    inform which combinations of hyperparameters to search over in the new tuning job.

    - **ParentHyperParameterTuningJobs** *(list) --*

      An array of hyperparameter tuning jobs that are used as the starting point for the new
      hyperparameter tuning job. For more information about warm starting a hyperparameter tuning
      job, see `Using a Previous Hyperparameter Tuning Job as a Starting Point
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-warm-start.html>`__
      .

      Hyperparameter tuning jobs created before October 1, 2018 cannot be used as parent jobs for
      warm start tuning jobs.

      - *(dict) --*

        A previously completed or stopped hyperparameter tuning job to be used as a starting
        point for a new hyperparameter tuning job.

        - **HyperParameterTuningJobName** *(string) --*

          The name of the hyperparameter tuning job to be used as a starting point for a new
          hyperparameter tuning job.

    - **WarmStartType** *(string) --*

      Specifies one of the following:

        IDENTICAL_DATA_AND_ALGORITHM

      The new hyperparameter tuning job uses the same input data and training image as the parent
      tuning jobs. You can change the hyperparameter ranges to search and the maximum number of
      training jobs that the hyperparameter tuning job launches. You cannot use a new version of
      the training algorithm, unless the changes in the new version do not affect the algorithm
      itself. For example, changes that improve logging or adding support for a different data
      format are allowed. You can also change hyperparameters from tunable to static, and from
      static to tunable, but the total number of static plus tunable hyperparameters must remain
      the same as it is in all parent jobs. The objective metric for the new tuning job must be
      the same as for all parent jobs.

        TRANSFER_LEARNING

      The new hyperparameter tuning job can include input data, hyperparameter ranges, maximum
      number of concurrent training jobs, and maximum number of training jobs that are different
      than those of its parent hyperparameter tuning jobs. The training image can also be a
      different version from the version used in the parent hyperparameter tuning job. You can
      also change hyperparameters from tunable to static, and from static to tunable, but the
      total number of static plus tunable hyperparameters must remain the same as it is in all
      parent jobs. The objective metric for the new tuning job must be the same as for all parent
      jobs.
    """


_ClientDescribeHyperParameterTuningJobResponseTypeDef = TypedDict(
    "_ClientDescribeHyperParameterTuningJobResponseTypeDef",
    {
        "HyperParameterTuningJobName": str,
        "HyperParameterTuningJobArn": str,
        "HyperParameterTuningJobConfig": ClientDescribeHyperParameterTuningJobResponseHyperParameterTuningJobConfigTypeDef,
        "TrainingJobDefinition": ClientDescribeHyperParameterTuningJobResponseTrainingJobDefinitionTypeDef,
        "HyperParameterTuningJobStatus": str,
        "CreationTime": datetime,
        "HyperParameterTuningEndTime": datetime,
        "LastModifiedTime": datetime,
        "TrainingJobStatusCounters": ClientDescribeHyperParameterTuningJobResponseTrainingJobStatusCountersTypeDef,
        "ObjectiveStatusCounters": ClientDescribeHyperParameterTuningJobResponseObjectiveStatusCountersTypeDef,
        "BestTrainingJob": ClientDescribeHyperParameterTuningJobResponseBestTrainingJobTypeDef,
        "OverallBestTrainingJob": ClientDescribeHyperParameterTuningJobResponseOverallBestTrainingJobTypeDef,
        "WarmStartConfig": ClientDescribeHyperParameterTuningJobResponseWarmStartConfigTypeDef,
        "FailureReason": str,
    },
    total=False,
)


class ClientDescribeHyperParameterTuningJobResponseTypeDef(
    _ClientDescribeHyperParameterTuningJobResponseTypeDef
):
    """
    Type definition for `ClientDescribeHyperParameterTuningJob` `Response`

    - **HyperParameterTuningJobName** *(string) --*

      The name of the tuning job.

    - **HyperParameterTuningJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the tuning job.

    - **HyperParameterTuningJobConfig** *(dict) --*

      The  HyperParameterTuningJobConfig object that specifies the configuration of the tuning job.

      - **Strategy** *(string) --*

        Specifies how hyperparameter tuning chooses the combinations of hyperparameter values to
        use for the training job it launches. To use the Bayesian search stategy, set this to
        ``Bayesian`` . To randomly search, set it to ``Random`` . For information about search
        strategies, see `How Hyperparameter Tuning Works
        <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html>`__
        .

      - **HyperParameterTuningJobObjective** *(dict) --*

        The  HyperParameterTuningJobObjective object that specifies the objective metric for this
        tuning job.

        - **Type** *(string) --*

          Whether to minimize or maximize the objective metric.

        - **MetricName** *(string) --*

          The name of the metric to use for the objective metric.

      - **ResourceLimits** *(dict) --*

        The  ResourceLimits object that specifies the maximum number of training jobs and parallel
        training jobs for this tuning job.

        - **MaxNumberOfTrainingJobs** *(integer) --*

          The maximum number of training jobs that a hyperparameter tuning job can launch.

        - **MaxParallelTrainingJobs** *(integer) --*

          The maximum number of concurrent training jobs that a hyperparameter tuning job can
          launch.

      - **ParameterRanges** *(dict) --*

        The  ParameterRanges object that specifies the ranges of hyperparameters that this tuning
        job searches.

        - **IntegerParameterRanges** *(list) --*

          The array of  IntegerParameterRange objects that specify ranges of integer
          hyperparameters that a hyperparameter tuning job searches.

          - *(dict) --*

            For a hyperparameter of the integer type, specifies the range that a hyperparameter
            tuning job searches.

            - **Name** *(string) --*

              The name of the hyperparameter to search.

            - **MinValue** *(string) --*

              The minimum value of the hyperparameter to search.

            - **MaxValue** *(string) --*

              The maximum value of the hyperparameter to search.

            - **ScalingType** *(string) --*

              The scale that hyperparameter tuning uses to search the hyperparameter range. For
              information about choosing a hyperparameter scale, see `Hyperparameter Scaling
              <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html#scaling-type>`__
              . One of the following values:

                Auto

              Amazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.

                Linear

              Hyperparameter tuning searches the values in the hyperparameter range by using a
              linear scale.

                Logarithmic

              Hyperparameter tuning searches the values in the hyperparameter range by using a
              logarithmic scale.

              Logarithmic scaling works only for ranges that have only values greater than 0.

        - **ContinuousParameterRanges** *(list) --*

          The array of  ContinuousParameterRange objects that specify ranges of continuous
          hyperparameters that a hyperparameter tuning job searches.

          - *(dict) --*

            A list of continuous hyperparameters to tune.

            - **Name** *(string) --*

              The name of the continuous hyperparameter to tune.

            - **MinValue** *(string) --*

              The minimum value for the hyperparameter. The tuning job uses floating-point values
              between this value and ``MaxValue`` for tuning.

            - **MaxValue** *(string) --*

              The maximum value for the hyperparameter. The tuning job uses floating-point values
              between ``MinValue`` value and this value for tuning.

            - **ScalingType** *(string) --*

              The scale that hyperparameter tuning uses to search the hyperparameter range. For
              information about choosing a hyperparameter scale, see `Hyperparameter Scaling
              <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html#scaling-type>`__
              . One of the following values:

                Auto

              Amazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.

                Linear

              Hyperparameter tuning searches the values in the hyperparameter range by using a
              linear scale.

                Logarithmic

              Hyperparameter tuning searches the values in the hyperparameter range by using a
              logarithmic scale.

              Logarithmic scaling works only for ranges that have only values greater than 0.

                ReverseLogarithmic

              Hyperparameter tuning searches the values in the hyperparameter range by using a
              reverse logarithmic scale.

              Reverse logarithmic scaling works only for ranges that are entirely within the range
              0<=x<1.0.

        - **CategoricalParameterRanges** *(list) --*

          The array of  CategoricalParameterRange objects that specify ranges of categorical
          hyperparameters that a hyperparameter tuning job searches.

          - *(dict) --*

            A list of categorical hyperparameters to tune.

            - **Name** *(string) --*

              The name of the categorical hyperparameter to tune.

            - **Values** *(list) --*

              A list of the categories for the hyperparameter.

              - *(string) --*

      - **TrainingJobEarlyStoppingType** *(string) --*

        Specifies whether to use early stopping for training jobs launched by the hyperparameter
        tuning job. This can be one of the following values (the default value is ``OFF`` ):

          OFF

        Training jobs launched by the hyperparameter tuning job do not use early stopping.

          AUTO

        Amazon SageMaker stops training jobs launched by the hyperparameter tuning job when they
        are unlikely to perform better than previously completed training jobs. For more
        information, see `Stop Training Jobs Early
        <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-early-stopping.html>`__
        .

    - **TrainingJobDefinition** *(dict) --*

      The  HyperParameterTrainingJobDefinition object that specifies the definition of the training
      jobs that this tuning job launches.

      - **StaticHyperParameters** *(dict) --*

        Specifies the values of hyperparameters that do not change for the tuning job.

        - *(string) --*

          - *(string) --*

      - **AlgorithmSpecification** *(dict) --*

        The  HyperParameterAlgorithmSpecification object that specifies the resource algorithm to
        use for the training jobs that the tuning job launches.

        - **TrainingImage** *(string) --*

          The registry path of the Docker image that contains the training algorithm. For
          information about Docker registry paths for built-in algorithms, see `Algorithms Provided
          by Amazon SageMaker\\: Common Parameters
          <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
          . Amazon SageMaker supports both ``registry/repository[:tag]`` and
          ``registry/repository[@digest]`` image path formats. For more information, see `Using
          Your Own Algorithms with Amazon SageMaker
          <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

        - **TrainingInputMode** *(string) --*

          The input mode that the algorithm supports: File or Pipe. In File input mode, Amazon
          SageMaker downloads the training data from Amazon S3 to the storage volume that is
          attached to the training instance and mounts the directory to the Docker volume for the
          training container. In Pipe input mode, Amazon SageMaker streams data directly from
          Amazon S3 to the container.

          If you specify File mode, make sure that you provision the storage volume that is
          attached to the training instance with enough capacity to accommodate the training data
          downloaded from Amazon S3, the model artifacts, and intermediate information.

          For more information about input modes, see `Algorithms
          <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ .

        - **AlgorithmName** *(string) --*

          The name of the resource algorithm to use for the hyperparameter tuning job. If you
          specify a value for this parameter, do not specify a value for ``TrainingImage`` .

        - **MetricDefinitions** *(list) --*

          An array of  MetricDefinition objects that specify the metrics that the algorithm emits.

          - *(dict) --*

            Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
            Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
            metric that a hyperparameter tuning job uses as its objective metric to choose the best
            training job.

            - **Name** *(string) --*

              The name of the metric.

            - **Regex** *(string) --*

              A regular expression that searches the output of a training job and gets the value of
              the metric. For more information about using regular expressions to define metrics,
              see `Defining Objective Metrics
              <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
              .

      - **RoleArn** *(string) --*

        The Amazon Resource Name (ARN) of the IAM role associated with the training jobs that the
        tuning job launches.

      - **InputDataConfig** *(list) --*

        An array of  Channel objects that specify the input for the training jobs that the tuning
        job launches.

        - *(dict) --*

          A channel is a named input source that training algorithms can consume.

          - **ChannelName** *(string) --*

            The name of the channel.

          - **DataSource** *(dict) --*

            The location of the channel data.

            - **S3DataSource** *(dict) --*

              The S3 location of the data source that is associated with a channel.

              - **S3DataType** *(string) --*

                If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
                SageMaker uses all objects that match the specified key name prefix for model
                training.

                If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
                file containing a list of object keys that you want Amazon SageMaker to use for
                model training.

                If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
                augmented manifest file in JSON lines format. This file contains the data you want
                to use for model training. ``AugmentedManifestFile`` can only be used if the
                Channel's input mode is ``Pipe`` .

              - **S3Uri** *(string) --*

                Depending on the value specified for the ``S3DataType`` , identifies either a key
                name prefix or a manifest. For example:

                * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

                * A manifest might look like this: ``s3://bucketname/example.manifest``   The
                manifest is an S3 object which is a JSON file with the following format:  The
                preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
                "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
                ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
                ``]``   The preceding JSON matches the following ``s3Uris`` :
                ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
                ``s3uris`` in this manifest is the input data for the channel for this datasource.
                The object that each ``s3uris`` points to must be readable by the IAM role that
                Amazon SageMaker uses to perform tasks on your behalf.

              - **S3DataDistributionType** *(string) --*

                If you want Amazon SageMaker to replicate the entire dataset on each ML compute
                instance that is launched for model training, specify ``FullyReplicated`` .

                If you want Amazon SageMaker to replicate a subset of data on each ML compute
                instance that is launched for model training, specify ``ShardedByS3Key`` . If there
                are *n* ML compute instances launched for a training job, each instance gets
                approximately 1/*n* of the number of S3 objects. In this case, model training on
                each machine uses only the subset of training data.

                Don't choose more ML compute instances for training than available S3 objects. If
                you do, some nodes won't get any data and you will pay for nodes that aren't
                getting any training data. This applies in both File and Pipe modes. Keep this in
                mind when developing algorithms.

                In distributed training, where you use multiple ML compute EC2 instances, you might
                choose ``ShardedByS3Key`` . If the algorithm requires copying training data to the
                ML storage volume (when ``TrainingInputMode`` is set to ``File`` ), this copies
                1/*n* of the number of objects.

              - **AttributeNames** *(list) --*

                A list of one or more attribute names to use that are found in a specified
                augmented manifest file.

                - *(string) --*

            - **FileSystemDataSource** *(dict) --*

              The file system that is associated with a channel.

              - **FileSystemId** *(string) --*

                The file system id.

              - **FileSystemAccessMode** *(string) --*

                The access mode of the mount of the directory associated with the channel. A
                directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

              - **FileSystemType** *(string) --*

                The file system type.

              - **DirectoryPath** *(string) --*

                The full path to the directory to associate with the channel.

          - **ContentType** *(string) --*

            The MIME type of the data.

          - **CompressionType** *(string) --*

            If training data is compressed, the compression type. The default value is ``None`` .
            ``CompressionType`` is used only in Pipe input mode. In File mode, leave this field
            unset or set it to None.

          - **RecordWrapperType** *(string) --*

            Specify RecordIO as the value when input data is in raw format but the training
            algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
            individual S3 object in a RecordIO record. If the input data is already in RecordIO
            format, you don't need to set this attribute. For more information, see `Create a
            Dataset Using RecordIO
            <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
            .

            In File mode, leave this field unset or set it to None.

          - **InputMode** *(string) --*

            (Optional) The input mode to use for the data channel in a training job. If you don't
            set a value for ``InputMode`` , Amazon SageMaker uses the value set for
            ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
            setting in a  AlgorithmSpecification request when you have a channel that needs a
            different input mode from the training job's general setting. To download the data from
            Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage volume, and
            mount the directory to a Docker volume, use ``File`` input mode. To stream data
            directly from Amazon S3 to the container, choose ``Pipe`` input mode.

            To use a model for incremental training, choose ``File`` input model.

          - **ShuffleConfig** *(dict) --*

            A configuration for a shuffle option for input data in a channel. If you use
            ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
            matches. If you use ``ManifestFile`` , the order of the S3 object references in the
            ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of the
            JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
            determined using the ``Seed`` value.

            For Pipe input mode, shuffling is done at the start of every epoch. With large datasets
            this ensures that the order of the training data is different for each epoch, it helps
            reduce bias and possible overfitting. In a multi-node training job when ShuffleConfig
            is combined with ``S3DataDistributionType`` of ``ShardedByS3Key`` , the data is
            shuffled across nodes so that the content sent to a particular node on the first epoch
            might be sent to a different node on the second epoch.

            - **Seed** *(integer) --*

              Determines the shuffling order in ``ShuffleConfig`` value.

      - **VpcConfig** *(dict) --*

        The  VpcConfig object that specifies the VPC that you want the training jobs that this
        hyperparameter tuning job launches to connect to. Control access to and from your training
        container by configuring the VPC. For more information, see `Protect Training Jobs by Using
        an Amazon Virtual Private Cloud
        <https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html>`__ .

        - **SecurityGroupIds** *(list) --*

          The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for the
          VPC that is specified in the ``Subnets`` field.

          - *(string) --*

        - **Subnets** *(list) --*

          The ID of the subnets in the VPC to which you want to connect your training job or model.

          .. note::

            Amazon EC2 P3 accelerated computing instances are not available in the c/d/e
            availability zones of region us-east-1. If you want to create endpoints with P3
            instances in VPC mode in region us-east-1, create subnets in a/b/f availability zones
            instead.

          - *(string) --*

      - **OutputDataConfig** *(dict) --*

        Specifies the path to the Amazon S3 bucket where you store model artifacts from the
        training jobs that the tuning job launches.

        - **KmsKeyId** *(string) --*

          The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
          model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be
          any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // KMS Key Alias  ``"alias/ExampleAlias"``

          * // Amazon Resource Name (ARN) of a KMS Key Alias
          ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

          If you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution
          role must include permissions to call ``kms:Encrypt`` . If you don't provide a KMS key
          ID, Amazon SageMaker uses the default KMS key for Amazon S3 for your role's account.
          Amazon SageMaker uses server-side encryption with KMS-managed keys for
          ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject`` permission
          that only allows objects with server-side encryption, set the condition key of
          ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information, see
          `KMS-Managed Encryption Keys
          <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
          *Amazon Simple Storage Service Developer Guide.*

          The KMS key policy must grant permission to the IAM role that you specify in your
          ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
          requests. For more information, see `Using Key Policies in AWS KMS
          <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
          in the *AWS Key Management Service Developer Guide* .

        - **S3OutputPath** *(string) --*

          Identifies the S3 path where you want Amazon SageMaker to store the model artifacts. For
          example, ``s3://bucket-name/key-name-prefix`` .

      - **ResourceConfig** *(dict) --*

        The resources, including the compute instances and storage volumes, to use for the training
        jobs that the tuning job launches.

        Storage volumes store model artifacts and incremental states. Training algorithms might
        also use storage volumes for scratch space. If you want Amazon SageMaker to use the storage
        volume to store the training data, choose ``File`` as the ``TrainingInputMode`` in the
        algorithm specification. For distributed training algorithms, specify an instance count
        greater than 1.

        - **InstanceType** *(string) --*

          The ML compute instance type.

        - **InstanceCount** *(integer) --*

          The number of ML compute instances to use. For distributed training, provide a value
          greater than 1.

        - **VolumeSizeInGB** *(integer) --*

          The size of the ML storage volume that you want to provision.

          ML storage volumes store model artifacts and incremental states. Training algorithms
          might also use the ML storage volume for scratch space. If you want to store the training
          data in the ML storage volume, choose ``File`` as the ``TrainingInputMode`` in the
          algorithm specification.

          You must specify sufficient ML storage for your scenario.

          .. note::

            Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

          .. note::

            Certain Nitro-based instances include local storage with a fixed total size, dependent
            on the instance type. When using these instances for training, Amazon SageMaker mounts
            the local instance storage instead of Amazon EBS gp2 storage. You can't request a
            ``VolumeSizeInGB`` greater than the total size of the local instance storage.

            For a list of instance types that support local instance storage, including the total
            size per instance type, see `Instance Store Volumes
            <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
            .

        - **VolumeKmsKeyId** *(string) --*

          The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume attached
          to the ML compute instance(s) that run the training job.

          .. note::

            Certain Nitro-based instances include local storage, dependent on the instance type.
            Local storage volumes are encrypted using a hardware module on the instance. You can't
            request a ``VolumeKmsKeyId`` when using an instance type with local storage.

            For a list of instance types that support local instance storage, see `Instance Store
            Volumes
            <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
            .

            For more information about local instance storage encryption, see `SSD Instance Store
            Volumes
            <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

          The ``VolumeKmsKeyId`` can be in any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      - **StoppingCondition** *(dict) --*

        Specifies a limit to how long a model hyperparameter training job can run. It also
        specifies how long you are willing to wait for a managed spot training job to complete.
        When the job reaches the a limit, Amazon SageMaker ends the training job. Use this API to
        cap model training costs.

        - **MaxRuntimeInSeconds** *(integer) --*

          The maximum length of time, in seconds, that the training or compilation job can run. If
          job does not complete during this time, Amazon SageMaker ends the job. If value is not
          specified, default value is 1 day. The maximum value is 28 days.

        - **MaxWaitTimeInSeconds** *(integer) --*

          The maximum length of time, in seconds, how long you are willing to wait for a managed
          spot training job to complete. It is the amount of time spent waiting for Spot capacity
          plus the amount of time the training job runs. It must be equal to or greater than
          ``MaxRuntimeInSeconds`` .

      - **EnableNetworkIsolation** *(boolean) --*

        Isolates the training container. No inbound or outbound network calls can be made, except
        for calls between peers within a training cluster for distributed training. If network
        isolation is used for training jobs that are configured to use a VPC, Amazon SageMaker
        downloads and uploads customer data and model artifacts through the specified VPC, but the
        training container does not have network access.

        .. note::

          The Semantic Segmentation built-in algorithm does not support network isolation.

      - **EnableInterContainerTrafficEncryption** *(boolean) --*

        To encrypt all communications between ML compute instances in distributed training, choose
        ``True`` . Encryption provides greater security for distributed training, but training
        might take longer. How long it takes depends on the amount of communication between compute
        instances, especially if you use a deep learning algorithm in distributed training.

      - **EnableManagedSpotTraining** *(boolean) --*

        A Boolean indicating whether managed spot training is enabled (``True`` ) or not (``False``
        ).

      - **CheckpointConfig** *(dict) --*

        Contains information about the output location for managed spot training checkpoint data.

        - **S3Uri** *(string) --*

          Identifies the S3 path where you want Amazon SageMaker to store checkpoints. For example,
          ``s3://bucket-name/key-name-prefix`` .

        - **LocalPath** *(string) --*

          (Optional) The local directory where checkpoints are written. The default directory is
          ``/opt/ml/checkpoints/`` .

    - **HyperParameterTuningJobStatus** *(string) --*

      The status of the tuning job: InProgress, Completed, Failed, Stopping, or Stopped.

    - **CreationTime** *(datetime) --*

      The date and time that the tuning job started.

    - **HyperParameterTuningEndTime** *(datetime) --*

      The date and time that the tuning job ended.

    - **LastModifiedTime** *(datetime) --*

      The date and time that the status of the tuning job was modified.

    - **TrainingJobStatusCounters** *(dict) --*

      The  TrainingJobStatusCounters object that specifies the number of training jobs, categorized
      by status, that this tuning job launched.

      - **Completed** *(integer) --*

        The number of completed training jobs launched by the hyperparameter tuning job.

      - **InProgress** *(integer) --*

        The number of in-progress training jobs launched by a hyperparameter tuning job.

      - **RetryableError** *(integer) --*

        The number of training jobs that failed, but can be retried. A failed training job can be
        retried only if it failed because an internal service error occurred.

      - **NonRetryableError** *(integer) --*

        The number of training jobs that failed and can't be retried. A failed training job can't
        be retried if it failed because a client error occurred.

      - **Stopped** *(integer) --*

        The number of training jobs launched by a hyperparameter tuning job that were manually
        stopped.

    - **ObjectiveStatusCounters** *(dict) --*

      The  ObjectiveStatusCounters object that specifies the number of training jobs, categorized
      by the status of their final objective metric, that this tuning job launched.

      - **Succeeded** *(integer) --*

        The number of training jobs whose final objective metric was evaluated by the
        hyperparameter tuning job and used in the hyperparameter tuning process.

      - **Pending** *(integer) --*

        The number of training jobs that are in progress and pending evaluation of their final
        objective metric.

      - **Failed** *(integer) --*

        The number of training jobs whose final objective metric was not evaluated and used in the
        hyperparameter tuning process. This typically occurs when the training job failed or did
        not emit an objective metric.

    - **BestTrainingJob** *(dict) --*

      A  TrainingJobSummary object that describes the training job that completed with the best
      current  HyperParameterTuningJobObjective .

      - **TrainingJobName** *(string) --*

        The name of the training job.

      - **TrainingJobArn** *(string) --*

        The Amazon Resource Name (ARN) of the training job.

      - **TuningJobName** *(string) --*

        The HyperParameter tuning job that launched the training job.

      - **CreationTime** *(datetime) --*

        The date and time that the training job was created.

      - **TrainingStartTime** *(datetime) --*

        The date and time that the training job started.

      - **TrainingEndTime** *(datetime) --*

        Specifies the time when the training job ends on training instances. You are billed for the
        time interval between the value of ``TrainingStartTime`` and this time. For successful jobs
        and stopped jobs, this is the time after model artifacts are uploaded. For failed jobs,
        this is the time when Amazon SageMaker detects a job failure.

      - **TrainingJobStatus** *(string) --*

        The status of the training job.

      - **TunedHyperParameters** *(dict) --*

        A list of the hyperparameters for which you specified ranges to search.

        - *(string) --*

          - *(string) --*

      - **FailureReason** *(string) --*

        The reason that the training job failed.

      - **FinalHyperParameterTuningJobObjectiveMetric** *(dict) --*

        The  FinalHyperParameterTuningJobObjectiveMetric object that specifies the value of the
        objective metric of the tuning job that launched this training job.

        - **Type** *(string) --*

          Whether to minimize or maximize the objective metric. Valid values are Minimize and
          Maximize.

        - **MetricName** *(string) --*

          The name of the objective metric.

        - **Value** *(float) --*

          The value of the objective metric.

      - **ObjectiveStatus** *(string) --*

        The status of the objective metric for the training job:

        * Succeeded: The final objective metric for the training job was evaluated by the
        hyperparameter tuning job and used in the hyperparameter tuning process.

        * Pending: The training job is in progress and evaluation of its final objective metric is
        pending.

        * Failed: The final objective metric for the training job was not evaluated, and was not
        used in the hyperparameter tuning process. This typically occurs when the training job
        failed or did not emit an objective metric.

    - **OverallBestTrainingJob** *(dict) --*

      If the hyperparameter tuning job is an warm start tuning job with a ``WarmStartType`` of
      ``IDENTICAL_DATA_AND_ALGORITHM`` , this is the  TrainingJobSummary for the training job with
      the best objective metric value of all training jobs launched by this tuning job and all
      parent jobs specified for the warm start tuning job.

      - **TrainingJobName** *(string) --*

        The name of the training job.

      - **TrainingJobArn** *(string) --*

        The Amazon Resource Name (ARN) of the training job.

      - **TuningJobName** *(string) --*

        The HyperParameter tuning job that launched the training job.

      - **CreationTime** *(datetime) --*

        The date and time that the training job was created.

      - **TrainingStartTime** *(datetime) --*

        The date and time that the training job started.

      - **TrainingEndTime** *(datetime) --*

        Specifies the time when the training job ends on training instances. You are billed for the
        time interval between the value of ``TrainingStartTime`` and this time. For successful jobs
        and stopped jobs, this is the time after model artifacts are uploaded. For failed jobs,
        this is the time when Amazon SageMaker detects a job failure.

      - **TrainingJobStatus** *(string) --*

        The status of the training job.

      - **TunedHyperParameters** *(dict) --*

        A list of the hyperparameters for which you specified ranges to search.

        - *(string) --*

          - *(string) --*

      - **FailureReason** *(string) --*

        The reason that the training job failed.

      - **FinalHyperParameterTuningJobObjectiveMetric** *(dict) --*

        The  FinalHyperParameterTuningJobObjectiveMetric object that specifies the value of the
        objective metric of the tuning job that launched this training job.

        - **Type** *(string) --*

          Whether to minimize or maximize the objective metric. Valid values are Minimize and
          Maximize.

        - **MetricName** *(string) --*

          The name of the objective metric.

        - **Value** *(float) --*

          The value of the objective metric.

      - **ObjectiveStatus** *(string) --*

        The status of the objective metric for the training job:

        * Succeeded: The final objective metric for the training job was evaluated by the
        hyperparameter tuning job and used in the hyperparameter tuning process.

        * Pending: The training job is in progress and evaluation of its final objective metric is
        pending.

        * Failed: The final objective metric for the training job was not evaluated, and was not
        used in the hyperparameter tuning process. This typically occurs when the training job
        failed or did not emit an objective metric.

    - **WarmStartConfig** *(dict) --*

      The configuration for starting the hyperparameter parameter tuning job using one or more
      previous tuning jobs as a starting point. The results of previous tuning jobs are used to
      inform which combinations of hyperparameters to search over in the new tuning job.

      - **ParentHyperParameterTuningJobs** *(list) --*

        An array of hyperparameter tuning jobs that are used as the starting point for the new
        hyperparameter tuning job. For more information about warm starting a hyperparameter tuning
        job, see `Using a Previous Hyperparameter Tuning Job as a Starting Point
        <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-warm-start.html>`__
        .

        Hyperparameter tuning jobs created before October 1, 2018 cannot be used as parent jobs for
        warm start tuning jobs.

        - *(dict) --*

          A previously completed or stopped hyperparameter tuning job to be used as a starting
          point for a new hyperparameter tuning job.

          - **HyperParameterTuningJobName** *(string) --*

            The name of the hyperparameter tuning job to be used as a starting point for a new
            hyperparameter tuning job.

      - **WarmStartType** *(string) --*

        Specifies one of the following:

          IDENTICAL_DATA_AND_ALGORITHM

        The new hyperparameter tuning job uses the same input data and training image as the parent
        tuning jobs. You can change the hyperparameter ranges to search and the maximum number of
        training jobs that the hyperparameter tuning job launches. You cannot use a new version of
        the training algorithm, unless the changes in the new version do not affect the algorithm
        itself. For example, changes that improve logging or adding support for a different data
        format are allowed. You can also change hyperparameters from tunable to static, and from
        static to tunable, but the total number of static plus tunable hyperparameters must remain
        the same as it is in all parent jobs. The objective metric for the new tuning job must be
        the same as for all parent jobs.

          TRANSFER_LEARNING

        The new hyperparameter tuning job can include input data, hyperparameter ranges, maximum
        number of concurrent training jobs, and maximum number of training jobs that are different
        than those of its parent hyperparameter tuning jobs. The training image can also be a
        different version from the version used in the parent hyperparameter tuning job. You can
        also change hyperparameters from tunable to static, and from static to tunable, but the
        total number of static plus tunable hyperparameters must remain the same as it is in all
        parent jobs. The objective metric for the new tuning job must be the same as for all parent
        jobs.

    - **FailureReason** *(string) --*

      If the tuning job failed, the reason it failed.
    """


_ClientDescribeLabelingJobResponseHumanTaskConfigAnnotationConsolidationConfigTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseHumanTaskConfigAnnotationConsolidationConfigTypeDef",
    {"AnnotationConsolidationLambdaArn": str},
    total=False,
)


class ClientDescribeLabelingJobResponseHumanTaskConfigAnnotationConsolidationConfigTypeDef(
    _ClientDescribeLabelingJobResponseHumanTaskConfigAnnotationConsolidationConfigTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJobResponseHumanTaskConfig` `AnnotationConsolidationConfig`

    Configures how labels are consolidated across human workers.

    - **AnnotationConsolidationLambdaArn** *(string) --*

      The Amazon Resource Name (ARN) of a Lambda function implements the logic for annotation
      consolidation.

      For the built-in bounding box, image classification, semantic segmentation, and text
      classification task types, Amazon SageMaker Ground Truth provides the following Lambda
      functions:

      * *Bounding box* - Finds the most similar boxes from different workers based on the
      Jaccard index of the boxes.
      ``arn:aws:lambda:us-east-1:432418664414:function:ACS-BoundingBox``
      ``arn:aws:lambda:us-east-2:266458841044:function:ACS-BoundingBox``
      ``arn:aws:lambda:us-west-2:081040173940:function:ACS-BoundingBox``
      ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-BoundingBox``
      ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-BoundingBox``
      ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-BoundingBox``
      ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-BoundingBox``
      ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-BoundingBox``
      ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-BoundingBox``
      ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-BoundingBox``
      ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-BoundingBox``
      ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-BoundingBox``

      * *Image classification* - Uses a variant of the Expectation Maximization approach to
      estimate the true class of an image based on annotations from individual workers.
      ``arn:aws:lambda:us-east-1:432418664414:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:us-east-2:266458841044:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:us-west-2:081040173940:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-ImageMultiClass``
      ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-ImageMultiClass``

      * *Semantic segmentation* - Treats each pixel in an image as a multi-class classification
      and treats pixel annotations from workers as "votes" for the correct label.
      ``arn:aws:lambda:us-east-1:432418664414:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:us-east-2:266458841044:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:us-west-2:081040173940:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-SemanticSegmentation``
      ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-SemanticSegmentation``

      * *Text classification* - Uses a variant of the Expectation Maximization approach to
      estimate the true class of text based on annotations from individual workers.
      ``arn:aws:lambda:us-east-1:432418664414:function:ACS-TextMultiClass``
      ``arn:aws:lambda:us-east-2:266458841044:function:ACS-TextMultiClass``
      ``arn:aws:lambda:us-west-2:081040173940:function:ACS-TextMultiClass``
      ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-TextMultiClass``
      ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-TextMultiClass``
      ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-TextMultiClass``
      ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-TextMultiClass``
      ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-TextMultiClass``
      ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-TextMultiClass``
      ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-TextMultiClass``
      ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-TextMultiClass``
      ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-TextMultiClass``

      * *Named entity eecognition* - Groups similar selections and calculates aggregate
      boundaries, resolving to most-assigned label.
      ``arn:aws:lambda:us-east-1:432418664414:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:us-east-2:266458841044:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:us-west-2:081040173940:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-NamedEntityRecognition``
      ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-NamedEntityRecognition``

      For more information, see `Annotation Consolidation
      <https://docs.aws.amazon.com/sagemaker/latest/dg/sms-annotation-consolidation.html>`__ .
    """


_ClientDescribeLabelingJobResponseHumanTaskConfigPublicWorkforceTaskPriceAmountInUsdTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseHumanTaskConfigPublicWorkforceTaskPriceAmountInUsdTypeDef",
    {"Dollars": int, "Cents": int, "TenthFractionsOfACent": int},
    total=False,
)


class ClientDescribeLabelingJobResponseHumanTaskConfigPublicWorkforceTaskPriceAmountInUsdTypeDef(
    _ClientDescribeLabelingJobResponseHumanTaskConfigPublicWorkforceTaskPriceAmountInUsdTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJobResponseHumanTaskConfigPublicWorkforceTaskPrice` `AmountInUsd`

    Defines the amount of money paid to an Amazon Mechanical Turk worker in United States
    dollars.

    - **Dollars** *(integer) --*

      The whole number of dollars in the amount.

    - **Cents** *(integer) --*

      The fractional portion, in cents, of the amount.

    - **TenthFractionsOfACent** *(integer) --*

      Fractions of a cent, in tenths.
    """


_ClientDescribeLabelingJobResponseHumanTaskConfigPublicWorkforceTaskPriceTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseHumanTaskConfigPublicWorkforceTaskPriceTypeDef",
    {
        "AmountInUsd": ClientDescribeLabelingJobResponseHumanTaskConfigPublicWorkforceTaskPriceAmountInUsdTypeDef
    },
    total=False,
)


class ClientDescribeLabelingJobResponseHumanTaskConfigPublicWorkforceTaskPriceTypeDef(
    _ClientDescribeLabelingJobResponseHumanTaskConfigPublicWorkforceTaskPriceTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJobResponseHumanTaskConfig` `PublicWorkforceTaskPrice`

    The price that you pay for each task performed by an Amazon Mechanical Turk worker.

    - **AmountInUsd** *(dict) --*

      Defines the amount of money paid to an Amazon Mechanical Turk worker in United States
      dollars.

      - **Dollars** *(integer) --*

        The whole number of dollars in the amount.

      - **Cents** *(integer) --*

        The fractional portion, in cents, of the amount.

      - **TenthFractionsOfACent** *(integer) --*

        Fractions of a cent, in tenths.
    """


_ClientDescribeLabelingJobResponseHumanTaskConfigUiConfigTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseHumanTaskConfigUiConfigTypeDef",
    {"UiTemplateS3Uri": str},
    total=False,
)


class ClientDescribeLabelingJobResponseHumanTaskConfigUiConfigTypeDef(
    _ClientDescribeLabelingJobResponseHumanTaskConfigUiConfigTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJobResponseHumanTaskConfig` `UiConfig`

    Information about the user interface that workers use to complete the labeling task.

    - **UiTemplateS3Uri** *(string) --*

      The Amazon S3 bucket location of the UI template. For more information about the contents
      of a UI template, see `Creating Your Custom Labeling Task Template
      <https://docs.aws.amazon.com/sagemaker/latest/dg/sms-custom-templates-step2.html>`__ .
    """


_ClientDescribeLabelingJobResponseHumanTaskConfigTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseHumanTaskConfigTypeDef",
    {
        "WorkteamArn": str,
        "UiConfig": ClientDescribeLabelingJobResponseHumanTaskConfigUiConfigTypeDef,
        "PreHumanTaskLambdaArn": str,
        "TaskKeywords": List[str],
        "TaskTitle": str,
        "TaskDescription": str,
        "NumberOfHumanWorkersPerDataObject": int,
        "TaskTimeLimitInSeconds": int,
        "TaskAvailabilityLifetimeInSeconds": int,
        "MaxConcurrentTaskCount": int,
        "AnnotationConsolidationConfig": ClientDescribeLabelingJobResponseHumanTaskConfigAnnotationConsolidationConfigTypeDef,
        "PublicWorkforceTaskPrice": ClientDescribeLabelingJobResponseHumanTaskConfigPublicWorkforceTaskPriceTypeDef,
    },
    total=False,
)


class ClientDescribeLabelingJobResponseHumanTaskConfigTypeDef(
    _ClientDescribeLabelingJobResponseHumanTaskConfigTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJobResponse` `HumanTaskConfig`

    Configuration information required for human workers to complete a labeling task.

    - **WorkteamArn** *(string) --*

      The Amazon Resource Name (ARN) of the work team assigned to complete the tasks.

    - **UiConfig** *(dict) --*

      Information about the user interface that workers use to complete the labeling task.

      - **UiTemplateS3Uri** *(string) --*

        The Amazon S3 bucket location of the UI template. For more information about the contents
        of a UI template, see `Creating Your Custom Labeling Task Template
        <https://docs.aws.amazon.com/sagemaker/latest/dg/sms-custom-templates-step2.html>`__ .

    - **PreHumanTaskLambdaArn** *(string) --*

      The Amazon Resource Name (ARN) of a Lambda function that is run before a data object is
      sent to a human worker. Use this function to provide input to a custom labeling job.

      For the built-in bounding box, image classification, semantic segmentation, and text
      classification task types, Amazon SageMaker Ground Truth provides the following Lambda
      functions:

       **US East (Northern Virginia) (us-east-1):**

      * ``arn:aws:lambda:us-east-1:432418664414:function:PRE-BoundingBox``

      * ``arn:aws:lambda:us-east-1:432418664414:function:PRE-ImageMultiClass``

      * ``arn:aws:lambda:us-east-1:432418664414:function:PRE-SemanticSegmentation``

      * ``arn:aws:lambda:us-east-1:432418664414:function:PRE-TextMultiClass``

      * ``arn:aws:lambda:us-east-1:432418664414:function:PRE-NamedEntityRecognition``

       **US East (Ohio) (us-east-2):**

      * ``arn:aws:lambda:us-east-2:266458841044:function:PRE-BoundingBox``

      * ``arn:aws:lambda:us-east-2:266458841044:function:PRE-ImageMultiClass``

      * ``arn:aws:lambda:us-east-2:266458841044:function:PRE-SemanticSegmentation``

      * ``arn:aws:lambda:us-east-2:266458841044:function:PRE-TextMultiClass``

      * ``arn:aws:lambda:us-east-2:266458841044:function:PRE-NamedEntityRecognition``

       **US West (Oregon) (us-west-2):**

      * ``arn:aws:lambda:us-west-2:081040173940:function:PRE-BoundingBox``

      * ``arn:aws:lambda:us-west-2:081040173940:function:PRE-ImageMultiClass``

      * ``arn:aws:lambda:us-west-2:081040173940:function:PRE-SemanticSegmentation``

      * ``arn:aws:lambda:us-west-2:081040173940:function:PRE-TextMultiClass``

      * ``arn:aws:lambda:us-west-2:081040173940:function:PRE-NamedEntityRecognition``

       **Canada (Central) (ca-central-1):**

      * ``arn:awslambda:ca-central-1:918755190332:function:PRE-BoundingBox``

      * ``arn:awslambda:ca-central-1:918755190332:function:PRE-ImageMultiClass``

      * ``arn:awslambda:ca-central-1:918755190332:function:PRE-SemanticSegmentation``

      * ``arn:awslambda:ca-central-1:918755190332:function:PRE-TextMultiClass``

      * ``arn:awslambda:ca-central-1:918755190332:function:PRE-NamedEntityRecognition``

       **EU (Ireland) (eu-west-1):**

      * ``arn:aws:lambda:eu-west-1:568282634449:function:PRE-BoundingBox``

      * ``arn:aws:lambda:eu-west-1:568282634449:function:PRE-ImageMultiClass``

      * ``arn:aws:lambda:eu-west-1:568282634449:function:PRE-SemanticSegmentation``

      * ``arn:aws:lambda:eu-west-1:568282634449:function:PRE-TextMultiClass``

      * ``arn:aws:lambda:eu-west-1:568282634449:function:PRE-NamedEntityRecognition``

       **EU (London) (eu-west-2):**

      * ``arn:awslambda:eu-west-2:487402164563:function:PRE-BoundingBox``

      * ``arn:awslambda:eu-west-2:487402164563:function:PRE-ImageMultiClass``

      * ``arn:awslambda:eu-west-2:487402164563:function:PRE-SemanticSegmentation``

      * ``arn:awslambda:eu-west-2:487402164563:function:PRE-TextMultiClass``

      * ``arn:awslambda:eu-west-2:487402164563:function:PRE-NamedEntityRecognition``

       **EU Frankfurt (eu-central-1):**

      * ``arn:awslambda:eu-central-1:203001061592:function:PRE-BoundingBox``

      * ``arn:awslambda:eu-central-1:203001061592:function:PRE-ImageMultiClass``

      * ``arn:awslambda:eu-central-1:203001061592:function:PRE-SemanticSegmentation``

      * ``arn:awslambda:eu-central-1:203001061592:function:PRE-TextMultiClass``

      * ``arn:awslambda:eu-central-1:203001061592:function:PRE-NamedEntityRecognition``

       **Asia Pacific (Tokyo) (ap-northeast-1):**

      * ``arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-BoundingBox``

      * ``arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-ImageMultiClass``

      * ``arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-SemanticSegmentation``

      * ``arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-TextMultiClass``

      * ``arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-NamedEntityRecognition``

       **Asia Pacific (Seoul) (ap-northeast-2):**

      * ``arn:awslambda:ap-northeast-2:845288260483:function:PRE-BoundingBox``

      * ``arn:awslambda:ap-northeast-2:845288260483:function:PRE-ImageMultiClass``

      * ``arn:awslambda:ap-northeast-2:845288260483:function:PRE-SemanticSegmentation``

      * ``arn:awslambda:ap-northeast-2:845288260483:function:PRE-TextMultiClass``

      * ``arn:awslambda:ap-northeast-2:845288260483:function:PRE-NamedEntityRecognition``

       **Asia Pacific (Mumbai) (ap-south-1):**

      * ``arn:awslambda:ap-south-1:565803892007:function:PRE-BoundingBox``

      * ``arn:awslambda:ap-south-1:565803892007:function:PRE-ImageMultiClass``

      * ``arn:awslambda:ap-south-1:565803892007:function:PRE-SemanticSegmentation``

      * ``arn:awslambda:ap-south-1:565803892007:function:PRE-TextMultiClass``

      * ``arn:awslambda:ap-south-1:565803892007:function:PRE-NamedEntityRecognition``

       **Asia Pacific (Singapore) (ap-southeast-1):**

      * ``arn:awslambda:ap-southeast-1:377565633583:function:PRE-BoundingBox``

      * ``arn:awslambda:ap-southeast-1:377565633583:function:PRE-ImageMultiClass``

      * ``arn:awslambda:ap-southeast-1:377565633583:function:PRE-SemanticSegmentation``

      * ``arn:awslambda:ap-southeast-1:377565633583:function:PRE-TextMultiClass``

      * ``arn:awslambda:ap-southeast-1:377565633583:function:PRE-NamedEntityRecognition``

       **Asia Pacific (Sydney) (ap-southeast-2):**

      * ``arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-BoundingBox``

      * ``arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-ImageMultiClass``

      * ``arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-SemanticSegmentation``

      * ``arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-TextMultiClass``

      * ``arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-NamedEntityRecognition``

    - **TaskKeywords** *(list) --*

      Keywords used to describe the task so that workers on Amazon Mechanical Turk can discover
      the task.

      - *(string) --*

    - **TaskTitle** *(string) --*

      A title for the task for your human workers.

    - **TaskDescription** *(string) --*

      A description of the task for your human workers.

    - **NumberOfHumanWorkersPerDataObject** *(integer) --*

      The number of human workers that will label an object.

    - **TaskTimeLimitInSeconds** *(integer) --*

      The amount of time that a worker has to complete a task.

    - **TaskAvailabilityLifetimeInSeconds** *(integer) --*

      The length of time that a task remains available for labeling by human workers. **If you
      choose the Amazon Mechanical Turk workforce, the maximum is 12 hours (43200)** . For
      private and vendor workforces, the maximum is as listed.

    - **MaxConcurrentTaskCount** *(integer) --*

      Defines the maximum number of data objects that can be labeled by human workers at the same
      time. Each object may have more than one worker at one time.

    - **AnnotationConsolidationConfig** *(dict) --*

      Configures how labels are consolidated across human workers.

      - **AnnotationConsolidationLambdaArn** *(string) --*

        The Amazon Resource Name (ARN) of a Lambda function implements the logic for annotation
        consolidation.

        For the built-in bounding box, image classification, semantic segmentation, and text
        classification task types, Amazon SageMaker Ground Truth provides the following Lambda
        functions:

        * *Bounding box* - Finds the most similar boxes from different workers based on the
        Jaccard index of the boxes.
        ``arn:aws:lambda:us-east-1:432418664414:function:ACS-BoundingBox``
        ``arn:aws:lambda:us-east-2:266458841044:function:ACS-BoundingBox``
        ``arn:aws:lambda:us-west-2:081040173940:function:ACS-BoundingBox``
        ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-BoundingBox``
        ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-BoundingBox``
        ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-BoundingBox``
        ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-BoundingBox``
        ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-BoundingBox``
        ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-BoundingBox``
        ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-BoundingBox``
        ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-BoundingBox``
        ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-BoundingBox``

        * *Image classification* - Uses a variant of the Expectation Maximization approach to
        estimate the true class of an image based on annotations from individual workers.
        ``arn:aws:lambda:us-east-1:432418664414:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:us-east-2:266458841044:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:us-west-2:081040173940:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-ImageMultiClass``
        ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-ImageMultiClass``

        * *Semantic segmentation* - Treats each pixel in an image as a multi-class classification
        and treats pixel annotations from workers as "votes" for the correct label.
        ``arn:aws:lambda:us-east-1:432418664414:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:us-east-2:266458841044:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:us-west-2:081040173940:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-SemanticSegmentation``
        ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-SemanticSegmentation``

        * *Text classification* - Uses a variant of the Expectation Maximization approach to
        estimate the true class of text based on annotations from individual workers.
        ``arn:aws:lambda:us-east-1:432418664414:function:ACS-TextMultiClass``
        ``arn:aws:lambda:us-east-2:266458841044:function:ACS-TextMultiClass``
        ``arn:aws:lambda:us-west-2:081040173940:function:ACS-TextMultiClass``
        ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-TextMultiClass``
        ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-TextMultiClass``
        ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-TextMultiClass``
        ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-TextMultiClass``
        ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-TextMultiClass``
        ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-TextMultiClass``
        ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-TextMultiClass``
        ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-TextMultiClass``
        ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-TextMultiClass``

        * *Named entity eecognition* - Groups similar selections and calculates aggregate
        boundaries, resolving to most-assigned label.
        ``arn:aws:lambda:us-east-1:432418664414:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:us-east-2:266458841044:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:us-west-2:081040173940:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-NamedEntityRecognition``
        ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-NamedEntityRecognition``

        For more information, see `Annotation Consolidation
        <https://docs.aws.amazon.com/sagemaker/latest/dg/sms-annotation-consolidation.html>`__ .

    - **PublicWorkforceTaskPrice** *(dict) --*

      The price that you pay for each task performed by an Amazon Mechanical Turk worker.

      - **AmountInUsd** *(dict) --*

        Defines the amount of money paid to an Amazon Mechanical Turk worker in United States
        dollars.

        - **Dollars** *(integer) --*

          The whole number of dollars in the amount.

        - **Cents** *(integer) --*

          The fractional portion, in cents, of the amount.

        - **TenthFractionsOfACent** *(integer) --*

          Fractions of a cent, in tenths.
    """


_ClientDescribeLabelingJobResponseInputConfigDataAttributesTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseInputConfigDataAttributesTypeDef",
    {"ContentClassifiers": List[str]},
    total=False,
)


class ClientDescribeLabelingJobResponseInputConfigDataAttributesTypeDef(
    _ClientDescribeLabelingJobResponseInputConfigDataAttributesTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJobResponseInputConfig` `DataAttributes`

    Attributes of the data specified by the customer.

    - **ContentClassifiers** *(list) --*

      Declares that your content is free of personally identifiable information or adult
      content. Amazon SageMaker may restrict the Amazon Mechanical Turk workers that can view
      your task based on this information.

      - *(string) --*
    """


_ClientDescribeLabelingJobResponseInputConfigDataSourceS3DataSourceTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseInputConfigDataSourceS3DataSourceTypeDef",
    {"ManifestS3Uri": str},
    total=False,
)


class ClientDescribeLabelingJobResponseInputConfigDataSourceS3DataSourceTypeDef(
    _ClientDescribeLabelingJobResponseInputConfigDataSourceS3DataSourceTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJobResponseInputConfigDataSource` `S3DataSource`

    The Amazon S3 location of the input data objects.

    - **ManifestS3Uri** *(string) --*

      The Amazon S3 location of the manifest file that describes the input data objects.
    """


_ClientDescribeLabelingJobResponseInputConfigDataSourceTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseInputConfigDataSourceTypeDef",
    {
        "S3DataSource": ClientDescribeLabelingJobResponseInputConfigDataSourceS3DataSourceTypeDef
    },
    total=False,
)


class ClientDescribeLabelingJobResponseInputConfigDataSourceTypeDef(
    _ClientDescribeLabelingJobResponseInputConfigDataSourceTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJobResponseInputConfig` `DataSource`

    The location of the input data.

    - **S3DataSource** *(dict) --*

      The Amazon S3 location of the input data objects.

      - **ManifestS3Uri** *(string) --*

        The Amazon S3 location of the manifest file that describes the input data objects.
    """


_ClientDescribeLabelingJobResponseInputConfigTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseInputConfigTypeDef",
    {
        "DataSource": ClientDescribeLabelingJobResponseInputConfigDataSourceTypeDef,
        "DataAttributes": ClientDescribeLabelingJobResponseInputConfigDataAttributesTypeDef,
    },
    total=False,
)


class ClientDescribeLabelingJobResponseInputConfigTypeDef(
    _ClientDescribeLabelingJobResponseInputConfigTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJobResponse` `InputConfig`

    Input configuration information for the labeling job, such as the Amazon S3 location of the
    data objects and the location of the manifest file that describes the data objects.

    - **DataSource** *(dict) --*

      The location of the input data.

      - **S3DataSource** *(dict) --*

        The Amazon S3 location of the input data objects.

        - **ManifestS3Uri** *(string) --*

          The Amazon S3 location of the manifest file that describes the input data objects.

    - **DataAttributes** *(dict) --*

      Attributes of the data specified by the customer.

      - **ContentClassifiers** *(list) --*

        Declares that your content is free of personally identifiable information or adult
        content. Amazon SageMaker may restrict the Amazon Mechanical Turk workers that can view
        your task based on this information.

        - *(string) --*
    """


_ClientDescribeLabelingJobResponseLabelCountersTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseLabelCountersTypeDef",
    {
        "TotalLabeled": int,
        "HumanLabeled": int,
        "MachineLabeled": int,
        "FailedNonRetryableError": int,
        "Unlabeled": int,
    },
    total=False,
)


class ClientDescribeLabelingJobResponseLabelCountersTypeDef(
    _ClientDescribeLabelingJobResponseLabelCountersTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJobResponse` `LabelCounters`

    Provides a breakdown of the number of data objects labeled by humans, the number of objects
    labeled by machine, the number of objects than couldn't be labeled, and the total number of
    objects labeled.

    - **TotalLabeled** *(integer) --*

      The total number of objects labeled.

    - **HumanLabeled** *(integer) --*

      The total number of objects labeled by a human worker.

    - **MachineLabeled** *(integer) --*

      The total number of objects labeled by automated data labeling.

    - **FailedNonRetryableError** *(integer) --*

      The total number of objects that could not be labeled due to an error.

    - **Unlabeled** *(integer) --*

      The total number of objects not yet labeled.
    """


_ClientDescribeLabelingJobResponseLabelingJobAlgorithmsConfigLabelingJobResourceConfigTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseLabelingJobAlgorithmsConfigLabelingJobResourceConfigTypeDef",
    {"VolumeKmsKeyId": str},
    total=False,
)


class ClientDescribeLabelingJobResponseLabelingJobAlgorithmsConfigLabelingJobResourceConfigTypeDef(
    _ClientDescribeLabelingJobResponseLabelingJobAlgorithmsConfigLabelingJobResourceConfigTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJobResponseLabelingJobAlgorithmsConfig` `LabelingJobResourceConfig`

    Provides configuration information for a labeling job.

    - **VolumeKmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data
      on the storage volume attached to the ML compute instance(s) that run the training job.
      The ``VolumeKmsKeyId`` can be any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientDescribeLabelingJobResponseLabelingJobAlgorithmsConfigTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseLabelingJobAlgorithmsConfigTypeDef",
    {
        "LabelingJobAlgorithmSpecificationArn": str,
        "InitialActiveLearningModelArn": str,
        "LabelingJobResourceConfig": ClientDescribeLabelingJobResponseLabelingJobAlgorithmsConfigLabelingJobResourceConfigTypeDef,
    },
    total=False,
)


class ClientDescribeLabelingJobResponseLabelingJobAlgorithmsConfigTypeDef(
    _ClientDescribeLabelingJobResponseLabelingJobAlgorithmsConfigTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJobResponse` `LabelingJobAlgorithmsConfig`

    Configuration information for automated data labeling.

    - **LabelingJobAlgorithmSpecificationArn** *(string) --*

      Specifies the Amazon Resource Name (ARN) of the algorithm used for auto-labeling. You must
      select one of the following ARNs:

      * *Image classification*    ``arn:aws:sagemaker:*region*
      :027400017018:labeling-job-algorithm-specification/image-classification``

      * *Text classification*    ``arn:aws:sagemaker:*region*
      :027400017018:labeling-job-algorithm-specification/text-classification``

      * *Object detection*    ``arn:aws:sagemaker:*region*
      :027400017018:labeling-job-algorithm-specification/object-detection``

      * *Semantic Segmentation*    ``arn:aws:sagemaker:*region*
      :027400017018:labeling-job-algorithm-specification/semantic-segmentation``

    - **InitialActiveLearningModelArn** *(string) --*

      At the end of an auto-label job Amazon SageMaker Ground Truth sends the Amazon Resource Nam
      (ARN) of the final model used for auto-labeling. You can use this model as the starting
      point for subsequent similar jobs by providing the ARN of the model here.

    - **LabelingJobResourceConfig** *(dict) --*

      Provides configuration information for a labeling job.

      - **VolumeKmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data
        on the storage volume attached to the ML compute instance(s) that run the training job.
        The ``VolumeKmsKeyId`` can be any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientDescribeLabelingJobResponseLabelingJobOutputTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseLabelingJobOutputTypeDef",
    {"OutputDatasetS3Uri": str, "FinalActiveLearningModelArn": str},
    total=False,
)


class ClientDescribeLabelingJobResponseLabelingJobOutputTypeDef(
    _ClientDescribeLabelingJobResponseLabelingJobOutputTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJobResponse` `LabelingJobOutput`

    The location of the output produced by the labeling job.

    - **OutputDatasetS3Uri** *(string) --*

      The Amazon S3 bucket location of the manifest file for labeled data.

    - **FinalActiveLearningModelArn** *(string) --*

      The Amazon Resource Name (ARN) for the most recent Amazon SageMaker model trained as part
      of automated data labeling.
    """


_ClientDescribeLabelingJobResponseOutputConfigTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseOutputConfigTypeDef",
    {"S3OutputPath": str, "KmsKeyId": str},
    total=False,
)


class ClientDescribeLabelingJobResponseOutputConfigTypeDef(
    _ClientDescribeLabelingJobResponseOutputConfigTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJobResponse` `OutputConfig`

    The location of the job's output data and the AWS Key Management Service key ID for the key
    used to encrypt the output data, if any.

    - **S3OutputPath** *(string) --*

      The Amazon S3 location to write output data.

    - **KmsKeyId** *(string) --*

      The AWS Key Management Service ID of the key used to encrypt the output data, if any.

      If you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution role
      must include permissions to call ``kms:Encrypt`` . If you don't provide a KMS key ID,
      Amazon SageMaker uses the default KMS key for Amazon S3 for your role's account. Amazon
      SageMaker uses server-side encryption with KMS-managed keys for ``LabelingJobOutputConfig``
      . If you use a bucket policy with an ``s3:PutObject`` permission that only allows objects
      with server-side encryption, set the condition key of ``s3:x-amz-server-side-encryption``
      to ``"aws:kms"`` . For more information, see `KMS-Managed Encryption Keys
      <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the *Amazon
      Simple Storage Service Developer Guide.*

      The KMS key policy must grant permission to the IAM role that you specify in your
      ``CreateLabelingJob`` request. For more information, see `Using Key Policies in AWS KMS
      <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the *AWS Key
      Management Service Developer Guide* .
    """


_ClientDescribeLabelingJobResponseStoppingConditionsTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseStoppingConditionsTypeDef",
    {"MaxHumanLabeledObjectCount": int, "MaxPercentageOfInputDatasetLabeled": int},
    total=False,
)


class ClientDescribeLabelingJobResponseStoppingConditionsTypeDef(
    _ClientDescribeLabelingJobResponseStoppingConditionsTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJobResponse` `StoppingConditions`

    A set of conditions for stopping a labeling job. If any of the conditions are met, the job is
    automatically stopped.

    - **MaxHumanLabeledObjectCount** *(integer) --*

      The maximum number of objects that can be labeled by human workers.

    - **MaxPercentageOfInputDatasetLabeled** *(integer) --*

      The maximum number of input data objects that should be labeled.
    """


_ClientDescribeLabelingJobResponseTagsTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseTagsTypeDef",
    {"Key": str, "Value": str},
    total=False,
)


class ClientDescribeLabelingJobResponseTagsTypeDef(
    _ClientDescribeLabelingJobResponseTagsTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJobResponse` `Tags`

    Describes a tag.

    - **Key** *(string) --*

      The tag key.

    - **Value** *(string) --*

      The tag value.
    """


_ClientDescribeLabelingJobResponseTypeDef = TypedDict(
    "_ClientDescribeLabelingJobResponseTypeDef",
    {
        "LabelingJobStatus": str,
        "LabelCounters": ClientDescribeLabelingJobResponseLabelCountersTypeDef,
        "FailureReason": str,
        "CreationTime": datetime,
        "LastModifiedTime": datetime,
        "JobReferenceCode": str,
        "LabelingJobName": str,
        "LabelingJobArn": str,
        "LabelAttributeName": str,
        "InputConfig": ClientDescribeLabelingJobResponseInputConfigTypeDef,
        "OutputConfig": ClientDescribeLabelingJobResponseOutputConfigTypeDef,
        "RoleArn": str,
        "LabelCategoryConfigS3Uri": str,
        "StoppingConditions": ClientDescribeLabelingJobResponseStoppingConditionsTypeDef,
        "LabelingJobAlgorithmsConfig": ClientDescribeLabelingJobResponseLabelingJobAlgorithmsConfigTypeDef,
        "HumanTaskConfig": ClientDescribeLabelingJobResponseHumanTaskConfigTypeDef,
        "Tags": List[ClientDescribeLabelingJobResponseTagsTypeDef],
        "LabelingJobOutput": ClientDescribeLabelingJobResponseLabelingJobOutputTypeDef,
    },
    total=False,
)


class ClientDescribeLabelingJobResponseTypeDef(
    _ClientDescribeLabelingJobResponseTypeDef
):
    """
    Type definition for `ClientDescribeLabelingJob` `Response`

    - **LabelingJobStatus** *(string) --*

      The processing status of the labeling job.

    - **LabelCounters** *(dict) --*

      Provides a breakdown of the number of data objects labeled by humans, the number of objects
      labeled by machine, the number of objects than couldn't be labeled, and the total number of
      objects labeled.

      - **TotalLabeled** *(integer) --*

        The total number of objects labeled.

      - **HumanLabeled** *(integer) --*

        The total number of objects labeled by a human worker.

      - **MachineLabeled** *(integer) --*

        The total number of objects labeled by automated data labeling.

      - **FailedNonRetryableError** *(integer) --*

        The total number of objects that could not be labeled due to an error.

      - **Unlabeled** *(integer) --*

        The total number of objects not yet labeled.

    - **FailureReason** *(string) --*

      If the job failed, the reason that it failed.

    - **CreationTime** *(datetime) --*

      The date and time that the labeling job was created.

    - **LastModifiedTime** *(datetime) --*

      The date and time that the labeling job was last updated.

    - **JobReferenceCode** *(string) --*

      A unique identifier for work done as part of a labeling job.

    - **LabelingJobName** *(string) --*

      The name assigned to the labeling job when it was created.

    - **LabelingJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the labeling job.

    - **LabelAttributeName** *(string) --*

      The attribute used as the label in the output manifest file.

    - **InputConfig** *(dict) --*

      Input configuration information for the labeling job, such as the Amazon S3 location of the
      data objects and the location of the manifest file that describes the data objects.

      - **DataSource** *(dict) --*

        The location of the input data.

        - **S3DataSource** *(dict) --*

          The Amazon S3 location of the input data objects.

          - **ManifestS3Uri** *(string) --*

            The Amazon S3 location of the manifest file that describes the input data objects.

      - **DataAttributes** *(dict) --*

        Attributes of the data specified by the customer.

        - **ContentClassifiers** *(list) --*

          Declares that your content is free of personally identifiable information or adult
          content. Amazon SageMaker may restrict the Amazon Mechanical Turk workers that can view
          your task based on this information.

          - *(string) --*

    - **OutputConfig** *(dict) --*

      The location of the job's output data and the AWS Key Management Service key ID for the key
      used to encrypt the output data, if any.

      - **S3OutputPath** *(string) --*

        The Amazon S3 location to write output data.

      - **KmsKeyId** *(string) --*

        The AWS Key Management Service ID of the key used to encrypt the output data, if any.

        If you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution role
        must include permissions to call ``kms:Encrypt`` . If you don't provide a KMS key ID,
        Amazon SageMaker uses the default KMS key for Amazon S3 for your role's account. Amazon
        SageMaker uses server-side encryption with KMS-managed keys for ``LabelingJobOutputConfig``
        . If you use a bucket policy with an ``s3:PutObject`` permission that only allows objects
        with server-side encryption, set the condition key of ``s3:x-amz-server-side-encryption``
        to ``"aws:kms"`` . For more information, see `KMS-Managed Encryption Keys
        <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the *Amazon
        Simple Storage Service Developer Guide.*

        The KMS key policy must grant permission to the IAM role that you specify in your
        ``CreateLabelingJob`` request. For more information, see `Using Key Policies in AWS KMS
        <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the *AWS Key
        Management Service Developer Guide* .

    - **RoleArn** *(string) --*

      The Amazon Resource Name (ARN) that Amazon SageMaker assumes to perform tasks on your behalf
      during data labeling.

    - **LabelCategoryConfigS3Uri** *(string) --*

      The S3 location of the JSON file that defines the categories used to label data objects.

      The file is a JSON structure in the following format:

       ``{``

       ``"document-version": "2018-11-28"``

       ``"labels": [``

       ``{``

       ``"label": "*label 1* "``

       ``},``

       ``{``

       ``"label": "*label 2* "``

       ``},``

       ``...``

       ``{``

       ``"label": "*label n* "``

       ``}``

       ``]``

       ``}``

    - **StoppingConditions** *(dict) --*

      A set of conditions for stopping a labeling job. If any of the conditions are met, the job is
      automatically stopped.

      - **MaxHumanLabeledObjectCount** *(integer) --*

        The maximum number of objects that can be labeled by human workers.

      - **MaxPercentageOfInputDatasetLabeled** *(integer) --*

        The maximum number of input data objects that should be labeled.

    - **LabelingJobAlgorithmsConfig** *(dict) --*

      Configuration information for automated data labeling.

      - **LabelingJobAlgorithmSpecificationArn** *(string) --*

        Specifies the Amazon Resource Name (ARN) of the algorithm used for auto-labeling. You must
        select one of the following ARNs:

        * *Image classification*    ``arn:aws:sagemaker:*region*
        :027400017018:labeling-job-algorithm-specification/image-classification``

        * *Text classification*    ``arn:aws:sagemaker:*region*
        :027400017018:labeling-job-algorithm-specification/text-classification``

        * *Object detection*    ``arn:aws:sagemaker:*region*
        :027400017018:labeling-job-algorithm-specification/object-detection``

        * *Semantic Segmentation*    ``arn:aws:sagemaker:*region*
        :027400017018:labeling-job-algorithm-specification/semantic-segmentation``

      - **InitialActiveLearningModelArn** *(string) --*

        At the end of an auto-label job Amazon SageMaker Ground Truth sends the Amazon Resource Nam
        (ARN) of the final model used for auto-labeling. You can use this model as the starting
        point for subsequent similar jobs by providing the ARN of the model here.

      - **LabelingJobResourceConfig** *(dict) --*

        Provides configuration information for a labeling job.

        - **VolumeKmsKeyId** *(string) --*

          The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data
          on the storage volume attached to the ML compute instance(s) that run the training job.
          The ``VolumeKmsKeyId`` can be any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

    - **HumanTaskConfig** *(dict) --*

      Configuration information required for human workers to complete a labeling task.

      - **WorkteamArn** *(string) --*

        The Amazon Resource Name (ARN) of the work team assigned to complete the tasks.

      - **UiConfig** *(dict) --*

        Information about the user interface that workers use to complete the labeling task.

        - **UiTemplateS3Uri** *(string) --*

          The Amazon S3 bucket location of the UI template. For more information about the contents
          of a UI template, see `Creating Your Custom Labeling Task Template
          <https://docs.aws.amazon.com/sagemaker/latest/dg/sms-custom-templates-step2.html>`__ .

      - **PreHumanTaskLambdaArn** *(string) --*

        The Amazon Resource Name (ARN) of a Lambda function that is run before a data object is
        sent to a human worker. Use this function to provide input to a custom labeling job.

        For the built-in bounding box, image classification, semantic segmentation, and text
        classification task types, Amazon SageMaker Ground Truth provides the following Lambda
        functions:

         **US East (Northern Virginia) (us-east-1):**

        * ``arn:aws:lambda:us-east-1:432418664414:function:PRE-BoundingBox``

        * ``arn:aws:lambda:us-east-1:432418664414:function:PRE-ImageMultiClass``

        * ``arn:aws:lambda:us-east-1:432418664414:function:PRE-SemanticSegmentation``

        * ``arn:aws:lambda:us-east-1:432418664414:function:PRE-TextMultiClass``

        * ``arn:aws:lambda:us-east-1:432418664414:function:PRE-NamedEntityRecognition``

         **US East (Ohio) (us-east-2):**

        * ``arn:aws:lambda:us-east-2:266458841044:function:PRE-BoundingBox``

        * ``arn:aws:lambda:us-east-2:266458841044:function:PRE-ImageMultiClass``

        * ``arn:aws:lambda:us-east-2:266458841044:function:PRE-SemanticSegmentation``

        * ``arn:aws:lambda:us-east-2:266458841044:function:PRE-TextMultiClass``

        * ``arn:aws:lambda:us-east-2:266458841044:function:PRE-NamedEntityRecognition``

         **US West (Oregon) (us-west-2):**

        * ``arn:aws:lambda:us-west-2:081040173940:function:PRE-BoundingBox``

        * ``arn:aws:lambda:us-west-2:081040173940:function:PRE-ImageMultiClass``

        * ``arn:aws:lambda:us-west-2:081040173940:function:PRE-SemanticSegmentation``

        * ``arn:aws:lambda:us-west-2:081040173940:function:PRE-TextMultiClass``

        * ``arn:aws:lambda:us-west-2:081040173940:function:PRE-NamedEntityRecognition``

         **Canada (Central) (ca-central-1):**

        * ``arn:awslambda:ca-central-1:918755190332:function:PRE-BoundingBox``

        * ``arn:awslambda:ca-central-1:918755190332:function:PRE-ImageMultiClass``

        * ``arn:awslambda:ca-central-1:918755190332:function:PRE-SemanticSegmentation``

        * ``arn:awslambda:ca-central-1:918755190332:function:PRE-TextMultiClass``

        * ``arn:awslambda:ca-central-1:918755190332:function:PRE-NamedEntityRecognition``

         **EU (Ireland) (eu-west-1):**

        * ``arn:aws:lambda:eu-west-1:568282634449:function:PRE-BoundingBox``

        * ``arn:aws:lambda:eu-west-1:568282634449:function:PRE-ImageMultiClass``

        * ``arn:aws:lambda:eu-west-1:568282634449:function:PRE-SemanticSegmentation``

        * ``arn:aws:lambda:eu-west-1:568282634449:function:PRE-TextMultiClass``

        * ``arn:aws:lambda:eu-west-1:568282634449:function:PRE-NamedEntityRecognition``

         **EU (London) (eu-west-2):**

        * ``arn:awslambda:eu-west-2:487402164563:function:PRE-BoundingBox``

        * ``arn:awslambda:eu-west-2:487402164563:function:PRE-ImageMultiClass``

        * ``arn:awslambda:eu-west-2:487402164563:function:PRE-SemanticSegmentation``

        * ``arn:awslambda:eu-west-2:487402164563:function:PRE-TextMultiClass``

        * ``arn:awslambda:eu-west-2:487402164563:function:PRE-NamedEntityRecognition``

         **EU Frankfurt (eu-central-1):**

        * ``arn:awslambda:eu-central-1:203001061592:function:PRE-BoundingBox``

        * ``arn:awslambda:eu-central-1:203001061592:function:PRE-ImageMultiClass``

        * ``arn:awslambda:eu-central-1:203001061592:function:PRE-SemanticSegmentation``

        * ``arn:awslambda:eu-central-1:203001061592:function:PRE-TextMultiClass``

        * ``arn:awslambda:eu-central-1:203001061592:function:PRE-NamedEntityRecognition``

         **Asia Pacific (Tokyo) (ap-northeast-1):**

        * ``arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-BoundingBox``

        * ``arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-ImageMultiClass``

        * ``arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-SemanticSegmentation``

        * ``arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-TextMultiClass``

        * ``arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-NamedEntityRecognition``

         **Asia Pacific (Seoul) (ap-northeast-2):**

        * ``arn:awslambda:ap-northeast-2:845288260483:function:PRE-BoundingBox``

        * ``arn:awslambda:ap-northeast-2:845288260483:function:PRE-ImageMultiClass``

        * ``arn:awslambda:ap-northeast-2:845288260483:function:PRE-SemanticSegmentation``

        * ``arn:awslambda:ap-northeast-2:845288260483:function:PRE-TextMultiClass``

        * ``arn:awslambda:ap-northeast-2:845288260483:function:PRE-NamedEntityRecognition``

         **Asia Pacific (Mumbai) (ap-south-1):**

        * ``arn:awslambda:ap-south-1:565803892007:function:PRE-BoundingBox``

        * ``arn:awslambda:ap-south-1:565803892007:function:PRE-ImageMultiClass``

        * ``arn:awslambda:ap-south-1:565803892007:function:PRE-SemanticSegmentation``

        * ``arn:awslambda:ap-south-1:565803892007:function:PRE-TextMultiClass``

        * ``arn:awslambda:ap-south-1:565803892007:function:PRE-NamedEntityRecognition``

         **Asia Pacific (Singapore) (ap-southeast-1):**

        * ``arn:awslambda:ap-southeast-1:377565633583:function:PRE-BoundingBox``

        * ``arn:awslambda:ap-southeast-1:377565633583:function:PRE-ImageMultiClass``

        * ``arn:awslambda:ap-southeast-1:377565633583:function:PRE-SemanticSegmentation``

        * ``arn:awslambda:ap-southeast-1:377565633583:function:PRE-TextMultiClass``

        * ``arn:awslambda:ap-southeast-1:377565633583:function:PRE-NamedEntityRecognition``

         **Asia Pacific (Sydney) (ap-southeast-2):**

        * ``arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-BoundingBox``

        * ``arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-ImageMultiClass``

        * ``arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-SemanticSegmentation``

        * ``arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-TextMultiClass``

        * ``arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-NamedEntityRecognition``

      - **TaskKeywords** *(list) --*

        Keywords used to describe the task so that workers on Amazon Mechanical Turk can discover
        the task.

        - *(string) --*

      - **TaskTitle** *(string) --*

        A title for the task for your human workers.

      - **TaskDescription** *(string) --*

        A description of the task for your human workers.

      - **NumberOfHumanWorkersPerDataObject** *(integer) --*

        The number of human workers that will label an object.

      - **TaskTimeLimitInSeconds** *(integer) --*

        The amount of time that a worker has to complete a task.

      - **TaskAvailabilityLifetimeInSeconds** *(integer) --*

        The length of time that a task remains available for labeling by human workers. **If you
        choose the Amazon Mechanical Turk workforce, the maximum is 12 hours (43200)** . For
        private and vendor workforces, the maximum is as listed.

      - **MaxConcurrentTaskCount** *(integer) --*

        Defines the maximum number of data objects that can be labeled by human workers at the same
        time. Each object may have more than one worker at one time.

      - **AnnotationConsolidationConfig** *(dict) --*

        Configures how labels are consolidated across human workers.

        - **AnnotationConsolidationLambdaArn** *(string) --*

          The Amazon Resource Name (ARN) of a Lambda function implements the logic for annotation
          consolidation.

          For the built-in bounding box, image classification, semantic segmentation, and text
          classification task types, Amazon SageMaker Ground Truth provides the following Lambda
          functions:

          * *Bounding box* - Finds the most similar boxes from different workers based on the
          Jaccard index of the boxes.
          ``arn:aws:lambda:us-east-1:432418664414:function:ACS-BoundingBox``
          ``arn:aws:lambda:us-east-2:266458841044:function:ACS-BoundingBox``
          ``arn:aws:lambda:us-west-2:081040173940:function:ACS-BoundingBox``
          ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-BoundingBox``
          ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-BoundingBox``
          ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-BoundingBox``
          ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-BoundingBox``
          ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-BoundingBox``
          ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-BoundingBox``
          ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-BoundingBox``
          ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-BoundingBox``
          ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-BoundingBox``

          * *Image classification* - Uses a variant of the Expectation Maximization approach to
          estimate the true class of an image based on annotations from individual workers.
          ``arn:aws:lambda:us-east-1:432418664414:function:ACS-ImageMultiClass``
          ``arn:aws:lambda:us-east-2:266458841044:function:ACS-ImageMultiClass``
          ``arn:aws:lambda:us-west-2:081040173940:function:ACS-ImageMultiClass``
          ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-ImageMultiClass``
          ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-ImageMultiClass``
          ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-ImageMultiClass``
          ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-ImageMultiClass``
          ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-ImageMultiClass``
          ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-ImageMultiClass``
          ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-ImageMultiClass``
          ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-ImageMultiClass``
          ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-ImageMultiClass``

          * *Semantic segmentation* - Treats each pixel in an image as a multi-class classification
          and treats pixel annotations from workers as "votes" for the correct label.
          ``arn:aws:lambda:us-east-1:432418664414:function:ACS-SemanticSegmentation``
          ``arn:aws:lambda:us-east-2:266458841044:function:ACS-SemanticSegmentation``
          ``arn:aws:lambda:us-west-2:081040173940:function:ACS-SemanticSegmentation``
          ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-SemanticSegmentation``
          ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-SemanticSegmentation``
          ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-SemanticSegmentation``
          ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-SemanticSegmentation``
          ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-SemanticSegmentation``
          ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-SemanticSegmentation``
          ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-SemanticSegmentation``
          ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-SemanticSegmentation``
          ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-SemanticSegmentation``

          * *Text classification* - Uses a variant of the Expectation Maximization approach to
          estimate the true class of text based on annotations from individual workers.
          ``arn:aws:lambda:us-east-1:432418664414:function:ACS-TextMultiClass``
          ``arn:aws:lambda:us-east-2:266458841044:function:ACS-TextMultiClass``
          ``arn:aws:lambda:us-west-2:081040173940:function:ACS-TextMultiClass``
          ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-TextMultiClass``
          ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-TextMultiClass``
          ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-TextMultiClass``
          ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-TextMultiClass``
          ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-TextMultiClass``
          ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-TextMultiClass``
          ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-TextMultiClass``
          ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-TextMultiClass``
          ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-TextMultiClass``

          * *Named entity eecognition* - Groups similar selections and calculates aggregate
          boundaries, resolving to most-assigned label.
          ``arn:aws:lambda:us-east-1:432418664414:function:ACS-NamedEntityRecognition``
          ``arn:aws:lambda:us-east-2:266458841044:function:ACS-NamedEntityRecognition``
          ``arn:aws:lambda:us-west-2:081040173940:function:ACS-NamedEntityRecognition``
          ``arn:aws:lambda:eu-west-1:568282634449:function:ACS-NamedEntityRecognition``
          ``arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-NamedEntityRecognition``
          ``arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-NamedEntityRecognition``
          ``arn:aws:lambda:ap-south-1:565803892007:function:ACS-NamedEntityRecognition``
          ``arn:aws:lambda:eu-central-1:203001061592:function:ACS-NamedEntityRecognition``
          ``arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-NamedEntityRecognition``
          ``arn:aws:lambda:eu-west-2:487402164563:function:ACS-NamedEntityRecognition``
          ``arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-NamedEntityRecognition``
          ``arn:aws:lambda:ca-central-1:918755190332:function:ACS-NamedEntityRecognition``

          For more information, see `Annotation Consolidation
          <https://docs.aws.amazon.com/sagemaker/latest/dg/sms-annotation-consolidation.html>`__ .

      - **PublicWorkforceTaskPrice** *(dict) --*

        The price that you pay for each task performed by an Amazon Mechanical Turk worker.

        - **AmountInUsd** *(dict) --*

          Defines the amount of money paid to an Amazon Mechanical Turk worker in United States
          dollars.

          - **Dollars** *(integer) --*

            The whole number of dollars in the amount.

          - **Cents** *(integer) --*

            The fractional portion, in cents, of the amount.

          - **TenthFractionsOfACent** *(integer) --*

            Fractions of a cent, in tenths.

    - **Tags** *(list) --*

      An array of key/value pairs. For more information, see `Using Cost Allocation Tags
      <https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html#allocation-what>`__
      in the *AWS Billing and Cost Management User Guide* .

      - *(dict) --*

        Describes a tag.

        - **Key** *(string) --*

          The tag key.

        - **Value** *(string) --*

          The tag value.

    - **LabelingJobOutput** *(dict) --*

      The location of the output produced by the labeling job.

      - **OutputDatasetS3Uri** *(string) --*

        The Amazon S3 bucket location of the manifest file for labeled data.

      - **FinalActiveLearningModelArn** *(string) --*

        The Amazon Resource Name (ARN) for the most recent Amazon SageMaker model trained as part
        of automated data labeling.
    """


_ClientDescribeModelPackageResponseInferenceSpecificationContainersTypeDef = TypedDict(
    "_ClientDescribeModelPackageResponseInferenceSpecificationContainersTypeDef",
    {
        "ContainerHostname": str,
        "Image": str,
        "ImageDigest": str,
        "ModelDataUrl": str,
        "ProductId": str,
    },
    total=False,
)


class ClientDescribeModelPackageResponseInferenceSpecificationContainersTypeDef(
    _ClientDescribeModelPackageResponseInferenceSpecificationContainersTypeDef
):
    """
    Type definition for `ClientDescribeModelPackageResponseInferenceSpecification` `Containers`

    Describes the Docker container for the model package.

    - **ContainerHostname** *(string) --*

      The DNS host name for the Docker container.

    - **Image** *(string) --*

      The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.

      If you are using your own custom algorithm instead of an algorithm provided by Amazon
      SageMaker, the inference code must meet Amazon SageMaker requirements. Amazon SageMaker
      supports both ``registry/repository[:tag]`` and ``registry/repository[@digest]`` image
      path formats. For more information, see `Using Your Own Algorithms with Amazon
      SageMaker <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

    - **ImageDigest** *(string) --*

      An MD5 hash of the training algorithm that identifies the Docker image used for
      training.

    - **ModelDataUrl** *(string) --*

      The Amazon S3 path where the model artifacts, which result from model training, are
      stored. This path must point to a single ``gzip`` compressed tar archive (``.tar.gz``
      suffix).

    - **ProductId** *(string) --*

      The AWS Marketplace product ID of the model package.
    """


_ClientDescribeModelPackageResponseInferenceSpecificationTypeDef = TypedDict(
    "_ClientDescribeModelPackageResponseInferenceSpecificationTypeDef",
    {
        "Containers": List[
            ClientDescribeModelPackageResponseInferenceSpecificationContainersTypeDef
        ],
        "SupportedTransformInstanceTypes": List[str],
        "SupportedRealtimeInferenceInstanceTypes": List[str],
        "SupportedContentTypes": List[str],
        "SupportedResponseMIMETypes": List[str],
    },
    total=False,
)


class ClientDescribeModelPackageResponseInferenceSpecificationTypeDef(
    _ClientDescribeModelPackageResponseInferenceSpecificationTypeDef
):
    """
    Type definition for `ClientDescribeModelPackageResponse` `InferenceSpecification`

    Details about inference jobs that can be run with models based on this model package.

    - **Containers** *(list) --*

      The Amazon ECR registry path of the Docker image that contains the inference code.

      - *(dict) --*

        Describes the Docker container for the model package.

        - **ContainerHostname** *(string) --*

          The DNS host name for the Docker container.

        - **Image** *(string) --*

          The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.

          If you are using your own custom algorithm instead of an algorithm provided by Amazon
          SageMaker, the inference code must meet Amazon SageMaker requirements. Amazon SageMaker
          supports both ``registry/repository[:tag]`` and ``registry/repository[@digest]`` image
          path formats. For more information, see `Using Your Own Algorithms with Amazon
          SageMaker <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

        - **ImageDigest** *(string) --*

          An MD5 hash of the training algorithm that identifies the Docker image used for
          training.

        - **ModelDataUrl** *(string) --*

          The Amazon S3 path where the model artifacts, which result from model training, are
          stored. This path must point to a single ``gzip`` compressed tar archive (``.tar.gz``
          suffix).

        - **ProductId** *(string) --*

          The AWS Marketplace product ID of the model package.

    - **SupportedTransformInstanceTypes** *(list) --*

      A list of the instance types on which a transformation job can be run or on which an
      endpoint can be deployed.

      - *(string) --*

    - **SupportedRealtimeInferenceInstanceTypes** *(list) --*

      A list of the instance types that are used to generate inferences in real-time.

      - *(string) --*

    - **SupportedContentTypes** *(list) --*

      The supported MIME types for the input data.

      - *(string) --*

    - **SupportedResponseMIMETypes** *(list) --*

      The supported MIME types for the output data.

      - *(string) --*
    """


_ClientDescribeModelPackageResponseModelPackageStatusDetailsImageScanStatusesTypeDef = TypedDict(
    "_ClientDescribeModelPackageResponseModelPackageStatusDetailsImageScanStatusesTypeDef",
    {"Name": str, "Status": str, "FailureReason": str},
    total=False,
)


class ClientDescribeModelPackageResponseModelPackageStatusDetailsImageScanStatusesTypeDef(
    _ClientDescribeModelPackageResponseModelPackageStatusDetailsImageScanStatusesTypeDef
):
    """
    Type definition for `ClientDescribeModelPackageResponseModelPackageStatusDetails` `ImageScanStatuses`

    Represents the overall status of a model package.

    - **Name** *(string) --*

      The name of the model package for which the overall status is being reported.

    - **Status** *(string) --*

      The current status.

    - **FailureReason** *(string) --*

      if the overall status is ``Failed`` , the reason for the failure.
    """


_ClientDescribeModelPackageResponseModelPackageStatusDetailsValidationStatusesTypeDef = TypedDict(
    "_ClientDescribeModelPackageResponseModelPackageStatusDetailsValidationStatusesTypeDef",
    {"Name": str, "Status": str, "FailureReason": str},
    total=False,
)


class ClientDescribeModelPackageResponseModelPackageStatusDetailsValidationStatusesTypeDef(
    _ClientDescribeModelPackageResponseModelPackageStatusDetailsValidationStatusesTypeDef
):
    """
    Type definition for `ClientDescribeModelPackageResponseModelPackageStatusDetails` `ValidationStatuses`

    Represents the overall status of a model package.

    - **Name** *(string) --*

      The name of the model package for which the overall status is being reported.

    - **Status** *(string) --*

      The current status.

    - **FailureReason** *(string) --*

      if the overall status is ``Failed`` , the reason for the failure.
    """


_ClientDescribeModelPackageResponseModelPackageStatusDetailsTypeDef = TypedDict(
    "_ClientDescribeModelPackageResponseModelPackageStatusDetailsTypeDef",
    {
        "ValidationStatuses": List[
            ClientDescribeModelPackageResponseModelPackageStatusDetailsValidationStatusesTypeDef
        ],
        "ImageScanStatuses": List[
            ClientDescribeModelPackageResponseModelPackageStatusDetailsImageScanStatusesTypeDef
        ],
    },
    total=False,
)


class ClientDescribeModelPackageResponseModelPackageStatusDetailsTypeDef(
    _ClientDescribeModelPackageResponseModelPackageStatusDetailsTypeDef
):
    """
    Type definition for `ClientDescribeModelPackageResponse` `ModelPackageStatusDetails`

    Details about the current status of the model package.

    - **ValidationStatuses** *(list) --*

      The validation status of the model package.

      - *(dict) --*

        Represents the overall status of a model package.

        - **Name** *(string) --*

          The name of the model package for which the overall status is being reported.

        - **Status** *(string) --*

          The current status.

        - **FailureReason** *(string) --*

          if the overall status is ``Failed`` , the reason for the failure.

    - **ImageScanStatuses** *(list) --*

      The status of the scan of the Docker image container for the model package.

      - *(dict) --*

        Represents the overall status of a model package.

        - **Name** *(string) --*

          The name of the model package for which the overall status is being reported.

        - **Status** *(string) --*

          The current status.

        - **FailureReason** *(string) --*

          if the overall status is ``Failed`` , the reason for the failure.
    """


_ClientDescribeModelPackageResponseSourceAlgorithmSpecificationSourceAlgorithmsTypeDef = TypedDict(
    "_ClientDescribeModelPackageResponseSourceAlgorithmSpecificationSourceAlgorithmsTypeDef",
    {"ModelDataUrl": str, "AlgorithmName": str},
    total=False,
)


class ClientDescribeModelPackageResponseSourceAlgorithmSpecificationSourceAlgorithmsTypeDef(
    _ClientDescribeModelPackageResponseSourceAlgorithmSpecificationSourceAlgorithmsTypeDef
):
    """
    Type definition for `ClientDescribeModelPackageResponseSourceAlgorithmSpecification` `SourceAlgorithms`

    Specifies an algorithm that was used to create the model package. The algorithm must be
    either an algorithm resource in your Amazon SageMaker account or an algorithm in AWS
    Marketplace that you are subscribed to.

    - **ModelDataUrl** *(string) --*

      The Amazon S3 path where the model artifacts, which result from model training, are
      stored. This path must point to a single ``gzip`` compressed tar archive (``.tar.gz``
      suffix).

    - **AlgorithmName** *(string) --*

      The name of an algorithm that was used to create the model package. The algorithm must
      be either an algorithm resource in your Amazon SageMaker account or an algorithm in AWS
      Marketplace that you are subscribed to.
    """


_ClientDescribeModelPackageResponseSourceAlgorithmSpecificationTypeDef = TypedDict(
    "_ClientDescribeModelPackageResponseSourceAlgorithmSpecificationTypeDef",
    {
        "SourceAlgorithms": List[
            ClientDescribeModelPackageResponseSourceAlgorithmSpecificationSourceAlgorithmsTypeDef
        ]
    },
    total=False,
)


class ClientDescribeModelPackageResponseSourceAlgorithmSpecificationTypeDef(
    _ClientDescribeModelPackageResponseSourceAlgorithmSpecificationTypeDef
):
    """
    Type definition for `ClientDescribeModelPackageResponse` `SourceAlgorithmSpecification`

    Details about the algorithm that was used to create the model package.

    - **SourceAlgorithms** *(list) --*

      A list of the algorithms that were used to create a model package.

      - *(dict) --*

        Specifies an algorithm that was used to create the model package. The algorithm must be
        either an algorithm resource in your Amazon SageMaker account or an algorithm in AWS
        Marketplace that you are subscribed to.

        - **ModelDataUrl** *(string) --*

          The Amazon S3 path where the model artifacts, which result from model training, are
          stored. This path must point to a single ``gzip`` compressed tar archive (``.tar.gz``
          suffix).

        - **AlgorithmName** *(string) --*

          The name of an algorithm that was used to create the model package. The algorithm must
          be either an algorithm resource in your Amazon SageMaker account or an algorithm in AWS
          Marketplace that you are subscribed to.
    """


_ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef = TypedDict(
    "_ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef",
    {"S3DataType": str, "S3Uri": str},
    total=False,
)


class ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef(
    _ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef
):
    """
    Type definition for `ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSource` `S3DataSource`

    The S3 location of the data source that is associated with a channel.

    - **S3DataType** *(string) --*

      If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
      SageMaker uses all objects with the specified key name prefix for batch
      transform.

      If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
      manifest file containing a list of object keys that you want Amazon SageMaker
      to use for batch transform.

      The following values are compatible: ``ManifestFile`` , ``S3Prefix``

      The following value is not compatible: ``AugmentedManifestFile``

    - **S3Uri** *(string) --*

      Depending on the value specified for the ``S3DataType`` , identifies either a
      key name prefix or a manifest. For example:

      * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

      * A manifest might look like this: ``s3://bucketname/example.manifest``   The
      manifest is an S3 object which is a JSON file with the following format:   ``[
      {"prefix": "s3://customer_bucket/some/prefix/"},``
      ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``
      ``...``    ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches
      the following ``s3Uris`` :
      ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
      set of ``S3Uris`` in this manifest constitutes the input data for the channel
      for this datasource. The object that each ``S3Uris`` points to must be readable
      by the IAM role that Amazon SageMaker uses to perform tasks on your behalf.
    """


_ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef = TypedDict(
    "_ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef",
    {
        "S3DataSource": ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceS3DataSourceTypeDef
    },
    total=False,
)


class ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef(
    _ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef
):
    """
    Type definition for `ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInput` `DataSource`

    Describes the location of the channel data, which is, the S3 location of the input
    data that the model can consume.

    - **S3DataSource** *(dict) --*

      The S3 location of the data source that is associated with a channel.

      - **S3DataType** *(string) --*

        If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
        SageMaker uses all objects with the specified key name prefix for batch
        transform.

        If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
        manifest file containing a list of object keys that you want Amazon SageMaker
        to use for batch transform.

        The following values are compatible: ``ManifestFile`` , ``S3Prefix``

        The following value is not compatible: ``AugmentedManifestFile``

      - **S3Uri** *(string) --*

        Depending on the value specified for the ``S3DataType`` , identifies either a
        key name prefix or a manifest. For example:

        * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

        * A manifest might look like this: ``s3://bucketname/example.manifest``   The
        manifest is an S3 object which is a JSON file with the following format:   ``[
        {"prefix": "s3://customer_bucket/some/prefix/"},``
        ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``
        ``...``    ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches
        the following ``s3Uris`` :
        ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
        set of ``S3Uris`` in this manifest constitutes the input data for the channel
        for this datasource. The object that each ``S3Uris`` points to must be readable
        by the IAM role that Amazon SageMaker uses to perform tasks on your behalf.
    """


_ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef = TypedDict(
    "_ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef",
    {
        "DataSource": ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputDataSourceTypeDef,
        "ContentType": str,
        "CompressionType": str,
        "SplitType": str,
    },
    total=False,
)


class ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef(
    _ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef
):
    """
    Type definition for `ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinition` `TransformInput`

    A description of the input source and the way the transform job consumes it.

    - **DataSource** *(dict) --*

      Describes the location of the channel data, which is, the S3 location of the input
      data that the model can consume.

      - **S3DataSource** *(dict) --*

        The S3 location of the data source that is associated with a channel.

        - **S3DataType** *(string) --*

          If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
          SageMaker uses all objects with the specified key name prefix for batch
          transform.

          If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
          manifest file containing a list of object keys that you want Amazon SageMaker
          to use for batch transform.

          The following values are compatible: ``ManifestFile`` , ``S3Prefix``

          The following value is not compatible: ``AugmentedManifestFile``

        - **S3Uri** *(string) --*

          Depending on the value specified for the ``S3DataType`` , identifies either a
          key name prefix or a manifest. For example:

          * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

          * A manifest might look like this: ``s3://bucketname/example.manifest``   The
          manifest is an S3 object which is a JSON file with the following format:   ``[
          {"prefix": "s3://customer_bucket/some/prefix/"},``
          ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``
          ``...``    ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches
          the following ``s3Uris`` :
          ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
          set of ``S3Uris`` in this manifest constitutes the input data for the channel
          for this datasource. The object that each ``S3Uris`` points to must be readable
          by the IAM role that Amazon SageMaker uses to perform tasks on your behalf.

    - **ContentType** *(string) --*

      The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker
      uses the MIME type with each http call to transfer data to the transform job.

    - **CompressionType** *(string) --*

      If your transform data is compressed, specify the compression type. Amazon
      SageMaker automatically decompresses the data for the transform job accordingly.
      The default value is ``None`` .

    - **SplitType** *(string) --*

      The method to use to split the transform job's data files into smaller batches.
      Splitting is necessary when the total size of each object is too large to fit in a
      single request. You can also use data splitting to improve performance by
      processing multiple concurrent mini-batches. The default value for ``SplitType`` is
      ``None`` , which indicates that input data files are not split, and request
      payloads contain the entire contents of an input object. Set the value of this
      parameter to ``Line`` to split records on a newline character boundary.
      ``SplitType`` also supports a number of record-oriented binary data formats.

      When splitting is enabled, the size of a mini-batch depends on the values of the
      ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
      ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
      records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
      ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records
      in each request.

      .. note::

        Some data formats represent a record as a binary payload wrapped with extra
        padding bytes. When splitting is applied to a binary data format, padding is
        removed if the value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is
        not removed if the value of ``BatchStrategy`` is set to ``MultiRecord`` .

        For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
        <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For
        more information about ``TFRecord`` , see `Consuming TFRecord data
        <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
        TensorFlow documentation.
    """


_ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef = TypedDict(
    "_ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef",
    {"S3OutputPath": str, "Accept": str, "AssembleWith": str, "KmsKeyId": str},
    total=False,
)


class ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef(
    _ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef
):
    """
    Type definition for `ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinition` `TransformOutput`

    Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
    from the transform job.

    - **S3OutputPath** *(string) --*

      The Amazon S3 path where you want Amazon SageMaker to store the results of the
      transform job. For example, ``s3://bucket-name/key-name-prefix`` .

      For every S3 object used as input for the transform job, batch transform stores the
      transformed data with an .``out`` suffix in a corresponding subfolder in the
      location in the output prefix. For example, for the input data stored at
      ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores
      the transformed data at
      ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
      transform doesn't upload partially processed objects. For an input S3 object that
      contains multiple records, it creates an .``out`` file only if the transform job
      succeeds on the entire file. When the input contains multiple S3 objects, the batch
      transform job processes the listed S3 objects and uploads only the output for
      successfully processed objects. If any object fails in the transform job batch
      transform marks the job as failed to prompt investigation.

    - **Accept** *(string) --*

      The MIME type used to specify the output data. Amazon SageMaker uses the MIME type
      with each http call to transfer data from the transform job.

    - **AssembleWith** *(string) --*

      Defines how to assemble the results of the transform job as a single S3 object.
      Choose a format that is most convenient to you. To concatenate the results in
      binary format, specify ``None`` . To add a newline character at the end of every
      transformed record, specify ``Line`` .

    - **KmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
      the model artifacts at rest using Amazon S3 server-side encryption. The
      ``KmsKeyId`` can be any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // KMS Key Alias  ``"alias/ExampleAlias"``

      * // Amazon Resource Name (ARN) of a KMS Key Alias
      ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

      If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for
      Amazon S3 for your role's account. For more information, see `KMS-Managed
      Encryption Keys
      <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
      *Amazon Simple Storage Service Developer Guide.*

      The KMS key policy must grant permission to the IAM role that you specify in your
      CreateModel request. For more information, see `Using Key Policies in AWS KMS
      <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the
      *AWS Key Management Service Developer Guide* .
    """


_ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef = TypedDict(
    "_ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef",
    {"InstanceType": str, "InstanceCount": int, "VolumeKmsKeyId": str},
    total=False,
)


class ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef(
    _ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef
):
    """
    Type definition for `ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinition` `TransformResources`

    Identifies the ML compute instances for the transform job.

    - **InstanceType** *(string) --*

      The ML compute instance type for the transform job. If you are using built-in
      algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge
      or ``ml.m5.large`` instance types.

    - **InstanceCount** *(integer) --*

      The number of ML compute instances to use in the transform job. For distributed
      transform jobs, specify a value greater than 1. The default value is ``1`` .

    - **VolumeKmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
      data on the storage volume attached to the ML compute instance(s) that run the
      batch transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef = TypedDict(
    "_ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef",
    {
        "MaxConcurrentTransforms": int,
        "MaxPayloadInMB": int,
        "BatchStrategy": str,
        "Environment": Dict[str, str],
        "TransformInput": ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformInputTypeDef,
        "TransformOutput": ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformOutputTypeDef,
        "TransformResources": ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTransformResourcesTypeDef,
    },
    total=False,
)


class ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef(
    _ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef
):
    """
    Type definition for `ClientDescribeModelPackageResponseValidationSpecificationValidationProfiles` `TransformJobDefinition`

    The ``TransformJobDefinition`` object that describes the transform job used for the
    validation of the model package.

    - **MaxConcurrentTransforms** *(integer) --*

      The maximum number of parallel requests that can be sent to each instance in a
      transform job. The default value is 1.

    - **MaxPayloadInMB** *(integer) --*

      The maximum payload size allowed, in MB. A payload is the data portion of a record
      (without metadata).

    - **BatchStrategy** *(string) --*

      A string that determines the number of records included in a single mini-batch.

       ``SingleRecord`` means only one record is used per mini-batch. ``MultiRecord`` means
       a mini-batch is set to contain as many records that can fit within the
       ``MaxPayloadInMB`` limit.

    - **Environment** *(dict) --*

      The environment variables to set in the Docker container. We support up to 16 key and
      values entries in the map.

      - *(string) --*

        - *(string) --*

    - **TransformInput** *(dict) --*

      A description of the input source and the way the transform job consumes it.

      - **DataSource** *(dict) --*

        Describes the location of the channel data, which is, the S3 location of the input
        data that the model can consume.

        - **S3DataSource** *(dict) --*

          The S3 location of the data source that is associated with a channel.

          - **S3DataType** *(string) --*

            If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
            SageMaker uses all objects with the specified key name prefix for batch
            transform.

            If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
            manifest file containing a list of object keys that you want Amazon SageMaker
            to use for batch transform.

            The following values are compatible: ``ManifestFile`` , ``S3Prefix``

            The following value is not compatible: ``AugmentedManifestFile``

          - **S3Uri** *(string) --*

            Depending on the value specified for the ``S3DataType`` , identifies either a
            key name prefix or a manifest. For example:

            * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

            * A manifest might look like this: ``s3://bucketname/example.manifest``   The
            manifest is an S3 object which is a JSON file with the following format:   ``[
            {"prefix": "s3://customer_bucket/some/prefix/"},``
            ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``
            ``...``    ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches
            the following ``s3Uris`` :
            ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
            set of ``S3Uris`` in this manifest constitutes the input data for the channel
            for this datasource. The object that each ``S3Uris`` points to must be readable
            by the IAM role that Amazon SageMaker uses to perform tasks on your behalf.

      - **ContentType** *(string) --*

        The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker
        uses the MIME type with each http call to transfer data to the transform job.

      - **CompressionType** *(string) --*

        If your transform data is compressed, specify the compression type. Amazon
        SageMaker automatically decompresses the data for the transform job accordingly.
        The default value is ``None`` .

      - **SplitType** *(string) --*

        The method to use to split the transform job's data files into smaller batches.
        Splitting is necessary when the total size of each object is too large to fit in a
        single request. You can also use data splitting to improve performance by
        processing multiple concurrent mini-batches. The default value for ``SplitType`` is
        ``None`` , which indicates that input data files are not split, and request
        payloads contain the entire contents of an input object. Set the value of this
        parameter to ``Line`` to split records on a newline character boundary.
        ``SplitType`` also supports a number of record-oriented binary data formats.

        When splitting is enabled, the size of a mini-batch depends on the values of the
        ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
        ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
        records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
        ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records
        in each request.

        .. note::

          Some data formats represent a record as a binary payload wrapped with extra
          padding bytes. When splitting is applied to a binary data format, padding is
          removed if the value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is
          not removed if the value of ``BatchStrategy`` is set to ``MultiRecord`` .

          For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
          <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For
          more information about ``TFRecord`` , see `Consuming TFRecord data
          <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
          TensorFlow documentation.

    - **TransformOutput** *(dict) --*

      Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
      from the transform job.

      - **S3OutputPath** *(string) --*

        The Amazon S3 path where you want Amazon SageMaker to store the results of the
        transform job. For example, ``s3://bucket-name/key-name-prefix`` .

        For every S3 object used as input for the transform job, batch transform stores the
        transformed data with an .``out`` suffix in a corresponding subfolder in the
        location in the output prefix. For example, for the input data stored at
        ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores
        the transformed data at
        ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
        transform doesn't upload partially processed objects. For an input S3 object that
        contains multiple records, it creates an .``out`` file only if the transform job
        succeeds on the entire file. When the input contains multiple S3 objects, the batch
        transform job processes the listed S3 objects and uploads only the output for
        successfully processed objects. If any object fails in the transform job batch
        transform marks the job as failed to prompt investigation.

      - **Accept** *(string) --*

        The MIME type used to specify the output data. Amazon SageMaker uses the MIME type
        with each http call to transfer data from the transform job.

      - **AssembleWith** *(string) --*

        Defines how to assemble the results of the transform job as a single S3 object.
        Choose a format that is most convenient to you. To concatenate the results in
        binary format, specify ``None`` . To add a newline character at the end of every
        transformed record, specify ``Line`` .

      - **KmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
        the model artifacts at rest using Amazon S3 server-side encryption. The
        ``KmsKeyId`` can be any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // KMS Key Alias  ``"alias/ExampleAlias"``

        * // Amazon Resource Name (ARN) of a KMS Key Alias
        ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

        If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for
        Amazon S3 for your role's account. For more information, see `KMS-Managed
        Encryption Keys
        <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
        *Amazon Simple Storage Service Developer Guide.*

        The KMS key policy must grant permission to the IAM role that you specify in your
        CreateModel request. For more information, see `Using Key Policies in AWS KMS
        <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the
        *AWS Key Management Service Developer Guide* .

    - **TransformResources** *(dict) --*

      Identifies the ML compute instances for the transform job.

      - **InstanceType** *(string) --*

        The ML compute instance type for the transform job. If you are using built-in
        algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge
        or ``ml.m5.large`` instance types.

      - **InstanceCount** *(integer) --*

        The number of ML compute instances to use in the transform job. For distributed
        transform jobs, specify a value greater than 1. The default value is ``1`` .

      - **VolumeKmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
        data on the storage volume attached to the ML compute instance(s) that run the
        batch transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTypeDef = TypedDict(
    "_ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTypeDef",
    {
        "ProfileName": str,
        "TransformJobDefinition": ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTransformJobDefinitionTypeDef,
    },
    total=False,
)


class ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTypeDef(
    _ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTypeDef
):
    """
    Type definition for `ClientDescribeModelPackageResponseValidationSpecification` `ValidationProfiles`

    Contains data, such as the inputs and targeted instance types that are used in the
    process of validating the model package.

    The data provided in the validation profile is made available to your buyers on AWS
    Marketplace.

    - **ProfileName** *(string) --*

      The name of the profile for the model package.

    - **TransformJobDefinition** *(dict) --*

      The ``TransformJobDefinition`` object that describes the transform job used for the
      validation of the model package.

      - **MaxConcurrentTransforms** *(integer) --*

        The maximum number of parallel requests that can be sent to each instance in a
        transform job. The default value is 1.

      - **MaxPayloadInMB** *(integer) --*

        The maximum payload size allowed, in MB. A payload is the data portion of a record
        (without metadata).

      - **BatchStrategy** *(string) --*

        A string that determines the number of records included in a single mini-batch.

         ``SingleRecord`` means only one record is used per mini-batch. ``MultiRecord`` means
         a mini-batch is set to contain as many records that can fit within the
         ``MaxPayloadInMB`` limit.

      - **Environment** *(dict) --*

        The environment variables to set in the Docker container. We support up to 16 key and
        values entries in the map.

        - *(string) --*

          - *(string) --*

      - **TransformInput** *(dict) --*

        A description of the input source and the way the transform job consumes it.

        - **DataSource** *(dict) --*

          Describes the location of the channel data, which is, the S3 location of the input
          data that the model can consume.

          - **S3DataSource** *(dict) --*

            The S3 location of the data source that is associated with a channel.

            - **S3DataType** *(string) --*

              If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
              SageMaker uses all objects with the specified key name prefix for batch
              transform.

              If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
              manifest file containing a list of object keys that you want Amazon SageMaker
              to use for batch transform.

              The following values are compatible: ``ManifestFile`` , ``S3Prefix``

              The following value is not compatible: ``AugmentedManifestFile``

            - **S3Uri** *(string) --*

              Depending on the value specified for the ``S3DataType`` , identifies either a
              key name prefix or a manifest. For example:

              * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

              * A manifest might look like this: ``s3://bucketname/example.manifest``   The
              manifest is an S3 object which is a JSON file with the following format:   ``[
              {"prefix": "s3://customer_bucket/some/prefix/"},``
              ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``
              ``...``    ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches
              the following ``s3Uris`` :
              ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
              ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
              ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
              set of ``S3Uris`` in this manifest constitutes the input data for the channel
              for this datasource. The object that each ``S3Uris`` points to must be readable
              by the IAM role that Amazon SageMaker uses to perform tasks on your behalf.

        - **ContentType** *(string) --*

          The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker
          uses the MIME type with each http call to transfer data to the transform job.

        - **CompressionType** *(string) --*

          If your transform data is compressed, specify the compression type. Amazon
          SageMaker automatically decompresses the data for the transform job accordingly.
          The default value is ``None`` .

        - **SplitType** *(string) --*

          The method to use to split the transform job's data files into smaller batches.
          Splitting is necessary when the total size of each object is too large to fit in a
          single request. You can also use data splitting to improve performance by
          processing multiple concurrent mini-batches. The default value for ``SplitType`` is
          ``None`` , which indicates that input data files are not split, and request
          payloads contain the entire contents of an input object. Set the value of this
          parameter to ``Line`` to split records on a newline character boundary.
          ``SplitType`` also supports a number of record-oriented binary data formats.

          When splitting is enabled, the size of a mini-batch depends on the values of the
          ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
          ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
          records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
          ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records
          in each request.

          .. note::

            Some data formats represent a record as a binary payload wrapped with extra
            padding bytes. When splitting is applied to a binary data format, padding is
            removed if the value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is
            not removed if the value of ``BatchStrategy`` is set to ``MultiRecord`` .

            For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
            <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For
            more information about ``TFRecord`` , see `Consuming TFRecord data
            <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
            TensorFlow documentation.

      - **TransformOutput** *(dict) --*

        Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
        from the transform job.

        - **S3OutputPath** *(string) --*

          The Amazon S3 path where you want Amazon SageMaker to store the results of the
          transform job. For example, ``s3://bucket-name/key-name-prefix`` .

          For every S3 object used as input for the transform job, batch transform stores the
          transformed data with an .``out`` suffix in a corresponding subfolder in the
          location in the output prefix. For example, for the input data stored at
          ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores
          the transformed data at
          ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
          transform doesn't upload partially processed objects. For an input S3 object that
          contains multiple records, it creates an .``out`` file only if the transform job
          succeeds on the entire file. When the input contains multiple S3 objects, the batch
          transform job processes the listed S3 objects and uploads only the output for
          successfully processed objects. If any object fails in the transform job batch
          transform marks the job as failed to prompt investigation.

        - **Accept** *(string) --*

          The MIME type used to specify the output data. Amazon SageMaker uses the MIME type
          with each http call to transfer data from the transform job.

        - **AssembleWith** *(string) --*

          Defines how to assemble the results of the transform job as a single S3 object.
          Choose a format that is most convenient to you. To concatenate the results in
          binary format, specify ``None`` . To add a newline character at the end of every
          transformed record, specify ``Line`` .

        - **KmsKeyId** *(string) --*

          The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
          the model artifacts at rest using Amazon S3 server-side encryption. The
          ``KmsKeyId`` can be any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // KMS Key Alias  ``"alias/ExampleAlias"``

          * // Amazon Resource Name (ARN) of a KMS Key Alias
          ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

          If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for
          Amazon S3 for your role's account. For more information, see `KMS-Managed
          Encryption Keys
          <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
          *Amazon Simple Storage Service Developer Guide.*

          The KMS key policy must grant permission to the IAM role that you specify in your
          CreateModel request. For more information, see `Using Key Policies in AWS KMS
          <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the
          *AWS Key Management Service Developer Guide* .

      - **TransformResources** *(dict) --*

        Identifies the ML compute instances for the transform job.

        - **InstanceType** *(string) --*

          The ML compute instance type for the transform job. If you are using built-in
          algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge
          or ``ml.m5.large`` instance types.

        - **InstanceCount** *(integer) --*

          The number of ML compute instances to use in the transform job. For distributed
          transform jobs, specify a value greater than 1. The default value is ``1`` .

        - **VolumeKmsKeyId** *(string) --*

          The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
          data on the storage volume attached to the ML compute instance(s) that run the
          batch transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientDescribeModelPackageResponseValidationSpecificationTypeDef = TypedDict(
    "_ClientDescribeModelPackageResponseValidationSpecificationTypeDef",
    {
        "ValidationRole": str,
        "ValidationProfiles": List[
            ClientDescribeModelPackageResponseValidationSpecificationValidationProfilesTypeDef
        ],
    },
    total=False,
)


class ClientDescribeModelPackageResponseValidationSpecificationTypeDef(
    _ClientDescribeModelPackageResponseValidationSpecificationTypeDef
):
    """
    Type definition for `ClientDescribeModelPackageResponse` `ValidationSpecification`

    Configurations for one or more transform jobs that Amazon SageMaker runs to test the model
    package.

    - **ValidationRole** *(string) --*

      The IAM roles to be used for the validation of the model package.

    - **ValidationProfiles** *(list) --*

      An array of ``ModelPackageValidationProfile`` objects, each of which specifies a batch
      transform job that Amazon SageMaker runs to validate your model package.

      - *(dict) --*

        Contains data, such as the inputs and targeted instance types that are used in the
        process of validating the model package.

        The data provided in the validation profile is made available to your buyers on AWS
        Marketplace.

        - **ProfileName** *(string) --*

          The name of the profile for the model package.

        - **TransformJobDefinition** *(dict) --*

          The ``TransformJobDefinition`` object that describes the transform job used for the
          validation of the model package.

          - **MaxConcurrentTransforms** *(integer) --*

            The maximum number of parallel requests that can be sent to each instance in a
            transform job. The default value is 1.

          - **MaxPayloadInMB** *(integer) --*

            The maximum payload size allowed, in MB. A payload is the data portion of a record
            (without metadata).

          - **BatchStrategy** *(string) --*

            A string that determines the number of records included in a single mini-batch.

             ``SingleRecord`` means only one record is used per mini-batch. ``MultiRecord`` means
             a mini-batch is set to contain as many records that can fit within the
             ``MaxPayloadInMB`` limit.

          - **Environment** *(dict) --*

            The environment variables to set in the Docker container. We support up to 16 key and
            values entries in the map.

            - *(string) --*

              - *(string) --*

          - **TransformInput** *(dict) --*

            A description of the input source and the way the transform job consumes it.

            - **DataSource** *(dict) --*

              Describes the location of the channel data, which is, the S3 location of the input
              data that the model can consume.

              - **S3DataSource** *(dict) --*

                The S3 location of the data source that is associated with a channel.

                - **S3DataType** *(string) --*

                  If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
                  SageMaker uses all objects with the specified key name prefix for batch
                  transform.

                  If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
                  manifest file containing a list of object keys that you want Amazon SageMaker
                  to use for batch transform.

                  The following values are compatible: ``ManifestFile`` , ``S3Prefix``

                  The following value is not compatible: ``AugmentedManifestFile``

                - **S3Uri** *(string) --*

                  Depending on the value specified for the ``S3DataType`` , identifies either a
                  key name prefix or a manifest. For example:

                  * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

                  * A manifest might look like this: ``s3://bucketname/example.manifest``   The
                  manifest is an S3 object which is a JSON file with the following format:   ``[
                  {"prefix": "s3://customer_bucket/some/prefix/"},``
                  ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``
                  ``...``    ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches
                  the following ``s3Uris`` :
                  ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                  ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                  ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
                  set of ``S3Uris`` in this manifest constitutes the input data for the channel
                  for this datasource. The object that each ``S3Uris`` points to must be readable
                  by the IAM role that Amazon SageMaker uses to perform tasks on your behalf.

            - **ContentType** *(string) --*

              The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker
              uses the MIME type with each http call to transfer data to the transform job.

            - **CompressionType** *(string) --*

              If your transform data is compressed, specify the compression type. Amazon
              SageMaker automatically decompresses the data for the transform job accordingly.
              The default value is ``None`` .

            - **SplitType** *(string) --*

              The method to use to split the transform job's data files into smaller batches.
              Splitting is necessary when the total size of each object is too large to fit in a
              single request. You can also use data splitting to improve performance by
              processing multiple concurrent mini-batches. The default value for ``SplitType`` is
              ``None`` , which indicates that input data files are not split, and request
              payloads contain the entire contents of an input object. Set the value of this
              parameter to ``Line`` to split records on a newline character boundary.
              ``SplitType`` also supports a number of record-oriented binary data formats.

              When splitting is enabled, the size of a mini-batch depends on the values of the
              ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
              ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
              records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
              ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records
              in each request.

              .. note::

                Some data formats represent a record as a binary payload wrapped with extra
                padding bytes. When splitting is applied to a binary data format, padding is
                removed if the value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is
                not removed if the value of ``BatchStrategy`` is set to ``MultiRecord`` .

                For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
                <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For
                more information about ``TFRecord`` , see `Consuming TFRecord data
                <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
                TensorFlow documentation.

          - **TransformOutput** *(dict) --*

            Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
            from the transform job.

            - **S3OutputPath** *(string) --*

              The Amazon S3 path where you want Amazon SageMaker to store the results of the
              transform job. For example, ``s3://bucket-name/key-name-prefix`` .

              For every S3 object used as input for the transform job, batch transform stores the
              transformed data with an .``out`` suffix in a corresponding subfolder in the
              location in the output prefix. For example, for the input data stored at
              ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores
              the transformed data at
              ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
              transform doesn't upload partially processed objects. For an input S3 object that
              contains multiple records, it creates an .``out`` file only if the transform job
              succeeds on the entire file. When the input contains multiple S3 objects, the batch
              transform job processes the listed S3 objects and uploads only the output for
              successfully processed objects. If any object fails in the transform job batch
              transform marks the job as failed to prompt investigation.

            - **Accept** *(string) --*

              The MIME type used to specify the output data. Amazon SageMaker uses the MIME type
              with each http call to transfer data from the transform job.

            - **AssembleWith** *(string) --*

              Defines how to assemble the results of the transform job as a single S3 object.
              Choose a format that is most convenient to you. To concatenate the results in
              binary format, specify ``None`` . To add a newline character at the end of every
              transformed record, specify ``Line`` .

            - **KmsKeyId** *(string) --*

              The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
              the model artifacts at rest using Amazon S3 server-side encryption. The
              ``KmsKeyId`` can be any of the following formats:

              * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // Amazon Resource Name (ARN) of a KMS Key
              ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // KMS Key Alias  ``"alias/ExampleAlias"``

              * // Amazon Resource Name (ARN) of a KMS Key Alias
              ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

              If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for
              Amazon S3 for your role's account. For more information, see `KMS-Managed
              Encryption Keys
              <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
              *Amazon Simple Storage Service Developer Guide.*

              The KMS key policy must grant permission to the IAM role that you specify in your
              CreateModel request. For more information, see `Using Key Policies in AWS KMS
              <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the
              *AWS Key Management Service Developer Guide* .

          - **TransformResources** *(dict) --*

            Identifies the ML compute instances for the transform job.

            - **InstanceType** *(string) --*

              The ML compute instance type for the transform job. If you are using built-in
              algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge
              or ``ml.m5.large`` instance types.

            - **InstanceCount** *(integer) --*

              The number of ML compute instances to use in the transform job. For distributed
              transform jobs, specify a value greater than 1. The default value is ``1`` .

            - **VolumeKmsKeyId** *(string) --*

              The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
              data on the storage volume attached to the ML compute instance(s) that run the
              batch transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

              * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // Amazon Resource Name (ARN) of a KMS Key
              ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientDescribeModelPackageResponseTypeDef = TypedDict(
    "_ClientDescribeModelPackageResponseTypeDef",
    {
        "ModelPackageName": str,
        "ModelPackageArn": str,
        "ModelPackageDescription": str,
        "CreationTime": datetime,
        "InferenceSpecification": ClientDescribeModelPackageResponseInferenceSpecificationTypeDef,
        "SourceAlgorithmSpecification": ClientDescribeModelPackageResponseSourceAlgorithmSpecificationTypeDef,
        "ValidationSpecification": ClientDescribeModelPackageResponseValidationSpecificationTypeDef,
        "ModelPackageStatus": str,
        "ModelPackageStatusDetails": ClientDescribeModelPackageResponseModelPackageStatusDetailsTypeDef,
        "CertifyForMarketplace": bool,
    },
    total=False,
)


class ClientDescribeModelPackageResponseTypeDef(
    _ClientDescribeModelPackageResponseTypeDef
):
    """
    Type definition for `ClientDescribeModelPackage` `Response`

    - **ModelPackageName** *(string) --*

      The name of the model package being described.

    - **ModelPackageArn** *(string) --*

      The Amazon Resource Name (ARN) of the model package.

    - **ModelPackageDescription** *(string) --*

      A brief summary of the model package.

    - **CreationTime** *(datetime) --*

      A timestamp specifying when the model package was created.

    - **InferenceSpecification** *(dict) --*

      Details about inference jobs that can be run with models based on this model package.

      - **Containers** *(list) --*

        The Amazon ECR registry path of the Docker image that contains the inference code.

        - *(dict) --*

          Describes the Docker container for the model package.

          - **ContainerHostname** *(string) --*

            The DNS host name for the Docker container.

          - **Image** *(string) --*

            The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.

            If you are using your own custom algorithm instead of an algorithm provided by Amazon
            SageMaker, the inference code must meet Amazon SageMaker requirements. Amazon SageMaker
            supports both ``registry/repository[:tag]`` and ``registry/repository[@digest]`` image
            path formats. For more information, see `Using Your Own Algorithms with Amazon
            SageMaker <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

          - **ImageDigest** *(string) --*

            An MD5 hash of the training algorithm that identifies the Docker image used for
            training.

          - **ModelDataUrl** *(string) --*

            The Amazon S3 path where the model artifacts, which result from model training, are
            stored. This path must point to a single ``gzip`` compressed tar archive (``.tar.gz``
            suffix).

          - **ProductId** *(string) --*

            The AWS Marketplace product ID of the model package.

      - **SupportedTransformInstanceTypes** *(list) --*

        A list of the instance types on which a transformation job can be run or on which an
        endpoint can be deployed.

        - *(string) --*

      - **SupportedRealtimeInferenceInstanceTypes** *(list) --*

        A list of the instance types that are used to generate inferences in real-time.

        - *(string) --*

      - **SupportedContentTypes** *(list) --*

        The supported MIME types for the input data.

        - *(string) --*

      - **SupportedResponseMIMETypes** *(list) --*

        The supported MIME types for the output data.

        - *(string) --*

    - **SourceAlgorithmSpecification** *(dict) --*

      Details about the algorithm that was used to create the model package.

      - **SourceAlgorithms** *(list) --*

        A list of the algorithms that were used to create a model package.

        - *(dict) --*

          Specifies an algorithm that was used to create the model package. The algorithm must be
          either an algorithm resource in your Amazon SageMaker account or an algorithm in AWS
          Marketplace that you are subscribed to.

          - **ModelDataUrl** *(string) --*

            The Amazon S3 path where the model artifacts, which result from model training, are
            stored. This path must point to a single ``gzip`` compressed tar archive (``.tar.gz``
            suffix).

          - **AlgorithmName** *(string) --*

            The name of an algorithm that was used to create the model package. The algorithm must
            be either an algorithm resource in your Amazon SageMaker account or an algorithm in AWS
            Marketplace that you are subscribed to.

    - **ValidationSpecification** *(dict) --*

      Configurations for one or more transform jobs that Amazon SageMaker runs to test the model
      package.

      - **ValidationRole** *(string) --*

        The IAM roles to be used for the validation of the model package.

      - **ValidationProfiles** *(list) --*

        An array of ``ModelPackageValidationProfile`` objects, each of which specifies a batch
        transform job that Amazon SageMaker runs to validate your model package.

        - *(dict) --*

          Contains data, such as the inputs and targeted instance types that are used in the
          process of validating the model package.

          The data provided in the validation profile is made available to your buyers on AWS
          Marketplace.

          - **ProfileName** *(string) --*

            The name of the profile for the model package.

          - **TransformJobDefinition** *(dict) --*

            The ``TransformJobDefinition`` object that describes the transform job used for the
            validation of the model package.

            - **MaxConcurrentTransforms** *(integer) --*

              The maximum number of parallel requests that can be sent to each instance in a
              transform job. The default value is 1.

            - **MaxPayloadInMB** *(integer) --*

              The maximum payload size allowed, in MB. A payload is the data portion of a record
              (without metadata).

            - **BatchStrategy** *(string) --*

              A string that determines the number of records included in a single mini-batch.

               ``SingleRecord`` means only one record is used per mini-batch. ``MultiRecord`` means
               a mini-batch is set to contain as many records that can fit within the
               ``MaxPayloadInMB`` limit.

            - **Environment** *(dict) --*

              The environment variables to set in the Docker container. We support up to 16 key and
              values entries in the map.

              - *(string) --*

                - *(string) --*

            - **TransformInput** *(dict) --*

              A description of the input source and the way the transform job consumes it.

              - **DataSource** *(dict) --*

                Describes the location of the channel data, which is, the S3 location of the input
                data that the model can consume.

                - **S3DataSource** *(dict) --*

                  The S3 location of the data source that is associated with a channel.

                  - **S3DataType** *(string) --*

                    If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
                    SageMaker uses all objects with the specified key name prefix for batch
                    transform.

                    If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
                    manifest file containing a list of object keys that you want Amazon SageMaker
                    to use for batch transform.

                    The following values are compatible: ``ManifestFile`` , ``S3Prefix``

                    The following value is not compatible: ``AugmentedManifestFile``

                  - **S3Uri** *(string) --*

                    Depending on the value specified for the ``S3DataType`` , identifies either a
                    key name prefix or a manifest. For example:

                    * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

                    * A manifest might look like this: ``s3://bucketname/example.manifest``   The
                    manifest is an S3 object which is a JSON file with the following format:   ``[
                    {"prefix": "s3://customer_bucket/some/prefix/"},``
                    ``"relative/path/to/custdata-1",``    ``"relative/path/custdata-2",``
                    ``...``    ``"relative/path/custdata-N"``    ``]``   The preceding JSON matches
                    the following ``s3Uris`` :
                    ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                    ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                    ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
                    set of ``S3Uris`` in this manifest constitutes the input data for the channel
                    for this datasource. The object that each ``S3Uris`` points to must be readable
                    by the IAM role that Amazon SageMaker uses to perform tasks on your behalf.

              - **ContentType** *(string) --*

                The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker
                uses the MIME type with each http call to transfer data to the transform job.

              - **CompressionType** *(string) --*

                If your transform data is compressed, specify the compression type. Amazon
                SageMaker automatically decompresses the data for the transform job accordingly.
                The default value is ``None`` .

              - **SplitType** *(string) --*

                The method to use to split the transform job's data files into smaller batches.
                Splitting is necessary when the total size of each object is too large to fit in a
                single request. You can also use data splitting to improve performance by
                processing multiple concurrent mini-batches. The default value for ``SplitType`` is
                ``None`` , which indicates that input data files are not split, and request
                payloads contain the entire contents of an input object. Set the value of this
                parameter to ``Line`` to split records on a newline character boundary.
                ``SplitType`` also supports a number of record-oriented binary data formats.

                When splitting is enabled, the size of a mini-batch depends on the values of the
                ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of
                ``BatchStrategy`` is ``MultiRecord`` , Amazon SageMaker sends the maximum number of
                records in each request, up to the ``MaxPayloadInMB`` limit. If the value of
                ``BatchStrategy`` is ``SingleRecord`` , Amazon SageMaker sends individual records
                in each request.

                .. note::

                  Some data formats represent a record as a binary payload wrapped with extra
                  padding bytes. When splitting is applied to a binary data format, padding is
                  removed if the value of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is
                  not removed if the value of ``BatchStrategy`` is set to ``MultiRecord`` .

                  For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
                  <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For
                  more information about ``TFRecord`` , see `Consuming TFRecord data
                  <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the
                  TensorFlow documentation.

            - **TransformOutput** *(dict) --*

              Identifies the Amazon S3 location where you want Amazon SageMaker to save the results
              from the transform job.

              - **S3OutputPath** *(string) --*

                The Amazon S3 path where you want Amazon SageMaker to store the results of the
                transform job. For example, ``s3://bucket-name/key-name-prefix`` .

                For every S3 object used as input for the transform job, batch transform stores the
                transformed data with an .``out`` suffix in a corresponding subfolder in the
                location in the output prefix. For example, for the input data stored at
                ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores
                the transformed data at
                ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out`` . Batch
                transform doesn't upload partially processed objects. For an input S3 object that
                contains multiple records, it creates an .``out`` file only if the transform job
                succeeds on the entire file. When the input contains multiple S3 objects, the batch
                transform job processes the listed S3 objects and uploads only the output for
                successfully processed objects. If any object fails in the transform job batch
                transform marks the job as failed to prompt investigation.

              - **Accept** *(string) --*

                The MIME type used to specify the output data. Amazon SageMaker uses the MIME type
                with each http call to transfer data from the transform job.

              - **AssembleWith** *(string) --*

                Defines how to assemble the results of the transform job as a single S3 object.
                Choose a format that is most convenient to you. To concatenate the results in
                binary format, specify ``None`` . To add a newline character at the end of every
                transformed record, specify ``Line`` .

              - **KmsKeyId** *(string) --*

                The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
                the model artifacts at rest using Amazon S3 server-side encryption. The
                ``KmsKeyId`` can be any of the following formats:

                * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

                * // Amazon Resource Name (ARN) of a KMS Key
                ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

                * // KMS Key Alias  ``"alias/ExampleAlias"``

                * // Amazon Resource Name (ARN) of a KMS Key Alias
                ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

                If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for
                Amazon S3 for your role's account. For more information, see `KMS-Managed
                Encryption Keys
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
                *Amazon Simple Storage Service Developer Guide.*

                The KMS key policy must grant permission to the IAM role that you specify in your
                CreateModel request. For more information, see `Using Key Policies in AWS KMS
                <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the
                *AWS Key Management Service Developer Guide* .

            - **TransformResources** *(dict) --*

              Identifies the ML compute instances for the transform job.

              - **InstanceType** *(string) --*

                The ML compute instance type for the transform job. If you are using built-in
                algorithms to transform moderately sized datasets, we recommend using ml.m4.xlarge
                or ``ml.m5.large`` instance types.

              - **InstanceCount** *(integer) --*

                The number of ML compute instances to use in the transform job. For distributed
                transform jobs, specify a value greater than 1. The default value is ``1`` .

              - **VolumeKmsKeyId** *(string) --*

                The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
                data on the storage volume attached to the ML compute instance(s) that run the
                batch transform job. The ``VolumeKmsKeyId`` can be any of the following formats:

                * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

                * // Amazon Resource Name (ARN) of a KMS Key
                ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

    - **ModelPackageStatus** *(string) --*

      The current status of the model package.

    - **ModelPackageStatusDetails** *(dict) --*

      Details about the current status of the model package.

      - **ValidationStatuses** *(list) --*

        The validation status of the model package.

        - *(dict) --*

          Represents the overall status of a model package.

          - **Name** *(string) --*

            The name of the model package for which the overall status is being reported.

          - **Status** *(string) --*

            The current status.

          - **FailureReason** *(string) --*

            if the overall status is ``Failed`` , the reason for the failure.

      - **ImageScanStatuses** *(list) --*

        The status of the scan of the Docker image container for the model package.

        - *(dict) --*

          Represents the overall status of a model package.

          - **Name** *(string) --*

            The name of the model package for which the overall status is being reported.

          - **Status** *(string) --*

            The current status.

          - **FailureReason** *(string) --*

            if the overall status is ``Failed`` , the reason for the failure.

    - **CertifyForMarketplace** *(boolean) --*

      Whether the model package is certified for listing on AWS Marketplace.
    """


_ClientDescribeModelResponseContainersTypeDef = TypedDict(
    "_ClientDescribeModelResponseContainersTypeDef",
    {
        "ContainerHostname": str,
        "Image": str,
        "Mode": str,
        "ModelDataUrl": str,
        "Environment": Dict[str, str],
        "ModelPackageName": str,
    },
    total=False,
)


class ClientDescribeModelResponseContainersTypeDef(
    _ClientDescribeModelResponseContainersTypeDef
):
    """
    Type definition for `ClientDescribeModelResponse` `Containers`

    Describes the container, as part of model definition.

    - **ContainerHostname** *(string) --*

      This parameter is ignored for models that contain only a ``PrimaryContainer`` .

      When a ``ContainerDefinition`` is part of an inference pipeline, the value of ths
      parameter uniquely identifies the container for the purposes of logging and metrics. For
      information, see `Use Logs and Metrics to Monitor an Inference Pipeline
      <https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipeline-logs-metrics.html>`__
      . If you don't specify a value for this parameter for a ``ContainerDefinition`` that is
      part of an inference pipeline, a unique name is automatically assigned based on the
      position of the ``ContainerDefinition`` in the pipeline. If you specify a value for the
      ``ContainerHostName`` for any ``ContainerDefinition`` that is part of an inference
      pipeline, you must specify a value for the ``ContainerHostName`` parameter of every
      ``ContainerDefinition`` in that pipeline.

    - **Image** *(string) --*

      The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored. If
      you are using your own custom algorithm instead of an algorithm provided by Amazon
      SageMaker, the inference code must meet Amazon SageMaker requirements. Amazon SageMaker
      supports both ``registry/repository[:tag]`` and ``registry/repository[@digest]`` image
      path formats. For more information, see `Using Your Own Algorithms with Amazon SageMaker
      <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__

    - **Mode** *(string) --*

      Specifies whether the container hosts a single model or multiple models.

    - **ModelDataUrl** *(string) --*

      The S3 path where the model artifacts, which result from model training, are stored. This
      path must point to a single gzip compressed tar archive (.tar.gz suffix). The S3 path is
      required for Amazon SageMaker built-in algorithms, but not if you use your own
      algorithms. For more information on built-in algorithms, see `Common Parameters
      <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
      .

      If you provide a value for this parameter, Amazon SageMaker uses AWS Security Token
      Service to download model artifacts from the S3 path you provide. AWS STS is activated in
      your IAM user account by default. If you previously deactivated AWS STS for a region, you
      need to reactivate AWS STS for that region. For more information, see `Activating and
      Deactivating AWS STS in an AWS Region
      <https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_enable-regions.html>`__
      in the *AWS Identity and Access Management User Guide* .

      .. warning::

        If you use a built-in algorithm to create a model, Amazon SageMaker requires that you
        provide a S3 path to the model artifacts in ``ModelDataUrl`` .

    - **Environment** *(dict) --*

      The environment variables to set in the Docker container. Each key and value in the
      ``Environment`` string to string map can have length of up to 1024. We support up to 16
      entries in the map.

      - *(string) --*

        - *(string) --*

    - **ModelPackageName** *(string) --*

      The name or Amazon Resource Name (ARN) of the model package to use to create the model.
    """


_ClientDescribeModelResponsePrimaryContainerTypeDef = TypedDict(
    "_ClientDescribeModelResponsePrimaryContainerTypeDef",
    {
        "ContainerHostname": str,
        "Image": str,
        "Mode": str,
        "ModelDataUrl": str,
        "Environment": Dict[str, str],
        "ModelPackageName": str,
    },
    total=False,
)


class ClientDescribeModelResponsePrimaryContainerTypeDef(
    _ClientDescribeModelResponsePrimaryContainerTypeDef
):
    """
    Type definition for `ClientDescribeModelResponse` `PrimaryContainer`

    The location of the primary inference code, associated artifacts, and custom environment map
    that the inference code uses when it is deployed in production.

    - **ContainerHostname** *(string) --*

      This parameter is ignored for models that contain only a ``PrimaryContainer`` .

      When a ``ContainerDefinition`` is part of an inference pipeline, the value of ths parameter
      uniquely identifies the container for the purposes of logging and metrics. For information,
      see `Use Logs and Metrics to Monitor an Inference Pipeline
      <https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipeline-logs-metrics.html>`__ .
      If you don't specify a value for this parameter for a ``ContainerDefinition`` that is part
      of an inference pipeline, a unique name is automatically assigned based on the position of
      the ``ContainerDefinition`` in the pipeline. If you specify a value for the
      ``ContainerHostName`` for any ``ContainerDefinition`` that is part of an inference
      pipeline, you must specify a value for the ``ContainerHostName`` parameter of every
      ``ContainerDefinition`` in that pipeline.

    - **Image** *(string) --*

      The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored. If you
      are using your own custom algorithm instead of an algorithm provided by Amazon SageMaker,
      the inference code must meet Amazon SageMaker requirements. Amazon SageMaker supports both
      ``registry/repository[:tag]`` and ``registry/repository[@digest]`` image path formats. For
      more information, see `Using Your Own Algorithms with Amazon SageMaker
      <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__

    - **Mode** *(string) --*

      Specifies whether the container hosts a single model or multiple models.

    - **ModelDataUrl** *(string) --*

      The S3 path where the model artifacts, which result from model training, are stored. This
      path must point to a single gzip compressed tar archive (.tar.gz suffix). The S3 path is
      required for Amazon SageMaker built-in algorithms, but not if you use your own algorithms.
      For more information on built-in algorithms, see `Common Parameters
      <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
      .

      If you provide a value for this parameter, Amazon SageMaker uses AWS Security Token Service
      to download model artifacts from the S3 path you provide. AWS STS is activated in your IAM
      user account by default. If you previously deactivated AWS STS for a region, you need to
      reactivate AWS STS for that region. For more information, see `Activating and Deactivating
      AWS STS in an AWS Region
      <https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_enable-regions.html>`__
      in the *AWS Identity and Access Management User Guide* .

      .. warning::

        If you use a built-in algorithm to create a model, Amazon SageMaker requires that you
        provide a S3 path to the model artifacts in ``ModelDataUrl`` .

    - **Environment** *(dict) --*

      The environment variables to set in the Docker container. Each key and value in the
      ``Environment`` string to string map can have length of up to 1024. We support up to 16
      entries in the map.

      - *(string) --*

        - *(string) --*

    - **ModelPackageName** *(string) --*

      The name or Amazon Resource Name (ARN) of the model package to use to create the model.
    """


_ClientDescribeModelResponseVpcConfigTypeDef = TypedDict(
    "_ClientDescribeModelResponseVpcConfigTypeDef",
    {"SecurityGroupIds": List[str], "Subnets": List[str]},
    total=False,
)


class ClientDescribeModelResponseVpcConfigTypeDef(
    _ClientDescribeModelResponseVpcConfigTypeDef
):
    """
    Type definition for `ClientDescribeModelResponse` `VpcConfig`

    A  VpcConfig object that specifies the VPC that this model has access to. For more
    information, see `Protect Endpoints by Using an Amazon Virtual Private Cloud
    <https://docs.aws.amazon.com/sagemaker/latest/dg/host-vpc.html>`__

    - **SecurityGroupIds** *(list) --*

      The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for the
      VPC that is specified in the ``Subnets`` field.

      - *(string) --*

    - **Subnets** *(list) --*

      The ID of the subnets in the VPC to which you want to connect your training job or model.

      .. note::

        Amazon EC2 P3 accelerated computing instances are not available in the c/d/e availability
        zones of region us-east-1. If you want to create endpoints with P3 instances in VPC mode
        in region us-east-1, create subnets in a/b/f availability zones instead.

      - *(string) --*
    """


_ClientDescribeModelResponseTypeDef = TypedDict(
    "_ClientDescribeModelResponseTypeDef",
    {
        "ModelName": str,
        "PrimaryContainer": ClientDescribeModelResponsePrimaryContainerTypeDef,
        "Containers": List[ClientDescribeModelResponseContainersTypeDef],
        "ExecutionRoleArn": str,
        "VpcConfig": ClientDescribeModelResponseVpcConfigTypeDef,
        "CreationTime": datetime,
        "ModelArn": str,
        "EnableNetworkIsolation": bool,
    },
    total=False,
)


class ClientDescribeModelResponseTypeDef(_ClientDescribeModelResponseTypeDef):
    """
    Type definition for `ClientDescribeModel` `Response`

    - **ModelName** *(string) --*

      Name of the Amazon SageMaker model.

    - **PrimaryContainer** *(dict) --*

      The location of the primary inference code, associated artifacts, and custom environment map
      that the inference code uses when it is deployed in production.

      - **ContainerHostname** *(string) --*

        This parameter is ignored for models that contain only a ``PrimaryContainer`` .

        When a ``ContainerDefinition`` is part of an inference pipeline, the value of ths parameter
        uniquely identifies the container for the purposes of logging and metrics. For information,
        see `Use Logs and Metrics to Monitor an Inference Pipeline
        <https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipeline-logs-metrics.html>`__ .
        If you don't specify a value for this parameter for a ``ContainerDefinition`` that is part
        of an inference pipeline, a unique name is automatically assigned based on the position of
        the ``ContainerDefinition`` in the pipeline. If you specify a value for the
        ``ContainerHostName`` for any ``ContainerDefinition`` that is part of an inference
        pipeline, you must specify a value for the ``ContainerHostName`` parameter of every
        ``ContainerDefinition`` in that pipeline.

      - **Image** *(string) --*

        The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored. If you
        are using your own custom algorithm instead of an algorithm provided by Amazon SageMaker,
        the inference code must meet Amazon SageMaker requirements. Amazon SageMaker supports both
        ``registry/repository[:tag]`` and ``registry/repository[@digest]`` image path formats. For
        more information, see `Using Your Own Algorithms with Amazon SageMaker
        <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__

      - **Mode** *(string) --*

        Specifies whether the container hosts a single model or multiple models.

      - **ModelDataUrl** *(string) --*

        The S3 path where the model artifacts, which result from model training, are stored. This
        path must point to a single gzip compressed tar archive (.tar.gz suffix). The S3 path is
        required for Amazon SageMaker built-in algorithms, but not if you use your own algorithms.
        For more information on built-in algorithms, see `Common Parameters
        <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
        .

        If you provide a value for this parameter, Amazon SageMaker uses AWS Security Token Service
        to download model artifacts from the S3 path you provide. AWS STS is activated in your IAM
        user account by default. If you previously deactivated AWS STS for a region, you need to
        reactivate AWS STS for that region. For more information, see `Activating and Deactivating
        AWS STS in an AWS Region
        <https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_enable-regions.html>`__
        in the *AWS Identity and Access Management User Guide* .

        .. warning::

          If you use a built-in algorithm to create a model, Amazon SageMaker requires that you
          provide a S3 path to the model artifacts in ``ModelDataUrl`` .

      - **Environment** *(dict) --*

        The environment variables to set in the Docker container. Each key and value in the
        ``Environment`` string to string map can have length of up to 1024. We support up to 16
        entries in the map.

        - *(string) --*

          - *(string) --*

      - **ModelPackageName** *(string) --*

        The name or Amazon Resource Name (ARN) of the model package to use to create the model.

    - **Containers** *(list) --*

      The containers in the inference pipeline.

      - *(dict) --*

        Describes the container, as part of model definition.

        - **ContainerHostname** *(string) --*

          This parameter is ignored for models that contain only a ``PrimaryContainer`` .

          When a ``ContainerDefinition`` is part of an inference pipeline, the value of ths
          parameter uniquely identifies the container for the purposes of logging and metrics. For
          information, see `Use Logs and Metrics to Monitor an Inference Pipeline
          <https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipeline-logs-metrics.html>`__
          . If you don't specify a value for this parameter for a ``ContainerDefinition`` that is
          part of an inference pipeline, a unique name is automatically assigned based on the
          position of the ``ContainerDefinition`` in the pipeline. If you specify a value for the
          ``ContainerHostName`` for any ``ContainerDefinition`` that is part of an inference
          pipeline, you must specify a value for the ``ContainerHostName`` parameter of every
          ``ContainerDefinition`` in that pipeline.

        - **Image** *(string) --*

          The Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored. If
          you are using your own custom algorithm instead of an algorithm provided by Amazon
          SageMaker, the inference code must meet Amazon SageMaker requirements. Amazon SageMaker
          supports both ``registry/repository[:tag]`` and ``registry/repository[@digest]`` image
          path formats. For more information, see `Using Your Own Algorithms with Amazon SageMaker
          <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__

        - **Mode** *(string) --*

          Specifies whether the container hosts a single model or multiple models.

        - **ModelDataUrl** *(string) --*

          The S3 path where the model artifacts, which result from model training, are stored. This
          path must point to a single gzip compressed tar archive (.tar.gz suffix). The S3 path is
          required for Amazon SageMaker built-in algorithms, but not if you use your own
          algorithms. For more information on built-in algorithms, see `Common Parameters
          <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
          .

          If you provide a value for this parameter, Amazon SageMaker uses AWS Security Token
          Service to download model artifacts from the S3 path you provide. AWS STS is activated in
          your IAM user account by default. If you previously deactivated AWS STS for a region, you
          need to reactivate AWS STS for that region. For more information, see `Activating and
          Deactivating AWS STS in an AWS Region
          <https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_enable-regions.html>`__
          in the *AWS Identity and Access Management User Guide* .

          .. warning::

            If you use a built-in algorithm to create a model, Amazon SageMaker requires that you
            provide a S3 path to the model artifacts in ``ModelDataUrl`` .

        - **Environment** *(dict) --*

          The environment variables to set in the Docker container. Each key and value in the
          ``Environment`` string to string map can have length of up to 1024. We support up to 16
          entries in the map.

          - *(string) --*

            - *(string) --*

        - **ModelPackageName** *(string) --*

          The name or Amazon Resource Name (ARN) of the model package to use to create the model.

    - **ExecutionRoleArn** *(string) --*

      The Amazon Resource Name (ARN) of the IAM role that you specified for the model.

    - **VpcConfig** *(dict) --*

      A  VpcConfig object that specifies the VPC that this model has access to. For more
      information, see `Protect Endpoints by Using an Amazon Virtual Private Cloud
      <https://docs.aws.amazon.com/sagemaker/latest/dg/host-vpc.html>`__

      - **SecurityGroupIds** *(list) --*

        The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for the
        VPC that is specified in the ``Subnets`` field.

        - *(string) --*

      - **Subnets** *(list) --*

        The ID of the subnets in the VPC to which you want to connect your training job or model.

        .. note::

          Amazon EC2 P3 accelerated computing instances are not available in the c/d/e availability
          zones of region us-east-1. If you want to create endpoints with P3 instances in VPC mode
          in region us-east-1, create subnets in a/b/f availability zones instead.

        - *(string) --*

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the model was created.

    - **ModelArn** *(string) --*

      The Amazon Resource Name (ARN) of the model.

    - **EnableNetworkIsolation** *(boolean) --*

      If ``True`` , no inbound or outbound network calls can be made to or from the model container.

      .. note::

        The Semantic Segmentation built-in algorithm does not support network isolation.
    """


_ClientDescribeNotebookInstanceLifecycleConfigResponseOnCreateTypeDef = TypedDict(
    "_ClientDescribeNotebookInstanceLifecycleConfigResponseOnCreateTypeDef",
    {"Content": str},
    total=False,
)


class ClientDescribeNotebookInstanceLifecycleConfigResponseOnCreateTypeDef(
    _ClientDescribeNotebookInstanceLifecycleConfigResponseOnCreateTypeDef
):
    """
    Type definition for `ClientDescribeNotebookInstanceLifecycleConfigResponse` `OnCreate`

    Contains the notebook instance lifecycle configuration script.

    Each lifecycle configuration script has a limit of 16384 characters.

    The value of the ``$PATH`` environment variable that is available to both scripts is
    ``/sbin:bin:/usr/sbin:/usr/bin`` .

    View CloudWatch Logs for notebook instance lifecycle configurations in log group
    ``/aws/sagemaker/NotebookInstances`` in log stream
    ``[notebook-instance-name]/[LifecycleConfigHook]`` .

    Lifecycle configuration scripts cannot run for longer than 5 minutes. If a script runs for
    longer than 5 minutes, it fails and the notebook instance is not created or started.

    For information about notebook instance lifestyle configurations, see `Step 2.1\\:
    (Optional) Customize a Notebook Instance
    <https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html>`__ .

    - **Content** *(string) --*

      A base64-encoded string that contains a shell script for a notebook instance lifecycle
      configuration.
    """


_ClientDescribeNotebookInstanceLifecycleConfigResponseOnStartTypeDef = TypedDict(
    "_ClientDescribeNotebookInstanceLifecycleConfigResponseOnStartTypeDef",
    {"Content": str},
    total=False,
)


class ClientDescribeNotebookInstanceLifecycleConfigResponseOnStartTypeDef(
    _ClientDescribeNotebookInstanceLifecycleConfigResponseOnStartTypeDef
):
    """
    Type definition for `ClientDescribeNotebookInstanceLifecycleConfigResponse` `OnStart`

    Contains the notebook instance lifecycle configuration script.

    Each lifecycle configuration script has a limit of 16384 characters.

    The value of the ``$PATH`` environment variable that is available to both scripts is
    ``/sbin:bin:/usr/sbin:/usr/bin`` .

    View CloudWatch Logs for notebook instance lifecycle configurations in log group
    ``/aws/sagemaker/NotebookInstances`` in log stream
    ``[notebook-instance-name]/[LifecycleConfigHook]`` .

    Lifecycle configuration scripts cannot run for longer than 5 minutes. If a script runs for
    longer than 5 minutes, it fails and the notebook instance is not created or started.

    For information about notebook instance lifestyle configurations, see `Step 2.1\\:
    (Optional) Customize a Notebook Instance
    <https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html>`__ .

    - **Content** *(string) --*

      A base64-encoded string that contains a shell script for a notebook instance lifecycle
      configuration.
    """


_ClientDescribeNotebookInstanceLifecycleConfigResponseTypeDef = TypedDict(
    "_ClientDescribeNotebookInstanceLifecycleConfigResponseTypeDef",
    {
        "NotebookInstanceLifecycleConfigArn": str,
        "NotebookInstanceLifecycleConfigName": str,
        "OnCreate": List[
            ClientDescribeNotebookInstanceLifecycleConfigResponseOnCreateTypeDef
        ],
        "OnStart": List[
            ClientDescribeNotebookInstanceLifecycleConfigResponseOnStartTypeDef
        ],
        "LastModifiedTime": datetime,
        "CreationTime": datetime,
    },
    total=False,
)


class ClientDescribeNotebookInstanceLifecycleConfigResponseTypeDef(
    _ClientDescribeNotebookInstanceLifecycleConfigResponseTypeDef
):
    """
    Type definition for `ClientDescribeNotebookInstanceLifecycleConfig` `Response`

    - **NotebookInstanceLifecycleConfigArn** *(string) --*

      The Amazon Resource Name (ARN) of the lifecycle configuration.

    - **NotebookInstanceLifecycleConfigName** *(string) --*

      The name of the lifecycle configuration.

    - **OnCreate** *(list) --*

      The shell script that runs only once, when you create a notebook instance.

      - *(dict) --*

        Contains the notebook instance lifecycle configuration script.

        Each lifecycle configuration script has a limit of 16384 characters.

        The value of the ``$PATH`` environment variable that is available to both scripts is
        ``/sbin:bin:/usr/sbin:/usr/bin`` .

        View CloudWatch Logs for notebook instance lifecycle configurations in log group
        ``/aws/sagemaker/NotebookInstances`` in log stream
        ``[notebook-instance-name]/[LifecycleConfigHook]`` .

        Lifecycle configuration scripts cannot run for longer than 5 minutes. If a script runs for
        longer than 5 minutes, it fails and the notebook instance is not created or started.

        For information about notebook instance lifestyle configurations, see `Step 2.1\\:
        (Optional) Customize a Notebook Instance
        <https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html>`__ .

        - **Content** *(string) --*

          A base64-encoded string that contains a shell script for a notebook instance lifecycle
          configuration.

    - **OnStart** *(list) --*

      The shell script that runs every time you start a notebook instance, including when you
      create the notebook instance.

      - *(dict) --*

        Contains the notebook instance lifecycle configuration script.

        Each lifecycle configuration script has a limit of 16384 characters.

        The value of the ``$PATH`` environment variable that is available to both scripts is
        ``/sbin:bin:/usr/sbin:/usr/bin`` .

        View CloudWatch Logs for notebook instance lifecycle configurations in log group
        ``/aws/sagemaker/NotebookInstances`` in log stream
        ``[notebook-instance-name]/[LifecycleConfigHook]`` .

        Lifecycle configuration scripts cannot run for longer than 5 minutes. If a script runs for
        longer than 5 minutes, it fails and the notebook instance is not created or started.

        For information about notebook instance lifestyle configurations, see `Step 2.1\\:
        (Optional) Customize a Notebook Instance
        <https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html>`__ .

        - **Content** *(string) --*

          A base64-encoded string that contains a shell script for a notebook instance lifecycle
          configuration.

    - **LastModifiedTime** *(datetime) --*

      A timestamp that tells when the lifecycle configuration was last modified.

    - **CreationTime** *(datetime) --*

      A timestamp that tells when the lifecycle configuration was created.
    """


_ClientDescribeNotebookInstanceResponseTypeDef = TypedDict(
    "_ClientDescribeNotebookInstanceResponseTypeDef",
    {
        "NotebookInstanceArn": str,
        "NotebookInstanceName": str,
        "NotebookInstanceStatus": str,
        "FailureReason": str,
        "Url": str,
        "InstanceType": str,
        "SubnetId": str,
        "SecurityGroups": List[str],
        "RoleArn": str,
        "KmsKeyId": str,
        "NetworkInterfaceId": str,
        "LastModifiedTime": datetime,
        "CreationTime": datetime,
        "NotebookInstanceLifecycleConfigName": str,
        "DirectInternetAccess": str,
        "VolumeSizeInGB": int,
        "AcceleratorTypes": List[str],
        "DefaultCodeRepository": str,
        "AdditionalCodeRepositories": List[str],
        "RootAccess": str,
    },
    total=False,
)


class ClientDescribeNotebookInstanceResponseTypeDef(
    _ClientDescribeNotebookInstanceResponseTypeDef
):
    """
    Type definition for `ClientDescribeNotebookInstance` `Response`

    - **NotebookInstanceArn** *(string) --*

      The Amazon Resource Name (ARN) of the notebook instance.

    - **NotebookInstanceName** *(string) --*

      The name of the Amazon SageMaker notebook instance.

    - **NotebookInstanceStatus** *(string) --*

      The status of the notebook instance.

    - **FailureReason** *(string) --*

      If status is ``Failed`` , the reason it failed.

    - **Url** *(string) --*

      The URL that you use to connect to the Jupyter notebook that is running in your notebook
      instance.

    - **InstanceType** *(string) --*

      The type of ML compute instance running on the notebook instance.

    - **SubnetId** *(string) --*

      The ID of the VPC subnet.

    - **SecurityGroups** *(list) --*

      The IDs of the VPC security groups.

      - *(string) --*

    - **RoleArn** *(string) --*

      The Amazon Resource Name (ARN) of the IAM role associated with the instance.

    - **KmsKeyId** *(string) --*

      The AWS KMS key ID Amazon SageMaker uses to encrypt data when storing it on the ML storage
      volume attached to the instance.

    - **NetworkInterfaceId** *(string) --*

      The network interface IDs that Amazon SageMaker created at the time of creating the instance.

    - **LastModifiedTime** *(datetime) --*

      A timestamp. Use this parameter to retrieve the time when the notebook instance was last
      modified.

    - **CreationTime** *(datetime) --*

      A timestamp. Use this parameter to return the time when the notebook instance was created

    - **NotebookInstanceLifecycleConfigName** *(string) --*

      Returns the name of a notebook instance lifecycle configuration.

      For information about notebook instance lifestyle configurations, see `Step 2.1\\: (Optional)
      Customize a Notebook Instance
      <https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html>`__

    - **DirectInternetAccess** *(string) --*

      Describes whether Amazon SageMaker provides internet access to the notebook instance. If this
      value is set to *Disabled* , the notebook instance does not have internet access, and cannot
      connect to Amazon SageMaker training and endpoint services.

      For more information, see `Notebook Instances Are Internet-Enabled by Default
      <https://docs.aws.amazon.com/sagemaker/latest/dg/appendix-additional-considerations.html#appendix-notebook-and-internet-access>`__
      .

    - **VolumeSizeInGB** *(integer) --*

      The size, in GB, of the ML storage volume attached to the notebook instance.

    - **AcceleratorTypes** *(list) --*

      A list of the Elastic Inference (EI) instance types associated with this notebook instance.
      Currently only one EI instance type can be associated with a notebook instance. For more
      information, see `Using Elastic Inference in Amazon SageMaker
      <sagemaker/latest/dg/ei.html>`__ .

      - *(string) --*

    - **DefaultCodeRepository** *(string) --*

      The Git repository associated with the notebook instance as its default code repository. This
      can be either the name of a Git repository stored as a resource in your account, or the URL
      of a Git repository in `AWS CodeCommit
      <https://docs.aws.amazon.com/codecommit/latest/userguide/welcome.html>`__ or in any other Git
      repository. When you open a notebook instance, it opens in the directory that contains this
      repository. For more information, see `Associating Git Repositories with Amazon SageMaker
      Notebook Instances <https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-git-repo.html>`__ .

    - **AdditionalCodeRepositories** *(list) --*

      An array of up to three Git repositories associated with the notebook instance. These can be
      either the names of Git repositories stored as resources in your account, or the URL of Git
      repositories in `AWS CodeCommit
      <https://docs.aws.amazon.com/codecommit/latest/userguide/welcome.html>`__ or in any other Git
      repository. These repositories are cloned at the same level as the default repository of your
      notebook instance. For more information, see `Associating Git Repositories with Amazon
      SageMaker Notebook Instances
      <https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-git-repo.html>`__ .

      - *(string) --*

    - **RootAccess** *(string) --*

      Whether root access is enabled or disabled for users of the notebook instance.

      .. note::

        Lifecycle configurations need root access to be able to set up a notebook instance. Because
        of this, lifecycle configurations associated with a notebook instance always run with root
        access even if you disable root access for users.
    """


_ClientDescribeSubscribedWorkteamResponseSubscribedWorkteamTypeDef = TypedDict(
    "_ClientDescribeSubscribedWorkteamResponseSubscribedWorkteamTypeDef",
    {
        "WorkteamArn": str,
        "MarketplaceTitle": str,
        "SellerName": str,
        "MarketplaceDescription": str,
        "ListingId": str,
    },
    total=False,
)


class ClientDescribeSubscribedWorkteamResponseSubscribedWorkteamTypeDef(
    _ClientDescribeSubscribedWorkteamResponseSubscribedWorkteamTypeDef
):
    """
    Type definition for `ClientDescribeSubscribedWorkteamResponse` `SubscribedWorkteam`

    A ``Workteam`` instance that contains information about the work team.

    - **WorkteamArn** *(string) --*

      The Amazon Resource Name (ARN) of the vendor that you have subscribed.

    - **MarketplaceTitle** *(string) --*

      The title of the service provided by the vendor in the Amazon Marketplace.

    - **SellerName** *(string) --*

      The name of the vendor in the Amazon Marketplace.

    - **MarketplaceDescription** *(string) --*

      The description of the vendor from the Amazon Marketplace.

    - **ListingId** *(string) --*
    """


_ClientDescribeSubscribedWorkteamResponseTypeDef = TypedDict(
    "_ClientDescribeSubscribedWorkteamResponseTypeDef",
    {
        "SubscribedWorkteam": ClientDescribeSubscribedWorkteamResponseSubscribedWorkteamTypeDef
    },
    total=False,
)


class ClientDescribeSubscribedWorkteamResponseTypeDef(
    _ClientDescribeSubscribedWorkteamResponseTypeDef
):
    """
    Type definition for `ClientDescribeSubscribedWorkteam` `Response`

    - **SubscribedWorkteam** *(dict) --*

      A ``Workteam`` instance that contains information about the work team.

      - **WorkteamArn** *(string) --*

        The Amazon Resource Name (ARN) of the vendor that you have subscribed.

      - **MarketplaceTitle** *(string) --*

        The title of the service provided by the vendor in the Amazon Marketplace.

      - **SellerName** *(string) --*

        The name of the vendor in the Amazon Marketplace.

      - **MarketplaceDescription** *(string) --*

        The description of the vendor from the Amazon Marketplace.

      - **ListingId** *(string) --*
    """


_ClientDescribeTrainingJobResponseAlgorithmSpecificationMetricDefinitionsTypeDef = TypedDict(
    "_ClientDescribeTrainingJobResponseAlgorithmSpecificationMetricDefinitionsTypeDef",
    {"Name": str, "Regex": str},
    total=False,
)


class ClientDescribeTrainingJobResponseAlgorithmSpecificationMetricDefinitionsTypeDef(
    _ClientDescribeTrainingJobResponseAlgorithmSpecificationMetricDefinitionsTypeDef
):
    """
    Type definition for `ClientDescribeTrainingJobResponseAlgorithmSpecification` `MetricDefinitions`

    Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
    Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
    metric that a hyperparameter tuning job uses as its objective metric to choose the best
    training job.

    - **Name** *(string) --*

      The name of the metric.

    - **Regex** *(string) --*

      A regular expression that searches the output of a training job and gets the value of
      the metric. For more information about using regular expressions to define metrics, see
      `Defining Objective Metrics
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
      .
    """


_ClientDescribeTrainingJobResponseAlgorithmSpecificationTypeDef = TypedDict(
    "_ClientDescribeTrainingJobResponseAlgorithmSpecificationTypeDef",
    {
        "TrainingImage": str,
        "AlgorithmName": str,
        "TrainingInputMode": str,
        "MetricDefinitions": List[
            ClientDescribeTrainingJobResponseAlgorithmSpecificationMetricDefinitionsTypeDef
        ],
    },
    total=False,
)


class ClientDescribeTrainingJobResponseAlgorithmSpecificationTypeDef(
    _ClientDescribeTrainingJobResponseAlgorithmSpecificationTypeDef
):
    """
    Type definition for `ClientDescribeTrainingJobResponse` `AlgorithmSpecification`

    Information about the algorithm used for training, and algorithm metadata.

    - **TrainingImage** *(string) --*

      The registry path of the Docker image that contains the training algorithm. For information
      about docker registry paths for built-in algorithms, see `Algorithms Provided by Amazon
      SageMaker\\: Common Parameters
      <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
      . Amazon SageMaker supports both ``registry/repository[:tag]`` and
      ``registry/repository[@digest]`` image path formats. For more information, see `Using Your
      Own Algorithms with Amazon SageMaker
      <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

    - **AlgorithmName** *(string) --*

      The name of the algorithm resource to use for the training job. This must be an algorithm
      resource that you created or subscribe to on AWS Marketplace. If you specify a value for
      this parameter, you can't specify a value for ``TrainingImage`` .

    - **TrainingInputMode** *(string) --*

      The input mode that the algorithm supports. For the input modes that Amazon SageMaker
      algorithms support, see `Algorithms
      <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ . If an algorithm supports
      the ``File`` input mode, Amazon SageMaker downloads the training data from S3 to the
      provisioned ML storage Volume, and mounts the directory to docker volume for training
      container. If an algorithm supports the ``Pipe`` input mode, Amazon SageMaker streams data
      directly from S3 to the container.

      In File mode, make sure you provision ML storage volume with sufficient capacity to
      accommodate the data download from S3. In addition to the training data, the ML storage
      volume also stores the output model. The algorithm container use ML storage volume to also
      store intermediate information, if any.

      For distributed algorithms using File mode, training data is distributed uniformly, and
      your training duration is predictable if the input data objects size is approximately same.
      Amazon SageMaker does not split the files any further for model training. If the object
      sizes are skewed, training won't be optimal as the data distribution is also skewed where
      one host in a training cluster is overloaded, thus becoming bottleneck in training.

    - **MetricDefinitions** *(list) --*

      A list of metric definition objects. Each object specifies the metric name and regular
      expressions used to parse algorithm logs. Amazon SageMaker publishes each metric to Amazon
      CloudWatch.

      - *(dict) --*

        Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
        Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
        metric that a hyperparameter tuning job uses as its objective metric to choose the best
        training job.

        - **Name** *(string) --*

          The name of the metric.

        - **Regex** *(string) --*

          A regular expression that searches the output of a training job and gets the value of
          the metric. For more information about using regular expressions to define metrics, see
          `Defining Objective Metrics
          <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
          .
    """


_ClientDescribeTrainingJobResponseCheckpointConfigTypeDef = TypedDict(
    "_ClientDescribeTrainingJobResponseCheckpointConfigTypeDef",
    {"S3Uri": str, "LocalPath": str},
    total=False,
)


class ClientDescribeTrainingJobResponseCheckpointConfigTypeDef(
    _ClientDescribeTrainingJobResponseCheckpointConfigTypeDef
):
    """
    Type definition for `ClientDescribeTrainingJobResponse` `CheckpointConfig`

    Contains information about the output location for managed spot training checkpoint data.

    - **S3Uri** *(string) --*

      Identifies the S3 path where you want Amazon SageMaker to store checkpoints. For example,
      ``s3://bucket-name/key-name-prefix`` .

    - **LocalPath** *(string) --*

      (Optional) The local directory where checkpoints are written. The default directory is
      ``/opt/ml/checkpoints/`` .
    """


_ClientDescribeTrainingJobResponseFinalMetricDataListTypeDef = TypedDict(
    "_ClientDescribeTrainingJobResponseFinalMetricDataListTypeDef",
    {"MetricName": str, "Value": float, "Timestamp": datetime},
    total=False,
)


class ClientDescribeTrainingJobResponseFinalMetricDataListTypeDef(
    _ClientDescribeTrainingJobResponseFinalMetricDataListTypeDef
):
    """
    Type definition for `ClientDescribeTrainingJobResponse` `FinalMetricDataList`

    The name, value, and date and time of a metric that was emitted to Amazon CloudWatch.

    - **MetricName** *(string) --*

      The name of the metric.

    - **Value** *(float) --*

      The value of the metric.

    - **Timestamp** *(datetime) --*

      The date and time that the algorithm emitted the metric.
    """


_ClientDescribeTrainingJobResponseInputDataConfigDataSourceFileSystemDataSourceTypeDef = TypedDict(
    "_ClientDescribeTrainingJobResponseInputDataConfigDataSourceFileSystemDataSourceTypeDef",
    {
        "FileSystemId": str,
        "FileSystemAccessMode": str,
        "FileSystemType": str,
        "DirectoryPath": str,
    },
    total=False,
)


class ClientDescribeTrainingJobResponseInputDataConfigDataSourceFileSystemDataSourceTypeDef(
    _ClientDescribeTrainingJobResponseInputDataConfigDataSourceFileSystemDataSourceTypeDef
):
    """
    Type definition for `ClientDescribeTrainingJobResponseInputDataConfigDataSource` `FileSystemDataSource`

    The file system that is associated with a channel.

    - **FileSystemId** *(string) --*

      The file system id.

    - **FileSystemAccessMode** *(string) --*

      The access mode of the mount of the directory associated with the channel. A
      directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

    - **FileSystemType** *(string) --*

      The file system type.

    - **DirectoryPath** *(string) --*

      The full path to the directory to associate with the channel.
    """


_ClientDescribeTrainingJobResponseInputDataConfigDataSourceS3DataSourceTypeDef = TypedDict(
    "_ClientDescribeTrainingJobResponseInputDataConfigDataSourceS3DataSourceTypeDef",
    {
        "S3DataType": str,
        "S3Uri": str,
        "S3DataDistributionType": str,
        "AttributeNames": List[str],
    },
    total=False,
)


class ClientDescribeTrainingJobResponseInputDataConfigDataSourceS3DataSourceTypeDef(
    _ClientDescribeTrainingJobResponseInputDataConfigDataSourceS3DataSourceTypeDef
):
    """
    Type definition for `ClientDescribeTrainingJobResponseInputDataConfigDataSource` `S3DataSource`

    The S3 location of the data source that is associated with a channel.

    - **S3DataType** *(string) --*

      If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker
      uses all objects that match the specified key name prefix for model training.

      If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
      file containing a list of object keys that you want Amazon SageMaker to use for model
      training.

      If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
      augmented manifest file in JSON lines format. This file contains the data you want to
      use for model training. ``AugmentedManifestFile`` can only be used if the Channel's
      input mode is ``Pipe`` .

    - **S3Uri** *(string) --*

      Depending on the value specified for the ``S3DataType`` , identifies either a key
      name prefix or a manifest. For example:

      * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

      * A manifest might look like this: ``s3://bucketname/example.manifest``   The
      manifest is an S3 object which is a JSON file with the following format:  The
      preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
      "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
      ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``    ``]``
        The preceding JSON matches the following ``s3Uris`` :
        ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
        ``s3uris`` in this manifest is the input data for the channel for this datasource.
        The object that each ``s3uris`` points to must be readable by the IAM role that
        Amazon SageMaker uses to perform tasks on your behalf.

    - **S3DataDistributionType** *(string) --*

      If you want Amazon SageMaker to replicate the entire dataset on each ML compute
      instance that is launched for model training, specify ``FullyReplicated`` .

      If you want Amazon SageMaker to replicate a subset of data on each ML compute
      instance that is launched for model training, specify ``ShardedByS3Key`` . If there
      are *n* ML compute instances launched for a training job, each instance gets
      approximately 1/*n* of the number of S3 objects. In this case, model training on each
      machine uses only the subset of training data.

      Don't choose more ML compute instances for training than available S3 objects. If you
      do, some nodes won't get any data and you will pay for nodes that aren't getting any
      training data. This applies in both File and Pipe modes. Keep this in mind when
      developing algorithms.

      In distributed training, where you use multiple ML compute EC2 instances, you might
      choose ``ShardedByS3Key`` . If the algorithm requires copying training data to the ML
      storage volume (when ``TrainingInputMode`` is set to ``File`` ), this copies 1/*n* of
      the number of objects.

    - **AttributeNames** *(list) --*

      A list of one or more attribute names to use that are found in a specified augmented
      manifest file.

      - *(string) --*
    """


_ClientDescribeTrainingJobResponseInputDataConfigDataSourceTypeDef = TypedDict(
    "_ClientDescribeTrainingJobResponseInputDataConfigDataSourceTypeDef",
    {
        "S3DataSource": ClientDescribeTrainingJobResponseInputDataConfigDataSourceS3DataSourceTypeDef,
        "FileSystemDataSource": ClientDescribeTrainingJobResponseInputDataConfigDataSourceFileSystemDataSourceTypeDef,
    },
    total=False,
)


class ClientDescribeTrainingJobResponseInputDataConfigDataSourceTypeDef(
    _ClientDescribeTrainingJobResponseInputDataConfigDataSourceTypeDef
):
    """
    Type definition for `ClientDescribeTrainingJobResponseInputDataConfig` `DataSource`

    The location of the channel data.

    - **S3DataSource** *(dict) --*

      The S3 location of the data source that is associated with a channel.

      - **S3DataType** *(string) --*

        If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker
        uses all objects that match the specified key name prefix for model training.

        If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
        file containing a list of object keys that you want Amazon SageMaker to use for model
        training.

        If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
        augmented manifest file in JSON lines format. This file contains the data you want to
        use for model training. ``AugmentedManifestFile`` can only be used if the Channel's
        input mode is ``Pipe`` .

      - **S3Uri** *(string) --*

        Depending on the value specified for the ``S3DataType`` , identifies either a key
        name prefix or a manifest. For example:

        * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

        * A manifest might look like this: ``s3://bucketname/example.manifest``   The
        manifest is an S3 object which is a JSON file with the following format:  The
        preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
        "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
        ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``    ``]``
          The preceding JSON matches the following ``s3Uris`` :
          ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
          ``s3uris`` in this manifest is the input data for the channel for this datasource.
          The object that each ``s3uris`` points to must be readable by the IAM role that
          Amazon SageMaker uses to perform tasks on your behalf.

      - **S3DataDistributionType** *(string) --*

        If you want Amazon SageMaker to replicate the entire dataset on each ML compute
        instance that is launched for model training, specify ``FullyReplicated`` .

        If you want Amazon SageMaker to replicate a subset of data on each ML compute
        instance that is launched for model training, specify ``ShardedByS3Key`` . If there
        are *n* ML compute instances launched for a training job, each instance gets
        approximately 1/*n* of the number of S3 objects. In this case, model training on each
        machine uses only the subset of training data.

        Don't choose more ML compute instances for training than available S3 objects. If you
        do, some nodes won't get any data and you will pay for nodes that aren't getting any
        training data. This applies in both File and Pipe modes. Keep this in mind when
        developing algorithms.

        In distributed training, where you use multiple ML compute EC2 instances, you might
        choose ``ShardedByS3Key`` . If the algorithm requires copying training data to the ML
        storage volume (when ``TrainingInputMode`` is set to ``File`` ), this copies 1/*n* of
        the number of objects.

      - **AttributeNames** *(list) --*

        A list of one or more attribute names to use that are found in a specified augmented
        manifest file.

        - *(string) --*

    - **FileSystemDataSource** *(dict) --*

      The file system that is associated with a channel.

      - **FileSystemId** *(string) --*

        The file system id.

      - **FileSystemAccessMode** *(string) --*

        The access mode of the mount of the directory associated with the channel. A
        directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

      - **FileSystemType** *(string) --*

        The file system type.

      - **DirectoryPath** *(string) --*

        The full path to the directory to associate with the channel.
    """


_ClientDescribeTrainingJobResponseInputDataConfigShuffleConfigTypeDef = TypedDict(
    "_ClientDescribeTrainingJobResponseInputDataConfigShuffleConfigTypeDef",
    {"Seed": int},
    total=False,
)


class ClientDescribeTrainingJobResponseInputDataConfigShuffleConfigTypeDef(
    _ClientDescribeTrainingJobResponseInputDataConfigShuffleConfigTypeDef
):
    """
    Type definition for `ClientDescribeTrainingJobResponseInputDataConfig` `ShuffleConfig`

    A configuration for a shuffle option for input data in a channel. If you use ``S3Prefix``
    for ``S3DataType`` , this shuffles the results of the S3 key prefix matches. If you use
    ``ManifestFile`` , the order of the S3 object references in the ``ManifestFile`` is
    shuffled. If you use ``AugmentedManifestFile`` , the order of the JSON lines in the
    ``AugmentedManifestFile`` is shuffled. The shuffling order is determined using the
    ``Seed`` value.

    For Pipe input mode, shuffling is done at the start of every epoch. With large datasets
    this ensures that the order of the training data is different for each epoch, it helps
    reduce bias and possible overfitting. In a multi-node training job when ShuffleConfig is
    combined with ``S3DataDistributionType`` of ``ShardedByS3Key`` , the data is shuffled
    across nodes so that the content sent to a particular node on the first epoch might be
    sent to a different node on the second epoch.

    - **Seed** *(integer) --*

      Determines the shuffling order in ``ShuffleConfig`` value.
    """


_ClientDescribeTrainingJobResponseInputDataConfigTypeDef = TypedDict(
    "_ClientDescribeTrainingJobResponseInputDataConfigTypeDef",
    {
        "ChannelName": str,
        "DataSource": ClientDescribeTrainingJobResponseInputDataConfigDataSourceTypeDef,
        "ContentType": str,
        "CompressionType": str,
        "RecordWrapperType": str,
        "InputMode": str,
        "ShuffleConfig": ClientDescribeTrainingJobResponseInputDataConfigShuffleConfigTypeDef,
    },
    total=False,
)


class ClientDescribeTrainingJobResponseInputDataConfigTypeDef(
    _ClientDescribeTrainingJobResponseInputDataConfigTypeDef
):
    """
    Type definition for `ClientDescribeTrainingJobResponse` `InputDataConfig`

    A channel is a named input source that training algorithms can consume.

    - **ChannelName** *(string) --*

      The name of the channel.

    - **DataSource** *(dict) --*

      The location of the channel data.

      - **S3DataSource** *(dict) --*

        The S3 location of the data source that is associated with a channel.

        - **S3DataType** *(string) --*

          If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker
          uses all objects that match the specified key name prefix for model training.

          If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
          file containing a list of object keys that you want Amazon SageMaker to use for model
          training.

          If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
          augmented manifest file in JSON lines format. This file contains the data you want to
          use for model training. ``AugmentedManifestFile`` can only be used if the Channel's
          input mode is ``Pipe`` .

        - **S3Uri** *(string) --*

          Depending on the value specified for the ``S3DataType`` , identifies either a key
          name prefix or a manifest. For example:

          * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

          * A manifest might look like this: ``s3://bucketname/example.manifest``   The
          manifest is an S3 object which is a JSON file with the following format:  The
          preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
          "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
          ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``    ``]``
            The preceding JSON matches the following ``s3Uris`` :
            ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
            ``s3uris`` in this manifest is the input data for the channel for this datasource.
            The object that each ``s3uris`` points to must be readable by the IAM role that
            Amazon SageMaker uses to perform tasks on your behalf.

        - **S3DataDistributionType** *(string) --*

          If you want Amazon SageMaker to replicate the entire dataset on each ML compute
          instance that is launched for model training, specify ``FullyReplicated`` .

          If you want Amazon SageMaker to replicate a subset of data on each ML compute
          instance that is launched for model training, specify ``ShardedByS3Key`` . If there
          are *n* ML compute instances launched for a training job, each instance gets
          approximately 1/*n* of the number of S3 objects. In this case, model training on each
          machine uses only the subset of training data.

          Don't choose more ML compute instances for training than available S3 objects. If you
          do, some nodes won't get any data and you will pay for nodes that aren't getting any
          training data. This applies in both File and Pipe modes. Keep this in mind when
          developing algorithms.

          In distributed training, where you use multiple ML compute EC2 instances, you might
          choose ``ShardedByS3Key`` . If the algorithm requires copying training data to the ML
          storage volume (when ``TrainingInputMode`` is set to ``File`` ), this copies 1/*n* of
          the number of objects.

        - **AttributeNames** *(list) --*

          A list of one or more attribute names to use that are found in a specified augmented
          manifest file.

          - *(string) --*

      - **FileSystemDataSource** *(dict) --*

        The file system that is associated with a channel.

        - **FileSystemId** *(string) --*

          The file system id.

        - **FileSystemAccessMode** *(string) --*

          The access mode of the mount of the directory associated with the channel. A
          directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

        - **FileSystemType** *(string) --*

          The file system type.

        - **DirectoryPath** *(string) --*

          The full path to the directory to associate with the channel.

    - **ContentType** *(string) --*

      The MIME type of the data.

    - **CompressionType** *(string) --*

      If training data is compressed, the compression type. The default value is ``None`` .
      ``CompressionType`` is used only in Pipe input mode. In File mode, leave this field unset
      or set it to None.

    - **RecordWrapperType** *(string) --*

      Specify RecordIO as the value when input data is in raw format but the training algorithm
      requires the RecordIO format. In this case, Amazon SageMaker wraps each individual S3
      object in a RecordIO record. If the input data is already in RecordIO format, you don't
      need to set this attribute. For more information, see `Create a Dataset Using RecordIO
      <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__ .

      In File mode, leave this field unset or set it to None.

    - **InputMode** *(string) --*

      (Optional) The input mode to use for the data channel in a training job. If you don't set
      a value for ``InputMode`` , Amazon SageMaker uses the value set for ``TrainingInputMode``
      . Use this parameter to override the ``TrainingInputMode`` setting in a
      AlgorithmSpecification request when you have a channel that needs a different input mode
      from the training job's general setting. To download the data from Amazon Simple Storage
      Service (Amazon S3) to the provisioned ML storage volume, and mount the directory to a
      Docker volume, use ``File`` input mode. To stream data directly from Amazon S3 to the
      container, choose ``Pipe`` input mode.

      To use a model for incremental training, choose ``File`` input model.

    - **ShuffleConfig** *(dict) --*

      A configuration for a shuffle option for input data in a channel. If you use ``S3Prefix``
      for ``S3DataType`` , this shuffles the results of the S3 key prefix matches. If you use
      ``ManifestFile`` , the order of the S3 object references in the ``ManifestFile`` is
      shuffled. If you use ``AugmentedManifestFile`` , the order of the JSON lines in the
      ``AugmentedManifestFile`` is shuffled. The shuffling order is determined using the
      ``Seed`` value.

      For Pipe input mode, shuffling is done at the start of every epoch. With large datasets
      this ensures that the order of the training data is different for each epoch, it helps
      reduce bias and possible overfitting. In a multi-node training job when ShuffleConfig is
      combined with ``S3DataDistributionType`` of ``ShardedByS3Key`` , the data is shuffled
      across nodes so that the content sent to a particular node on the first epoch might be
      sent to a different node on the second epoch.

      - **Seed** *(integer) --*

        Determines the shuffling order in ``ShuffleConfig`` value.
    """


_ClientDescribeTrainingJobResponseModelArtifactsTypeDef = TypedDict(
    "_ClientDescribeTrainingJobResponseModelArtifactsTypeDef",
    {"S3ModelArtifacts": str},
    total=False,
)


class ClientDescribeTrainingJobResponseModelArtifactsTypeDef(
    _ClientDescribeTrainingJobResponseModelArtifactsTypeDef
):
    """
    Type definition for `ClientDescribeTrainingJobResponse` `ModelArtifacts`

    Information about the Amazon S3 location that is configured for storing model artifacts.

    - **S3ModelArtifacts** *(string) --*

      The path of the S3 object that contains the model artifacts. For example,
      ``s3://bucket-name/keynameprefix/model.tar.gz`` .
    """


_ClientDescribeTrainingJobResponseOutputDataConfigTypeDef = TypedDict(
    "_ClientDescribeTrainingJobResponseOutputDataConfigTypeDef",
    {"KmsKeyId": str, "S3OutputPath": str},
    total=False,
)


class ClientDescribeTrainingJobResponseOutputDataConfigTypeDef(
    _ClientDescribeTrainingJobResponseOutputDataConfigTypeDef
):
    """
    Type definition for `ClientDescribeTrainingJobResponse` `OutputDataConfig`

    The S3 path where model artifacts that you configured when creating the job are stored.
    Amazon SageMaker creates subfolders for model artifacts.

    - **KmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
      model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be any
      of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // KMS Key Alias  ``"alias/ExampleAlias"``

      * // Amazon Resource Name (ARN) of a KMS Key Alias
      ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

      If you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution role
      must include permissions to call ``kms:Encrypt`` . If you don't provide a KMS key ID,
      Amazon SageMaker uses the default KMS key for Amazon S3 for your role's account. Amazon
      SageMaker uses server-side encryption with KMS-managed keys for ``OutputDataConfig`` . If
      you use a bucket policy with an ``s3:PutObject`` permission that only allows objects with
      server-side encryption, set the condition key of ``s3:x-amz-server-side-encryption`` to
      ``"aws:kms"`` . For more information, see `KMS-Managed Encryption Keys
      <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the *Amazon
      Simple Storage Service Developer Guide.*

      The KMS key policy must grant permission to the IAM role that you specify in your
      ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
      requests. For more information, see `Using Key Policies in AWS KMS
      <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
      in the *AWS Key Management Service Developer Guide* .

    - **S3OutputPath** *(string) --*

      Identifies the S3 path where you want Amazon SageMaker to store the model artifacts. For
      example, ``s3://bucket-name/key-name-prefix`` .
    """


_ClientDescribeTrainingJobResponseResourceConfigTypeDef = TypedDict(
    "_ClientDescribeTrainingJobResponseResourceConfigTypeDef",
    {
        "InstanceType": str,
        "InstanceCount": int,
        "VolumeSizeInGB": int,
        "VolumeKmsKeyId": str,
    },
    total=False,
)


class ClientDescribeTrainingJobResponseResourceConfigTypeDef(
    _ClientDescribeTrainingJobResponseResourceConfigTypeDef
):
    """
    Type definition for `ClientDescribeTrainingJobResponse` `ResourceConfig`

    Resources, including ML compute instances and ML storage volumes, that are configured for
    model training.

    - **InstanceType** *(string) --*

      The ML compute instance type.

    - **InstanceCount** *(integer) --*

      The number of ML compute instances to use. For distributed training, provide a value
      greater than 1.

    - **VolumeSizeInGB** *(integer) --*

      The size of the ML storage volume that you want to provision.

      ML storage volumes store model artifacts and incremental states. Training algorithms might
      also use the ML storage volume for scratch space. If you want to store the training data in
      the ML storage volume, choose ``File`` as the ``TrainingInputMode`` in the algorithm
      specification.

      You must specify sufficient ML storage for your scenario.

      .. note::

        Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

      .. note::

        Certain Nitro-based instances include local storage with a fixed total size, dependent on
        the instance type. When using these instances for training, Amazon SageMaker mounts the
        local instance storage instead of Amazon EBS gp2 storage. You can't request a
        ``VolumeSizeInGB`` greater than the total size of the local instance storage.

        For a list of instance types that support local instance storage, including the total
        size per instance type, see `Instance Store Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
        .

    - **VolumeKmsKeyId** *(string) --*

      The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume attached
      to the ML compute instance(s) that run the training job.

      .. note::

        Certain Nitro-based instances include local storage, dependent on the instance type.
        Local storage volumes are encrypted using a hardware module on the instance. You can't
        request a ``VolumeKmsKeyId`` when using an instance type with local storage.

        For a list of instance types that support local instance storage, see `Instance Store
        Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
        .

        For more information about local instance storage encryption, see `SSD Instance Store
        Volumes <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

      The ``VolumeKmsKeyId`` can be in any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientDescribeTrainingJobResponseSecondaryStatusTransitionsTypeDef = TypedDict(
    "_ClientDescribeTrainingJobResponseSecondaryStatusTransitionsTypeDef",
    {"Status": str, "StartTime": datetime, "EndTime": datetime, "StatusMessage": str},
    total=False,
)


class ClientDescribeTrainingJobResponseSecondaryStatusTransitionsTypeDef(
    _ClientDescribeTrainingJobResponseSecondaryStatusTransitionsTypeDef
):
    """
    Type definition for `ClientDescribeTrainingJobResponse` `SecondaryStatusTransitions`

    An array element of  DescribeTrainingJobResponse$SecondaryStatusTransitions . It provides
    additional details about a status that the training job has transitioned through. A
    training job can be in one of several states, for example, starting, downloading, training,
    or uploading. Within each state, there are a number of intermediate states. For example,
    within the starting state, Amazon SageMaker could be starting the training job or launching
    the ML instances. These transitional states are referred to as the job's secondary status.

    - **Status** *(string) --*

      Contains a secondary status information from a training job.

      Status might be one of the following secondary statuses:

        InProgress

      * ``Starting`` - Starting the training job.

      * ``Downloading`` - An optional stage for algorithms that support ``File`` training input
      mode. It indicates that data is being downloaded to the ML storage volumes.

      * ``Training`` - Training is in progress.

      * ``Uploading`` - Training is complete and the model artifacts are being uploaded to the
      S3 location.

        Completed

      * ``Completed`` - The training job has completed.

        Failed

      * ``Failed`` - The training job has failed. The reason for the failure is returned in the
      ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

        Stopped

      * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed
      runtime.

      * ``Stopped`` - The training job has stopped.

        Stopping

      * ``Stopping`` - Stopping the training job.

      We no longer support the following secondary statuses:

      * ``LaunchingMLInstances``

      * ``PreparingTrainingStack``

      * ``DownloadingTrainingImage``

    - **StartTime** *(datetime) --*

      A timestamp that shows when the training job transitioned to the current secondary status
      state.

    - **EndTime** *(datetime) --*

      A timestamp that shows when the training job transitioned out of this secondary status
      state into another secondary status state or when the training job has ended.

    - **StatusMessage** *(string) --*

      A detailed description of the progress within a secondary status.

      Amazon SageMaker provides secondary statuses and status messages that apply to each of
      them:

        Starting

      * Starting the training job.

      * Launching requested ML instances.

      * Insufficient capacity error from EC2 while launching instances, retrying!

      * Launched instance was unhealthy, replacing it!

      * Preparing the instances for training.

        Training

      * Downloading the training image.

      * Training image download completed. Training in progress.

      .. warning::

        Status messages are subject to change. Therefore, we recommend not including them in
        code that programmatically initiates actions. For examples, don't use status messages
        in if statements.

      To have an overview of your training job's progress, view ``TrainingJobStatus`` and
      ``SecondaryStatus`` in  DescribeTrainingJob , and ``StatusMessage`` together. For
      example, at the start of a training job, you might see the following:

      * ``TrainingJobStatus`` - InProgress

      * ``SecondaryStatus`` - Training

      * ``StatusMessage`` - Downloading the training image
    """


_ClientDescribeTrainingJobResponseStoppingConditionTypeDef = TypedDict(
    "_ClientDescribeTrainingJobResponseStoppingConditionTypeDef",
    {"MaxRuntimeInSeconds": int, "MaxWaitTimeInSeconds": int},
    total=False,
)


class ClientDescribeTrainingJobResponseStoppingConditionTypeDef(
    _ClientDescribeTrainingJobResponseStoppingConditionTypeDef
):
    """
    Type definition for `ClientDescribeTrainingJobResponse` `StoppingCondition`

    Specifies a limit to how long a model training job can run. It also specifies the maximum
    time to wait for a spot instance. When the job reaches the time limit, Amazon SageMaker ends
    the training job. Use this API to cap model training costs.

    To stop a job, Amazon SageMaker sends the algorithm the ``SIGTERM`` signal, which delays job
    termination for 120 seconds. Algorithms can use this 120-second window to save the model
    artifacts, so the results of training are not lost.

    - **MaxRuntimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, that the training or compilation job can run. If
      job does not complete during this time, Amazon SageMaker ends the job. If value is not
      specified, default value is 1 day. The maximum value is 28 days.

    - **MaxWaitTimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, how long you are willing to wait for a managed spot
      training job to complete. It is the amount of time spent waiting for Spot capacity plus the
      amount of time the training job runs. It must be equal to or greater than
      ``MaxRuntimeInSeconds`` .
    """


_ClientDescribeTrainingJobResponseVpcConfigTypeDef = TypedDict(
    "_ClientDescribeTrainingJobResponseVpcConfigTypeDef",
    {"SecurityGroupIds": List[str], "Subnets": List[str]},
    total=False,
)


class ClientDescribeTrainingJobResponseVpcConfigTypeDef(
    _ClientDescribeTrainingJobResponseVpcConfigTypeDef
):
    """
    Type definition for `ClientDescribeTrainingJobResponse` `VpcConfig`

    A  VpcConfig object that specifies the VPC that this training job has access to. For more
    information, see `Protect Training Jobs by Using an Amazon Virtual Private Cloud
    <https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html>`__ .

    - **SecurityGroupIds** *(list) --*

      The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for the
      VPC that is specified in the ``Subnets`` field.

      - *(string) --*

    - **Subnets** *(list) --*

      The ID of the subnets in the VPC to which you want to connect your training job or model.

      .. note::

        Amazon EC2 P3 accelerated computing instances are not available in the c/d/e availability
        zones of region us-east-1. If you want to create endpoints with P3 instances in VPC mode
        in region us-east-1, create subnets in a/b/f availability zones instead.

      - *(string) --*
    """


_ClientDescribeTrainingJobResponseTypeDef = TypedDict(
    "_ClientDescribeTrainingJobResponseTypeDef",
    {
        "TrainingJobName": str,
        "TrainingJobArn": str,
        "TuningJobArn": str,
        "LabelingJobArn": str,
        "ModelArtifacts": ClientDescribeTrainingJobResponseModelArtifactsTypeDef,
        "TrainingJobStatus": str,
        "SecondaryStatus": str,
        "FailureReason": str,
        "HyperParameters": Dict[str, str],
        "AlgorithmSpecification": ClientDescribeTrainingJobResponseAlgorithmSpecificationTypeDef,
        "RoleArn": str,
        "InputDataConfig": List[
            ClientDescribeTrainingJobResponseInputDataConfigTypeDef
        ],
        "OutputDataConfig": ClientDescribeTrainingJobResponseOutputDataConfigTypeDef,
        "ResourceConfig": ClientDescribeTrainingJobResponseResourceConfigTypeDef,
        "VpcConfig": ClientDescribeTrainingJobResponseVpcConfigTypeDef,
        "StoppingCondition": ClientDescribeTrainingJobResponseStoppingConditionTypeDef,
        "CreationTime": datetime,
        "TrainingStartTime": datetime,
        "TrainingEndTime": datetime,
        "LastModifiedTime": datetime,
        "SecondaryStatusTransitions": List[
            ClientDescribeTrainingJobResponseSecondaryStatusTransitionsTypeDef
        ],
        "FinalMetricDataList": List[
            ClientDescribeTrainingJobResponseFinalMetricDataListTypeDef
        ],
        "EnableNetworkIsolation": bool,
        "EnableInterContainerTrafficEncryption": bool,
        "EnableManagedSpotTraining": bool,
        "CheckpointConfig": ClientDescribeTrainingJobResponseCheckpointConfigTypeDef,
        "TrainingTimeInSeconds": int,
        "BillableTimeInSeconds": int,
    },
    total=False,
)


class ClientDescribeTrainingJobResponseTypeDef(
    _ClientDescribeTrainingJobResponseTypeDef
):
    """
    Type definition for `ClientDescribeTrainingJob` `Response`

    - **TrainingJobName** *(string) --*

      Name of the model training job.

    - **TrainingJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the training job.

    - **TuningJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the associated hyperparameter tuning job if the training
      job was launched by a hyperparameter tuning job.

    - **LabelingJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the Amazon SageMaker Ground Truth labeling job that created
      the transform or training job.

    - **ModelArtifacts** *(dict) --*

      Information about the Amazon S3 location that is configured for storing model artifacts.

      - **S3ModelArtifacts** *(string) --*

        The path of the S3 object that contains the model artifacts. For example,
        ``s3://bucket-name/keynameprefix/model.tar.gz`` .

    - **TrainingJobStatus** *(string) --*

      The status of the training job.

      Amazon SageMaker provides the following training job statuses:

      * ``InProgress`` - The training is in progress.

      * ``Completed`` - The training job has completed.

      * ``Failed`` - The training job has failed. To see the reason for the failure, see the
      ``FailureReason`` field in the response to a ``DescribeTrainingJobResponse`` call.

      * ``Stopping`` - The training job is stopping.

      * ``Stopped`` - The training job has stopped.

      For more detailed information, see ``SecondaryStatus`` .

    - **SecondaryStatus** *(string) --*

      Provides detailed information about the state of the training job. For detailed information
      on the secondary status of the training job, see ``StatusMessage`` under
      SecondaryStatusTransition .

      Amazon SageMaker provides primary statuses and secondary statuses that apply to each of them:

        InProgress

      * ``Starting`` - Starting the training job.

      * ``Downloading`` - An optional stage for algorithms that support ``File`` training input
      mode. It indicates that data is being downloaded to the ML storage volumes.

      * ``Training`` - Training is in progress.

      * ``Interrupted`` - The job stopped because the managed spot training instances were
      interrupted.

      * ``Uploading`` - Training is complete and the model artifacts are being uploaded to the S3
      location.

        Completed

      * ``Completed`` - The training job has completed.

        Failed

      * ``Failed`` - The training job has failed. The reason for the failure is returned in the
      ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

        Stopped

      * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed runtime.

      * ``MaxWaitTmeExceeded`` - The job stopped because it exceeded the maximum allowed wait time.

      * ``Stopped`` - The training job has stopped.

        Stopping

      * ``Stopping`` - Stopping the training job.

      .. warning::

        Valid values for ``SecondaryStatus`` are subject to change.

      We no longer support the following secondary statuses:

      * ``LaunchingMLInstances``

      * ``PreparingTrainingStack``

      * ``DownloadingTrainingImage``

    - **FailureReason** *(string) --*

      If the training job failed, the reason it failed.

    - **HyperParameters** *(dict) --*

      Algorithm-specific parameters.

      - *(string) --*

        - *(string) --*

    - **AlgorithmSpecification** *(dict) --*

      Information about the algorithm used for training, and algorithm metadata.

      - **TrainingImage** *(string) --*

        The registry path of the Docker image that contains the training algorithm. For information
        about docker registry paths for built-in algorithms, see `Algorithms Provided by Amazon
        SageMaker\\: Common Parameters
        <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
        . Amazon SageMaker supports both ``registry/repository[:tag]`` and
        ``registry/repository[@digest]`` image path formats. For more information, see `Using Your
        Own Algorithms with Amazon SageMaker
        <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

      - **AlgorithmName** *(string) --*

        The name of the algorithm resource to use for the training job. This must be an algorithm
        resource that you created or subscribe to on AWS Marketplace. If you specify a value for
        this parameter, you can't specify a value for ``TrainingImage`` .

      - **TrainingInputMode** *(string) --*

        The input mode that the algorithm supports. For the input modes that Amazon SageMaker
        algorithms support, see `Algorithms
        <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ . If an algorithm supports
        the ``File`` input mode, Amazon SageMaker downloads the training data from S3 to the
        provisioned ML storage Volume, and mounts the directory to docker volume for training
        container. If an algorithm supports the ``Pipe`` input mode, Amazon SageMaker streams data
        directly from S3 to the container.

        In File mode, make sure you provision ML storage volume with sufficient capacity to
        accommodate the data download from S3. In addition to the training data, the ML storage
        volume also stores the output model. The algorithm container use ML storage volume to also
        store intermediate information, if any.

        For distributed algorithms using File mode, training data is distributed uniformly, and
        your training duration is predictable if the input data objects size is approximately same.
        Amazon SageMaker does not split the files any further for model training. If the object
        sizes are skewed, training won't be optimal as the data distribution is also skewed where
        one host in a training cluster is overloaded, thus becoming bottleneck in training.

      - **MetricDefinitions** *(list) --*

        A list of metric definition objects. Each object specifies the metric name and regular
        expressions used to parse algorithm logs. Amazon SageMaker publishes each metric to Amazon
        CloudWatch.

        - *(dict) --*

          Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
          Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
          metric that a hyperparameter tuning job uses as its objective metric to choose the best
          training job.

          - **Name** *(string) --*

            The name of the metric.

          - **Regex** *(string) --*

            A regular expression that searches the output of a training job and gets the value of
            the metric. For more information about using regular expressions to define metrics, see
            `Defining Objective Metrics
            <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
            .

    - **RoleArn** *(string) --*

      The AWS Identity and Access Management (IAM) role configured for the training job.

    - **InputDataConfig** *(list) --*

      An array of ``Channel`` objects that describes each data input channel.

      - *(dict) --*

        A channel is a named input source that training algorithms can consume.

        - **ChannelName** *(string) --*

          The name of the channel.

        - **DataSource** *(dict) --*

          The location of the channel data.

          - **S3DataSource** *(dict) --*

            The S3 location of the data source that is associated with a channel.

            - **S3DataType** *(string) --*

              If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker
              uses all objects that match the specified key name prefix for model training.

              If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest
              file containing a list of object keys that you want Amazon SageMaker to use for model
              training.

              If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
              augmented manifest file in JSON lines format. This file contains the data you want to
              use for model training. ``AugmentedManifestFile`` can only be used if the Channel's
              input mode is ``Pipe`` .

            - **S3Uri** *(string) --*

              Depending on the value specified for the ``S3DataType`` , identifies either a key
              name prefix or a manifest. For example:

              * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

              * A manifest might look like this: ``s3://bucketname/example.manifest``   The
              manifest is an S3 object which is a JSON file with the following format:  The
              preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
              "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
              ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``    ``]``
                The preceding JSON matches the following ``s3Uris`` :
                ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
                ``s3uris`` in this manifest is the input data for the channel for this datasource.
                The object that each ``s3uris`` points to must be readable by the IAM role that
                Amazon SageMaker uses to perform tasks on your behalf.

            - **S3DataDistributionType** *(string) --*

              If you want Amazon SageMaker to replicate the entire dataset on each ML compute
              instance that is launched for model training, specify ``FullyReplicated`` .

              If you want Amazon SageMaker to replicate a subset of data on each ML compute
              instance that is launched for model training, specify ``ShardedByS3Key`` . If there
              are *n* ML compute instances launched for a training job, each instance gets
              approximately 1/*n* of the number of S3 objects. In this case, model training on each
              machine uses only the subset of training data.

              Don't choose more ML compute instances for training than available S3 objects. If you
              do, some nodes won't get any data and you will pay for nodes that aren't getting any
              training data. This applies in both File and Pipe modes. Keep this in mind when
              developing algorithms.

              In distributed training, where you use multiple ML compute EC2 instances, you might
              choose ``ShardedByS3Key`` . If the algorithm requires copying training data to the ML
              storage volume (when ``TrainingInputMode`` is set to ``File`` ), this copies 1/*n* of
              the number of objects.

            - **AttributeNames** *(list) --*

              A list of one or more attribute names to use that are found in a specified augmented
              manifest file.

              - *(string) --*

          - **FileSystemDataSource** *(dict) --*

            The file system that is associated with a channel.

            - **FileSystemId** *(string) --*

              The file system id.

            - **FileSystemAccessMode** *(string) --*

              The access mode of the mount of the directory associated with the channel. A
              directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write) mode.

            - **FileSystemType** *(string) --*

              The file system type.

            - **DirectoryPath** *(string) --*

              The full path to the directory to associate with the channel.

        - **ContentType** *(string) --*

          The MIME type of the data.

        - **CompressionType** *(string) --*

          If training data is compressed, the compression type. The default value is ``None`` .
          ``CompressionType`` is used only in Pipe input mode. In File mode, leave this field unset
          or set it to None.

        - **RecordWrapperType** *(string) --*

          Specify RecordIO as the value when input data is in raw format but the training algorithm
          requires the RecordIO format. In this case, Amazon SageMaker wraps each individual S3
          object in a RecordIO record. If the input data is already in RecordIO format, you don't
          need to set this attribute. For more information, see `Create a Dataset Using RecordIO
          <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__ .

          In File mode, leave this field unset or set it to None.

        - **InputMode** *(string) --*

          (Optional) The input mode to use for the data channel in a training job. If you don't set
          a value for ``InputMode`` , Amazon SageMaker uses the value set for ``TrainingInputMode``
          . Use this parameter to override the ``TrainingInputMode`` setting in a
          AlgorithmSpecification request when you have a channel that needs a different input mode
          from the training job's general setting. To download the data from Amazon Simple Storage
          Service (Amazon S3) to the provisioned ML storage volume, and mount the directory to a
          Docker volume, use ``File`` input mode. To stream data directly from Amazon S3 to the
          container, choose ``Pipe`` input mode.

          To use a model for incremental training, choose ``File`` input model.

        - **ShuffleConfig** *(dict) --*

          A configuration for a shuffle option for input data in a channel. If you use ``S3Prefix``
          for ``S3DataType`` , this shuffles the results of the S3 key prefix matches. If you use
          ``ManifestFile`` , the order of the S3 object references in the ``ManifestFile`` is
          shuffled. If you use ``AugmentedManifestFile`` , the order of the JSON lines in the
          ``AugmentedManifestFile`` is shuffled. The shuffling order is determined using the
          ``Seed`` value.

          For Pipe input mode, shuffling is done at the start of every epoch. With large datasets
          this ensures that the order of the training data is different for each epoch, it helps
          reduce bias and possible overfitting. In a multi-node training job when ShuffleConfig is
          combined with ``S3DataDistributionType`` of ``ShardedByS3Key`` , the data is shuffled
          across nodes so that the content sent to a particular node on the first epoch might be
          sent to a different node on the second epoch.

          - **Seed** *(integer) --*

            Determines the shuffling order in ``ShuffleConfig`` value.

    - **OutputDataConfig** *(dict) --*

      The S3 path where model artifacts that you configured when creating the job are stored.
      Amazon SageMaker creates subfolders for model artifacts.

      - **KmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
        model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be any
        of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // KMS Key Alias  ``"alias/ExampleAlias"``

        * // Amazon Resource Name (ARN) of a KMS Key Alias
        ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

        If you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution role
        must include permissions to call ``kms:Encrypt`` . If you don't provide a KMS key ID,
        Amazon SageMaker uses the default KMS key for Amazon S3 for your role's account. Amazon
        SageMaker uses server-side encryption with KMS-managed keys for ``OutputDataConfig`` . If
        you use a bucket policy with an ``s3:PutObject`` permission that only allows objects with
        server-side encryption, set the condition key of ``s3:x-amz-server-side-encryption`` to
        ``"aws:kms"`` . For more information, see `KMS-Managed Encryption Keys
        <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the *Amazon
        Simple Storage Service Developer Guide.*

        The KMS key policy must grant permission to the IAM role that you specify in your
        ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
        requests. For more information, see `Using Key Policies in AWS KMS
        <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
        in the *AWS Key Management Service Developer Guide* .

      - **S3OutputPath** *(string) --*

        Identifies the S3 path where you want Amazon SageMaker to store the model artifacts. For
        example, ``s3://bucket-name/key-name-prefix`` .

    - **ResourceConfig** *(dict) --*

      Resources, including ML compute instances and ML storage volumes, that are configured for
      model training.

      - **InstanceType** *(string) --*

        The ML compute instance type.

      - **InstanceCount** *(integer) --*

        The number of ML compute instances to use. For distributed training, provide a value
        greater than 1.

      - **VolumeSizeInGB** *(integer) --*

        The size of the ML storage volume that you want to provision.

        ML storage volumes store model artifacts and incremental states. Training algorithms might
        also use the ML storage volume for scratch space. If you want to store the training data in
        the ML storage volume, choose ``File`` as the ``TrainingInputMode`` in the algorithm
        specification.

        You must specify sufficient ML storage for your scenario.

        .. note::

          Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

        .. note::

          Certain Nitro-based instances include local storage with a fixed total size, dependent on
          the instance type. When using these instances for training, Amazon SageMaker mounts the
          local instance storage instead of Amazon EBS gp2 storage. You can't request a
          ``VolumeSizeInGB`` greater than the total size of the local instance storage.

          For a list of instance types that support local instance storage, including the total
          size per instance type, see `Instance Store Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
          .

      - **VolumeKmsKeyId** *(string) --*

        The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume attached
        to the ML compute instance(s) that run the training job.

        .. note::

          Certain Nitro-based instances include local storage, dependent on the instance type.
          Local storage volumes are encrypted using a hardware module on the instance. You can't
          request a ``VolumeKmsKeyId`` when using an instance type with local storage.

          For a list of instance types that support local instance storage, see `Instance Store
          Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
          .

          For more information about local instance storage encryption, see `SSD Instance Store
          Volumes <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

        The ``VolumeKmsKeyId`` can be in any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

    - **VpcConfig** *(dict) --*

      A  VpcConfig object that specifies the VPC that this training job has access to. For more
      information, see `Protect Training Jobs by Using an Amazon Virtual Private Cloud
      <https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html>`__ .

      - **SecurityGroupIds** *(list) --*

        The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for the
        VPC that is specified in the ``Subnets`` field.

        - *(string) --*

      - **Subnets** *(list) --*

        The ID of the subnets in the VPC to which you want to connect your training job or model.

        .. note::

          Amazon EC2 P3 accelerated computing instances are not available in the c/d/e availability
          zones of region us-east-1. If you want to create endpoints with P3 instances in VPC mode
          in region us-east-1, create subnets in a/b/f availability zones instead.

        - *(string) --*

    - **StoppingCondition** *(dict) --*

      Specifies a limit to how long a model training job can run. It also specifies the maximum
      time to wait for a spot instance. When the job reaches the time limit, Amazon SageMaker ends
      the training job. Use this API to cap model training costs.

      To stop a job, Amazon SageMaker sends the algorithm the ``SIGTERM`` signal, which delays job
      termination for 120 seconds. Algorithms can use this 120-second window to save the model
      artifacts, so the results of training are not lost.

      - **MaxRuntimeInSeconds** *(integer) --*

        The maximum length of time, in seconds, that the training or compilation job can run. If
        job does not complete during this time, Amazon SageMaker ends the job. If value is not
        specified, default value is 1 day. The maximum value is 28 days.

      - **MaxWaitTimeInSeconds** *(integer) --*

        The maximum length of time, in seconds, how long you are willing to wait for a managed spot
        training job to complete. It is the amount of time spent waiting for Spot capacity plus the
        amount of time the training job runs. It must be equal to or greater than
        ``MaxRuntimeInSeconds`` .

    - **CreationTime** *(datetime) --*

      A timestamp that indicates when the training job was created.

    - **TrainingStartTime** *(datetime) --*

      Indicates the time when the training job starts on training instances. You are billed for the
      time interval between this time and the value of ``TrainingEndTime`` . The start time in
      CloudWatch Logs might be later than this time. The difference is due to the time it takes to
      download the training data and to the size of the training container.

    - **TrainingEndTime** *(datetime) --*

      Indicates the time when the training job ends on training instances. You are billed for the
      time interval between the value of ``TrainingStartTime`` and this time. For successful jobs
      and stopped jobs, this is the time after model artifacts are uploaded. For failed jobs, this
      is the time when Amazon SageMaker detects a job failure.

    - **LastModifiedTime** *(datetime) --*

      A timestamp that indicates when the status of the training job was last modified.

    - **SecondaryStatusTransitions** *(list) --*

      A history of all of the secondary statuses that the training job has transitioned through.

      - *(dict) --*

        An array element of  DescribeTrainingJobResponse$SecondaryStatusTransitions . It provides
        additional details about a status that the training job has transitioned through. A
        training job can be in one of several states, for example, starting, downloading, training,
        or uploading. Within each state, there are a number of intermediate states. For example,
        within the starting state, Amazon SageMaker could be starting the training job or launching
        the ML instances. These transitional states are referred to as the job's secondary status.

        - **Status** *(string) --*

          Contains a secondary status information from a training job.

          Status might be one of the following secondary statuses:

            InProgress

          * ``Starting`` - Starting the training job.

          * ``Downloading`` - An optional stage for algorithms that support ``File`` training input
          mode. It indicates that data is being downloaded to the ML storage volumes.

          * ``Training`` - Training is in progress.

          * ``Uploading`` - Training is complete and the model artifacts are being uploaded to the
          S3 location.

            Completed

          * ``Completed`` - The training job has completed.

            Failed

          * ``Failed`` - The training job has failed. The reason for the failure is returned in the
          ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

            Stopped

          * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed
          runtime.

          * ``Stopped`` - The training job has stopped.

            Stopping

          * ``Stopping`` - Stopping the training job.

          We no longer support the following secondary statuses:

          * ``LaunchingMLInstances``

          * ``PreparingTrainingStack``

          * ``DownloadingTrainingImage``

        - **StartTime** *(datetime) --*

          A timestamp that shows when the training job transitioned to the current secondary status
          state.

        - **EndTime** *(datetime) --*

          A timestamp that shows when the training job transitioned out of this secondary status
          state into another secondary status state or when the training job has ended.

        - **StatusMessage** *(string) --*

          A detailed description of the progress within a secondary status.

          Amazon SageMaker provides secondary statuses and status messages that apply to each of
          them:

            Starting

          * Starting the training job.

          * Launching requested ML instances.

          * Insufficient capacity error from EC2 while launching instances, retrying!

          * Launched instance was unhealthy, replacing it!

          * Preparing the instances for training.

            Training

          * Downloading the training image.

          * Training image download completed. Training in progress.

          .. warning::

            Status messages are subject to change. Therefore, we recommend not including them in
            code that programmatically initiates actions. For examples, don't use status messages
            in if statements.

          To have an overview of your training job's progress, view ``TrainingJobStatus`` and
          ``SecondaryStatus`` in  DescribeTrainingJob , and ``StatusMessage`` together. For
          example, at the start of a training job, you might see the following:

          * ``TrainingJobStatus`` - InProgress

          * ``SecondaryStatus`` - Training

          * ``StatusMessage`` - Downloading the training image

    - **FinalMetricDataList** *(list) --*

      A collection of ``MetricData`` objects that specify the names, values, and dates and times
      that the training algorithm emitted to Amazon CloudWatch.

      - *(dict) --*

        The name, value, and date and time of a metric that was emitted to Amazon CloudWatch.

        - **MetricName** *(string) --*

          The name of the metric.

        - **Value** *(float) --*

          The value of the metric.

        - **Timestamp** *(datetime) --*

          The date and time that the algorithm emitted the metric.

    - **EnableNetworkIsolation** *(boolean) --*

      If you want to allow inbound or outbound network calls, except for calls between peers within
      a training cluster for distributed training, choose ``True`` . If you enable network
      isolation for training jobs that are configured to use a VPC, Amazon SageMaker downloads and
      uploads customer data and model artifacts through the specified VPC, but the training
      container does not have network access.

      .. note::

        The Semantic Segmentation built-in algorithm does not support network isolation.

    - **EnableInterContainerTrafficEncryption** *(boolean) --*

      To encrypt all communications between ML compute instances in distributed training, choose
      ``True`` . Encryption provides greater security for distributed training, but training might
      take longer. How long it takes depends on the amount of communication between compute
      instances, especially if you use a deep learning algorithms in distributed training.

    - **EnableManagedSpotTraining** *(boolean) --*

      A Boolean indicating whether managed spot training is enabled (``True`` ) or not (``False`` ).

    - **CheckpointConfig** *(dict) --*

      Contains information about the output location for managed spot training checkpoint data.

      - **S3Uri** *(string) --*

        Identifies the S3 path where you want Amazon SageMaker to store checkpoints. For example,
        ``s3://bucket-name/key-name-prefix`` .

      - **LocalPath** *(string) --*

        (Optional) The local directory where checkpoints are written. The default directory is
        ``/opt/ml/checkpoints/`` .

    - **TrainingTimeInSeconds** *(integer) --*

      The training time in seconds.

    - **BillableTimeInSeconds** *(integer) --*

      The billable time in seconds.

      You can calculate the savings from using managed spot training using the formula ``(1 -
      BillableTimeInSeconds / TrainingTimeInSeconds) * 100`` . For example, if
      ``BillableTimeInSeconds`` is 100 and ``TrainingTimeInSeconds`` is 500, the savings is 80%.
    """


_ClientDescribeTransformJobResponseDataProcessingTypeDef = TypedDict(
    "_ClientDescribeTransformJobResponseDataProcessingTypeDef",
    {"InputFilter": str, "OutputFilter": str, "JoinSource": str},
    total=False,
)


class ClientDescribeTransformJobResponseDataProcessingTypeDef(
    _ClientDescribeTransformJobResponseDataProcessingTypeDef
):
    """
    Type definition for `ClientDescribeTransformJobResponse` `DataProcessing`

    The data structure used to specify the data to be used for inference in a batch transform job
    and to associate the data that is relevant to the prediction results in the output. The input
    filter provided allows you to exclude input data that is not needed for inference in a batch
    transform job. The output filter provided allows you to include input data relevant to
    interpreting the predictions in the output from the job. For more information, see `Associate
    Prediction Results with their Corresponding Input Records
    <https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html>`__ .

    - **InputFilter** *(string) --*

      A `JSONPath
      <https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html#data-processing-operators>`__
      expression used to select a portion of the input data to pass to the algorithm. Use the
      ``InputFilter`` parameter to exclude fields, such as an ID column, from the input. If you
      want Amazon SageMaker to pass the entire input dataset to the algorithm, accept the default
      value ``$`` .

      Examples: ``"$"`` , ``"$[1:]"`` , ``"$.features"``

    - **OutputFilter** *(string) --*

      A `JSONPath
      <https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html#data-processing-operators>`__
      expression used to select a portion of the joined dataset to save in the output file for a
      batch transform job. If you want Amazon SageMaker to store the entire input dataset in the
      output file, leave the default value, ``$`` . If you specify indexes that aren't within the
      dimension size of the joined dataset, you get an error.

      Examples: ``"$"`` , ``"$[0,5:]"`` , ``"$['id','SageMakerOutput']"``

    - **JoinSource** *(string) --*

      Specifies the source of the data to join with the transformed data. The valid values are
      ``None`` and ``Input`` . The default value is ``None`` , which specifies not to join the
      input with the transformed data. If you want the batch transform job to join the original
      input data with the transformed data, set ``JoinSource`` to ``Input`` .

      For JSON or JSONLines objects, such as a JSON array, Amazon SageMaker adds the transformed
      data to the input JSON object in an attribute called ``SageMakerOutput`` . The joined
      result for JSON must be a key-value pair object. If the input is not a key-value pair
      object, Amazon SageMaker creates a new JSON file. In the new JSON file, and the input data
      is stored under the ``SageMakerInput`` key and the results are stored in
      ``SageMakerOutput`` .

      For CSV files, Amazon SageMaker combines the transformed data with the input data at the
      end of the input data and stores it in the output file. The joined data has the joined
      input data followed by the transformed data and the output is a CSV file.
    """


_ClientDescribeTransformJobResponseTransformInputDataSourceS3DataSourceTypeDef = TypedDict(
    "_ClientDescribeTransformJobResponseTransformInputDataSourceS3DataSourceTypeDef",
    {"S3DataType": str, "S3Uri": str},
    total=False,
)


class ClientDescribeTransformJobResponseTransformInputDataSourceS3DataSourceTypeDef(
    _ClientDescribeTransformJobResponseTransformInputDataSourceS3DataSourceTypeDef
):
    """
    Type definition for `ClientDescribeTransformJobResponseTransformInputDataSource` `S3DataSource`

    The S3 location of the data source that is associated with a channel.

    - **S3DataType** *(string) --*

      If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker
      uses all objects with the specified key name prefix for batch transform.

      If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest file
      containing a list of object keys that you want Amazon SageMaker to use for batch
      transform.

      The following values are compatible: ``ManifestFile`` , ``S3Prefix``

      The following value is not compatible: ``AugmentedManifestFile``

    - **S3Uri** *(string) --*

      Depending on the value specified for the ``S3DataType`` , identifies either a key name
      prefix or a manifest. For example:

      * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

      * A manifest might look like this: ``s3://bucketname/example.manifest``   The manifest
      is an S3 object which is a JSON file with the following format:   ``[ {"prefix":
      "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
      ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``    ``]``
      The preceding JSON matches the following ``s3Uris`` :
      ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
      ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
      ``S3Uris`` in this manifest constitutes the input data for the channel for this
      datasource. The object that each ``S3Uris`` points to must be readable by the IAM role
      that Amazon SageMaker uses to perform tasks on your behalf.
    """


_ClientDescribeTransformJobResponseTransformInputDataSourceTypeDef = TypedDict(
    "_ClientDescribeTransformJobResponseTransformInputDataSourceTypeDef",
    {
        "S3DataSource": ClientDescribeTransformJobResponseTransformInputDataSourceS3DataSourceTypeDef
    },
    total=False,
)


class ClientDescribeTransformJobResponseTransformInputDataSourceTypeDef(
    _ClientDescribeTransformJobResponseTransformInputDataSourceTypeDef
):
    """
    Type definition for `ClientDescribeTransformJobResponseTransformInput` `DataSource`

    Describes the location of the channel data, which is, the S3 location of the input data
    that the model can consume.

    - **S3DataSource** *(dict) --*

      The S3 location of the data source that is associated with a channel.

      - **S3DataType** *(string) --*

        If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker
        uses all objects with the specified key name prefix for batch transform.

        If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest file
        containing a list of object keys that you want Amazon SageMaker to use for batch
        transform.

        The following values are compatible: ``ManifestFile`` , ``S3Prefix``

        The following value is not compatible: ``AugmentedManifestFile``

      - **S3Uri** *(string) --*

        Depending on the value specified for the ``S3DataType`` , identifies either a key name
        prefix or a manifest. For example:

        * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

        * A manifest might look like this: ``s3://bucketname/example.manifest``   The manifest
        is an S3 object which is a JSON file with the following format:   ``[ {"prefix":
        "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
        ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``    ``]``
        The preceding JSON matches the following ``s3Uris`` :
        ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
        ``S3Uris`` in this manifest constitutes the input data for the channel for this
        datasource. The object that each ``S3Uris`` points to must be readable by the IAM role
        that Amazon SageMaker uses to perform tasks on your behalf.
    """


_ClientDescribeTransformJobResponseTransformInputTypeDef = TypedDict(
    "_ClientDescribeTransformJobResponseTransformInputTypeDef",
    {
        "DataSource": ClientDescribeTransformJobResponseTransformInputDataSourceTypeDef,
        "ContentType": str,
        "CompressionType": str,
        "SplitType": str,
    },
    total=False,
)


class ClientDescribeTransformJobResponseTransformInputTypeDef(
    _ClientDescribeTransformJobResponseTransformInputTypeDef
):
    """
    Type definition for `ClientDescribeTransformJobResponse` `TransformInput`

    Describes the dataset to be transformed and the Amazon S3 location where it is stored.

    - **DataSource** *(dict) --*

      Describes the location of the channel data, which is, the S3 location of the input data
      that the model can consume.

      - **S3DataSource** *(dict) --*

        The S3 location of the data source that is associated with a channel.

        - **S3DataType** *(string) --*

          If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker
          uses all objects with the specified key name prefix for batch transform.

          If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest file
          containing a list of object keys that you want Amazon SageMaker to use for batch
          transform.

          The following values are compatible: ``ManifestFile`` , ``S3Prefix``

          The following value is not compatible: ``AugmentedManifestFile``

        - **S3Uri** *(string) --*

          Depending on the value specified for the ``S3DataType`` , identifies either a key name
          prefix or a manifest. For example:

          * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

          * A manifest might look like this: ``s3://bucketname/example.manifest``   The manifest
          is an S3 object which is a JSON file with the following format:   ``[ {"prefix":
          "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
          ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``    ``]``
          The preceding JSON matches the following ``s3Uris`` :
          ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
          ``S3Uris`` in this manifest constitutes the input data for the channel for this
          datasource. The object that each ``S3Uris`` points to must be readable by the IAM role
          that Amazon SageMaker uses to perform tasks on your behalf.

    - **ContentType** *(string) --*

      The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker uses the
      MIME type with each http call to transfer data to the transform job.

    - **CompressionType** *(string) --*

      If your transform data is compressed, specify the compression type. Amazon SageMaker
      automatically decompresses the data for the transform job accordingly. The default value is
      ``None`` .

    - **SplitType** *(string) --*

      The method to use to split the transform job's data files into smaller batches. Splitting
      is necessary when the total size of each object is too large to fit in a single request.
      You can also use data splitting to improve performance by processing multiple concurrent
      mini-batches. The default value for ``SplitType`` is ``None`` , which indicates that input
      data files are not split, and request payloads contain the entire contents of an input
      object. Set the value of this parameter to ``Line`` to split records on a newline character
      boundary. ``SplitType`` also supports a number of record-oriented binary data formats.

      When splitting is enabled, the size of a mini-batch depends on the values of the
      ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of ``BatchStrategy`` is
      ``MultiRecord`` , Amazon SageMaker sends the maximum number of records in each request, up
      to the ``MaxPayloadInMB`` limit. If the value of ``BatchStrategy`` is ``SingleRecord`` ,
      Amazon SageMaker sends individual records in each request.

      .. note::

        Some data formats represent a record as a binary payload wrapped with extra padding
        bytes. When splitting is applied to a binary data format, padding is removed if the value
        of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is not removed if the value of
        ``BatchStrategy`` is set to ``MultiRecord`` .

        For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
        <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For more
        information about ``TFRecord`` , see `Consuming TFRecord data
        <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the TensorFlow
        documentation.
    """


_ClientDescribeTransformJobResponseTransformOutputTypeDef = TypedDict(
    "_ClientDescribeTransformJobResponseTransformOutputTypeDef",
    {"S3OutputPath": str, "Accept": str, "AssembleWith": str, "KmsKeyId": str},
    total=False,
)


class ClientDescribeTransformJobResponseTransformOutputTypeDef(
    _ClientDescribeTransformJobResponseTransformOutputTypeDef
):
    """
    Type definition for `ClientDescribeTransformJobResponse` `TransformOutput`

    Identifies the Amazon S3 location where you want Amazon SageMaker to save the results from
    the transform job.

    - **S3OutputPath** *(string) --*

      The Amazon S3 path where you want Amazon SageMaker to store the results of the transform
      job. For example, ``s3://bucket-name/key-name-prefix`` .

      For every S3 object used as input for the transform job, batch transform stores the
      transformed data with an .``out`` suffix in a corresponding subfolder in the location in
      the output prefix. For example, for the input data stored at
      ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores the
      transformed data at ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out``
      . Batch transform doesn't upload partially processed objects. For an input S3 object that
      contains multiple records, it creates an .``out`` file only if the transform job succeeds
      on the entire file. When the input contains multiple S3 objects, the batch transform job
      processes the listed S3 objects and uploads only the output for successfully processed
      objects. If any object fails in the transform job batch transform marks the job as failed
      to prompt investigation.

    - **Accept** *(string) --*

      The MIME type used to specify the output data. Amazon SageMaker uses the MIME type with
      each http call to transfer data from the transform job.

    - **AssembleWith** *(string) --*

      Defines how to assemble the results of the transform job as a single S3 object. Choose a
      format that is most convenient to you. To concatenate the results in binary format, specify
      ``None`` . To add a newline character at the end of every transformed record, specify
      ``Line`` .

    - **KmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
      model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be any
      of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // KMS Key Alias  ``"alias/ExampleAlias"``

      * // Amazon Resource Name (ARN) of a KMS Key Alias
      ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

      If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3
      for your role's account. For more information, see `KMS-Managed Encryption Keys
      <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the *Amazon
      Simple Storage Service Developer Guide.*

      The KMS key policy must grant permission to the IAM role that you specify in your
      CreateModel request. For more information, see `Using Key Policies in AWS KMS
      <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the *AWS Key
      Management Service Developer Guide* .
    """


_ClientDescribeTransformJobResponseTransformResourcesTypeDef = TypedDict(
    "_ClientDescribeTransformJobResponseTransformResourcesTypeDef",
    {"InstanceType": str, "InstanceCount": int, "VolumeKmsKeyId": str},
    total=False,
)


class ClientDescribeTransformJobResponseTransformResourcesTypeDef(
    _ClientDescribeTransformJobResponseTransformResourcesTypeDef
):
    """
    Type definition for `ClientDescribeTransformJobResponse` `TransformResources`

    Describes the resources, including ML instance types and ML instance count, to use for the
    transform job.

    - **InstanceType** *(string) --*

      The ML compute instance type for the transform job. If you are using built-in algorithms to
      transform moderately sized datasets, we recommend using ml.m4.xlarge or ``ml.m5.large``
      instance types.

    - **InstanceCount** *(integer) --*

      The number of ML compute instances to use in the transform job. For distributed transform
      jobs, specify a value greater than 1. The default value is ``1`` .

    - **VolumeKmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data on
      the storage volume attached to the ML compute instance(s) that run the batch transform job.
      The ``VolumeKmsKeyId`` can be any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientDescribeTransformJobResponseTypeDef = TypedDict(
    "_ClientDescribeTransformJobResponseTypeDef",
    {
        "TransformJobName": str,
        "TransformJobArn": str,
        "TransformJobStatus": str,
        "FailureReason": str,
        "ModelName": str,
        "MaxConcurrentTransforms": int,
        "MaxPayloadInMB": int,
        "BatchStrategy": str,
        "Environment": Dict[str, str],
        "TransformInput": ClientDescribeTransformJobResponseTransformInputTypeDef,
        "TransformOutput": ClientDescribeTransformJobResponseTransformOutputTypeDef,
        "TransformResources": ClientDescribeTransformJobResponseTransformResourcesTypeDef,
        "CreationTime": datetime,
        "TransformStartTime": datetime,
        "TransformEndTime": datetime,
        "LabelingJobArn": str,
        "DataProcessing": ClientDescribeTransformJobResponseDataProcessingTypeDef,
    },
    total=False,
)


class ClientDescribeTransformJobResponseTypeDef(
    _ClientDescribeTransformJobResponseTypeDef
):
    """
    Type definition for `ClientDescribeTransformJob` `Response`

    - **TransformJobName** *(string) --*

      The name of the transform job.

    - **TransformJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the transform job.

    - **TransformJobStatus** *(string) --*

      The status of the transform job. If the transform job failed, the reason is returned in the
      ``FailureReason`` field.

    - **FailureReason** *(string) --*

      If the transform job failed, ``FailureReason`` describes why it failed. A transform job
      creates a log file, which includes error messages, and stores it as an Amazon S3 object. For
      more information, see `Log Amazon SageMaker Events with Amazon CloudWatch
      <https://docs.aws.amazon.com/sagemaker/latest/dg/logging-cloudwatch.html>`__ .

    - **ModelName** *(string) --*

      The name of the model used in the transform job.

    - **MaxConcurrentTransforms** *(integer) --*

      The maximum number of parallel requests on each instance node that can be launched in a
      transform job. The default value is 1.

    - **MaxPayloadInMB** *(integer) --*

      The maximum payload size, in MB, used in the transform job.

    - **BatchStrategy** *(string) --*

      Specifies the number of records to include in a mini-batch for an HTTP inference request. A
      *record*  is a single unit of input data that inference can be made on. For example, a single
      line in a CSV file is a record.

      To enable the batch strategy, you must set ``SplitType`` to ``Line`` , ``RecordIO`` , or
      ``TFRecord`` .

    - **Environment** *(dict) --*

      The environment variables to set in the Docker container. We support up to 16 key and values
      entries in the map.

      - *(string) --*

        - *(string) --*

    - **TransformInput** *(dict) --*

      Describes the dataset to be transformed and the Amazon S3 location where it is stored.

      - **DataSource** *(dict) --*

        Describes the location of the channel data, which is, the S3 location of the input data
        that the model can consume.

        - **S3DataSource** *(dict) --*

          The S3 location of the data source that is associated with a channel.

          - **S3DataType** *(string) --*

            If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon SageMaker
            uses all objects with the specified key name prefix for batch transform.

            If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a manifest file
            containing a list of object keys that you want Amazon SageMaker to use for batch
            transform.

            The following values are compatible: ``ManifestFile`` , ``S3Prefix``

            The following value is not compatible: ``AugmentedManifestFile``

          - **S3Uri** *(string) --*

            Depending on the value specified for the ``S3DataType`` , identifies either a key name
            prefix or a manifest. For example:

            * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

            * A manifest might look like this: ``s3://bucketname/example.manifest``   The manifest
            is an S3 object which is a JSON file with the following format:   ``[ {"prefix":
            "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
            ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``    ``]``
            The preceding JSON matches the following ``s3Uris`` :
            ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete set of
            ``S3Uris`` in this manifest constitutes the input data for the channel for this
            datasource. The object that each ``S3Uris`` points to must be readable by the IAM role
            that Amazon SageMaker uses to perform tasks on your behalf.

      - **ContentType** *(string) --*

        The multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker uses the
        MIME type with each http call to transfer data to the transform job.

      - **CompressionType** *(string) --*

        If your transform data is compressed, specify the compression type. Amazon SageMaker
        automatically decompresses the data for the transform job accordingly. The default value is
        ``None`` .

      - **SplitType** *(string) --*

        The method to use to split the transform job's data files into smaller batches. Splitting
        is necessary when the total size of each object is too large to fit in a single request.
        You can also use data splitting to improve performance by processing multiple concurrent
        mini-batches. The default value for ``SplitType`` is ``None`` , which indicates that input
        data files are not split, and request payloads contain the entire contents of an input
        object. Set the value of this parameter to ``Line`` to split records on a newline character
        boundary. ``SplitType`` also supports a number of record-oriented binary data formats.

        When splitting is enabled, the size of a mini-batch depends on the values of the
        ``BatchStrategy`` and ``MaxPayloadInMB`` parameters. When the value of ``BatchStrategy`` is
        ``MultiRecord`` , Amazon SageMaker sends the maximum number of records in each request, up
        to the ``MaxPayloadInMB`` limit. If the value of ``BatchStrategy`` is ``SingleRecord`` ,
        Amazon SageMaker sends individual records in each request.

        .. note::

          Some data formats represent a record as a binary payload wrapped with extra padding
          bytes. When splitting is applied to a binary data format, padding is removed if the value
          of ``BatchStrategy`` is set to ``SingleRecord`` . Padding is not removed if the value of
          ``BatchStrategy`` is set to ``MultiRecord`` .

          For more information about ``RecordIO`` , see `Create a Dataset Using RecordIO
          <https://mxnet.apache.org/api/faq/recordio>`__ in the MXNet documentation. For more
          information about ``TFRecord`` , see `Consuming TFRecord data
          <https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data>`__ in the TensorFlow
          documentation.

    - **TransformOutput** *(dict) --*

      Identifies the Amazon S3 location where you want Amazon SageMaker to save the results from
      the transform job.

      - **S3OutputPath** *(string) --*

        The Amazon S3 path where you want Amazon SageMaker to store the results of the transform
        job. For example, ``s3://bucket-name/key-name-prefix`` .

        For every S3 object used as input for the transform job, batch transform stores the
        transformed data with an .``out`` suffix in a corresponding subfolder in the location in
        the output prefix. For example, for the input data stored at
        ``s3://bucket-name/input-name-prefix/dataset01/data.csv`` , batch transform stores the
        transformed data at ``s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out``
        . Batch transform doesn't upload partially processed objects. For an input S3 object that
        contains multiple records, it creates an .``out`` file only if the transform job succeeds
        on the entire file. When the input contains multiple S3 objects, the batch transform job
        processes the listed S3 objects and uploads only the output for successfully processed
        objects. If any object fails in the transform job batch transform marks the job as failed
        to prompt investigation.

      - **Accept** *(string) --*

        The MIME type used to specify the output data. Amazon SageMaker uses the MIME type with
        each http call to transfer data from the transform job.

      - **AssembleWith** *(string) --*

        Defines how to assemble the results of the transform job as a single S3 object. Choose a
        format that is most convenient to you. To concatenate the results in binary format, specify
        ``None`` . To add a newline character at the end of every transformed record, specify
        ``Line`` .

      - **KmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the
        model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId`` can be any
        of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // KMS Key Alias  ``"alias/ExampleAlias"``

        * // Amazon Resource Name (ARN) of a KMS Key Alias
        ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

        If you don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3
        for your role's account. For more information, see `KMS-Managed Encryption Keys
        <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the *Amazon
        Simple Storage Service Developer Guide.*

        The KMS key policy must grant permission to the IAM role that you specify in your
        CreateModel request. For more information, see `Using Key Policies in AWS KMS
        <http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__ in the *AWS Key
        Management Service Developer Guide* .

    - **TransformResources** *(dict) --*

      Describes the resources, including ML instance types and ML instance count, to use for the
      transform job.

      - **InstanceType** *(string) --*

        The ML compute instance type for the transform job. If you are using built-in algorithms to
        transform moderately sized datasets, we recommend using ml.m4.xlarge or ``ml.m5.large``
        instance types.

      - **InstanceCount** *(integer) --*

        The number of ML compute instances to use in the transform job. For distributed transform
        jobs, specify a value greater than 1. The default value is ``1`` .

      - **VolumeKmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data on
        the storage volume attached to the ML compute instance(s) that run the batch transform job.
        The ``VolumeKmsKeyId`` can be any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the transform Job was created.

    - **TransformStartTime** *(datetime) --*

      Indicates when the transform job starts on ML instances. You are billed for the time interval
      between this time and the value of ``TransformEndTime`` .

    - **TransformEndTime** *(datetime) --*

      Indicates when the transform job has been completed, or has stopped or failed. You are billed
      for the time interval between this time and the value of ``TransformStartTime`` .

    - **LabelingJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the Amazon SageMaker Ground Truth labeling job that created
      the transform or training job.

    - **DataProcessing** *(dict) --*

      The data structure used to specify the data to be used for inference in a batch transform job
      and to associate the data that is relevant to the prediction results in the output. The input
      filter provided allows you to exclude input data that is not needed for inference in a batch
      transform job. The output filter provided allows you to include input data relevant to
      interpreting the predictions in the output from the job. For more information, see `Associate
      Prediction Results with their Corresponding Input Records
      <https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html>`__ .

      - **InputFilter** *(string) --*

        A `JSONPath
        <https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html#data-processing-operators>`__
        expression used to select a portion of the input data to pass to the algorithm. Use the
        ``InputFilter`` parameter to exclude fields, such as an ID column, from the input. If you
        want Amazon SageMaker to pass the entire input dataset to the algorithm, accept the default
        value ``$`` .

        Examples: ``"$"`` , ``"$[1:]"`` , ``"$.features"``

      - **OutputFilter** *(string) --*

        A `JSONPath
        <https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html#data-processing-operators>`__
        expression used to select a portion of the joined dataset to save in the output file for a
        batch transform job. If you want Amazon SageMaker to store the entire input dataset in the
        output file, leave the default value, ``$`` . If you specify indexes that aren't within the
        dimension size of the joined dataset, you get an error.

        Examples: ``"$"`` , ``"$[0,5:]"`` , ``"$['id','SageMakerOutput']"``

      - **JoinSource** *(string) --*

        Specifies the source of the data to join with the transformed data. The valid values are
        ``None`` and ``Input`` . The default value is ``None`` , which specifies not to join the
        input with the transformed data. If you want the batch transform job to join the original
        input data with the transformed data, set ``JoinSource`` to ``Input`` .

        For JSON or JSONLines objects, such as a JSON array, Amazon SageMaker adds the transformed
        data to the input JSON object in an attribute called ``SageMakerOutput`` . The joined
        result for JSON must be a key-value pair object. If the input is not a key-value pair
        object, Amazon SageMaker creates a new JSON file. In the new JSON file, and the input data
        is stored under the ``SageMakerInput`` key and the results are stored in
        ``SageMakerOutput`` .

        For CSV files, Amazon SageMaker combines the transformed data with the input data at the
        end of the input data and stores it in the output file. The joined data has the joined
        input data followed by the transformed data and the output is a CSV file.
    """


_ClientDescribeWorkteamResponseWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef = TypedDict(
    "_ClientDescribeWorkteamResponseWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef",
    {"UserPool": str, "UserGroup": str, "ClientId": str},
    total=False,
)


class ClientDescribeWorkteamResponseWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef(
    _ClientDescribeWorkteamResponseWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef
):
    """
    Type definition for `ClientDescribeWorkteamResponseWorkteamMemberDefinitions` `CognitoMemberDefinition`

    The Amazon Cognito user group that is part of the work team.

    - **UserPool** *(string) --*

      An identifier for a user pool. The user pool must be in the same region as the
      service that you are calling.

    - **UserGroup** *(string) --*

      An identifier for a user group.

    - **ClientId** *(string) --*

      An identifier for an application client. You must create the app client ID using
      Amazon Cognito.
    """


_ClientDescribeWorkteamResponseWorkteamMemberDefinitionsTypeDef = TypedDict(
    "_ClientDescribeWorkteamResponseWorkteamMemberDefinitionsTypeDef",
    {
        "CognitoMemberDefinition": ClientDescribeWorkteamResponseWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef
    },
    total=False,
)


class ClientDescribeWorkteamResponseWorkteamMemberDefinitionsTypeDef(
    _ClientDescribeWorkteamResponseWorkteamMemberDefinitionsTypeDef
):
    """
    Type definition for `ClientDescribeWorkteamResponseWorkteam` `MemberDefinitions`

    Defines the Amazon Cognito user group that is part of a work team.

    - **CognitoMemberDefinition** *(dict) --*

      The Amazon Cognito user group that is part of the work team.

      - **UserPool** *(string) --*

        An identifier for a user pool. The user pool must be in the same region as the
        service that you are calling.

      - **UserGroup** *(string) --*

        An identifier for a user group.

      - **ClientId** *(string) --*

        An identifier for an application client. You must create the app client ID using
        Amazon Cognito.
    """


_ClientDescribeWorkteamResponseWorkteamNotificationConfigurationTypeDef = TypedDict(
    "_ClientDescribeWorkteamResponseWorkteamNotificationConfigurationTypeDef",
    {"NotificationTopicArn": str},
    total=False,
)


class ClientDescribeWorkteamResponseWorkteamNotificationConfigurationTypeDef(
    _ClientDescribeWorkteamResponseWorkteamNotificationConfigurationTypeDef
):
    """
    Type definition for `ClientDescribeWorkteamResponseWorkteam` `NotificationConfiguration`

    Configures SNS notifications of available or expiring work items for work teams.

    - **NotificationTopicArn** *(string) --*

      The ARN for the SNS topic to which notifications should be published.
    """


_ClientDescribeWorkteamResponseWorkteamTypeDef = TypedDict(
    "_ClientDescribeWorkteamResponseWorkteamTypeDef",
    {
        "WorkteamName": str,
        "MemberDefinitions": List[
            ClientDescribeWorkteamResponseWorkteamMemberDefinitionsTypeDef
        ],
        "WorkteamArn": str,
        "ProductListingIds": List[str],
        "Description": str,
        "SubDomain": str,
        "CreateDate": datetime,
        "LastUpdatedDate": datetime,
        "NotificationConfiguration": ClientDescribeWorkteamResponseWorkteamNotificationConfigurationTypeDef,
    },
    total=False,
)


class ClientDescribeWorkteamResponseWorkteamTypeDef(
    _ClientDescribeWorkteamResponseWorkteamTypeDef
):
    """
    Type definition for `ClientDescribeWorkteamResponse` `Workteam`

    A ``Workteam`` instance that contains information about the work team.

    - **WorkteamName** *(string) --*

      The name of the work team.

    - **MemberDefinitions** *(list) --*

      The Amazon Cognito user groups that make up the work team.

      - *(dict) --*

        Defines the Amazon Cognito user group that is part of a work team.

        - **CognitoMemberDefinition** *(dict) --*

          The Amazon Cognito user group that is part of the work team.

          - **UserPool** *(string) --*

            An identifier for a user pool. The user pool must be in the same region as the
            service that you are calling.

          - **UserGroup** *(string) --*

            An identifier for a user group.

          - **ClientId** *(string) --*

            An identifier for an application client. You must create the app client ID using
            Amazon Cognito.

    - **WorkteamArn** *(string) --*

      The Amazon Resource Name (ARN) that identifies the work team.

    - **ProductListingIds** *(list) --*

      The Amazon Marketplace identifier for a vendor's work team.

      - *(string) --*

    - **Description** *(string) --*

      A description of the work team.

    - **SubDomain** *(string) --*

      The URI of the labeling job's user interface. Workers open this URI to start labeling your
      data objects.

    - **CreateDate** *(datetime) --*

      The date and time that the work team was created (timestamp).

    - **LastUpdatedDate** *(datetime) --*

      The date and time that the work team was last updated (timestamp).

    - **NotificationConfiguration** *(dict) --*

      Configures SNS notifications of available or expiring work items for work teams.

      - **NotificationTopicArn** *(string) --*

        The ARN for the SNS topic to which notifications should be published.
    """


_ClientDescribeWorkteamResponseTypeDef = TypedDict(
    "_ClientDescribeWorkteamResponseTypeDef",
    {"Workteam": ClientDescribeWorkteamResponseWorkteamTypeDef},
    total=False,
)


class ClientDescribeWorkteamResponseTypeDef(_ClientDescribeWorkteamResponseTypeDef):
    """
    Type definition for `ClientDescribeWorkteam` `Response`

    - **Workteam** *(dict) --*

      A ``Workteam`` instance that contains information about the work team.

      - **WorkteamName** *(string) --*

        The name of the work team.

      - **MemberDefinitions** *(list) --*

        The Amazon Cognito user groups that make up the work team.

        - *(dict) --*

          Defines the Amazon Cognito user group that is part of a work team.

          - **CognitoMemberDefinition** *(dict) --*

            The Amazon Cognito user group that is part of the work team.

            - **UserPool** *(string) --*

              An identifier for a user pool. The user pool must be in the same region as the
              service that you are calling.

            - **UserGroup** *(string) --*

              An identifier for a user group.

            - **ClientId** *(string) --*

              An identifier for an application client. You must create the app client ID using
              Amazon Cognito.

      - **WorkteamArn** *(string) --*

        The Amazon Resource Name (ARN) that identifies the work team.

      - **ProductListingIds** *(list) --*

        The Amazon Marketplace identifier for a vendor's work team.

        - *(string) --*

      - **Description** *(string) --*

        A description of the work team.

      - **SubDomain** *(string) --*

        The URI of the labeling job's user interface. Workers open this URI to start labeling your
        data objects.

      - **CreateDate** *(datetime) --*

        The date and time that the work team was created (timestamp).

      - **LastUpdatedDate** *(datetime) --*

        The date and time that the work team was last updated (timestamp).

      - **NotificationConfiguration** *(dict) --*

        Configures SNS notifications of available or expiring work items for work teams.

        - **NotificationTopicArn** *(string) --*

          The ARN for the SNS topic to which notifications should be published.
    """


_ClientGetSearchSuggestionsResponsePropertyNameSuggestionsTypeDef = TypedDict(
    "_ClientGetSearchSuggestionsResponsePropertyNameSuggestionsTypeDef",
    {"PropertyName": str},
    total=False,
)


class ClientGetSearchSuggestionsResponsePropertyNameSuggestionsTypeDef(
    _ClientGetSearchSuggestionsResponsePropertyNameSuggestionsTypeDef
):
    """
    Type definition for `ClientGetSearchSuggestionsResponse` `PropertyNameSuggestions`

    A property name returned from a ``GetSearchSuggestions`` call that specifies a value in the
    ``PropertyNameQuery`` field.

    - **PropertyName** *(string) --*

      A suggested property name based on what you entered in the search textbox in the Amazon
      SageMaker console.
    """


_ClientGetSearchSuggestionsResponseTypeDef = TypedDict(
    "_ClientGetSearchSuggestionsResponseTypeDef",
    {
        "PropertyNameSuggestions": List[
            ClientGetSearchSuggestionsResponsePropertyNameSuggestionsTypeDef
        ]
    },
    total=False,
)


class ClientGetSearchSuggestionsResponseTypeDef(
    _ClientGetSearchSuggestionsResponseTypeDef
):
    """
    Type definition for `ClientGetSearchSuggestions` `Response`

    - **PropertyNameSuggestions** *(list) --*

      A list of property names for a ``Resource`` that match a ``SuggestionQuery`` .

      - *(dict) --*

        A property name returned from a ``GetSearchSuggestions`` call that specifies a value in the
        ``PropertyNameQuery`` field.

        - **PropertyName** *(string) --*

          A suggested property name based on what you entered in the search textbox in the Amazon
          SageMaker console.
    """


_ClientGetSearchSuggestionsSuggestionQueryPropertyNameQueryTypeDef = TypedDict(
    "_ClientGetSearchSuggestionsSuggestionQueryPropertyNameQueryTypeDef",
    {"PropertyNameHint": str},
)


class ClientGetSearchSuggestionsSuggestionQueryPropertyNameQueryTypeDef(
    _ClientGetSearchSuggestionsSuggestionQueryPropertyNameQueryTypeDef
):
    """
    Type definition for `ClientGetSearchSuggestionsSuggestionQuery` `PropertyNameQuery`

    A type of ``SuggestionQuery`` . Defines a property name hint. Only property names that match
    the specified hint are included in the response.

    - **PropertyNameHint** *(string) --* **[REQUIRED]**

      Text that is part of a property's name. The property names of hyperparameter, metric, and tag
      key names that begin with the specified text in the ``PropertyNameHint`` .
    """


_ClientGetSearchSuggestionsSuggestionQueryTypeDef = TypedDict(
    "_ClientGetSearchSuggestionsSuggestionQueryTypeDef",
    {
        "PropertyNameQuery": ClientGetSearchSuggestionsSuggestionQueryPropertyNameQueryTypeDef
    },
    total=False,
)


class ClientGetSearchSuggestionsSuggestionQueryTypeDef(
    _ClientGetSearchSuggestionsSuggestionQueryTypeDef
):
    """
    Type definition for `ClientGetSearchSuggestions` `SuggestionQuery`

    Limits the property names that are included in the response.

    - **PropertyNameQuery** *(dict) --*

      A type of ``SuggestionQuery`` . Defines a property name hint. Only property names that match
      the specified hint are included in the response.

      - **PropertyNameHint** *(string) --* **[REQUIRED]**

        Text that is part of a property's name. The property names of hyperparameter, metric, and tag
        key names that begin with the specified text in the ``PropertyNameHint`` .
    """


_ClientListAlgorithmsResponseAlgorithmSummaryListTypeDef = TypedDict(
    "_ClientListAlgorithmsResponseAlgorithmSummaryListTypeDef",
    {
        "AlgorithmName": str,
        "AlgorithmArn": str,
        "AlgorithmDescription": str,
        "CreationTime": datetime,
        "AlgorithmStatus": str,
    },
    total=False,
)


class ClientListAlgorithmsResponseAlgorithmSummaryListTypeDef(
    _ClientListAlgorithmsResponseAlgorithmSummaryListTypeDef
):
    """
    Type definition for `ClientListAlgorithmsResponse` `AlgorithmSummaryList`

    Provides summary information about an algorithm.

    - **AlgorithmName** *(string) --*

      The name of the algorithm that is described by the summary.

    - **AlgorithmArn** *(string) --*

      The Amazon Resource Name (ARN) of the algorithm.

    - **AlgorithmDescription** *(string) --*

      A brief description of the algorithm.

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the algorithm was created.

    - **AlgorithmStatus** *(string) --*

      The overall status of the algorithm.
    """


_ClientListAlgorithmsResponseTypeDef = TypedDict(
    "_ClientListAlgorithmsResponseTypeDef",
    {
        "AlgorithmSummaryList": List[
            ClientListAlgorithmsResponseAlgorithmSummaryListTypeDef
        ],
        "NextToken": str,
    },
    total=False,
)


class ClientListAlgorithmsResponseTypeDef(_ClientListAlgorithmsResponseTypeDef):
    """
    Type definition for `ClientListAlgorithms` `Response`

    - **AlgorithmSummaryList** *(list) --*

      >An array of ``AlgorithmSummary`` objects, each of which lists an algorithm.

      - *(dict) --*

        Provides summary information about an algorithm.

        - **AlgorithmName** *(string) --*

          The name of the algorithm that is described by the summary.

        - **AlgorithmArn** *(string) --*

          The Amazon Resource Name (ARN) of the algorithm.

        - **AlgorithmDescription** *(string) --*

          A brief description of the algorithm.

        - **CreationTime** *(datetime) --*

          A timestamp that shows when the algorithm was created.

        - **AlgorithmStatus** *(string) --*

          The overall status of the algorithm.

    - **NextToken** *(string) --*

      If the response is truncated, Amazon SageMaker returns this token. To retrieve the next set
      of algorithms, use it in the subsequent request.
    """


_ClientListCodeRepositoriesResponseCodeRepositorySummaryListGitConfigTypeDef = TypedDict(
    "_ClientListCodeRepositoriesResponseCodeRepositorySummaryListGitConfigTypeDef",
    {"RepositoryUrl": str, "Branch": str, "SecretArn": str},
    total=False,
)


class ClientListCodeRepositoriesResponseCodeRepositorySummaryListGitConfigTypeDef(
    _ClientListCodeRepositoriesResponseCodeRepositorySummaryListGitConfigTypeDef
):
    """
    Type definition for `ClientListCodeRepositoriesResponseCodeRepositorySummaryList` `GitConfig`

    Configuration details for the Git repository, including the URL where it is located and
    the ARN of the AWS Secrets Manager secret that contains the credentials used to access
    the repository.

    - **RepositoryUrl** *(string) --*

      The URL where the Git repository is located.

    - **Branch** *(string) --*

      The default branch for the Git repository.

    - **SecretArn** *(string) --*

      The Amazon Resource Name (ARN) of the AWS Secrets Manager secret that contains the
      credentials used to access the git repository. The secret must have a staging label of
      ``AWSCURRENT`` and must be in the following format:

       ``{"username": *UserName* , "password": *Password* }``
    """


_ClientListCodeRepositoriesResponseCodeRepositorySummaryListTypeDef = TypedDict(
    "_ClientListCodeRepositoriesResponseCodeRepositorySummaryListTypeDef",
    {
        "CodeRepositoryName": str,
        "CodeRepositoryArn": str,
        "CreationTime": datetime,
        "LastModifiedTime": datetime,
        "GitConfig": ClientListCodeRepositoriesResponseCodeRepositorySummaryListGitConfigTypeDef,
    },
    total=False,
)


class ClientListCodeRepositoriesResponseCodeRepositorySummaryListTypeDef(
    _ClientListCodeRepositoriesResponseCodeRepositorySummaryListTypeDef
):
    """
    Type definition for `ClientListCodeRepositoriesResponse` `CodeRepositorySummaryList`

    Specifies summary information about a Git repository.

    - **CodeRepositoryName** *(string) --*

      The name of the Git repository.

    - **CodeRepositoryArn** *(string) --*

      The Amazon Resource Name (ARN) of the Git repository.

    - **CreationTime** *(datetime) --*

      The date and time that the Git repository was created.

    - **LastModifiedTime** *(datetime) --*

      The date and time that the Git repository was last modified.

    - **GitConfig** *(dict) --*

      Configuration details for the Git repository, including the URL where it is located and
      the ARN of the AWS Secrets Manager secret that contains the credentials used to access
      the repository.

      - **RepositoryUrl** *(string) --*

        The URL where the Git repository is located.

      - **Branch** *(string) --*

        The default branch for the Git repository.

      - **SecretArn** *(string) --*

        The Amazon Resource Name (ARN) of the AWS Secrets Manager secret that contains the
        credentials used to access the git repository. The secret must have a staging label of
        ``AWSCURRENT`` and must be in the following format:

         ``{"username": *UserName* , "password": *Password* }``
    """


_ClientListCodeRepositoriesResponseTypeDef = TypedDict(
    "_ClientListCodeRepositoriesResponseTypeDef",
    {
        "CodeRepositorySummaryList": List[
            ClientListCodeRepositoriesResponseCodeRepositorySummaryListTypeDef
        ],
        "NextToken": str,
    },
    total=False,
)


class ClientListCodeRepositoriesResponseTypeDef(
    _ClientListCodeRepositoriesResponseTypeDef
):
    """
    Type definition for `ClientListCodeRepositories` `Response`

    - **CodeRepositorySummaryList** *(list) --*

      Gets a list of summaries of the Git repositories. Each summary specifies the following values
      for the repository:

      * Name

      * Amazon Resource Name (ARN)

      * Creation time

      * Last modified time

      * Configuration information, including the URL location of the repository and the ARN of the
      AWS Secrets Manager secret that contains the credentials used to access the repository.

      - *(dict) --*

        Specifies summary information about a Git repository.

        - **CodeRepositoryName** *(string) --*

          The name of the Git repository.

        - **CodeRepositoryArn** *(string) --*

          The Amazon Resource Name (ARN) of the Git repository.

        - **CreationTime** *(datetime) --*

          The date and time that the Git repository was created.

        - **LastModifiedTime** *(datetime) --*

          The date and time that the Git repository was last modified.

        - **GitConfig** *(dict) --*

          Configuration details for the Git repository, including the URL where it is located and
          the ARN of the AWS Secrets Manager secret that contains the credentials used to access
          the repository.

          - **RepositoryUrl** *(string) --*

            The URL where the Git repository is located.

          - **Branch** *(string) --*

            The default branch for the Git repository.

          - **SecretArn** *(string) --*

            The Amazon Resource Name (ARN) of the AWS Secrets Manager secret that contains the
            credentials used to access the git repository. The secret must have a staging label of
            ``AWSCURRENT`` and must be in the following format:

             ``{"username": *UserName* , "password": *Password* }``

    - **NextToken** *(string) --*

      If the result of a ``ListCodeRepositoriesOutput`` request was truncated, the response
      includes a ``NextToken`` . To get the next set of Git repositories, use the token in the next
      request.
    """


_ClientListCompilationJobsResponseCompilationJobSummariesTypeDef = TypedDict(
    "_ClientListCompilationJobsResponseCompilationJobSummariesTypeDef",
    {
        "CompilationJobName": str,
        "CompilationJobArn": str,
        "CreationTime": datetime,
        "CompilationStartTime": datetime,
        "CompilationEndTime": datetime,
        "CompilationTargetDevice": str,
        "LastModifiedTime": datetime,
        "CompilationJobStatus": str,
    },
    total=False,
)


class ClientListCompilationJobsResponseCompilationJobSummariesTypeDef(
    _ClientListCompilationJobsResponseCompilationJobSummariesTypeDef
):
    """
    Type definition for `ClientListCompilationJobsResponse` `CompilationJobSummaries`

    A summary of a model compilation job.

    - **CompilationJobName** *(string) --*

      The name of the model compilation job that you want a summary for.

    - **CompilationJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the model compilation job.

    - **CreationTime** *(datetime) --*

      The time when the model compilation job was created.

    - **CompilationStartTime** *(datetime) --*

      The time when the model compilation job started.

    - **CompilationEndTime** *(datetime) --*

      The time when the model compilation job completed.

    - **CompilationTargetDevice** *(string) --*

      The type of device that the model will run on after compilation has completed.

    - **LastModifiedTime** *(datetime) --*

      The time when the model compilation job was last modified.

    - **CompilationJobStatus** *(string) --*

      The status of the model compilation job.
    """


_ClientListCompilationJobsResponseTypeDef = TypedDict(
    "_ClientListCompilationJobsResponseTypeDef",
    {
        "CompilationJobSummaries": List[
            ClientListCompilationJobsResponseCompilationJobSummariesTypeDef
        ],
        "NextToken": str,
    },
    total=False,
)


class ClientListCompilationJobsResponseTypeDef(
    _ClientListCompilationJobsResponseTypeDef
):
    """
    Type definition for `ClientListCompilationJobs` `Response`

    - **CompilationJobSummaries** *(list) --*

      An array of  CompilationJobSummary objects, each describing a model compilation job.

      - *(dict) --*

        A summary of a model compilation job.

        - **CompilationJobName** *(string) --*

          The name of the model compilation job that you want a summary for.

        - **CompilationJobArn** *(string) --*

          The Amazon Resource Name (ARN) of the model compilation job.

        - **CreationTime** *(datetime) --*

          The time when the model compilation job was created.

        - **CompilationStartTime** *(datetime) --*

          The time when the model compilation job started.

        - **CompilationEndTime** *(datetime) --*

          The time when the model compilation job completed.

        - **CompilationTargetDevice** *(string) --*

          The type of device that the model will run on after compilation has completed.

        - **LastModifiedTime** *(datetime) --*

          The time when the model compilation job was last modified.

        - **CompilationJobStatus** *(string) --*

          The status of the model compilation job.

    - **NextToken** *(string) --*

      If the response is truncated, Amazon SageMaker returns this ``NextToken`` . To retrieve the
      next set of model compilation jobs, use this token in the next request.
    """


_ClientListEndpointConfigsResponseEndpointConfigsTypeDef = TypedDict(
    "_ClientListEndpointConfigsResponseEndpointConfigsTypeDef",
    {"EndpointConfigName": str, "EndpointConfigArn": str, "CreationTime": datetime},
    total=False,
)


class ClientListEndpointConfigsResponseEndpointConfigsTypeDef(
    _ClientListEndpointConfigsResponseEndpointConfigsTypeDef
):
    """
    Type definition for `ClientListEndpointConfigsResponse` `EndpointConfigs`

    Provides summary information for an endpoint configuration.

    - **EndpointConfigName** *(string) --*

      The name of the endpoint configuration.

    - **EndpointConfigArn** *(string) --*

      The Amazon Resource Name (ARN) of the endpoint configuration.

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the endpoint configuration was created.
    """


_ClientListEndpointConfigsResponseTypeDef = TypedDict(
    "_ClientListEndpointConfigsResponseTypeDef",
    {
        "EndpointConfigs": List[
            ClientListEndpointConfigsResponseEndpointConfigsTypeDef
        ],
        "NextToken": str,
    },
    total=False,
)


class ClientListEndpointConfigsResponseTypeDef(
    _ClientListEndpointConfigsResponseTypeDef
):
    """
    Type definition for `ClientListEndpointConfigs` `Response`

    - **EndpointConfigs** *(list) --*

      An array of endpoint configurations.

      - *(dict) --*

        Provides summary information for an endpoint configuration.

        - **EndpointConfigName** *(string) --*

          The name of the endpoint configuration.

        - **EndpointConfigArn** *(string) --*

          The Amazon Resource Name (ARN) of the endpoint configuration.

        - **CreationTime** *(datetime) --*

          A timestamp that shows when the endpoint configuration was created.

    - **NextToken** *(string) --*

      If the response is truncated, Amazon SageMaker returns this token. To retrieve the next set
      of endpoint configurations, use it in the subsequent request
    """


_ClientListEndpointsResponseEndpointsTypeDef = TypedDict(
    "_ClientListEndpointsResponseEndpointsTypeDef",
    {
        "EndpointName": str,
        "EndpointArn": str,
        "CreationTime": datetime,
        "LastModifiedTime": datetime,
        "EndpointStatus": str,
    },
    total=False,
)


class ClientListEndpointsResponseEndpointsTypeDef(
    _ClientListEndpointsResponseEndpointsTypeDef
):
    """
    Type definition for `ClientListEndpointsResponse` `Endpoints`

    Provides summary information for an endpoint.

    - **EndpointName** *(string) --*

      The name of the endpoint.

    - **EndpointArn** *(string) --*

      The Amazon Resource Name (ARN) of the endpoint.

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the endpoint was created.

    - **LastModifiedTime** *(datetime) --*

      A timestamp that shows when the endpoint was last modified.

    - **EndpointStatus** *(string) --*

      The status of the endpoint.

      * ``OutOfService`` : Endpoint is not available to take incoming requests.

      * ``Creating`` :  CreateEndpoint is executing.

      * ``Updating`` :  UpdateEndpoint or  UpdateEndpointWeightsAndCapacities is executing.

      * ``SystemUpdating`` : Endpoint is undergoing maintenance and cannot be updated or
      deleted or re-scaled until it has completed. This maintenance operation does not change
      any customer-specified values such as VPC config, KMS encryption, model, instance type,
      or instance count.

      * ``RollingBack`` : Endpoint fails to scale up or down or change its variant weight and
      is in the process of rolling back to its previous configuration. Once the rollback
      completes, endpoint returns to an ``InService`` status. This transitional status only
      applies to an endpoint that has autoscaling enabled and is undergoing variant weight or
      capacity changes as part of an  UpdateEndpointWeightsAndCapacities call or when the
      UpdateEndpointWeightsAndCapacities operation is called explicitly.

      * ``InService`` : Endpoint is available to process incoming requests.

      * ``Deleting`` :  DeleteEndpoint is executing.

      * ``Failed`` : Endpoint could not be created, updated, or re-scaled. Use
      DescribeEndpointOutput$FailureReason for information about the failure.  DeleteEndpoint
      is the only operation that can be performed on a failed endpoint.

      To get a list of endpoints with a specified status, use the
      ListEndpointsInput$StatusEquals filter.
    """


_ClientListEndpointsResponseTypeDef = TypedDict(
    "_ClientListEndpointsResponseTypeDef",
    {"Endpoints": List[ClientListEndpointsResponseEndpointsTypeDef], "NextToken": str},
    total=False,
)


class ClientListEndpointsResponseTypeDef(_ClientListEndpointsResponseTypeDef):
    """
    Type definition for `ClientListEndpoints` `Response`

    - **Endpoints** *(list) --*

      An array or endpoint objects.

      - *(dict) --*

        Provides summary information for an endpoint.

        - **EndpointName** *(string) --*

          The name of the endpoint.

        - **EndpointArn** *(string) --*

          The Amazon Resource Name (ARN) of the endpoint.

        - **CreationTime** *(datetime) --*

          A timestamp that shows when the endpoint was created.

        - **LastModifiedTime** *(datetime) --*

          A timestamp that shows when the endpoint was last modified.

        - **EndpointStatus** *(string) --*

          The status of the endpoint.

          * ``OutOfService`` : Endpoint is not available to take incoming requests.

          * ``Creating`` :  CreateEndpoint is executing.

          * ``Updating`` :  UpdateEndpoint or  UpdateEndpointWeightsAndCapacities is executing.

          * ``SystemUpdating`` : Endpoint is undergoing maintenance and cannot be updated or
          deleted or re-scaled until it has completed. This maintenance operation does not change
          any customer-specified values such as VPC config, KMS encryption, model, instance type,
          or instance count.

          * ``RollingBack`` : Endpoint fails to scale up or down or change its variant weight and
          is in the process of rolling back to its previous configuration. Once the rollback
          completes, endpoint returns to an ``InService`` status. This transitional status only
          applies to an endpoint that has autoscaling enabled and is undergoing variant weight or
          capacity changes as part of an  UpdateEndpointWeightsAndCapacities call or when the
          UpdateEndpointWeightsAndCapacities operation is called explicitly.

          * ``InService`` : Endpoint is available to process incoming requests.

          * ``Deleting`` :  DeleteEndpoint is executing.

          * ``Failed`` : Endpoint could not be created, updated, or re-scaled. Use
          DescribeEndpointOutput$FailureReason for information about the failure.  DeleteEndpoint
          is the only operation that can be performed on a failed endpoint.

          To get a list of endpoints with a specified status, use the
          ListEndpointsInput$StatusEquals filter.

    - **NextToken** *(string) --*

      If the response is truncated, Amazon SageMaker returns this token. To retrieve the next set
      of training jobs, use it in the subsequent request.
    """


_ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesObjectiveStatusCountersTypeDef = TypedDict(
    "_ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesObjectiveStatusCountersTypeDef",
    {"Succeeded": int, "Pending": int, "Failed": int},
    total=False,
)


class ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesObjectiveStatusCountersTypeDef(
    _ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesObjectiveStatusCountersTypeDef
):
    """
    Type definition for `ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummaries` `ObjectiveStatusCounters`

    The  ObjectiveStatusCounters object that specifies the numbers of training jobs,
    categorized by objective metric status, that this tuning job launched.

    - **Succeeded** *(integer) --*

      The number of training jobs whose final objective metric was evaluated by the
      hyperparameter tuning job and used in the hyperparameter tuning process.

    - **Pending** *(integer) --*

      The number of training jobs that are in progress and pending evaluation of their final
      objective metric.

    - **Failed** *(integer) --*

      The number of training jobs whose final objective metric was not evaluated and used in
      the hyperparameter tuning process. This typically occurs when the training job failed
      or did not emit an objective metric.
    """


_ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesResourceLimitsTypeDef = TypedDict(
    "_ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesResourceLimitsTypeDef",
    {"MaxNumberOfTrainingJobs": int, "MaxParallelTrainingJobs": int},
    total=False,
)


class ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesResourceLimitsTypeDef(
    _ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesResourceLimitsTypeDef
):
    """
    Type definition for `ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummaries` `ResourceLimits`

    The  ResourceLimits object that specifies the maximum number of training jobs and
    parallel training jobs allowed for this tuning job.

    - **MaxNumberOfTrainingJobs** *(integer) --*

      The maximum number of training jobs that a hyperparameter tuning job can launch.

    - **MaxParallelTrainingJobs** *(integer) --*

      The maximum number of concurrent training jobs that a hyperparameter tuning job can
      launch.
    """


_ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesTrainingJobStatusCountersTypeDef = TypedDict(
    "_ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesTrainingJobStatusCountersTypeDef",
    {
        "Completed": int,
        "InProgress": int,
        "RetryableError": int,
        "NonRetryableError": int,
        "Stopped": int,
    },
    total=False,
)


class ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesTrainingJobStatusCountersTypeDef(
    _ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesTrainingJobStatusCountersTypeDef
):
    """
    Type definition for `ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummaries` `TrainingJobStatusCounters`

    The  TrainingJobStatusCounters object that specifies the numbers of training jobs,
    categorized by status, that this tuning job launched.

    - **Completed** *(integer) --*

      The number of completed training jobs launched by the hyperparameter tuning job.

    - **InProgress** *(integer) --*

      The number of in-progress training jobs launched by a hyperparameter tuning job.

    - **RetryableError** *(integer) --*

      The number of training jobs that failed, but can be retried. A failed training job can
      be retried only if it failed because an internal service error occurred.

    - **NonRetryableError** *(integer) --*

      The number of training jobs that failed and can't be retried. A failed training job
      can't be retried if it failed because a client error occurred.

    - **Stopped** *(integer) --*

      The number of training jobs launched by a hyperparameter tuning job that were manually
      stopped.
    """


_ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesTypeDef = TypedDict(
    "_ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesTypeDef",
    {
        "HyperParameterTuningJobName": str,
        "HyperParameterTuningJobArn": str,
        "HyperParameterTuningJobStatus": str,
        "Strategy": str,
        "CreationTime": datetime,
        "HyperParameterTuningEndTime": datetime,
        "LastModifiedTime": datetime,
        "TrainingJobStatusCounters": ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesTrainingJobStatusCountersTypeDef,
        "ObjectiveStatusCounters": ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesObjectiveStatusCountersTypeDef,
        "ResourceLimits": ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesResourceLimitsTypeDef,
    },
    total=False,
)


class ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesTypeDef(
    _ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesTypeDef
):
    """
    Type definition for `ClientListHyperParameterTuningJobsResponse` `HyperParameterTuningJobSummaries`

    Provides summary information about a hyperparameter tuning job.

    - **HyperParameterTuningJobName** *(string) --*

      The name of the tuning job.

    - **HyperParameterTuningJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the tuning job.

    - **HyperParameterTuningJobStatus** *(string) --*

      The status of the tuning job.

    - **Strategy** *(string) --*

      Specifies the search strategy hyperparameter tuning uses to choose which hyperparameters
      to use for each iteration. Currently, the only valid value is Bayesian.

    - **CreationTime** *(datetime) --*

      The date and time that the tuning job was created.

    - **HyperParameterTuningEndTime** *(datetime) --*

      The date and time that the tuning job ended.

    - **LastModifiedTime** *(datetime) --*

      The date and time that the tuning job was modified.

    - **TrainingJobStatusCounters** *(dict) --*

      The  TrainingJobStatusCounters object that specifies the numbers of training jobs,
      categorized by status, that this tuning job launched.

      - **Completed** *(integer) --*

        The number of completed training jobs launched by the hyperparameter tuning job.

      - **InProgress** *(integer) --*

        The number of in-progress training jobs launched by a hyperparameter tuning job.

      - **RetryableError** *(integer) --*

        The number of training jobs that failed, but can be retried. A failed training job can
        be retried only if it failed because an internal service error occurred.

      - **NonRetryableError** *(integer) --*

        The number of training jobs that failed and can't be retried. A failed training job
        can't be retried if it failed because a client error occurred.

      - **Stopped** *(integer) --*

        The number of training jobs launched by a hyperparameter tuning job that were manually
        stopped.

    - **ObjectiveStatusCounters** *(dict) --*

      The  ObjectiveStatusCounters object that specifies the numbers of training jobs,
      categorized by objective metric status, that this tuning job launched.

      - **Succeeded** *(integer) --*

        The number of training jobs whose final objective metric was evaluated by the
        hyperparameter tuning job and used in the hyperparameter tuning process.

      - **Pending** *(integer) --*

        The number of training jobs that are in progress and pending evaluation of their final
        objective metric.

      - **Failed** *(integer) --*

        The number of training jobs whose final objective metric was not evaluated and used in
        the hyperparameter tuning process. This typically occurs when the training job failed
        or did not emit an objective metric.

    - **ResourceLimits** *(dict) --*

      The  ResourceLimits object that specifies the maximum number of training jobs and
      parallel training jobs allowed for this tuning job.

      - **MaxNumberOfTrainingJobs** *(integer) --*

        The maximum number of training jobs that a hyperparameter tuning job can launch.

      - **MaxParallelTrainingJobs** *(integer) --*

        The maximum number of concurrent training jobs that a hyperparameter tuning job can
        launch.
    """


_ClientListHyperParameterTuningJobsResponseTypeDef = TypedDict(
    "_ClientListHyperParameterTuningJobsResponseTypeDef",
    {
        "HyperParameterTuningJobSummaries": List[
            ClientListHyperParameterTuningJobsResponseHyperParameterTuningJobSummariesTypeDef
        ],
        "NextToken": str,
    },
    total=False,
)


class ClientListHyperParameterTuningJobsResponseTypeDef(
    _ClientListHyperParameterTuningJobsResponseTypeDef
):
    """
    Type definition for `ClientListHyperParameterTuningJobs` `Response`

    - **HyperParameterTuningJobSummaries** *(list) --*

      A list of  HyperParameterTuningJobSummary objects that describe the tuning jobs that the
      ``ListHyperParameterTuningJobs`` request returned.

      - *(dict) --*

        Provides summary information about a hyperparameter tuning job.

        - **HyperParameterTuningJobName** *(string) --*

          The name of the tuning job.

        - **HyperParameterTuningJobArn** *(string) --*

          The Amazon Resource Name (ARN) of the tuning job.

        - **HyperParameterTuningJobStatus** *(string) --*

          The status of the tuning job.

        - **Strategy** *(string) --*

          Specifies the search strategy hyperparameter tuning uses to choose which hyperparameters
          to use for each iteration. Currently, the only valid value is Bayesian.

        - **CreationTime** *(datetime) --*

          The date and time that the tuning job was created.

        - **HyperParameterTuningEndTime** *(datetime) --*

          The date and time that the tuning job ended.

        - **LastModifiedTime** *(datetime) --*

          The date and time that the tuning job was modified.

        - **TrainingJobStatusCounters** *(dict) --*

          The  TrainingJobStatusCounters object that specifies the numbers of training jobs,
          categorized by status, that this tuning job launched.

          - **Completed** *(integer) --*

            The number of completed training jobs launched by the hyperparameter tuning job.

          - **InProgress** *(integer) --*

            The number of in-progress training jobs launched by a hyperparameter tuning job.

          - **RetryableError** *(integer) --*

            The number of training jobs that failed, but can be retried. A failed training job can
            be retried only if it failed because an internal service error occurred.

          - **NonRetryableError** *(integer) --*

            The number of training jobs that failed and can't be retried. A failed training job
            can't be retried if it failed because a client error occurred.

          - **Stopped** *(integer) --*

            The number of training jobs launched by a hyperparameter tuning job that were manually
            stopped.

        - **ObjectiveStatusCounters** *(dict) --*

          The  ObjectiveStatusCounters object that specifies the numbers of training jobs,
          categorized by objective metric status, that this tuning job launched.

          - **Succeeded** *(integer) --*

            The number of training jobs whose final objective metric was evaluated by the
            hyperparameter tuning job and used in the hyperparameter tuning process.

          - **Pending** *(integer) --*

            The number of training jobs that are in progress and pending evaluation of their final
            objective metric.

          - **Failed** *(integer) --*

            The number of training jobs whose final objective metric was not evaluated and used in
            the hyperparameter tuning process. This typically occurs when the training job failed
            or did not emit an objective metric.

        - **ResourceLimits** *(dict) --*

          The  ResourceLimits object that specifies the maximum number of training jobs and
          parallel training jobs allowed for this tuning job.

          - **MaxNumberOfTrainingJobs** *(integer) --*

            The maximum number of training jobs that a hyperparameter tuning job can launch.

          - **MaxParallelTrainingJobs** *(integer) --*

            The maximum number of concurrent training jobs that a hyperparameter tuning job can
            launch.

    - **NextToken** *(string) --*

      If the result of this ``ListHyperParameterTuningJobs`` request was truncated, the response
      includes a ``NextToken`` . To retrieve the next set of tuning jobs, use the token in the next
      request.
    """


_ClientListLabelingJobsForWorkteamResponseLabelingJobSummaryListLabelCountersTypeDef = TypedDict(
    "_ClientListLabelingJobsForWorkteamResponseLabelingJobSummaryListLabelCountersTypeDef",
    {"HumanLabeled": int, "PendingHuman": int, "Total": int},
    total=False,
)


class ClientListLabelingJobsForWorkteamResponseLabelingJobSummaryListLabelCountersTypeDef(
    _ClientListLabelingJobsForWorkteamResponseLabelingJobSummaryListLabelCountersTypeDef
):
    """
    Type definition for `ClientListLabelingJobsForWorkteamResponseLabelingJobSummaryList` `LabelCounters`

    Provides information about the progress of a labeling job.

    - **HumanLabeled** *(integer) --*

      The total number of data objects labeled by a human worker.

    - **PendingHuman** *(integer) --*

      The total number of data objects that need to be labeled by a human worker.

    - **Total** *(integer) --*

      The total number of tasks in the labeling job.
    """


_ClientListLabelingJobsForWorkteamResponseLabelingJobSummaryListTypeDef = TypedDict(
    "_ClientListLabelingJobsForWorkteamResponseLabelingJobSummaryListTypeDef",
    {
        "LabelingJobName": str,
        "JobReferenceCode": str,
        "WorkRequesterAccountId": str,
        "CreationTime": datetime,
        "LabelCounters": ClientListLabelingJobsForWorkteamResponseLabelingJobSummaryListLabelCountersTypeDef,
        "NumberOfHumanWorkersPerDataObject": int,
    },
    total=False,
)


class ClientListLabelingJobsForWorkteamResponseLabelingJobSummaryListTypeDef(
    _ClientListLabelingJobsForWorkteamResponseLabelingJobSummaryListTypeDef
):
    """
    Type definition for `ClientListLabelingJobsForWorkteamResponse` `LabelingJobSummaryList`

    Provides summary information for a work team.

    - **LabelingJobName** *(string) --*

      The name of the labeling job that the work team is assigned to.

    - **JobReferenceCode** *(string) --*

      A unique identifier for a labeling job. You can use this to refer to a specific labeling
      job.

    - **WorkRequesterAccountId** *(string) --*

    - **CreationTime** *(datetime) --*

      The date and time that the labeling job was created.

    - **LabelCounters** *(dict) --*

      Provides information about the progress of a labeling job.

      - **HumanLabeled** *(integer) --*

        The total number of data objects labeled by a human worker.

      - **PendingHuman** *(integer) --*

        The total number of data objects that need to be labeled by a human worker.

      - **Total** *(integer) --*

        The total number of tasks in the labeling job.

    - **NumberOfHumanWorkersPerDataObject** *(integer) --*

      The configured number of workers per data object.
    """


_ClientListLabelingJobsForWorkteamResponseTypeDef = TypedDict(
    "_ClientListLabelingJobsForWorkteamResponseTypeDef",
    {
        "LabelingJobSummaryList": List[
            ClientListLabelingJobsForWorkteamResponseLabelingJobSummaryListTypeDef
        ],
        "NextToken": str,
    },
    total=False,
)


class ClientListLabelingJobsForWorkteamResponseTypeDef(
    _ClientListLabelingJobsForWorkteamResponseTypeDef
):
    """
    Type definition for `ClientListLabelingJobsForWorkteam` `Response`

    - **LabelingJobSummaryList** *(list) --*

      An array of ``LabelingJobSummary`` objects, each describing a labeling job.

      - *(dict) --*

        Provides summary information for a work team.

        - **LabelingJobName** *(string) --*

          The name of the labeling job that the work team is assigned to.

        - **JobReferenceCode** *(string) --*

          A unique identifier for a labeling job. You can use this to refer to a specific labeling
          job.

        - **WorkRequesterAccountId** *(string) --*

        - **CreationTime** *(datetime) --*

          The date and time that the labeling job was created.

        - **LabelCounters** *(dict) --*

          Provides information about the progress of a labeling job.

          - **HumanLabeled** *(integer) --*

            The total number of data objects labeled by a human worker.

          - **PendingHuman** *(integer) --*

            The total number of data objects that need to be labeled by a human worker.

          - **Total** *(integer) --*

            The total number of tasks in the labeling job.

        - **NumberOfHumanWorkersPerDataObject** *(integer) --*

          The configured number of workers per data object.

    - **NextToken** *(string) --*

      If the response is truncated, Amazon SageMaker returns this token. To retrieve the next set
      of labeling jobs, use it in the subsequent request.
    """


_ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataAttributesTypeDef = TypedDict(
    "_ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataAttributesTypeDef",
    {"ContentClassifiers": List[str]},
    total=False,
)


class ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataAttributesTypeDef(
    _ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataAttributesTypeDef
):
    """
    Type definition for `ClientListLabelingJobsResponseLabelingJobSummaryListInputConfig` `DataAttributes`

    Attributes of the data specified by the customer.

    - **ContentClassifiers** *(list) --*

      Declares that your content is free of personally identifiable information or adult
      content. Amazon SageMaker may restrict the Amazon Mechanical Turk workers that can
      view your task based on this information.

      - *(string) --*
    """


_ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataSourceS3DataSourceTypeDef = TypedDict(
    "_ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataSourceS3DataSourceTypeDef",
    {"ManifestS3Uri": str},
    total=False,
)


class ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataSourceS3DataSourceTypeDef(
    _ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataSourceS3DataSourceTypeDef
):
    """
    Type definition for `ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataSource` `S3DataSource`

    The Amazon S3 location of the input data objects.

    - **ManifestS3Uri** *(string) --*

      The Amazon S3 location of the manifest file that describes the input data objects.
    """


_ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataSourceTypeDef = TypedDict(
    "_ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataSourceTypeDef",
    {
        "S3DataSource": ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataSourceS3DataSourceTypeDef
    },
    total=False,
)


class ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataSourceTypeDef(
    _ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataSourceTypeDef
):
    """
    Type definition for `ClientListLabelingJobsResponseLabelingJobSummaryListInputConfig` `DataSource`

    The location of the input data.

    - **S3DataSource** *(dict) --*

      The Amazon S3 location of the input data objects.

      - **ManifestS3Uri** *(string) --*

        The Amazon S3 location of the manifest file that describes the input data objects.
    """


_ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigTypeDef = TypedDict(
    "_ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigTypeDef",
    {
        "DataSource": ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataSourceTypeDef,
        "DataAttributes": ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigDataAttributesTypeDef,
    },
    total=False,
)


class ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigTypeDef(
    _ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigTypeDef
):
    """
    Type definition for `ClientListLabelingJobsResponseLabelingJobSummaryList` `InputConfig`

    Input configuration for the labeling job.

    - **DataSource** *(dict) --*

      The location of the input data.

      - **S3DataSource** *(dict) --*

        The Amazon S3 location of the input data objects.

        - **ManifestS3Uri** *(string) --*

          The Amazon S3 location of the manifest file that describes the input data objects.

    - **DataAttributes** *(dict) --*

      Attributes of the data specified by the customer.

      - **ContentClassifiers** *(list) --*

        Declares that your content is free of personally identifiable information or adult
        content. Amazon SageMaker may restrict the Amazon Mechanical Turk workers that can
        view your task based on this information.

        - *(string) --*
    """


_ClientListLabelingJobsResponseLabelingJobSummaryListLabelCountersTypeDef = TypedDict(
    "_ClientListLabelingJobsResponseLabelingJobSummaryListLabelCountersTypeDef",
    {
        "TotalLabeled": int,
        "HumanLabeled": int,
        "MachineLabeled": int,
        "FailedNonRetryableError": int,
        "Unlabeled": int,
    },
    total=False,
)


class ClientListLabelingJobsResponseLabelingJobSummaryListLabelCountersTypeDef(
    _ClientListLabelingJobsResponseLabelingJobSummaryListLabelCountersTypeDef
):
    """
    Type definition for `ClientListLabelingJobsResponseLabelingJobSummaryList` `LabelCounters`

    Counts showing the progress of the labeling job.

    - **TotalLabeled** *(integer) --*

      The total number of objects labeled.

    - **HumanLabeled** *(integer) --*

      The total number of objects labeled by a human worker.

    - **MachineLabeled** *(integer) --*

      The total number of objects labeled by automated data labeling.

    - **FailedNonRetryableError** *(integer) --*

      The total number of objects that could not be labeled due to an error.

    - **Unlabeled** *(integer) --*

      The total number of objects not yet labeled.
    """


_ClientListLabelingJobsResponseLabelingJobSummaryListLabelingJobOutputTypeDef = TypedDict(
    "_ClientListLabelingJobsResponseLabelingJobSummaryListLabelingJobOutputTypeDef",
    {"OutputDatasetS3Uri": str, "FinalActiveLearningModelArn": str},
    total=False,
)


class ClientListLabelingJobsResponseLabelingJobSummaryListLabelingJobOutputTypeDef(
    _ClientListLabelingJobsResponseLabelingJobSummaryListLabelingJobOutputTypeDef
):
    """
    Type definition for `ClientListLabelingJobsResponseLabelingJobSummaryList` `LabelingJobOutput`

    The location of the output produced by the labeling job.

    - **OutputDatasetS3Uri** *(string) --*

      The Amazon S3 bucket location of the manifest file for labeled data.

    - **FinalActiveLearningModelArn** *(string) --*

      The Amazon Resource Name (ARN) for the most recent Amazon SageMaker model trained as
      part of automated data labeling.
    """


_ClientListLabelingJobsResponseLabelingJobSummaryListTypeDef = TypedDict(
    "_ClientListLabelingJobsResponseLabelingJobSummaryListTypeDef",
    {
        "LabelingJobName": str,
        "LabelingJobArn": str,
        "CreationTime": datetime,
        "LastModifiedTime": datetime,
        "LabelingJobStatus": str,
        "LabelCounters": ClientListLabelingJobsResponseLabelingJobSummaryListLabelCountersTypeDef,
        "WorkteamArn": str,
        "PreHumanTaskLambdaArn": str,
        "AnnotationConsolidationLambdaArn": str,
        "FailureReason": str,
        "LabelingJobOutput": ClientListLabelingJobsResponseLabelingJobSummaryListLabelingJobOutputTypeDef,
        "InputConfig": ClientListLabelingJobsResponseLabelingJobSummaryListInputConfigTypeDef,
    },
    total=False,
)


class ClientListLabelingJobsResponseLabelingJobSummaryListTypeDef(
    _ClientListLabelingJobsResponseLabelingJobSummaryListTypeDef
):
    """
    Type definition for `ClientListLabelingJobsResponse` `LabelingJobSummaryList`

    Provides summary information about a labeling job.

    - **LabelingJobName** *(string) --*

      The name of the labeling job.

    - **LabelingJobArn** *(string) --*

      The Amazon Resource Name (ARN) assigned to the labeling job when it was created.

    - **CreationTime** *(datetime) --*

      The date and time that the job was created (timestamp).

    - **LastModifiedTime** *(datetime) --*

      The date and time that the job was last modified (timestamp).

    - **LabelingJobStatus** *(string) --*

      The current status of the labeling job.

    - **LabelCounters** *(dict) --*

      Counts showing the progress of the labeling job.

      - **TotalLabeled** *(integer) --*

        The total number of objects labeled.

      - **HumanLabeled** *(integer) --*

        The total number of objects labeled by a human worker.

      - **MachineLabeled** *(integer) --*

        The total number of objects labeled by automated data labeling.

      - **FailedNonRetryableError** *(integer) --*

        The total number of objects that could not be labeled due to an error.

      - **Unlabeled** *(integer) --*

        The total number of objects not yet labeled.

    - **WorkteamArn** *(string) --*

      The Amazon Resource Name (ARN) of the work team assigned to the job.

    - **PreHumanTaskLambdaArn** *(string) --*

      The Amazon Resource Name (ARN) of a Lambda function. The function is run before each data
      object is sent to a worker.

    - **AnnotationConsolidationLambdaArn** *(string) --*

      The Amazon Resource Name (ARN) of the Lambda function used to consolidate the annotations
      from individual workers into a label for a data object. For more information, see
      `Annotation Consolidation
      <https://docs.aws.amazon.com/sagemaker/latest/dg/sms-annotation-consolidation.html>`__ .

    - **FailureReason** *(string) --*

      If the ``LabelingJobStatus`` field is ``Failed`` , this field contains a description of
      the error.

    - **LabelingJobOutput** *(dict) --*

      The location of the output produced by the labeling job.

      - **OutputDatasetS3Uri** *(string) --*

        The Amazon S3 bucket location of the manifest file for labeled data.

      - **FinalActiveLearningModelArn** *(string) --*

        The Amazon Resource Name (ARN) for the most recent Amazon SageMaker model trained as
        part of automated data labeling.

    - **InputConfig** *(dict) --*

      Input configuration for the labeling job.

      - **DataSource** *(dict) --*

        The location of the input data.

        - **S3DataSource** *(dict) --*

          The Amazon S3 location of the input data objects.

          - **ManifestS3Uri** *(string) --*

            The Amazon S3 location of the manifest file that describes the input data objects.

      - **DataAttributes** *(dict) --*

        Attributes of the data specified by the customer.

        - **ContentClassifiers** *(list) --*

          Declares that your content is free of personally identifiable information or adult
          content. Amazon SageMaker may restrict the Amazon Mechanical Turk workers that can
          view your task based on this information.

          - *(string) --*
    """


_ClientListLabelingJobsResponseTypeDef = TypedDict(
    "_ClientListLabelingJobsResponseTypeDef",
    {
        "LabelingJobSummaryList": List[
            ClientListLabelingJobsResponseLabelingJobSummaryListTypeDef
        ],
        "NextToken": str,
    },
    total=False,
)


class ClientListLabelingJobsResponseTypeDef(_ClientListLabelingJobsResponseTypeDef):
    """
    Type definition for `ClientListLabelingJobs` `Response`

    - **LabelingJobSummaryList** *(list) --*

      An array of ``LabelingJobSummary`` objects, each describing a labeling job.

      - *(dict) --*

        Provides summary information about a labeling job.

        - **LabelingJobName** *(string) --*

          The name of the labeling job.

        - **LabelingJobArn** *(string) --*

          The Amazon Resource Name (ARN) assigned to the labeling job when it was created.

        - **CreationTime** *(datetime) --*

          The date and time that the job was created (timestamp).

        - **LastModifiedTime** *(datetime) --*

          The date and time that the job was last modified (timestamp).

        - **LabelingJobStatus** *(string) --*

          The current status of the labeling job.

        - **LabelCounters** *(dict) --*

          Counts showing the progress of the labeling job.

          - **TotalLabeled** *(integer) --*

            The total number of objects labeled.

          - **HumanLabeled** *(integer) --*

            The total number of objects labeled by a human worker.

          - **MachineLabeled** *(integer) --*

            The total number of objects labeled by automated data labeling.

          - **FailedNonRetryableError** *(integer) --*

            The total number of objects that could not be labeled due to an error.

          - **Unlabeled** *(integer) --*

            The total number of objects not yet labeled.

        - **WorkteamArn** *(string) --*

          The Amazon Resource Name (ARN) of the work team assigned to the job.

        - **PreHumanTaskLambdaArn** *(string) --*

          The Amazon Resource Name (ARN) of a Lambda function. The function is run before each data
          object is sent to a worker.

        - **AnnotationConsolidationLambdaArn** *(string) --*

          The Amazon Resource Name (ARN) of the Lambda function used to consolidate the annotations
          from individual workers into a label for a data object. For more information, see
          `Annotation Consolidation
          <https://docs.aws.amazon.com/sagemaker/latest/dg/sms-annotation-consolidation.html>`__ .

        - **FailureReason** *(string) --*

          If the ``LabelingJobStatus`` field is ``Failed`` , this field contains a description of
          the error.

        - **LabelingJobOutput** *(dict) --*

          The location of the output produced by the labeling job.

          - **OutputDatasetS3Uri** *(string) --*

            The Amazon S3 bucket location of the manifest file for labeled data.

          - **FinalActiveLearningModelArn** *(string) --*

            The Amazon Resource Name (ARN) for the most recent Amazon SageMaker model trained as
            part of automated data labeling.

        - **InputConfig** *(dict) --*

          Input configuration for the labeling job.

          - **DataSource** *(dict) --*

            The location of the input data.

            - **S3DataSource** *(dict) --*

              The Amazon S3 location of the input data objects.

              - **ManifestS3Uri** *(string) --*

                The Amazon S3 location of the manifest file that describes the input data objects.

          - **DataAttributes** *(dict) --*

            Attributes of the data specified by the customer.

            - **ContentClassifiers** *(list) --*

              Declares that your content is free of personally identifiable information or adult
              content. Amazon SageMaker may restrict the Amazon Mechanical Turk workers that can
              view your task based on this information.

              - *(string) --*

    - **NextToken** *(string) --*

      If the response is truncated, Amazon SageMaker returns this token. To retrieve the next set
      of labeling jobs, use it in the subsequent request.
    """


_ClientListModelPackagesResponseModelPackageSummaryListTypeDef = TypedDict(
    "_ClientListModelPackagesResponseModelPackageSummaryListTypeDef",
    {
        "ModelPackageName": str,
        "ModelPackageArn": str,
        "ModelPackageDescription": str,
        "CreationTime": datetime,
        "ModelPackageStatus": str,
    },
    total=False,
)


class ClientListModelPackagesResponseModelPackageSummaryListTypeDef(
    _ClientListModelPackagesResponseModelPackageSummaryListTypeDef
):
    """
    Type definition for `ClientListModelPackagesResponse` `ModelPackageSummaryList`

    Provides summary information about a model package.

    - **ModelPackageName** *(string) --*

      The name of the model package.

    - **ModelPackageArn** *(string) --*

      The Amazon Resource Name (ARN) of the model package.

    - **ModelPackageDescription** *(string) --*

      A brief description of the model package.

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the model package was created.

    - **ModelPackageStatus** *(string) --*

      The overall status of the model package.
    """


_ClientListModelPackagesResponseTypeDef = TypedDict(
    "_ClientListModelPackagesResponseTypeDef",
    {
        "ModelPackageSummaryList": List[
            ClientListModelPackagesResponseModelPackageSummaryListTypeDef
        ],
        "NextToken": str,
    },
    total=False,
)


class ClientListModelPackagesResponseTypeDef(_ClientListModelPackagesResponseTypeDef):
    """
    Type definition for `ClientListModelPackages` `Response`

    - **ModelPackageSummaryList** *(list) --*

      An array of ``ModelPackageSummary`` objects, each of which lists a model package.

      - *(dict) --*

        Provides summary information about a model package.

        - **ModelPackageName** *(string) --*

          The name of the model package.

        - **ModelPackageArn** *(string) --*

          The Amazon Resource Name (ARN) of the model package.

        - **ModelPackageDescription** *(string) --*

          A brief description of the model package.

        - **CreationTime** *(datetime) --*

          A timestamp that shows when the model package was created.

        - **ModelPackageStatus** *(string) --*

          The overall status of the model package.

    - **NextToken** *(string) --*

      If the response is truncated, Amazon SageMaker returns this token. To retrieve the next set
      of model packages, use it in the subsequent request.
    """


_ClientListModelsResponseModelsTypeDef = TypedDict(
    "_ClientListModelsResponseModelsTypeDef",
    {"ModelName": str, "ModelArn": str, "CreationTime": datetime},
    total=False,
)


class ClientListModelsResponseModelsTypeDef(_ClientListModelsResponseModelsTypeDef):
    """
    Type definition for `ClientListModelsResponse` `Models`

    Provides summary information about a model.

    - **ModelName** *(string) --*

      The name of the model that you want a summary for.

    - **ModelArn** *(string) --*

      The Amazon Resource Name (ARN) of the model.

    - **CreationTime** *(datetime) --*

      A timestamp that indicates when the model was created.
    """


_ClientListModelsResponseTypeDef = TypedDict(
    "_ClientListModelsResponseTypeDef",
    {"Models": List[ClientListModelsResponseModelsTypeDef], "NextToken": str},
    total=False,
)


class ClientListModelsResponseTypeDef(_ClientListModelsResponseTypeDef):
    """
    Type definition for `ClientListModels` `Response`

    - **Models** *(list) --*

      An array of ``ModelSummary`` objects, each of which lists a model.

      - *(dict) --*

        Provides summary information about a model.

        - **ModelName** *(string) --*

          The name of the model that you want a summary for.

        - **ModelArn** *(string) --*

          The Amazon Resource Name (ARN) of the model.

        - **CreationTime** *(datetime) --*

          A timestamp that indicates when the model was created.

    - **NextToken** *(string) --*

      If the response is truncated, Amazon SageMaker returns this token. To retrieve the next set
      of models, use it in the subsequent request.
    """


_ClientListNotebookInstanceLifecycleConfigsResponseNotebookInstanceLifecycleConfigsTypeDef = TypedDict(
    "_ClientListNotebookInstanceLifecycleConfigsResponseNotebookInstanceLifecycleConfigsTypeDef",
    {
        "NotebookInstanceLifecycleConfigName": str,
        "NotebookInstanceLifecycleConfigArn": str,
        "CreationTime": datetime,
        "LastModifiedTime": datetime,
    },
    total=False,
)


class ClientListNotebookInstanceLifecycleConfigsResponseNotebookInstanceLifecycleConfigsTypeDef(
    _ClientListNotebookInstanceLifecycleConfigsResponseNotebookInstanceLifecycleConfigsTypeDef
):
    """
    Type definition for `ClientListNotebookInstanceLifecycleConfigsResponse` `NotebookInstanceLifecycleConfigs`

    Provides a summary of a notebook instance lifecycle configuration.

    - **NotebookInstanceLifecycleConfigName** *(string) --*

      The name of the lifecycle configuration.

    - **NotebookInstanceLifecycleConfigArn** *(string) --*

      The Amazon Resource Name (ARN) of the lifecycle configuration.

    - **CreationTime** *(datetime) --*

      A timestamp that tells when the lifecycle configuration was created.

    - **LastModifiedTime** *(datetime) --*

      A timestamp that tells when the lifecycle configuration was last modified.
    """


_ClientListNotebookInstanceLifecycleConfigsResponseTypeDef = TypedDict(
    "_ClientListNotebookInstanceLifecycleConfigsResponseTypeDef",
    {
        "NextToken": str,
        "NotebookInstanceLifecycleConfigs": List[
            ClientListNotebookInstanceLifecycleConfigsResponseNotebookInstanceLifecycleConfigsTypeDef
        ],
    },
    total=False,
)


class ClientListNotebookInstanceLifecycleConfigsResponseTypeDef(
    _ClientListNotebookInstanceLifecycleConfigsResponseTypeDef
):
    """
    Type definition for `ClientListNotebookInstanceLifecycleConfigs` `Response`

    - **NextToken** *(string) --*

      If the response is truncated, Amazon SageMaker returns this token. To get the next set of
      lifecycle configurations, use it in the next request.

    - **NotebookInstanceLifecycleConfigs** *(list) --*

      An array of ``NotebookInstanceLifecycleConfiguration`` objects, each listing a lifecycle
      configuration.

      - *(dict) --*

        Provides a summary of a notebook instance lifecycle configuration.

        - **NotebookInstanceLifecycleConfigName** *(string) --*

          The name of the lifecycle configuration.

        - **NotebookInstanceLifecycleConfigArn** *(string) --*

          The Amazon Resource Name (ARN) of the lifecycle configuration.

        - **CreationTime** *(datetime) --*

          A timestamp that tells when the lifecycle configuration was created.

        - **LastModifiedTime** *(datetime) --*

          A timestamp that tells when the lifecycle configuration was last modified.
    """


_ClientListNotebookInstancesResponseNotebookInstancesTypeDef = TypedDict(
    "_ClientListNotebookInstancesResponseNotebookInstancesTypeDef",
    {
        "NotebookInstanceName": str,
        "NotebookInstanceArn": str,
        "NotebookInstanceStatus": str,
        "Url": str,
        "InstanceType": str,
        "CreationTime": datetime,
        "LastModifiedTime": datetime,
        "NotebookInstanceLifecycleConfigName": str,
        "DefaultCodeRepository": str,
        "AdditionalCodeRepositories": List[str],
    },
    total=False,
)


class ClientListNotebookInstancesResponseNotebookInstancesTypeDef(
    _ClientListNotebookInstancesResponseNotebookInstancesTypeDef
):
    """
    Type definition for `ClientListNotebookInstancesResponse` `NotebookInstances`

    Provides summary information for an Amazon SageMaker notebook instance.

    - **NotebookInstanceName** *(string) --*

      The name of the notebook instance that you want a summary for.

    - **NotebookInstanceArn** *(string) --*

      The Amazon Resource Name (ARN) of the notebook instance.

    - **NotebookInstanceStatus** *(string) --*

      The status of the notebook instance.

    - **Url** *(string) --*

      The URL that you use to connect to the Jupyter instance running in your notebook instance.

    - **InstanceType** *(string) --*

      The type of ML compute instance that the notebook instance is running on.

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the notebook instance was created.

    - **LastModifiedTime** *(datetime) --*

      A timestamp that shows when the notebook instance was last modified.

    - **NotebookInstanceLifecycleConfigName** *(string) --*

      The name of a notebook instance lifecycle configuration associated with this notebook
      instance.

      For information about notebook instance lifestyle configurations, see `Step 2.1\\:
      (Optional) Customize a Notebook Instance
      <https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html>`__ .

    - **DefaultCodeRepository** *(string) --*

      The Git repository associated with the notebook instance as its default code repository.
      This can be either the name of a Git repository stored as a resource in your account, or
      the URL of a Git repository in `AWS CodeCommit
      <https://docs.aws.amazon.com/codecommit/latest/userguide/welcome.html>`__ or in any other
      Git repository. When you open a notebook instance, it opens in the directory that
      contains this repository. For more information, see `Associating Git Repositories with
      Amazon SageMaker Notebook Instances
      <https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-git-repo.html>`__ .

    - **AdditionalCodeRepositories** *(list) --*

      An array of up to three Git repositories associated with the notebook instance. These can
      be either the names of Git repositories stored as resources in your account, or the URL
      of Git repositories in `AWS CodeCommit
      <https://docs.aws.amazon.com/codecommit/latest/userguide/welcome.html>`__ or in any other
      Git repository. These repositories are cloned at the same level as the default repository
      of your notebook instance. For more information, see `Associating Git Repositories with
      Amazon SageMaker Notebook Instances
      <https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-git-repo.html>`__ .

      - *(string) --*
    """


_ClientListNotebookInstancesResponseTypeDef = TypedDict(
    "_ClientListNotebookInstancesResponseTypeDef",
    {
        "NextToken": str,
        "NotebookInstances": List[
            ClientListNotebookInstancesResponseNotebookInstancesTypeDef
        ],
    },
    total=False,
)


class ClientListNotebookInstancesResponseTypeDef(
    _ClientListNotebookInstancesResponseTypeDef
):
    """
    Type definition for `ClientListNotebookInstances` `Response`

    - **NextToken** *(string) --*

      If the response to the previous ``ListNotebookInstances`` request was truncated, Amazon
      SageMaker returns this token. To retrieve the next set of notebook instances, use the token
      in the next request.

    - **NotebookInstances** *(list) --*

      An array of ``NotebookInstanceSummary`` objects, one for each notebook instance.

      - *(dict) --*

        Provides summary information for an Amazon SageMaker notebook instance.

        - **NotebookInstanceName** *(string) --*

          The name of the notebook instance that you want a summary for.

        - **NotebookInstanceArn** *(string) --*

          The Amazon Resource Name (ARN) of the notebook instance.

        - **NotebookInstanceStatus** *(string) --*

          The status of the notebook instance.

        - **Url** *(string) --*

          The URL that you use to connect to the Jupyter instance running in your notebook instance.

        - **InstanceType** *(string) --*

          The type of ML compute instance that the notebook instance is running on.

        - **CreationTime** *(datetime) --*

          A timestamp that shows when the notebook instance was created.

        - **LastModifiedTime** *(datetime) --*

          A timestamp that shows when the notebook instance was last modified.

        - **NotebookInstanceLifecycleConfigName** *(string) --*

          The name of a notebook instance lifecycle configuration associated with this notebook
          instance.

          For information about notebook instance lifestyle configurations, see `Step 2.1\\:
          (Optional) Customize a Notebook Instance
          <https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html>`__ .

        - **DefaultCodeRepository** *(string) --*

          The Git repository associated with the notebook instance as its default code repository.
          This can be either the name of a Git repository stored as a resource in your account, or
          the URL of a Git repository in `AWS CodeCommit
          <https://docs.aws.amazon.com/codecommit/latest/userguide/welcome.html>`__ or in any other
          Git repository. When you open a notebook instance, it opens in the directory that
          contains this repository. For more information, see `Associating Git Repositories with
          Amazon SageMaker Notebook Instances
          <https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-git-repo.html>`__ .

        - **AdditionalCodeRepositories** *(list) --*

          An array of up to three Git repositories associated with the notebook instance. These can
          be either the names of Git repositories stored as resources in your account, or the URL
          of Git repositories in `AWS CodeCommit
          <https://docs.aws.amazon.com/codecommit/latest/userguide/welcome.html>`__ or in any other
          Git repository. These repositories are cloned at the same level as the default repository
          of your notebook instance. For more information, see `Associating Git Repositories with
          Amazon SageMaker Notebook Instances
          <https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-git-repo.html>`__ .

          - *(string) --*
    """


_ClientListSubscribedWorkteamsResponseSubscribedWorkteamsTypeDef = TypedDict(
    "_ClientListSubscribedWorkteamsResponseSubscribedWorkteamsTypeDef",
    {
        "WorkteamArn": str,
        "MarketplaceTitle": str,
        "SellerName": str,
        "MarketplaceDescription": str,
        "ListingId": str,
    },
    total=False,
)


class ClientListSubscribedWorkteamsResponseSubscribedWorkteamsTypeDef(
    _ClientListSubscribedWorkteamsResponseSubscribedWorkteamsTypeDef
):
    """
    Type definition for `ClientListSubscribedWorkteamsResponse` `SubscribedWorkteams`

    Describes a work team of a vendor that does the a labelling job.

    - **WorkteamArn** *(string) --*

      The Amazon Resource Name (ARN) of the vendor that you have subscribed.

    - **MarketplaceTitle** *(string) --*

      The title of the service provided by the vendor in the Amazon Marketplace.

    - **SellerName** *(string) --*

      The name of the vendor in the Amazon Marketplace.

    - **MarketplaceDescription** *(string) --*

      The description of the vendor from the Amazon Marketplace.

    - **ListingId** *(string) --*
    """


_ClientListSubscribedWorkteamsResponseTypeDef = TypedDict(
    "_ClientListSubscribedWorkteamsResponseTypeDef",
    {
        "SubscribedWorkteams": List[
            ClientListSubscribedWorkteamsResponseSubscribedWorkteamsTypeDef
        ],
        "NextToken": str,
    },
    total=False,
)


class ClientListSubscribedWorkteamsResponseTypeDef(
    _ClientListSubscribedWorkteamsResponseTypeDef
):
    """
    Type definition for `ClientListSubscribedWorkteams` `Response`

    - **SubscribedWorkteams** *(list) --*

      An array of ``Workteam`` objects, each describing a work team.

      - *(dict) --*

        Describes a work team of a vendor that does the a labelling job.

        - **WorkteamArn** *(string) --*

          The Amazon Resource Name (ARN) of the vendor that you have subscribed.

        - **MarketplaceTitle** *(string) --*

          The title of the service provided by the vendor in the Amazon Marketplace.

        - **SellerName** *(string) --*

          The name of the vendor in the Amazon Marketplace.

        - **MarketplaceDescription** *(string) --*

          The description of the vendor from the Amazon Marketplace.

        - **ListingId** *(string) --*

    - **NextToken** *(string) --*

      If the response is truncated, Amazon SageMaker returns this token. To retrieve the next set
      of work teams, use it in the subsequent request.
    """


_ClientListTagsResponseTagsTypeDef = TypedDict(
    "_ClientListTagsResponseTagsTypeDef", {"Key": str, "Value": str}, total=False
)


class ClientListTagsResponseTagsTypeDef(_ClientListTagsResponseTagsTypeDef):
    """
    Type definition for `ClientListTagsResponse` `Tags`

    Describes a tag.

    - **Key** *(string) --*

      The tag key.

    - **Value** *(string) --*

      The tag value.
    """


_ClientListTagsResponseTypeDef = TypedDict(
    "_ClientListTagsResponseTypeDef",
    {"Tags": List[ClientListTagsResponseTagsTypeDef], "NextToken": str},
    total=False,
)


class ClientListTagsResponseTypeDef(_ClientListTagsResponseTypeDef):
    """
    Type definition for `ClientListTags` `Response`

    - **Tags** *(list) --*

      An array of ``Tag`` objects, each with a tag key and a value.

      - *(dict) --*

        Describes a tag.

        - **Key** *(string) --*

          The tag key.

        - **Value** *(string) --*

          The tag value.

    - **NextToken** *(string) --*

      If response is truncated, Amazon SageMaker includes a token in the response. You can use this
      token in your subsequent request to fetch next set of tokens.
    """


_ClientListTrainingJobsForHyperParameterTuningJobResponseTrainingJobSummariesFinalHyperParameterTuningJobObjectiveMetricTypeDef = TypedDict(
    "_ClientListTrainingJobsForHyperParameterTuningJobResponseTrainingJobSummariesFinalHyperParameterTuningJobObjectiveMetricTypeDef",
    {"Type": str, "MetricName": str, "Value": float},
    total=False,
)


class ClientListTrainingJobsForHyperParameterTuningJobResponseTrainingJobSummariesFinalHyperParameterTuningJobObjectiveMetricTypeDef(
    _ClientListTrainingJobsForHyperParameterTuningJobResponseTrainingJobSummariesFinalHyperParameterTuningJobObjectiveMetricTypeDef
):
    """
    Type definition for `ClientListTrainingJobsForHyperParameterTuningJobResponseTrainingJobSummaries` `FinalHyperParameterTuningJobObjectiveMetric`

    The  FinalHyperParameterTuningJobObjectiveMetric object that specifies the value of the
    objective metric of the tuning job that launched this training job.

    - **Type** *(string) --*

      Whether to minimize or maximize the objective metric. Valid values are Minimize and
      Maximize.

    - **MetricName** *(string) --*

      The name of the objective metric.

    - **Value** *(float) --*

      The value of the objective metric.
    """


_ClientListTrainingJobsForHyperParameterTuningJobResponseTrainingJobSummariesTypeDef = TypedDict(
    "_ClientListTrainingJobsForHyperParameterTuningJobResponseTrainingJobSummariesTypeDef",
    {
        "TrainingJobName": str,
        "TrainingJobArn": str,
        "TuningJobName": str,
        "CreationTime": datetime,
        "TrainingStartTime": datetime,
        "TrainingEndTime": datetime,
        "TrainingJobStatus": str,
        "TunedHyperParameters": Dict[str, str],
        "FailureReason": str,
        "FinalHyperParameterTuningJobObjectiveMetric": ClientListTrainingJobsForHyperParameterTuningJobResponseTrainingJobSummariesFinalHyperParameterTuningJobObjectiveMetricTypeDef,
        "ObjectiveStatus": str,
    },
    total=False,
)


class ClientListTrainingJobsForHyperParameterTuningJobResponseTrainingJobSummariesTypeDef(
    _ClientListTrainingJobsForHyperParameterTuningJobResponseTrainingJobSummariesTypeDef
):
    """
    Type definition for `ClientListTrainingJobsForHyperParameterTuningJobResponse` `TrainingJobSummaries`

    Specifies summary information about a training job.

    - **TrainingJobName** *(string) --*

      The name of the training job.

    - **TrainingJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the training job.

    - **TuningJobName** *(string) --*

      The HyperParameter tuning job that launched the training job.

    - **CreationTime** *(datetime) --*

      The date and time that the training job was created.

    - **TrainingStartTime** *(datetime) --*

      The date and time that the training job started.

    - **TrainingEndTime** *(datetime) --*

      Specifies the time when the training job ends on training instances. You are billed for
      the time interval between the value of ``TrainingStartTime`` and this time. For
      successful jobs and stopped jobs, this is the time after model artifacts are uploaded.
      For failed jobs, this is the time when Amazon SageMaker detects a job failure.

    - **TrainingJobStatus** *(string) --*

      The status of the training job.

    - **TunedHyperParameters** *(dict) --*

      A list of the hyperparameters for which you specified ranges to search.

      - *(string) --*

        - *(string) --*

    - **FailureReason** *(string) --*

      The reason that the training job failed.

    - **FinalHyperParameterTuningJobObjectiveMetric** *(dict) --*

      The  FinalHyperParameterTuningJobObjectiveMetric object that specifies the value of the
      objective metric of the tuning job that launched this training job.

      - **Type** *(string) --*

        Whether to minimize or maximize the objective metric. Valid values are Minimize and
        Maximize.

      - **MetricName** *(string) --*

        The name of the objective metric.

      - **Value** *(float) --*

        The value of the objective metric.

    - **ObjectiveStatus** *(string) --*

      The status of the objective metric for the training job:

      * Succeeded: The final objective metric for the training job was evaluated by the
      hyperparameter tuning job and used in the hyperparameter tuning process.

      * Pending: The training job is in progress and evaluation of its final objective metric
      is pending.

      * Failed: The final objective metric for the training job was not evaluated, and was not
      used in the hyperparameter tuning process. This typically occurs when the training job
      failed or did not emit an objective metric.
    """


_ClientListTrainingJobsForHyperParameterTuningJobResponseTypeDef = TypedDict(
    "_ClientListTrainingJobsForHyperParameterTuningJobResponseTypeDef",
    {
        "TrainingJobSummaries": List[
            ClientListTrainingJobsForHyperParameterTuningJobResponseTrainingJobSummariesTypeDef
        ],
        "NextToken": str,
    },
    total=False,
)


class ClientListTrainingJobsForHyperParameterTuningJobResponseTypeDef(
    _ClientListTrainingJobsForHyperParameterTuningJobResponseTypeDef
):
    """
    Type definition for `ClientListTrainingJobsForHyperParameterTuningJob` `Response`

    - **TrainingJobSummaries** *(list) --*

      A list of  TrainingJobSummary objects that describe the training jobs that the
      ``ListTrainingJobsForHyperParameterTuningJob`` request returned.

      - *(dict) --*

        Specifies summary information about a training job.

        - **TrainingJobName** *(string) --*

          The name of the training job.

        - **TrainingJobArn** *(string) --*

          The Amazon Resource Name (ARN) of the training job.

        - **TuningJobName** *(string) --*

          The HyperParameter tuning job that launched the training job.

        - **CreationTime** *(datetime) --*

          The date and time that the training job was created.

        - **TrainingStartTime** *(datetime) --*

          The date and time that the training job started.

        - **TrainingEndTime** *(datetime) --*

          Specifies the time when the training job ends on training instances. You are billed for
          the time interval between the value of ``TrainingStartTime`` and this time. For
          successful jobs and stopped jobs, this is the time after model artifacts are uploaded.
          For failed jobs, this is the time when Amazon SageMaker detects a job failure.

        - **TrainingJobStatus** *(string) --*

          The status of the training job.

        - **TunedHyperParameters** *(dict) --*

          A list of the hyperparameters for which you specified ranges to search.

          - *(string) --*

            - *(string) --*

        - **FailureReason** *(string) --*

          The reason that the training job failed.

        - **FinalHyperParameterTuningJobObjectiveMetric** *(dict) --*

          The  FinalHyperParameterTuningJobObjectiveMetric object that specifies the value of the
          objective metric of the tuning job that launched this training job.

          - **Type** *(string) --*

            Whether to minimize or maximize the objective metric. Valid values are Minimize and
            Maximize.

          - **MetricName** *(string) --*

            The name of the objective metric.

          - **Value** *(float) --*

            The value of the objective metric.

        - **ObjectiveStatus** *(string) --*

          The status of the objective metric for the training job:

          * Succeeded: The final objective metric for the training job was evaluated by the
          hyperparameter tuning job and used in the hyperparameter tuning process.

          * Pending: The training job is in progress and evaluation of its final objective metric
          is pending.

          * Failed: The final objective metric for the training job was not evaluated, and was not
          used in the hyperparameter tuning process. This typically occurs when the training job
          failed or did not emit an objective metric.

    - **NextToken** *(string) --*

      If the result of this ``ListTrainingJobsForHyperParameterTuningJob`` request was truncated,
      the response includes a ``NextToken`` . To retrieve the next set of training jobs, use the
      token in the next request.
    """


_ClientListTrainingJobsResponseTrainingJobSummariesTypeDef = TypedDict(
    "_ClientListTrainingJobsResponseTrainingJobSummariesTypeDef",
    {
        "TrainingJobName": str,
        "TrainingJobArn": str,
        "CreationTime": datetime,
        "TrainingEndTime": datetime,
        "LastModifiedTime": datetime,
        "TrainingJobStatus": str,
    },
    total=False,
)


class ClientListTrainingJobsResponseTrainingJobSummariesTypeDef(
    _ClientListTrainingJobsResponseTrainingJobSummariesTypeDef
):
    """
    Type definition for `ClientListTrainingJobsResponse` `TrainingJobSummaries`

    Provides summary information about a training job.

    - **TrainingJobName** *(string) --*

      The name of the training job that you want a summary for.

    - **TrainingJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the training job.

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the training job was created.

    - **TrainingEndTime** *(datetime) --*

      A timestamp that shows when the training job ended. This field is set only if the
      training job has one of the terminal statuses (``Completed`` , ``Failed`` , or
      ``Stopped`` ).

    - **LastModifiedTime** *(datetime) --*

      Timestamp when the training job was last modified.

    - **TrainingJobStatus** *(string) --*

      The status of the training job.
    """


_ClientListTrainingJobsResponseTypeDef = TypedDict(
    "_ClientListTrainingJobsResponseTypeDef",
    {
        "TrainingJobSummaries": List[
            ClientListTrainingJobsResponseTrainingJobSummariesTypeDef
        ],
        "NextToken": str,
    },
    total=False,
)


class ClientListTrainingJobsResponseTypeDef(_ClientListTrainingJobsResponseTypeDef):
    """
    Type definition for `ClientListTrainingJobs` `Response`

    - **TrainingJobSummaries** *(list) --*

      An array of ``TrainingJobSummary`` objects, each listing a training job.

      - *(dict) --*

        Provides summary information about a training job.

        - **TrainingJobName** *(string) --*

          The name of the training job that you want a summary for.

        - **TrainingJobArn** *(string) --*

          The Amazon Resource Name (ARN) of the training job.

        - **CreationTime** *(datetime) --*

          A timestamp that shows when the training job was created.

        - **TrainingEndTime** *(datetime) --*

          A timestamp that shows when the training job ended. This field is set only if the
          training job has one of the terminal statuses (``Completed`` , ``Failed`` , or
          ``Stopped`` ).

        - **LastModifiedTime** *(datetime) --*

          Timestamp when the training job was last modified.

        - **TrainingJobStatus** *(string) --*

          The status of the training job.

    - **NextToken** *(string) --*

      If the response is truncated, Amazon SageMaker returns this token. To retrieve the next set
      of training jobs, use it in the subsequent request.
    """


_ClientListTransformJobsResponseTransformJobSummariesTypeDef = TypedDict(
    "_ClientListTransformJobsResponseTransformJobSummariesTypeDef",
    {
        "TransformJobName": str,
        "TransformJobArn": str,
        "CreationTime": datetime,
        "TransformEndTime": datetime,
        "LastModifiedTime": datetime,
        "TransformJobStatus": str,
        "FailureReason": str,
    },
    total=False,
)


class ClientListTransformJobsResponseTransformJobSummariesTypeDef(
    _ClientListTransformJobsResponseTransformJobSummariesTypeDef
):
    """
    Type definition for `ClientListTransformJobsResponse` `TransformJobSummaries`

    Provides a summary of a transform job. Multiple ``TransformJobSummary`` objects are
    returned as a list after in response to a  ListTransformJobs call.

    - **TransformJobName** *(string) --*

      The name of the transform job.

    - **TransformJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the transform job.

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the transform Job was created.

    - **TransformEndTime** *(datetime) --*

      Indicates when the transform job ends on compute instances. For successful jobs and
      stopped jobs, this is the exact time recorded after the results are uploaded. For failed
      jobs, this is when Amazon SageMaker detected that the job failed.

    - **LastModifiedTime** *(datetime) --*

      Indicates when the transform job was last modified.

    - **TransformJobStatus** *(string) --*

      The status of the transform job.

    - **FailureReason** *(string) --*

      If the transform job failed, the reason it failed.
    """


_ClientListTransformJobsResponseTypeDef = TypedDict(
    "_ClientListTransformJobsResponseTypeDef",
    {
        "TransformJobSummaries": List[
            ClientListTransformJobsResponseTransformJobSummariesTypeDef
        ],
        "NextToken": str,
    },
    total=False,
)


class ClientListTransformJobsResponseTypeDef(_ClientListTransformJobsResponseTypeDef):
    """
    Type definition for `ClientListTransformJobs` `Response`

    - **TransformJobSummaries** *(list) --*

      An array of ``TransformJobSummary`` objects.

      - *(dict) --*

        Provides a summary of a transform job. Multiple ``TransformJobSummary`` objects are
        returned as a list after in response to a  ListTransformJobs call.

        - **TransformJobName** *(string) --*

          The name of the transform job.

        - **TransformJobArn** *(string) --*

          The Amazon Resource Name (ARN) of the transform job.

        - **CreationTime** *(datetime) --*

          A timestamp that shows when the transform Job was created.

        - **TransformEndTime** *(datetime) --*

          Indicates when the transform job ends on compute instances. For successful jobs and
          stopped jobs, this is the exact time recorded after the results are uploaded. For failed
          jobs, this is when Amazon SageMaker detected that the job failed.

        - **LastModifiedTime** *(datetime) --*

          Indicates when the transform job was last modified.

        - **TransformJobStatus** *(string) --*

          The status of the transform job.

        - **FailureReason** *(string) --*

          If the transform job failed, the reason it failed.

    - **NextToken** *(string) --*

      If the response is truncated, Amazon SageMaker returns this token. To retrieve the next set
      of transform jobs, use it in the next request.
    """


_ClientListWorkteamsResponseWorkteamsMemberDefinitionsCognitoMemberDefinitionTypeDef = TypedDict(
    "_ClientListWorkteamsResponseWorkteamsMemberDefinitionsCognitoMemberDefinitionTypeDef",
    {"UserPool": str, "UserGroup": str, "ClientId": str},
    total=False,
)


class ClientListWorkteamsResponseWorkteamsMemberDefinitionsCognitoMemberDefinitionTypeDef(
    _ClientListWorkteamsResponseWorkteamsMemberDefinitionsCognitoMemberDefinitionTypeDef
):
    """
    Type definition for `ClientListWorkteamsResponseWorkteamsMemberDefinitions` `CognitoMemberDefinition`

    The Amazon Cognito user group that is part of the work team.

    - **UserPool** *(string) --*

      An identifier for a user pool. The user pool must be in the same region as the
      service that you are calling.

    - **UserGroup** *(string) --*

      An identifier for a user group.

    - **ClientId** *(string) --*

      An identifier for an application client. You must create the app client ID using
      Amazon Cognito.
    """


_ClientListWorkteamsResponseWorkteamsMemberDefinitionsTypeDef = TypedDict(
    "_ClientListWorkteamsResponseWorkteamsMemberDefinitionsTypeDef",
    {
        "CognitoMemberDefinition": ClientListWorkteamsResponseWorkteamsMemberDefinitionsCognitoMemberDefinitionTypeDef
    },
    total=False,
)


class ClientListWorkteamsResponseWorkteamsMemberDefinitionsTypeDef(
    _ClientListWorkteamsResponseWorkteamsMemberDefinitionsTypeDef
):
    """
    Type definition for `ClientListWorkteamsResponseWorkteams` `MemberDefinitions`

    Defines the Amazon Cognito user group that is part of a work team.

    - **CognitoMemberDefinition** *(dict) --*

      The Amazon Cognito user group that is part of the work team.

      - **UserPool** *(string) --*

        An identifier for a user pool. The user pool must be in the same region as the
        service that you are calling.

      - **UserGroup** *(string) --*

        An identifier for a user group.

      - **ClientId** *(string) --*

        An identifier for an application client. You must create the app client ID using
        Amazon Cognito.
    """


_ClientListWorkteamsResponseWorkteamsNotificationConfigurationTypeDef = TypedDict(
    "_ClientListWorkteamsResponseWorkteamsNotificationConfigurationTypeDef",
    {"NotificationTopicArn": str},
    total=False,
)


class ClientListWorkteamsResponseWorkteamsNotificationConfigurationTypeDef(
    _ClientListWorkteamsResponseWorkteamsNotificationConfigurationTypeDef
):
    """
    Type definition for `ClientListWorkteamsResponseWorkteams` `NotificationConfiguration`

    Configures SNS notifications of available or expiring work items for work teams.

    - **NotificationTopicArn** *(string) --*

      The ARN for the SNS topic to which notifications should be published.
    """


_ClientListWorkteamsResponseWorkteamsTypeDef = TypedDict(
    "_ClientListWorkteamsResponseWorkteamsTypeDef",
    {
        "WorkteamName": str,
        "MemberDefinitions": List[
            ClientListWorkteamsResponseWorkteamsMemberDefinitionsTypeDef
        ],
        "WorkteamArn": str,
        "ProductListingIds": List[str],
        "Description": str,
        "SubDomain": str,
        "CreateDate": datetime,
        "LastUpdatedDate": datetime,
        "NotificationConfiguration": ClientListWorkteamsResponseWorkteamsNotificationConfigurationTypeDef,
    },
    total=False,
)


class ClientListWorkteamsResponseWorkteamsTypeDef(
    _ClientListWorkteamsResponseWorkteamsTypeDef
):
    """
    Type definition for `ClientListWorkteamsResponse` `Workteams`

    Provides details about a labeling work team.

    - **WorkteamName** *(string) --*

      The name of the work team.

    - **MemberDefinitions** *(list) --*

      The Amazon Cognito user groups that make up the work team.

      - *(dict) --*

        Defines the Amazon Cognito user group that is part of a work team.

        - **CognitoMemberDefinition** *(dict) --*

          The Amazon Cognito user group that is part of the work team.

          - **UserPool** *(string) --*

            An identifier for a user pool. The user pool must be in the same region as the
            service that you are calling.

          - **UserGroup** *(string) --*

            An identifier for a user group.

          - **ClientId** *(string) --*

            An identifier for an application client. You must create the app client ID using
            Amazon Cognito.

    - **WorkteamArn** *(string) --*

      The Amazon Resource Name (ARN) that identifies the work team.

    - **ProductListingIds** *(list) --*

      The Amazon Marketplace identifier for a vendor's work team.

      - *(string) --*

    - **Description** *(string) --*

      A description of the work team.

    - **SubDomain** *(string) --*

      The URI of the labeling job's user interface. Workers open this URI to start labeling
      your data objects.

    - **CreateDate** *(datetime) --*

      The date and time that the work team was created (timestamp).

    - **LastUpdatedDate** *(datetime) --*

      The date and time that the work team was last updated (timestamp).

    - **NotificationConfiguration** *(dict) --*

      Configures SNS notifications of available or expiring work items for work teams.

      - **NotificationTopicArn** *(string) --*

        The ARN for the SNS topic to which notifications should be published.
    """


_ClientListWorkteamsResponseTypeDef = TypedDict(
    "_ClientListWorkteamsResponseTypeDef",
    {"Workteams": List[ClientListWorkteamsResponseWorkteamsTypeDef], "NextToken": str},
    total=False,
)


class ClientListWorkteamsResponseTypeDef(_ClientListWorkteamsResponseTypeDef):
    """
    Type definition for `ClientListWorkteams` `Response`

    - **Workteams** *(list) --*

      An array of ``Workteam`` objects, each describing a work team.

      - *(dict) --*

        Provides details about a labeling work team.

        - **WorkteamName** *(string) --*

          The name of the work team.

        - **MemberDefinitions** *(list) --*

          The Amazon Cognito user groups that make up the work team.

          - *(dict) --*

            Defines the Amazon Cognito user group that is part of a work team.

            - **CognitoMemberDefinition** *(dict) --*

              The Amazon Cognito user group that is part of the work team.

              - **UserPool** *(string) --*

                An identifier for a user pool. The user pool must be in the same region as the
                service that you are calling.

              - **UserGroup** *(string) --*

                An identifier for a user group.

              - **ClientId** *(string) --*

                An identifier for an application client. You must create the app client ID using
                Amazon Cognito.

        - **WorkteamArn** *(string) --*

          The Amazon Resource Name (ARN) that identifies the work team.

        - **ProductListingIds** *(list) --*

          The Amazon Marketplace identifier for a vendor's work team.

          - *(string) --*

        - **Description** *(string) --*

          A description of the work team.

        - **SubDomain** *(string) --*

          The URI of the labeling job's user interface. Workers open this URI to start labeling
          your data objects.

        - **CreateDate** *(datetime) --*

          The date and time that the work team was created (timestamp).

        - **LastUpdatedDate** *(datetime) --*

          The date and time that the work team was last updated (timestamp).

        - **NotificationConfiguration** *(dict) --*

          Configures SNS notifications of available or expiring work items for work teams.

          - **NotificationTopicArn** *(string) --*

            The ARN for the SNS topic to which notifications should be published.

    - **NextToken** *(string) --*

      If the response is truncated, Amazon SageMaker returns this token. To retrieve the next set
      of work teams, use it in the subsequent request.
    """


_ClientRenderUiTemplateResponseErrorsTypeDef = TypedDict(
    "_ClientRenderUiTemplateResponseErrorsTypeDef",
    {"Code": str, "Message": str},
    total=False,
)


class ClientRenderUiTemplateResponseErrorsTypeDef(
    _ClientRenderUiTemplateResponseErrorsTypeDef
):
    """
    Type definition for `ClientRenderUiTemplateResponse` `Errors`

    A description of an error that occurred while rendering the template.

    - **Code** *(string) --*

      A unique identifier for a specific class of errors.

    - **Message** *(string) --*

      A human-readable message describing the error.
    """


_ClientRenderUiTemplateResponseTypeDef = TypedDict(
    "_ClientRenderUiTemplateResponseTypeDef",
    {
        "RenderedContent": str,
        "Errors": List[ClientRenderUiTemplateResponseErrorsTypeDef],
    },
    total=False,
)


class ClientRenderUiTemplateResponseTypeDef(_ClientRenderUiTemplateResponseTypeDef):
    """
    Type definition for `ClientRenderUiTemplate` `Response`

    - **RenderedContent** *(string) --*

      A Liquid template that renders the HTML for the worker UI.

    - **Errors** *(list) --*

      A list of one or more ``RenderingError`` objects if any were encountered while rendering the
      template. If there were no errors, the list is empty.

      - *(dict) --*

        A description of an error that occurred while rendering the template.

        - **Code** *(string) --*

          A unique identifier for a specific class of errors.

        - **Message** *(string) --*

          A human-readable message describing the error.
    """


_ClientRenderUiTemplateTaskTypeDef = TypedDict(
    "_ClientRenderUiTemplateTaskTypeDef", {"Input": str}
)


class ClientRenderUiTemplateTaskTypeDef(_ClientRenderUiTemplateTaskTypeDef):
    """
    Type definition for `ClientRenderUiTemplate` `Task`

    A ``RenderableTask`` object containing a representative task to render.

    - **Input** *(string) --* **[REQUIRED]**

      A JSON object that contains values for the variables defined in the template. It is made
      available to the template under the substitution variable ``task.input`` . For example, if you
      define a variable ``task.input.text`` in your template, you can supply the variable in the JSON
      object as ``"text": "sample text"`` .
    """


_ClientRenderUiTemplateUiTemplateTypeDef = TypedDict(
    "_ClientRenderUiTemplateUiTemplateTypeDef", {"Content": str}
)


class ClientRenderUiTemplateUiTemplateTypeDef(_ClientRenderUiTemplateUiTemplateTypeDef):
    """
    Type definition for `ClientRenderUiTemplate` `UiTemplate`

    A ``Template`` object containing the worker UI template to render.

    - **Content** *(string) --* **[REQUIRED]**

      The content of the Liquid template for the worker user interface.
    """


_ClientSearchResponseResultsTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef = TypedDict(
    "_ClientSearchResponseResultsTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef",
    {"Name": str, "Regex": str},
    total=False,
)


class ClientSearchResponseResultsTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef(
    _ClientSearchResponseResultsTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef
):
    """
    Type definition for `ClientSearchResponseResultsTrainingJobAlgorithmSpecification` `MetricDefinitions`

    Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
    Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
    metric that a hyperparameter tuning job uses as its objective metric to choose the
    best training job.

    - **Name** *(string) --*

      The name of the metric.

    - **Regex** *(string) --*

      A regular expression that searches the output of a training job and gets the
      value of the metric. For more information about using regular expressions to
      define metrics, see `Defining Objective Metrics
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
      .
    """


_ClientSearchResponseResultsTrainingJobAlgorithmSpecificationTypeDef = TypedDict(
    "_ClientSearchResponseResultsTrainingJobAlgorithmSpecificationTypeDef",
    {
        "TrainingImage": str,
        "AlgorithmName": str,
        "TrainingInputMode": str,
        "MetricDefinitions": List[
            ClientSearchResponseResultsTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef
        ],
    },
    total=False,
)


class ClientSearchResponseResultsTrainingJobAlgorithmSpecificationTypeDef(
    _ClientSearchResponseResultsTrainingJobAlgorithmSpecificationTypeDef
):
    """
    Type definition for `ClientSearchResponseResultsTrainingJob` `AlgorithmSpecification`

    Information about the algorithm used for training, and algorithm metadata.

    - **TrainingImage** *(string) --*

      The registry path of the Docker image that contains the training algorithm. For
      information about docker registry paths for built-in algorithms, see `Algorithms
      Provided by Amazon SageMaker\\: Common Parameters
      <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
      . Amazon SageMaker supports both ``registry/repository[:tag]`` and
      ``registry/repository[@digest]`` image path formats. For more information, see `Using
      Your Own Algorithms with Amazon SageMaker
      <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

    - **AlgorithmName** *(string) --*

      The name of the algorithm resource to use for the training job. This must be an
      algorithm resource that you created or subscribe to on AWS Marketplace. If you
      specify a value for this parameter, you can't specify a value for ``TrainingImage`` .

    - **TrainingInputMode** *(string) --*

      The input mode that the algorithm supports. For the input modes that Amazon SageMaker
      algorithms support, see `Algorithms
      <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ . If an algorithm
      supports the ``File`` input mode, Amazon SageMaker downloads the training data from
      S3 to the provisioned ML storage Volume, and mounts the directory to docker volume
      for training container. If an algorithm supports the ``Pipe`` input mode, Amazon
      SageMaker streams data directly from S3 to the container.

      In File mode, make sure you provision ML storage volume with sufficient capacity to
      accommodate the data download from S3. In addition to the training data, the ML
      storage volume also stores the output model. The algorithm container use ML storage
      volume to also store intermediate information, if any.

      For distributed algorithms using File mode, training data is distributed uniformly,
      and your training duration is predictable if the input data objects size is
      approximately same. Amazon SageMaker does not split the files any further for model
      training. If the object sizes are skewed, training won't be optimal as the data
      distribution is also skewed where one host in a training cluster is overloaded, thus
      becoming bottleneck in training.

    - **MetricDefinitions** *(list) --*

      A list of metric definition objects. Each object specifies the metric name and
      regular expressions used to parse algorithm logs. Amazon SageMaker publishes each
      metric to Amazon CloudWatch.

      - *(dict) --*

        Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
        Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
        metric that a hyperparameter tuning job uses as its objective metric to choose the
        best training job.

        - **Name** *(string) --*

          The name of the metric.

        - **Regex** *(string) --*

          A regular expression that searches the output of a training job and gets the
          value of the metric. For more information about using regular expressions to
          define metrics, see `Defining Objective Metrics
          <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
          .
    """


_ClientSearchResponseResultsTrainingJobFinalMetricDataListTypeDef = TypedDict(
    "_ClientSearchResponseResultsTrainingJobFinalMetricDataListTypeDef",
    {"MetricName": str, "Value": float, "Timestamp": datetime},
    total=False,
)


class ClientSearchResponseResultsTrainingJobFinalMetricDataListTypeDef(
    _ClientSearchResponseResultsTrainingJobFinalMetricDataListTypeDef
):
    """
    Type definition for `ClientSearchResponseResultsTrainingJob` `FinalMetricDataList`

    The name, value, and date and time of a metric that was emitted to Amazon CloudWatch.

    - **MetricName** *(string) --*

      The name of the metric.

    - **Value** *(float) --*

      The value of the metric.

    - **Timestamp** *(datetime) --*

      The date and time that the algorithm emitted the metric.
    """


_ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef = TypedDict(
    "_ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef",
    {
        "FileSystemId": str,
        "FileSystemAccessMode": str,
        "FileSystemType": str,
        "DirectoryPath": str,
    },
    total=False,
)


class ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef(
    _ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef
):
    """
    Type definition for `ClientSearchResponseResultsTrainingJobInputDataConfigDataSource` `FileSystemDataSource`

    The file system that is associated with a channel.

    - **FileSystemId** *(string) --*

      The file system id.

    - **FileSystemAccessMode** *(string) --*

      The access mode of the mount of the directory associated with the channel. A
      directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
      mode.

    - **FileSystemType** *(string) --*

      The file system type.

    - **DirectoryPath** *(string) --*

      The full path to the directory to associate with the channel.
    """


_ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef = TypedDict(
    "_ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef",
    {
        "S3DataType": str,
        "S3Uri": str,
        "S3DataDistributionType": str,
        "AttributeNames": List[str],
    },
    total=False,
)


class ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef(
    _ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef
):
    """
    Type definition for `ClientSearchResponseResultsTrainingJobInputDataConfigDataSource` `S3DataSource`

    The S3 location of the data source that is associated with a channel.

    - **S3DataType** *(string) --*

      If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
      SageMaker uses all objects that match the specified key name prefix for model
      training.

      If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
      manifest file containing a list of object keys that you want Amazon SageMaker
      to use for model training.

      If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
      augmented manifest file in JSON lines format. This file contains the data you
      want to use for model training. ``AugmentedManifestFile`` can only be used if
      the Channel's input mode is ``Pipe`` .

    - **S3Uri** *(string) --*

      Depending on the value specified for the ``S3DataType`` , identifies either a
      key name prefix or a manifest. For example:

      * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

      * A manifest might look like this: ``s3://bucketname/example.manifest``   The
      manifest is an S3 object which is a JSON file with the following format:  The
      preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
      "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
       ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
        ``]``   The preceding JSON matches the following ``s3Uris`` :
        ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
        set of ``s3uris`` in this manifest is the input data for the channel for this
        datasource. The object that each ``s3uris`` points to must be readable by the
        IAM role that Amazon SageMaker uses to perform tasks on your behalf.

    - **S3DataDistributionType** *(string) --*

      If you want Amazon SageMaker to replicate the entire dataset on each ML compute
      instance that is launched for model training, specify ``FullyReplicated`` .

      If you want Amazon SageMaker to replicate a subset of data on each ML compute
      instance that is launched for model training, specify ``ShardedByS3Key`` . If
      there are *n* ML compute instances launched for a training job, each instance
      gets approximately 1/*n* of the number of S3 objects. In this case, model
      training on each machine uses only the subset of training data.

      Don't choose more ML compute instances for training than available S3 objects.
      If you do, some nodes won't get any data and you will pay for nodes that aren't
      getting any training data. This applies in both File and Pipe modes. Keep this
      in mind when developing algorithms.

      In distributed training, where you use multiple ML compute EC2 instances, you
      might choose ``ShardedByS3Key`` . If the algorithm requires copying training
      data to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ),
      this copies 1/*n* of the number of objects.

    - **AttributeNames** *(list) --*

      A list of one or more attribute names to use that are found in a specified
      augmented manifest file.

      - *(string) --*
    """


_ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceTypeDef = TypedDict(
    "_ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceTypeDef",
    {
        "S3DataSource": ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef,
        "FileSystemDataSource": ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef,
    },
    total=False,
)


class ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceTypeDef(
    _ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceTypeDef
):
    """
    Type definition for `ClientSearchResponseResultsTrainingJobInputDataConfig` `DataSource`

    The location of the channel data.

    - **S3DataSource** *(dict) --*

      The S3 location of the data source that is associated with a channel.

      - **S3DataType** *(string) --*

        If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
        SageMaker uses all objects that match the specified key name prefix for model
        training.

        If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
        manifest file containing a list of object keys that you want Amazon SageMaker
        to use for model training.

        If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
        augmented manifest file in JSON lines format. This file contains the data you
        want to use for model training. ``AugmentedManifestFile`` can only be used if
        the Channel's input mode is ``Pipe`` .

      - **S3Uri** *(string) --*

        Depending on the value specified for the ``S3DataType`` , identifies either a
        key name prefix or a manifest. For example:

        * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

        * A manifest might look like this: ``s3://bucketname/example.manifest``   The
        manifest is an S3 object which is a JSON file with the following format:  The
        preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
        "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
         ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
          ``]``   The preceding JSON matches the following ``s3Uris`` :
          ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
          set of ``s3uris`` in this manifest is the input data for the channel for this
          datasource. The object that each ``s3uris`` points to must be readable by the
          IAM role that Amazon SageMaker uses to perform tasks on your behalf.

      - **S3DataDistributionType** *(string) --*

        If you want Amazon SageMaker to replicate the entire dataset on each ML compute
        instance that is launched for model training, specify ``FullyReplicated`` .

        If you want Amazon SageMaker to replicate a subset of data on each ML compute
        instance that is launched for model training, specify ``ShardedByS3Key`` . If
        there are *n* ML compute instances launched for a training job, each instance
        gets approximately 1/*n* of the number of S3 objects. In this case, model
        training on each machine uses only the subset of training data.

        Don't choose more ML compute instances for training than available S3 objects.
        If you do, some nodes won't get any data and you will pay for nodes that aren't
        getting any training data. This applies in both File and Pipe modes. Keep this
        in mind when developing algorithms.

        In distributed training, where you use multiple ML compute EC2 instances, you
        might choose ``ShardedByS3Key`` . If the algorithm requires copying training
        data to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ),
        this copies 1/*n* of the number of objects.

      - **AttributeNames** *(list) --*

        A list of one or more attribute names to use that are found in a specified
        augmented manifest file.

        - *(string) --*

    - **FileSystemDataSource** *(dict) --*

      The file system that is associated with a channel.

      - **FileSystemId** *(string) --*

        The file system id.

      - **FileSystemAccessMode** *(string) --*

        The access mode of the mount of the directory associated with the channel. A
        directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
        mode.

      - **FileSystemType** *(string) --*

        The file system type.

      - **DirectoryPath** *(string) --*

        The full path to the directory to associate with the channel.
    """


_ClientSearchResponseResultsTrainingJobInputDataConfigShuffleConfigTypeDef = TypedDict(
    "_ClientSearchResponseResultsTrainingJobInputDataConfigShuffleConfigTypeDef",
    {"Seed": int},
    total=False,
)


class ClientSearchResponseResultsTrainingJobInputDataConfigShuffleConfigTypeDef(
    _ClientSearchResponseResultsTrainingJobInputDataConfigShuffleConfigTypeDef
):
    """
    Type definition for `ClientSearchResponseResultsTrainingJobInputDataConfig` `ShuffleConfig`

    A configuration for a shuffle option for input data in a channel. If you use
    ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
    matches. If you use ``ManifestFile`` , the order of the S3 object references in the
    ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of
    the JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
    determined using the ``Seed`` value.

    For Pipe input mode, shuffling is done at the start of every epoch. With large
    datasets this ensures that the order of the training data is different for each
    epoch, it helps reduce bias and possible overfitting. In a multi-node training job
    when ShuffleConfig is combined with ``S3DataDistributionType`` of
    ``ShardedByS3Key`` , the data is shuffled across nodes so that the content sent to
    a particular node on the first epoch might be sent to a different node on the
    second epoch.

    - **Seed** *(integer) --*

      Determines the shuffling order in ``ShuffleConfig`` value.
    """


_ClientSearchResponseResultsTrainingJobInputDataConfigTypeDef = TypedDict(
    "_ClientSearchResponseResultsTrainingJobInputDataConfigTypeDef",
    {
        "ChannelName": str,
        "DataSource": ClientSearchResponseResultsTrainingJobInputDataConfigDataSourceTypeDef,
        "ContentType": str,
        "CompressionType": str,
        "RecordWrapperType": str,
        "InputMode": str,
        "ShuffleConfig": ClientSearchResponseResultsTrainingJobInputDataConfigShuffleConfigTypeDef,
    },
    total=False,
)


class ClientSearchResponseResultsTrainingJobInputDataConfigTypeDef(
    _ClientSearchResponseResultsTrainingJobInputDataConfigTypeDef
):
    """
    Type definition for `ClientSearchResponseResultsTrainingJob` `InputDataConfig`

    A channel is a named input source that training algorithms can consume.

    - **ChannelName** *(string) --*

      The name of the channel.

    - **DataSource** *(dict) --*

      The location of the channel data.

      - **S3DataSource** *(dict) --*

        The S3 location of the data source that is associated with a channel.

        - **S3DataType** *(string) --*

          If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
          SageMaker uses all objects that match the specified key name prefix for model
          training.

          If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
          manifest file containing a list of object keys that you want Amazon SageMaker
          to use for model training.

          If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
          augmented manifest file in JSON lines format. This file contains the data you
          want to use for model training. ``AugmentedManifestFile`` can only be used if
          the Channel's input mode is ``Pipe`` .

        - **S3Uri** *(string) --*

          Depending on the value specified for the ``S3DataType`` , identifies either a
          key name prefix or a manifest. For example:

          * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

          * A manifest might look like this: ``s3://bucketname/example.manifest``   The
          manifest is an S3 object which is a JSON file with the following format:  The
          preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
          "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
           ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
            ``]``   The preceding JSON matches the following ``s3Uris`` :
            ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
            set of ``s3uris`` in this manifest is the input data for the channel for this
            datasource. The object that each ``s3uris`` points to must be readable by the
            IAM role that Amazon SageMaker uses to perform tasks on your behalf.

        - **S3DataDistributionType** *(string) --*

          If you want Amazon SageMaker to replicate the entire dataset on each ML compute
          instance that is launched for model training, specify ``FullyReplicated`` .

          If you want Amazon SageMaker to replicate a subset of data on each ML compute
          instance that is launched for model training, specify ``ShardedByS3Key`` . If
          there are *n* ML compute instances launched for a training job, each instance
          gets approximately 1/*n* of the number of S3 objects. In this case, model
          training on each machine uses only the subset of training data.

          Don't choose more ML compute instances for training than available S3 objects.
          If you do, some nodes won't get any data and you will pay for nodes that aren't
          getting any training data. This applies in both File and Pipe modes. Keep this
          in mind when developing algorithms.

          In distributed training, where you use multiple ML compute EC2 instances, you
          might choose ``ShardedByS3Key`` . If the algorithm requires copying training
          data to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ),
          this copies 1/*n* of the number of objects.

        - **AttributeNames** *(list) --*

          A list of one or more attribute names to use that are found in a specified
          augmented manifest file.

          - *(string) --*

      - **FileSystemDataSource** *(dict) --*

        The file system that is associated with a channel.

        - **FileSystemId** *(string) --*

          The file system id.

        - **FileSystemAccessMode** *(string) --*

          The access mode of the mount of the directory associated with the channel. A
          directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
          mode.

        - **FileSystemType** *(string) --*

          The file system type.

        - **DirectoryPath** *(string) --*

          The full path to the directory to associate with the channel.

    - **ContentType** *(string) --*

      The MIME type of the data.

    - **CompressionType** *(string) --*

      If training data is compressed, the compression type. The default value is ``None``
      . ``CompressionType`` is used only in Pipe input mode. In File mode, leave this
      field unset or set it to None.

    - **RecordWrapperType** *(string) --*

      Specify RecordIO as the value when input data is in raw format but the training
      algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
      individual S3 object in a RecordIO record. If the input data is already in RecordIO
      format, you don't need to set this attribute. For more information, see `Create a
      Dataset Using RecordIO
      <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
      .

      In File mode, leave this field unset or set it to None.

    - **InputMode** *(string) --*

      (Optional) The input mode to use for the data channel in a training job. If you
      don't set a value for ``InputMode`` , Amazon SageMaker uses the value set for
      ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
      setting in a  AlgorithmSpecification request when you have a channel that needs a
      different input mode from the training job's general setting. To download the data
      from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage
      volume, and mount the directory to a Docker volume, use ``File`` input mode. To
      stream data directly from Amazon S3 to the container, choose ``Pipe`` input mode.

      To use a model for incremental training, choose ``File`` input model.

    - **ShuffleConfig** *(dict) --*

      A configuration for a shuffle option for input data in a channel. If you use
      ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
      matches. If you use ``ManifestFile`` , the order of the S3 object references in the
      ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of
      the JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
      determined using the ``Seed`` value.

      For Pipe input mode, shuffling is done at the start of every epoch. With large
      datasets this ensures that the order of the training data is different for each
      epoch, it helps reduce bias and possible overfitting. In a multi-node training job
      when ShuffleConfig is combined with ``S3DataDistributionType`` of
      ``ShardedByS3Key`` , the data is shuffled across nodes so that the content sent to
      a particular node on the first epoch might be sent to a different node on the
      second epoch.

      - **Seed** *(integer) --*

        Determines the shuffling order in ``ShuffleConfig`` value.
    """


_ClientSearchResponseResultsTrainingJobModelArtifactsTypeDef = TypedDict(
    "_ClientSearchResponseResultsTrainingJobModelArtifactsTypeDef",
    {"S3ModelArtifacts": str},
    total=False,
)


class ClientSearchResponseResultsTrainingJobModelArtifactsTypeDef(
    _ClientSearchResponseResultsTrainingJobModelArtifactsTypeDef
):
    """
    Type definition for `ClientSearchResponseResultsTrainingJob` `ModelArtifacts`

    Information about the Amazon S3 location that is configured for storing model artifacts.

    - **S3ModelArtifacts** *(string) --*

      The path of the S3 object that contains the model artifacts. For example,
      ``s3://bucket-name/keynameprefix/model.tar.gz`` .
    """


_ClientSearchResponseResultsTrainingJobOutputDataConfigTypeDef = TypedDict(
    "_ClientSearchResponseResultsTrainingJobOutputDataConfigTypeDef",
    {"KmsKeyId": str, "S3OutputPath": str},
    total=False,
)


class ClientSearchResponseResultsTrainingJobOutputDataConfigTypeDef(
    _ClientSearchResponseResultsTrainingJobOutputDataConfigTypeDef
):
    """
    Type definition for `ClientSearchResponseResultsTrainingJob` `OutputDataConfig`

    The S3 path where model artifacts that you configured when creating the job are stored.
    Amazon SageMaker creates subfolders for model artifacts.

    - **KmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
      the model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId``
      can be any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // KMS Key Alias  ``"alias/ExampleAlias"``

      * // Amazon Resource Name (ARN) of a KMS Key Alias
      ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

      If you use a KMS key ID or an alias of your master key, the Amazon SageMaker
      execution role must include permissions to call ``kms:Encrypt`` . If you don't
      provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3 for
      your role's account. Amazon SageMaker uses server-side encryption with KMS-managed
      keys for ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject``
      permission that only allows objects with server-side encryption, set the condition
      key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information,
      see `KMS-Managed Encryption Keys
      <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
      *Amazon Simple Storage Service Developer Guide.*

      The KMS key policy must grant permission to the IAM role that you specify in your
      ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
      requests. For more information, see `Using Key Policies in AWS KMS
      <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
      in the *AWS Key Management Service Developer Guide* .

    - **S3OutputPath** *(string) --*

      Identifies the S3 path where you want Amazon SageMaker to store the model artifacts.
      For example, ``s3://bucket-name/key-name-prefix`` .
    """


_ClientSearchResponseResultsTrainingJobResourceConfigTypeDef = TypedDict(
    "_ClientSearchResponseResultsTrainingJobResourceConfigTypeDef",
    {
        "InstanceType": str,
        "InstanceCount": int,
        "VolumeSizeInGB": int,
        "VolumeKmsKeyId": str,
    },
    total=False,
)


class ClientSearchResponseResultsTrainingJobResourceConfigTypeDef(
    _ClientSearchResponseResultsTrainingJobResourceConfigTypeDef
):
    """
    Type definition for `ClientSearchResponseResultsTrainingJob` `ResourceConfig`

    Resources, including ML compute instances and ML storage volumes, that are configured
    for model training.

    - **InstanceType** *(string) --*

      The ML compute instance type.

    - **InstanceCount** *(integer) --*

      The number of ML compute instances to use. For distributed training, provide a value
      greater than 1.

    - **VolumeSizeInGB** *(integer) --*

      The size of the ML storage volume that you want to provision.

      ML storage volumes store model artifacts and incremental states. Training algorithms
      might also use the ML storage volume for scratch space. If you want to store the
      training data in the ML storage volume, choose ``File`` as the ``TrainingInputMode``
      in the algorithm specification.

      You must specify sufficient ML storage for your scenario.

      .. note::

        Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

      .. note::

        Certain Nitro-based instances include local storage with a fixed total size,
        dependent on the instance type. When using these instances for training, Amazon
        SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage. You
        can't request a ``VolumeSizeInGB`` greater than the total size of the local
        instance storage.

        For a list of instance types that support local instance storage, including the
        total size per instance type, see `Instance Store Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
        .

    - **VolumeKmsKeyId** *(string) --*

      The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
      attached to the ML compute instance(s) that run the training job.

      .. note::

        Certain Nitro-based instances include local storage, dependent on the instance
        type. Local storage volumes are encrypted using a hardware module on the instance.
        You can't request a ``VolumeKmsKeyId`` when using an instance type with local
        storage.

        For a list of instance types that support local instance storage, see `Instance
        Store Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
        .

        For more information about local instance storage encryption, see `SSD Instance
        Store Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

      The ``VolumeKmsKeyId`` can be in any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_ClientSearchResponseResultsTrainingJobSecondaryStatusTransitionsTypeDef = TypedDict(
    "_ClientSearchResponseResultsTrainingJobSecondaryStatusTransitionsTypeDef",
    {"Status": str, "StartTime": datetime, "EndTime": datetime, "StatusMessage": str},
    total=False,
)


class ClientSearchResponseResultsTrainingJobSecondaryStatusTransitionsTypeDef(
    _ClientSearchResponseResultsTrainingJobSecondaryStatusTransitionsTypeDef
):
    """
    Type definition for `ClientSearchResponseResultsTrainingJob` `SecondaryStatusTransitions`

    An array element of  DescribeTrainingJobResponse$SecondaryStatusTransitions . It
    provides additional details about a status that the training job has transitioned
    through. A training job can be in one of several states, for example, starting,
    downloading, training, or uploading. Within each state, there are a number of
    intermediate states. For example, within the starting state, Amazon SageMaker could
    be starting the training job or launching the ML instances. These transitional states
    are referred to as the job's secondary status.

    - **Status** *(string) --*

      Contains a secondary status information from a training job.

      Status might be one of the following secondary statuses:

        InProgress

      * ``Starting`` - Starting the training job.

      * ``Downloading`` - An optional stage for algorithms that support ``File`` training
      input mode. It indicates that data is being downloaded to the ML storage volumes.

      * ``Training`` - Training is in progress.

      * ``Uploading`` - Training is complete and the model artifacts are being uploaded
      to the S3 location.

        Completed

      * ``Completed`` - The training job has completed.

        Failed

      * ``Failed`` - The training job has failed. The reason for the failure is returned
      in the ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

        Stopped

      * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed
      runtime.

      * ``Stopped`` - The training job has stopped.

        Stopping

      * ``Stopping`` - Stopping the training job.

      We no longer support the following secondary statuses:

      * ``LaunchingMLInstances``

      * ``PreparingTrainingStack``

      * ``DownloadingTrainingImage``

    - **StartTime** *(datetime) --*

      A timestamp that shows when the training job transitioned to the current secondary
      status state.

    - **EndTime** *(datetime) --*

      A timestamp that shows when the training job transitioned out of this secondary
      status state into another secondary status state or when the training job has ended.

    - **StatusMessage** *(string) --*

      A detailed description of the progress within a secondary status.

      Amazon SageMaker provides secondary statuses and status messages that apply to each
      of them:

        Starting

      * Starting the training job.

      * Launching requested ML instances.

      * Insufficient capacity error from EC2 while launching instances, retrying!

      * Launched instance was unhealthy, replacing it!

      * Preparing the instances for training.

        Training

      * Downloading the training image.

      * Training image download completed. Training in progress.

      .. warning::

        Status messages are subject to change. Therefore, we recommend not including them
        in code that programmatically initiates actions. For examples, don't use status
        messages in if statements.

      To have an overview of your training job's progress, view ``TrainingJobStatus`` and
      ``SecondaryStatus`` in  DescribeTrainingJob , and ``StatusMessage`` together. For
      example, at the start of a training job, you might see the following:

      * ``TrainingJobStatus`` - InProgress

      * ``SecondaryStatus`` - Training

      * ``StatusMessage`` - Downloading the training image
    """


_ClientSearchResponseResultsTrainingJobStoppingConditionTypeDef = TypedDict(
    "_ClientSearchResponseResultsTrainingJobStoppingConditionTypeDef",
    {"MaxRuntimeInSeconds": int, "MaxWaitTimeInSeconds": int},
    total=False,
)


class ClientSearchResponseResultsTrainingJobStoppingConditionTypeDef(
    _ClientSearchResponseResultsTrainingJobStoppingConditionTypeDef
):
    """
    Type definition for `ClientSearchResponseResultsTrainingJob` `StoppingCondition`

    Specifies a limit to how long a model training job can run. When the job reaches the
    time limit, Amazon SageMaker ends the training job. Use this API to cap model training
    costs.

    To stop a job, Amazon SageMaker sends the algorithm the ``SIGTERM`` signal, which
    delays job termination for 120 seconds. Algorithms can use this 120-second window to
    save the model artifacts, so the results of training are not lost.

    - **MaxRuntimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, that the training or compilation job can run.
      If job does not complete during this time, Amazon SageMaker ends the job. If value is
      not specified, default value is 1 day. The maximum value is 28 days.

    - **MaxWaitTimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, how long you are willing to wait for a
      managed spot training job to complete. It is the amount of time spent waiting for
      Spot capacity plus the amount of time the training job runs. It must be equal to or
      greater than ``MaxRuntimeInSeconds`` .
    """


_ClientSearchResponseResultsTrainingJobTagsTypeDef = TypedDict(
    "_ClientSearchResponseResultsTrainingJobTagsTypeDef",
    {"Key": str, "Value": str},
    total=False,
)


class ClientSearchResponseResultsTrainingJobTagsTypeDef(
    _ClientSearchResponseResultsTrainingJobTagsTypeDef
):
    """
    Type definition for `ClientSearchResponseResultsTrainingJob` `Tags`

    Describes a tag.

    - **Key** *(string) --*

      The tag key.

    - **Value** *(string) --*

      The tag value.
    """


_ClientSearchResponseResultsTrainingJobVpcConfigTypeDef = TypedDict(
    "_ClientSearchResponseResultsTrainingJobVpcConfigTypeDef",
    {"SecurityGroupIds": List[str], "Subnets": List[str]},
    total=False,
)


class ClientSearchResponseResultsTrainingJobVpcConfigTypeDef(
    _ClientSearchResponseResultsTrainingJobVpcConfigTypeDef
):
    """
    Type definition for `ClientSearchResponseResultsTrainingJob` `VpcConfig`

    A  VpcConfig object that specifies the VPC that this training job has access to. For
    more information, see `Protect Training Jobs by Using an Amazon Virtual Private Cloud
    <https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html>`__ .

    - **SecurityGroupIds** *(list) --*

      The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for
      the VPC that is specified in the ``Subnets`` field.

      - *(string) --*

    - **Subnets** *(list) --*

      The ID of the subnets in the VPC to which you want to connect your training job or
      model.

      .. note::

        Amazon EC2 P3 accelerated computing instances are not available in the c/d/e
        availability zones of region us-east-1. If you want to create endpoints with P3
        instances in VPC mode in region us-east-1, create subnets in a/b/f availability
        zones instead.

      - *(string) --*
    """


_ClientSearchResponseResultsTrainingJobTypeDef = TypedDict(
    "_ClientSearchResponseResultsTrainingJobTypeDef",
    {
        "TrainingJobName": str,
        "TrainingJobArn": str,
        "TuningJobArn": str,
        "LabelingJobArn": str,
        "ModelArtifacts": ClientSearchResponseResultsTrainingJobModelArtifactsTypeDef,
        "TrainingJobStatus": str,
        "SecondaryStatus": str,
        "FailureReason": str,
        "HyperParameters": Dict[str, str],
        "AlgorithmSpecification": ClientSearchResponseResultsTrainingJobAlgorithmSpecificationTypeDef,
        "RoleArn": str,
        "InputDataConfig": List[
            ClientSearchResponseResultsTrainingJobInputDataConfigTypeDef
        ],
        "OutputDataConfig": ClientSearchResponseResultsTrainingJobOutputDataConfigTypeDef,
        "ResourceConfig": ClientSearchResponseResultsTrainingJobResourceConfigTypeDef,
        "VpcConfig": ClientSearchResponseResultsTrainingJobVpcConfigTypeDef,
        "StoppingCondition": ClientSearchResponseResultsTrainingJobStoppingConditionTypeDef,
        "CreationTime": datetime,
        "TrainingStartTime": datetime,
        "TrainingEndTime": datetime,
        "LastModifiedTime": datetime,
        "SecondaryStatusTransitions": List[
            ClientSearchResponseResultsTrainingJobSecondaryStatusTransitionsTypeDef
        ],
        "FinalMetricDataList": List[
            ClientSearchResponseResultsTrainingJobFinalMetricDataListTypeDef
        ],
        "EnableNetworkIsolation": bool,
        "EnableInterContainerTrafficEncryption": bool,
        "Tags": List[ClientSearchResponseResultsTrainingJobTagsTypeDef],
    },
    total=False,
)


class ClientSearchResponseResultsTrainingJobTypeDef(
    _ClientSearchResponseResultsTrainingJobTypeDef
):
    """
    Type definition for `ClientSearchResponseResults` `TrainingJob`

    A ``TrainingJob`` object that is returned as part of a ``Search`` request.

    - **TrainingJobName** *(string) --*

      The name of the training job.

    - **TrainingJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the training job.

    - **TuningJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the associated hyperparameter tuning job if the
      training job was launched by a hyperparameter tuning job.

    - **LabelingJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the labeling job.

    - **ModelArtifacts** *(dict) --*

      Information about the Amazon S3 location that is configured for storing model artifacts.

      - **S3ModelArtifacts** *(string) --*

        The path of the S3 object that contains the model artifacts. For example,
        ``s3://bucket-name/keynameprefix/model.tar.gz`` .

    - **TrainingJobStatus** *(string) --*

      The status of the training job.

      Training job statuses are:

      * ``InProgress`` - The training is in progress.

      * ``Completed`` - The training job has completed.

      * ``Failed`` - The training job has failed. To see the reason for the failure, see the
      ``FailureReason`` field in the response to a ``DescribeTrainingJobResponse`` call.

      * ``Stopping`` - The training job is stopping.

      * ``Stopped`` - The training job has stopped.

      For more detailed information, see ``SecondaryStatus`` .

    - **SecondaryStatus** *(string) --*

      Provides detailed information about the state of the training job. For detailed
      information about the secondary status of the training job, see ``StatusMessage`` under
       SecondaryStatusTransition .

      Amazon SageMaker provides primary statuses and secondary statuses that apply to each of
      them:

        InProgress

      * ``Starting`` - Starting the training job.

      * ``Downloading`` - An optional stage for algorithms that support ``File`` training
      input mode. It indicates that data is being downloaded to the ML storage volumes.

      * ``Training`` - Training is in progress.

      * ``Uploading`` - Training is complete and the model artifacts are being uploaded to
      the S3 location.

        Completed

      * ``Completed`` - The training job has completed.

        Failed

      * ``Failed`` - The training job has failed. The reason for the failure is returned in
      the ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

        Stopped

      * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed
      runtime.

      * ``Stopped`` - The training job has stopped.

        Stopping

      * ``Stopping`` - Stopping the training job.

      .. warning::

        Valid values for ``SecondaryStatus`` are subject to change.

      We no longer support the following secondary statuses:

      * ``LaunchingMLInstances``

      * ``PreparingTrainingStack``

      * ``DownloadingTrainingImage``

    - **FailureReason** *(string) --*

      If the training job failed, the reason it failed.

    - **HyperParameters** *(dict) --*

      Algorithm-specific parameters.

      - *(string) --*

        - *(string) --*

    - **AlgorithmSpecification** *(dict) --*

      Information about the algorithm used for training, and algorithm metadata.

      - **TrainingImage** *(string) --*

        The registry path of the Docker image that contains the training algorithm. For
        information about docker registry paths for built-in algorithms, see `Algorithms
        Provided by Amazon SageMaker\\: Common Parameters
        <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
        . Amazon SageMaker supports both ``registry/repository[:tag]`` and
        ``registry/repository[@digest]`` image path formats. For more information, see `Using
        Your Own Algorithms with Amazon SageMaker
        <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

      - **AlgorithmName** *(string) --*

        The name of the algorithm resource to use for the training job. This must be an
        algorithm resource that you created or subscribe to on AWS Marketplace. If you
        specify a value for this parameter, you can't specify a value for ``TrainingImage`` .

      - **TrainingInputMode** *(string) --*

        The input mode that the algorithm supports. For the input modes that Amazon SageMaker
        algorithms support, see `Algorithms
        <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ . If an algorithm
        supports the ``File`` input mode, Amazon SageMaker downloads the training data from
        S3 to the provisioned ML storage Volume, and mounts the directory to docker volume
        for training container. If an algorithm supports the ``Pipe`` input mode, Amazon
        SageMaker streams data directly from S3 to the container.

        In File mode, make sure you provision ML storage volume with sufficient capacity to
        accommodate the data download from S3. In addition to the training data, the ML
        storage volume also stores the output model. The algorithm container use ML storage
        volume to also store intermediate information, if any.

        For distributed algorithms using File mode, training data is distributed uniformly,
        and your training duration is predictable if the input data objects size is
        approximately same. Amazon SageMaker does not split the files any further for model
        training. If the object sizes are skewed, training won't be optimal as the data
        distribution is also skewed where one host in a training cluster is overloaded, thus
        becoming bottleneck in training.

      - **MetricDefinitions** *(list) --*

        A list of metric definition objects. Each object specifies the metric name and
        regular expressions used to parse algorithm logs. Amazon SageMaker publishes each
        metric to Amazon CloudWatch.

        - *(dict) --*

          Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
          Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
          metric that a hyperparameter tuning job uses as its objective metric to choose the
          best training job.

          - **Name** *(string) --*

            The name of the metric.

          - **Regex** *(string) --*

            A regular expression that searches the output of a training job and gets the
            value of the metric. For more information about using regular expressions to
            define metrics, see `Defining Objective Metrics
            <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
            .

    - **RoleArn** *(string) --*

      The AWS Identity and Access Management (IAM) role configured for the training job.

    - **InputDataConfig** *(list) --*

      An array of ``Channel`` objects that describes each data input channel.

      - *(dict) --*

        A channel is a named input source that training algorithms can consume.

        - **ChannelName** *(string) --*

          The name of the channel.

        - **DataSource** *(dict) --*

          The location of the channel data.

          - **S3DataSource** *(dict) --*

            The S3 location of the data source that is associated with a channel.

            - **S3DataType** *(string) --*

              If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
              SageMaker uses all objects that match the specified key name prefix for model
              training.

              If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
              manifest file containing a list of object keys that you want Amazon SageMaker
              to use for model training.

              If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
              augmented manifest file in JSON lines format. This file contains the data you
              want to use for model training. ``AugmentedManifestFile`` can only be used if
              the Channel's input mode is ``Pipe`` .

            - **S3Uri** *(string) --*

              Depending on the value specified for the ``S3DataType`` , identifies either a
              key name prefix or a manifest. For example:

              * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

              * A manifest might look like this: ``s3://bucketname/example.manifest``   The
              manifest is an S3 object which is a JSON file with the following format:  The
              preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
              "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
               ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
                ``]``   The preceding JSON matches the following ``s3Uris`` :
                ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
                set of ``s3uris`` in this manifest is the input data for the channel for this
                datasource. The object that each ``s3uris`` points to must be readable by the
                IAM role that Amazon SageMaker uses to perform tasks on your behalf.

            - **S3DataDistributionType** *(string) --*

              If you want Amazon SageMaker to replicate the entire dataset on each ML compute
              instance that is launched for model training, specify ``FullyReplicated`` .

              If you want Amazon SageMaker to replicate a subset of data on each ML compute
              instance that is launched for model training, specify ``ShardedByS3Key`` . If
              there are *n* ML compute instances launched for a training job, each instance
              gets approximately 1/*n* of the number of S3 objects. In this case, model
              training on each machine uses only the subset of training data.

              Don't choose more ML compute instances for training than available S3 objects.
              If you do, some nodes won't get any data and you will pay for nodes that aren't
              getting any training data. This applies in both File and Pipe modes. Keep this
              in mind when developing algorithms.

              In distributed training, where you use multiple ML compute EC2 instances, you
              might choose ``ShardedByS3Key`` . If the algorithm requires copying training
              data to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ),
              this copies 1/*n* of the number of objects.

            - **AttributeNames** *(list) --*

              A list of one or more attribute names to use that are found in a specified
              augmented manifest file.

              - *(string) --*

          - **FileSystemDataSource** *(dict) --*

            The file system that is associated with a channel.

            - **FileSystemId** *(string) --*

              The file system id.

            - **FileSystemAccessMode** *(string) --*

              The access mode of the mount of the directory associated with the channel. A
              directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
              mode.

            - **FileSystemType** *(string) --*

              The file system type.

            - **DirectoryPath** *(string) --*

              The full path to the directory to associate with the channel.

        - **ContentType** *(string) --*

          The MIME type of the data.

        - **CompressionType** *(string) --*

          If training data is compressed, the compression type. The default value is ``None``
          . ``CompressionType`` is used only in Pipe input mode. In File mode, leave this
          field unset or set it to None.

        - **RecordWrapperType** *(string) --*

          Specify RecordIO as the value when input data is in raw format but the training
          algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
          individual S3 object in a RecordIO record. If the input data is already in RecordIO
          format, you don't need to set this attribute. For more information, see `Create a
          Dataset Using RecordIO
          <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
          .

          In File mode, leave this field unset or set it to None.

        - **InputMode** *(string) --*

          (Optional) The input mode to use for the data channel in a training job. If you
          don't set a value for ``InputMode`` , Amazon SageMaker uses the value set for
          ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
          setting in a  AlgorithmSpecification request when you have a channel that needs a
          different input mode from the training job's general setting. To download the data
          from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage
          volume, and mount the directory to a Docker volume, use ``File`` input mode. To
          stream data directly from Amazon S3 to the container, choose ``Pipe`` input mode.

          To use a model for incremental training, choose ``File`` input model.

        - **ShuffleConfig** *(dict) --*

          A configuration for a shuffle option for input data in a channel. If you use
          ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
          matches. If you use ``ManifestFile`` , the order of the S3 object references in the
          ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of
          the JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
          determined using the ``Seed`` value.

          For Pipe input mode, shuffling is done at the start of every epoch. With large
          datasets this ensures that the order of the training data is different for each
          epoch, it helps reduce bias and possible overfitting. In a multi-node training job
          when ShuffleConfig is combined with ``S3DataDistributionType`` of
          ``ShardedByS3Key`` , the data is shuffled across nodes so that the content sent to
          a particular node on the first epoch might be sent to a different node on the
          second epoch.

          - **Seed** *(integer) --*

            Determines the shuffling order in ``ShuffleConfig`` value.

    - **OutputDataConfig** *(dict) --*

      The S3 path where model artifacts that you configured when creating the job are stored.
      Amazon SageMaker creates subfolders for model artifacts.

      - **KmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
        the model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId``
        can be any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // KMS Key Alias  ``"alias/ExampleAlias"``

        * // Amazon Resource Name (ARN) of a KMS Key Alias
        ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

        If you use a KMS key ID or an alias of your master key, the Amazon SageMaker
        execution role must include permissions to call ``kms:Encrypt`` . If you don't
        provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3 for
        your role's account. Amazon SageMaker uses server-side encryption with KMS-managed
        keys for ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject``
        permission that only allows objects with server-side encryption, set the condition
        key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information,
        see `KMS-Managed Encryption Keys
        <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
        *Amazon Simple Storage Service Developer Guide.*

        The KMS key policy must grant permission to the IAM role that you specify in your
        ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
        requests. For more information, see `Using Key Policies in AWS KMS
        <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
        in the *AWS Key Management Service Developer Guide* .

      - **S3OutputPath** *(string) --*

        Identifies the S3 path where you want Amazon SageMaker to store the model artifacts.
        For example, ``s3://bucket-name/key-name-prefix`` .

    - **ResourceConfig** *(dict) --*

      Resources, including ML compute instances and ML storage volumes, that are configured
      for model training.

      - **InstanceType** *(string) --*

        The ML compute instance type.

      - **InstanceCount** *(integer) --*

        The number of ML compute instances to use. For distributed training, provide a value
        greater than 1.

      - **VolumeSizeInGB** *(integer) --*

        The size of the ML storage volume that you want to provision.

        ML storage volumes store model artifacts and incremental states. Training algorithms
        might also use the ML storage volume for scratch space. If you want to store the
        training data in the ML storage volume, choose ``File`` as the ``TrainingInputMode``
        in the algorithm specification.

        You must specify sufficient ML storage for your scenario.

        .. note::

          Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

        .. note::

          Certain Nitro-based instances include local storage with a fixed total size,
          dependent on the instance type. When using these instances for training, Amazon
          SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage. You
          can't request a ``VolumeSizeInGB`` greater than the total size of the local
          instance storage.

          For a list of instance types that support local instance storage, including the
          total size per instance type, see `Instance Store Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
          .

      - **VolumeKmsKeyId** *(string) --*

        The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
        attached to the ML compute instance(s) that run the training job.

        .. note::

          Certain Nitro-based instances include local storage, dependent on the instance
          type. Local storage volumes are encrypted using a hardware module on the instance.
          You can't request a ``VolumeKmsKeyId`` when using an instance type with local
          storage.

          For a list of instance types that support local instance storage, see `Instance
          Store Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
          .

          For more information about local instance storage encryption, see `SSD Instance
          Store Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

        The ``VolumeKmsKeyId`` can be in any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

    - **VpcConfig** *(dict) --*

      A  VpcConfig object that specifies the VPC that this training job has access to. For
      more information, see `Protect Training Jobs by Using an Amazon Virtual Private Cloud
      <https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html>`__ .

      - **SecurityGroupIds** *(list) --*

        The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for
        the VPC that is specified in the ``Subnets`` field.

        - *(string) --*

      - **Subnets** *(list) --*

        The ID of the subnets in the VPC to which you want to connect your training job or
        model.

        .. note::

          Amazon EC2 P3 accelerated computing instances are not available in the c/d/e
          availability zones of region us-east-1. If you want to create endpoints with P3
          instances in VPC mode in region us-east-1, create subnets in a/b/f availability
          zones instead.

        - *(string) --*

    - **StoppingCondition** *(dict) --*

      Specifies a limit to how long a model training job can run. When the job reaches the
      time limit, Amazon SageMaker ends the training job. Use this API to cap model training
      costs.

      To stop a job, Amazon SageMaker sends the algorithm the ``SIGTERM`` signal, which
      delays job termination for 120 seconds. Algorithms can use this 120-second window to
      save the model artifacts, so the results of training are not lost.

      - **MaxRuntimeInSeconds** *(integer) --*

        The maximum length of time, in seconds, that the training or compilation job can run.
        If job does not complete during this time, Amazon SageMaker ends the job. If value is
        not specified, default value is 1 day. The maximum value is 28 days.

      - **MaxWaitTimeInSeconds** *(integer) --*

        The maximum length of time, in seconds, how long you are willing to wait for a
        managed spot training job to complete. It is the amount of time spent waiting for
        Spot capacity plus the amount of time the training job runs. It must be equal to or
        greater than ``MaxRuntimeInSeconds`` .

    - **CreationTime** *(datetime) --*

      A timestamp that indicates when the training job was created.

    - **TrainingStartTime** *(datetime) --*

      Indicates the time when the training job starts on training instances. You are billed
      for the time interval between this time and the value of ``TrainingEndTime`` . The
      start time in CloudWatch Logs might be later than this time. The difference is due to
      the time it takes to download the training data and to the size of the training
      container.

    - **TrainingEndTime** *(datetime) --*

      Indicates the time when the training job ends on training instances. You are billed for
      the time interval between the value of ``TrainingStartTime`` and this time. For
      successful jobs and stopped jobs, this is the time after model artifacts are uploaded.
      For failed jobs, this is the time when Amazon SageMaker detects a job failure.

    - **LastModifiedTime** *(datetime) --*

      A timestamp that indicates when the status of the training job was last modified.

    - **SecondaryStatusTransitions** *(list) --*

      A history of all of the secondary statuses that the training job has transitioned
      through.

      - *(dict) --*

        An array element of  DescribeTrainingJobResponse$SecondaryStatusTransitions . It
        provides additional details about a status that the training job has transitioned
        through. A training job can be in one of several states, for example, starting,
        downloading, training, or uploading. Within each state, there are a number of
        intermediate states. For example, within the starting state, Amazon SageMaker could
        be starting the training job or launching the ML instances. These transitional states
        are referred to as the job's secondary status.

        - **Status** *(string) --*

          Contains a secondary status information from a training job.

          Status might be one of the following secondary statuses:

            InProgress

          * ``Starting`` - Starting the training job.

          * ``Downloading`` - An optional stage for algorithms that support ``File`` training
          input mode. It indicates that data is being downloaded to the ML storage volumes.

          * ``Training`` - Training is in progress.

          * ``Uploading`` - Training is complete and the model artifacts are being uploaded
          to the S3 location.

            Completed

          * ``Completed`` - The training job has completed.

            Failed

          * ``Failed`` - The training job has failed. The reason for the failure is returned
          in the ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

            Stopped

          * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed
          runtime.

          * ``Stopped`` - The training job has stopped.

            Stopping

          * ``Stopping`` - Stopping the training job.

          We no longer support the following secondary statuses:

          * ``LaunchingMLInstances``

          * ``PreparingTrainingStack``

          * ``DownloadingTrainingImage``

        - **StartTime** *(datetime) --*

          A timestamp that shows when the training job transitioned to the current secondary
          status state.

        - **EndTime** *(datetime) --*

          A timestamp that shows when the training job transitioned out of this secondary
          status state into another secondary status state or when the training job has ended.

        - **StatusMessage** *(string) --*

          A detailed description of the progress within a secondary status.

          Amazon SageMaker provides secondary statuses and status messages that apply to each
          of them:

            Starting

          * Starting the training job.

          * Launching requested ML instances.

          * Insufficient capacity error from EC2 while launching instances, retrying!

          * Launched instance was unhealthy, replacing it!

          * Preparing the instances for training.

            Training

          * Downloading the training image.

          * Training image download completed. Training in progress.

          .. warning::

            Status messages are subject to change. Therefore, we recommend not including them
            in code that programmatically initiates actions. For examples, don't use status
            messages in if statements.

          To have an overview of your training job's progress, view ``TrainingJobStatus`` and
          ``SecondaryStatus`` in  DescribeTrainingJob , and ``StatusMessage`` together. For
          example, at the start of a training job, you might see the following:

          * ``TrainingJobStatus`` - InProgress

          * ``SecondaryStatus`` - Training

          * ``StatusMessage`` - Downloading the training image

    - **FinalMetricDataList** *(list) --*

      A list of final metric values that are set when the training job completes. Used only
      if the training job was configured to use metrics.

      - *(dict) --*

        The name, value, and date and time of a metric that was emitted to Amazon CloudWatch.

        - **MetricName** *(string) --*

          The name of the metric.

        - **Value** *(float) --*

          The value of the metric.

        - **Timestamp** *(datetime) --*

          The date and time that the algorithm emitted the metric.

    - **EnableNetworkIsolation** *(boolean) --*

      If the ``TrainingJob`` was created with network isolation, the value is set to ``true``
      . If network isolation is enabled, nodes can't communicate beyond the VPC they run in.

    - **EnableInterContainerTrafficEncryption** *(boolean) --*

      To encrypt all communications between ML compute instances in distributed training,
      choose ``True`` . Encryption provides greater security for distributed training, but
      training might take longer. How long it takes depends on the amount of communication
      between compute instances, especially if you use a deep learning algorithm in
      distributed training.

    - **Tags** *(list) --*

      An array of key-value pairs. For more information, see `Using Cost Allocation Tags
      <https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html#allocation-what>`__
      in the *AWS Billing and Cost Management User Guide* .

      - *(dict) --*

        Describes a tag.

        - **Key** *(string) --*

          The tag key.

        - **Value** *(string) --*

          The tag value.
    """


_ClientSearchResponseResultsTypeDef = TypedDict(
    "_ClientSearchResponseResultsTypeDef",
    {"TrainingJob": ClientSearchResponseResultsTrainingJobTypeDef},
    total=False,
)


class ClientSearchResponseResultsTypeDef(_ClientSearchResponseResultsTypeDef):
    """
    Type definition for `ClientSearchResponse` `Results`

    An individual search result record that contains a single resource object.

    - **TrainingJob** *(dict) --*

      A ``TrainingJob`` object that is returned as part of a ``Search`` request.

      - **TrainingJobName** *(string) --*

        The name of the training job.

      - **TrainingJobArn** *(string) --*

        The Amazon Resource Name (ARN) of the training job.

      - **TuningJobArn** *(string) --*

        The Amazon Resource Name (ARN) of the associated hyperparameter tuning job if the
        training job was launched by a hyperparameter tuning job.

      - **LabelingJobArn** *(string) --*

        The Amazon Resource Name (ARN) of the labeling job.

      - **ModelArtifacts** *(dict) --*

        Information about the Amazon S3 location that is configured for storing model artifacts.

        - **S3ModelArtifacts** *(string) --*

          The path of the S3 object that contains the model artifacts. For example,
          ``s3://bucket-name/keynameprefix/model.tar.gz`` .

      - **TrainingJobStatus** *(string) --*

        The status of the training job.

        Training job statuses are:

        * ``InProgress`` - The training is in progress.

        * ``Completed`` - The training job has completed.

        * ``Failed`` - The training job has failed. To see the reason for the failure, see the
        ``FailureReason`` field in the response to a ``DescribeTrainingJobResponse`` call.

        * ``Stopping`` - The training job is stopping.

        * ``Stopped`` - The training job has stopped.

        For more detailed information, see ``SecondaryStatus`` .

      - **SecondaryStatus** *(string) --*

        Provides detailed information about the state of the training job. For detailed
        information about the secondary status of the training job, see ``StatusMessage`` under
         SecondaryStatusTransition .

        Amazon SageMaker provides primary statuses and secondary statuses that apply to each of
        them:

          InProgress

        * ``Starting`` - Starting the training job.

        * ``Downloading`` - An optional stage for algorithms that support ``File`` training
        input mode. It indicates that data is being downloaded to the ML storage volumes.

        * ``Training`` - Training is in progress.

        * ``Uploading`` - Training is complete and the model artifacts are being uploaded to
        the S3 location.

          Completed

        * ``Completed`` - The training job has completed.

          Failed

        * ``Failed`` - The training job has failed. The reason for the failure is returned in
        the ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

          Stopped

        * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed
        runtime.

        * ``Stopped`` - The training job has stopped.

          Stopping

        * ``Stopping`` - Stopping the training job.

        .. warning::

          Valid values for ``SecondaryStatus`` are subject to change.

        We no longer support the following secondary statuses:

        * ``LaunchingMLInstances``

        * ``PreparingTrainingStack``

        * ``DownloadingTrainingImage``

      - **FailureReason** *(string) --*

        If the training job failed, the reason it failed.

      - **HyperParameters** *(dict) --*

        Algorithm-specific parameters.

        - *(string) --*

          - *(string) --*

      - **AlgorithmSpecification** *(dict) --*

        Information about the algorithm used for training, and algorithm metadata.

        - **TrainingImage** *(string) --*

          The registry path of the Docker image that contains the training algorithm. For
          information about docker registry paths for built-in algorithms, see `Algorithms
          Provided by Amazon SageMaker\\: Common Parameters
          <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
          . Amazon SageMaker supports both ``registry/repository[:tag]`` and
          ``registry/repository[@digest]`` image path formats. For more information, see `Using
          Your Own Algorithms with Amazon SageMaker
          <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

        - **AlgorithmName** *(string) --*

          The name of the algorithm resource to use for the training job. This must be an
          algorithm resource that you created or subscribe to on AWS Marketplace. If you
          specify a value for this parameter, you can't specify a value for ``TrainingImage`` .

        - **TrainingInputMode** *(string) --*

          The input mode that the algorithm supports. For the input modes that Amazon SageMaker
          algorithms support, see `Algorithms
          <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ . If an algorithm
          supports the ``File`` input mode, Amazon SageMaker downloads the training data from
          S3 to the provisioned ML storage Volume, and mounts the directory to docker volume
          for training container. If an algorithm supports the ``Pipe`` input mode, Amazon
          SageMaker streams data directly from S3 to the container.

          In File mode, make sure you provision ML storage volume with sufficient capacity to
          accommodate the data download from S3. In addition to the training data, the ML
          storage volume also stores the output model. The algorithm container use ML storage
          volume to also store intermediate information, if any.

          For distributed algorithms using File mode, training data is distributed uniformly,
          and your training duration is predictable if the input data objects size is
          approximately same. Amazon SageMaker does not split the files any further for model
          training. If the object sizes are skewed, training won't be optimal as the data
          distribution is also skewed where one host in a training cluster is overloaded, thus
          becoming bottleneck in training.

        - **MetricDefinitions** *(list) --*

          A list of metric definition objects. Each object specifies the metric name and
          regular expressions used to parse algorithm logs. Amazon SageMaker publishes each
          metric to Amazon CloudWatch.

          - *(dict) --*

            Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
            Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
            metric that a hyperparameter tuning job uses as its objective metric to choose the
            best training job.

            - **Name** *(string) --*

              The name of the metric.

            - **Regex** *(string) --*

              A regular expression that searches the output of a training job and gets the
              value of the metric. For more information about using regular expressions to
              define metrics, see `Defining Objective Metrics
              <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
              .

      - **RoleArn** *(string) --*

        The AWS Identity and Access Management (IAM) role configured for the training job.

      - **InputDataConfig** *(list) --*

        An array of ``Channel`` objects that describes each data input channel.

        - *(dict) --*

          A channel is a named input source that training algorithms can consume.

          - **ChannelName** *(string) --*

            The name of the channel.

          - **DataSource** *(dict) --*

            The location of the channel data.

            - **S3DataSource** *(dict) --*

              The S3 location of the data source that is associated with a channel.

              - **S3DataType** *(string) --*

                If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
                SageMaker uses all objects that match the specified key name prefix for model
                training.

                If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
                manifest file containing a list of object keys that you want Amazon SageMaker
                to use for model training.

                If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
                augmented manifest file in JSON lines format. This file contains the data you
                want to use for model training. ``AugmentedManifestFile`` can only be used if
                the Channel's input mode is ``Pipe`` .

              - **S3Uri** *(string) --*

                Depending on the value specified for the ``S3DataType`` , identifies either a
                key name prefix or a manifest. For example:

                * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

                * A manifest might look like this: ``s3://bucketname/example.manifest``   The
                manifest is an S3 object which is a JSON file with the following format:  The
                preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
                "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
                 ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
                  ``]``   The preceding JSON matches the following ``s3Uris`` :
                  ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                  ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                  ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
                  set of ``s3uris`` in this manifest is the input data for the channel for this
                  datasource. The object that each ``s3uris`` points to must be readable by the
                  IAM role that Amazon SageMaker uses to perform tasks on your behalf.

              - **S3DataDistributionType** *(string) --*

                If you want Amazon SageMaker to replicate the entire dataset on each ML compute
                instance that is launched for model training, specify ``FullyReplicated`` .

                If you want Amazon SageMaker to replicate a subset of data on each ML compute
                instance that is launched for model training, specify ``ShardedByS3Key`` . If
                there are *n* ML compute instances launched for a training job, each instance
                gets approximately 1/*n* of the number of S3 objects. In this case, model
                training on each machine uses only the subset of training data.

                Don't choose more ML compute instances for training than available S3 objects.
                If you do, some nodes won't get any data and you will pay for nodes that aren't
                getting any training data. This applies in both File and Pipe modes. Keep this
                in mind when developing algorithms.

                In distributed training, where you use multiple ML compute EC2 instances, you
                might choose ``ShardedByS3Key`` . If the algorithm requires copying training
                data to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ),
                this copies 1/*n* of the number of objects.

              - **AttributeNames** *(list) --*

                A list of one or more attribute names to use that are found in a specified
                augmented manifest file.

                - *(string) --*

            - **FileSystemDataSource** *(dict) --*

              The file system that is associated with a channel.

              - **FileSystemId** *(string) --*

                The file system id.

              - **FileSystemAccessMode** *(string) --*

                The access mode of the mount of the directory associated with the channel. A
                directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
                mode.

              - **FileSystemType** *(string) --*

                The file system type.

              - **DirectoryPath** *(string) --*

                The full path to the directory to associate with the channel.

          - **ContentType** *(string) --*

            The MIME type of the data.

          - **CompressionType** *(string) --*

            If training data is compressed, the compression type. The default value is ``None``
            . ``CompressionType`` is used only in Pipe input mode. In File mode, leave this
            field unset or set it to None.

          - **RecordWrapperType** *(string) --*

            Specify RecordIO as the value when input data is in raw format but the training
            algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
            individual S3 object in a RecordIO record. If the input data is already in RecordIO
            format, you don't need to set this attribute. For more information, see `Create a
            Dataset Using RecordIO
            <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
            .

            In File mode, leave this field unset or set it to None.

          - **InputMode** *(string) --*

            (Optional) The input mode to use for the data channel in a training job. If you
            don't set a value for ``InputMode`` , Amazon SageMaker uses the value set for
            ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
            setting in a  AlgorithmSpecification request when you have a channel that needs a
            different input mode from the training job's general setting. To download the data
            from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage
            volume, and mount the directory to a Docker volume, use ``File`` input mode. To
            stream data directly from Amazon S3 to the container, choose ``Pipe`` input mode.

            To use a model for incremental training, choose ``File`` input model.

          - **ShuffleConfig** *(dict) --*

            A configuration for a shuffle option for input data in a channel. If you use
            ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
            matches. If you use ``ManifestFile`` , the order of the S3 object references in the
            ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of
            the JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
            determined using the ``Seed`` value.

            For Pipe input mode, shuffling is done at the start of every epoch. With large
            datasets this ensures that the order of the training data is different for each
            epoch, it helps reduce bias and possible overfitting. In a multi-node training job
            when ShuffleConfig is combined with ``S3DataDistributionType`` of
            ``ShardedByS3Key`` , the data is shuffled across nodes so that the content sent to
            a particular node on the first epoch might be sent to a different node on the
            second epoch.

            - **Seed** *(integer) --*

              Determines the shuffling order in ``ShuffleConfig`` value.

      - **OutputDataConfig** *(dict) --*

        The S3 path where model artifacts that you configured when creating the job are stored.
        Amazon SageMaker creates subfolders for model artifacts.

        - **KmsKeyId** *(string) --*

          The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
          the model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId``
          can be any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // KMS Key Alias  ``"alias/ExampleAlias"``

          * // Amazon Resource Name (ARN) of a KMS Key Alias
          ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

          If you use a KMS key ID or an alias of your master key, the Amazon SageMaker
          execution role must include permissions to call ``kms:Encrypt`` . If you don't
          provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3 for
          your role's account. Amazon SageMaker uses server-side encryption with KMS-managed
          keys for ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject``
          permission that only allows objects with server-side encryption, set the condition
          key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information,
          see `KMS-Managed Encryption Keys
          <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
          *Amazon Simple Storage Service Developer Guide.*

          The KMS key policy must grant permission to the IAM role that you specify in your
          ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
          requests. For more information, see `Using Key Policies in AWS KMS
          <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
          in the *AWS Key Management Service Developer Guide* .

        - **S3OutputPath** *(string) --*

          Identifies the S3 path where you want Amazon SageMaker to store the model artifacts.
          For example, ``s3://bucket-name/key-name-prefix`` .

      - **ResourceConfig** *(dict) --*

        Resources, including ML compute instances and ML storage volumes, that are configured
        for model training.

        - **InstanceType** *(string) --*

          The ML compute instance type.

        - **InstanceCount** *(integer) --*

          The number of ML compute instances to use. For distributed training, provide a value
          greater than 1.

        - **VolumeSizeInGB** *(integer) --*

          The size of the ML storage volume that you want to provision.

          ML storage volumes store model artifacts and incremental states. Training algorithms
          might also use the ML storage volume for scratch space. If you want to store the
          training data in the ML storage volume, choose ``File`` as the ``TrainingInputMode``
          in the algorithm specification.

          You must specify sufficient ML storage for your scenario.

          .. note::

            Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

          .. note::

            Certain Nitro-based instances include local storage with a fixed total size,
            dependent on the instance type. When using these instances for training, Amazon
            SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage. You
            can't request a ``VolumeSizeInGB`` greater than the total size of the local
            instance storage.

            For a list of instance types that support local instance storage, including the
            total size per instance type, see `Instance Store Volumes
            <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
            .

        - **VolumeKmsKeyId** *(string) --*

          The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
          attached to the ML compute instance(s) that run the training job.

          .. note::

            Certain Nitro-based instances include local storage, dependent on the instance
            type. Local storage volumes are encrypted using a hardware module on the instance.
            You can't request a ``VolumeKmsKeyId`` when using an instance type with local
            storage.

            For a list of instance types that support local instance storage, see `Instance
            Store Volumes
            <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
            .

            For more information about local instance storage encryption, see `SSD Instance
            Store Volumes
            <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

          The ``VolumeKmsKeyId`` can be in any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      - **VpcConfig** *(dict) --*

        A  VpcConfig object that specifies the VPC that this training job has access to. For
        more information, see `Protect Training Jobs by Using an Amazon Virtual Private Cloud
        <https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html>`__ .

        - **SecurityGroupIds** *(list) --*

          The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for
          the VPC that is specified in the ``Subnets`` field.

          - *(string) --*

        - **Subnets** *(list) --*

          The ID of the subnets in the VPC to which you want to connect your training job or
          model.

          .. note::

            Amazon EC2 P3 accelerated computing instances are not available in the c/d/e
            availability zones of region us-east-1. If you want to create endpoints with P3
            instances in VPC mode in region us-east-1, create subnets in a/b/f availability
            zones instead.

          - *(string) --*

      - **StoppingCondition** *(dict) --*

        Specifies a limit to how long a model training job can run. When the job reaches the
        time limit, Amazon SageMaker ends the training job. Use this API to cap model training
        costs.

        To stop a job, Amazon SageMaker sends the algorithm the ``SIGTERM`` signal, which
        delays job termination for 120 seconds. Algorithms can use this 120-second window to
        save the model artifacts, so the results of training are not lost.

        - **MaxRuntimeInSeconds** *(integer) --*

          The maximum length of time, in seconds, that the training or compilation job can run.
          If job does not complete during this time, Amazon SageMaker ends the job. If value is
          not specified, default value is 1 day. The maximum value is 28 days.

        - **MaxWaitTimeInSeconds** *(integer) --*

          The maximum length of time, in seconds, how long you are willing to wait for a
          managed spot training job to complete. It is the amount of time spent waiting for
          Spot capacity plus the amount of time the training job runs. It must be equal to or
          greater than ``MaxRuntimeInSeconds`` .

      - **CreationTime** *(datetime) --*

        A timestamp that indicates when the training job was created.

      - **TrainingStartTime** *(datetime) --*

        Indicates the time when the training job starts on training instances. You are billed
        for the time interval between this time and the value of ``TrainingEndTime`` . The
        start time in CloudWatch Logs might be later than this time. The difference is due to
        the time it takes to download the training data and to the size of the training
        container.

      - **TrainingEndTime** *(datetime) --*

        Indicates the time when the training job ends on training instances. You are billed for
        the time interval between the value of ``TrainingStartTime`` and this time. For
        successful jobs and stopped jobs, this is the time after model artifacts are uploaded.
        For failed jobs, this is the time when Amazon SageMaker detects a job failure.

      - **LastModifiedTime** *(datetime) --*

        A timestamp that indicates when the status of the training job was last modified.

      - **SecondaryStatusTransitions** *(list) --*

        A history of all of the secondary statuses that the training job has transitioned
        through.

        - *(dict) --*

          An array element of  DescribeTrainingJobResponse$SecondaryStatusTransitions . It
          provides additional details about a status that the training job has transitioned
          through. A training job can be in one of several states, for example, starting,
          downloading, training, or uploading. Within each state, there are a number of
          intermediate states. For example, within the starting state, Amazon SageMaker could
          be starting the training job or launching the ML instances. These transitional states
          are referred to as the job's secondary status.

          - **Status** *(string) --*

            Contains a secondary status information from a training job.

            Status might be one of the following secondary statuses:

              InProgress

            * ``Starting`` - Starting the training job.

            * ``Downloading`` - An optional stage for algorithms that support ``File`` training
            input mode. It indicates that data is being downloaded to the ML storage volumes.

            * ``Training`` - Training is in progress.

            * ``Uploading`` - Training is complete and the model artifacts are being uploaded
            to the S3 location.

              Completed

            * ``Completed`` - The training job has completed.

              Failed

            * ``Failed`` - The training job has failed. The reason for the failure is returned
            in the ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

              Stopped

            * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed
            runtime.

            * ``Stopped`` - The training job has stopped.

              Stopping

            * ``Stopping`` - Stopping the training job.

            We no longer support the following secondary statuses:

            * ``LaunchingMLInstances``

            * ``PreparingTrainingStack``

            * ``DownloadingTrainingImage``

          - **StartTime** *(datetime) --*

            A timestamp that shows when the training job transitioned to the current secondary
            status state.

          - **EndTime** *(datetime) --*

            A timestamp that shows when the training job transitioned out of this secondary
            status state into another secondary status state or when the training job has ended.

          - **StatusMessage** *(string) --*

            A detailed description of the progress within a secondary status.

            Amazon SageMaker provides secondary statuses and status messages that apply to each
            of them:

              Starting

            * Starting the training job.

            * Launching requested ML instances.

            * Insufficient capacity error from EC2 while launching instances, retrying!

            * Launched instance was unhealthy, replacing it!

            * Preparing the instances for training.

              Training

            * Downloading the training image.

            * Training image download completed. Training in progress.

            .. warning::

              Status messages are subject to change. Therefore, we recommend not including them
              in code that programmatically initiates actions. For examples, don't use status
              messages in if statements.

            To have an overview of your training job's progress, view ``TrainingJobStatus`` and
            ``SecondaryStatus`` in  DescribeTrainingJob , and ``StatusMessage`` together. For
            example, at the start of a training job, you might see the following:

            * ``TrainingJobStatus`` - InProgress

            * ``SecondaryStatus`` - Training

            * ``StatusMessage`` - Downloading the training image

      - **FinalMetricDataList** *(list) --*

        A list of final metric values that are set when the training job completes. Used only
        if the training job was configured to use metrics.

        - *(dict) --*

          The name, value, and date and time of a metric that was emitted to Amazon CloudWatch.

          - **MetricName** *(string) --*

            The name of the metric.

          - **Value** *(float) --*

            The value of the metric.

          - **Timestamp** *(datetime) --*

            The date and time that the algorithm emitted the metric.

      - **EnableNetworkIsolation** *(boolean) --*

        If the ``TrainingJob`` was created with network isolation, the value is set to ``true``
        . If network isolation is enabled, nodes can't communicate beyond the VPC they run in.

      - **EnableInterContainerTrafficEncryption** *(boolean) --*

        To encrypt all communications between ML compute instances in distributed training,
        choose ``True`` . Encryption provides greater security for distributed training, but
        training might take longer. How long it takes depends on the amount of communication
        between compute instances, especially if you use a deep learning algorithm in
        distributed training.

      - **Tags** *(list) --*

        An array of key-value pairs. For more information, see `Using Cost Allocation Tags
        <https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html#allocation-what>`__
        in the *AWS Billing and Cost Management User Guide* .

        - *(dict) --*

          Describes a tag.

          - **Key** *(string) --*

            The tag key.

          - **Value** *(string) --*

            The tag value.
    """


_ClientSearchResponseTypeDef = TypedDict(
    "_ClientSearchResponseTypeDef",
    {"Results": List[ClientSearchResponseResultsTypeDef], "NextToken": str},
    total=False,
)


class ClientSearchResponseTypeDef(_ClientSearchResponseTypeDef):
    """
    Type definition for `ClientSearch` `Response`

    - **Results** *(list) --*

      A list of ``SearchResult`` objects.

      - *(dict) --*

        An individual search result record that contains a single resource object.

        - **TrainingJob** *(dict) --*

          A ``TrainingJob`` object that is returned as part of a ``Search`` request.

          - **TrainingJobName** *(string) --*

            The name of the training job.

          - **TrainingJobArn** *(string) --*

            The Amazon Resource Name (ARN) of the training job.

          - **TuningJobArn** *(string) --*

            The Amazon Resource Name (ARN) of the associated hyperparameter tuning job if the
            training job was launched by a hyperparameter tuning job.

          - **LabelingJobArn** *(string) --*

            The Amazon Resource Name (ARN) of the labeling job.

          - **ModelArtifacts** *(dict) --*

            Information about the Amazon S3 location that is configured for storing model artifacts.

            - **S3ModelArtifacts** *(string) --*

              The path of the S3 object that contains the model artifacts. For example,
              ``s3://bucket-name/keynameprefix/model.tar.gz`` .

          - **TrainingJobStatus** *(string) --*

            The status of the training job.

            Training job statuses are:

            * ``InProgress`` - The training is in progress.

            * ``Completed`` - The training job has completed.

            * ``Failed`` - The training job has failed. To see the reason for the failure, see the
            ``FailureReason`` field in the response to a ``DescribeTrainingJobResponse`` call.

            * ``Stopping`` - The training job is stopping.

            * ``Stopped`` - The training job has stopped.

            For more detailed information, see ``SecondaryStatus`` .

          - **SecondaryStatus** *(string) --*

            Provides detailed information about the state of the training job. For detailed
            information about the secondary status of the training job, see ``StatusMessage`` under
             SecondaryStatusTransition .

            Amazon SageMaker provides primary statuses and secondary statuses that apply to each of
            them:

              InProgress

            * ``Starting`` - Starting the training job.

            * ``Downloading`` - An optional stage for algorithms that support ``File`` training
            input mode. It indicates that data is being downloaded to the ML storage volumes.

            * ``Training`` - Training is in progress.

            * ``Uploading`` - Training is complete and the model artifacts are being uploaded to
            the S3 location.

              Completed

            * ``Completed`` - The training job has completed.

              Failed

            * ``Failed`` - The training job has failed. The reason for the failure is returned in
            the ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

              Stopped

            * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed
            runtime.

            * ``Stopped`` - The training job has stopped.

              Stopping

            * ``Stopping`` - Stopping the training job.

            .. warning::

              Valid values for ``SecondaryStatus`` are subject to change.

            We no longer support the following secondary statuses:

            * ``LaunchingMLInstances``

            * ``PreparingTrainingStack``

            * ``DownloadingTrainingImage``

          - **FailureReason** *(string) --*

            If the training job failed, the reason it failed.

          - **HyperParameters** *(dict) --*

            Algorithm-specific parameters.

            - *(string) --*

              - *(string) --*

          - **AlgorithmSpecification** *(dict) --*

            Information about the algorithm used for training, and algorithm metadata.

            - **TrainingImage** *(string) --*

              The registry path of the Docker image that contains the training algorithm. For
              information about docker registry paths for built-in algorithms, see `Algorithms
              Provided by Amazon SageMaker\\: Common Parameters
              <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
              . Amazon SageMaker supports both ``registry/repository[:tag]`` and
              ``registry/repository[@digest]`` image path formats. For more information, see `Using
              Your Own Algorithms with Amazon SageMaker
              <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

            - **AlgorithmName** *(string) --*

              The name of the algorithm resource to use for the training job. This must be an
              algorithm resource that you created or subscribe to on AWS Marketplace. If you
              specify a value for this parameter, you can't specify a value for ``TrainingImage`` .

            - **TrainingInputMode** *(string) --*

              The input mode that the algorithm supports. For the input modes that Amazon SageMaker
              algorithms support, see `Algorithms
              <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ . If an algorithm
              supports the ``File`` input mode, Amazon SageMaker downloads the training data from
              S3 to the provisioned ML storage Volume, and mounts the directory to docker volume
              for training container. If an algorithm supports the ``Pipe`` input mode, Amazon
              SageMaker streams data directly from S3 to the container.

              In File mode, make sure you provision ML storage volume with sufficient capacity to
              accommodate the data download from S3. In addition to the training data, the ML
              storage volume also stores the output model. The algorithm container use ML storage
              volume to also store intermediate information, if any.

              For distributed algorithms using File mode, training data is distributed uniformly,
              and your training duration is predictable if the input data objects size is
              approximately same. Amazon SageMaker does not split the files any further for model
              training. If the object sizes are skewed, training won't be optimal as the data
              distribution is also skewed where one host in a training cluster is overloaded, thus
              becoming bottleneck in training.

            - **MetricDefinitions** *(list) --*

              A list of metric definition objects. Each object specifies the metric name and
              regular expressions used to parse algorithm logs. Amazon SageMaker publishes each
              metric to Amazon CloudWatch.

              - *(dict) --*

                Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
                Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
                metric that a hyperparameter tuning job uses as its objective metric to choose the
                best training job.

                - **Name** *(string) --*

                  The name of the metric.

                - **Regex** *(string) --*

                  A regular expression that searches the output of a training job and gets the
                  value of the metric. For more information about using regular expressions to
                  define metrics, see `Defining Objective Metrics
                  <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
                  .

          - **RoleArn** *(string) --*

            The AWS Identity and Access Management (IAM) role configured for the training job.

          - **InputDataConfig** *(list) --*

            An array of ``Channel`` objects that describes each data input channel.

            - *(dict) --*

              A channel is a named input source that training algorithms can consume.

              - **ChannelName** *(string) --*

                The name of the channel.

              - **DataSource** *(dict) --*

                The location of the channel data.

                - **S3DataSource** *(dict) --*

                  The S3 location of the data source that is associated with a channel.

                  - **S3DataType** *(string) --*

                    If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
                    SageMaker uses all objects that match the specified key name prefix for model
                    training.

                    If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
                    manifest file containing a list of object keys that you want Amazon SageMaker
                    to use for model training.

                    If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
                    augmented manifest file in JSON lines format. This file contains the data you
                    want to use for model training. ``AugmentedManifestFile`` can only be used if
                    the Channel's input mode is ``Pipe`` .

                  - **S3Uri** *(string) --*

                    Depending on the value specified for the ``S3DataType`` , identifies either a
                    key name prefix or a manifest. For example:

                    * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

                    * A manifest might look like this: ``s3://bucketname/example.manifest``   The
                    manifest is an S3 object which is a JSON file with the following format:  The
                    preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
                    "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
                     ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
                      ``]``   The preceding JSON matches the following ``s3Uris`` :
                      ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                      ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                      ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
                      set of ``s3uris`` in this manifest is the input data for the channel for this
                      datasource. The object that each ``s3uris`` points to must be readable by the
                      IAM role that Amazon SageMaker uses to perform tasks on your behalf.

                  - **S3DataDistributionType** *(string) --*

                    If you want Amazon SageMaker to replicate the entire dataset on each ML compute
                    instance that is launched for model training, specify ``FullyReplicated`` .

                    If you want Amazon SageMaker to replicate a subset of data on each ML compute
                    instance that is launched for model training, specify ``ShardedByS3Key`` . If
                    there are *n* ML compute instances launched for a training job, each instance
                    gets approximately 1/*n* of the number of S3 objects. In this case, model
                    training on each machine uses only the subset of training data.

                    Don't choose more ML compute instances for training than available S3 objects.
                    If you do, some nodes won't get any data and you will pay for nodes that aren't
                    getting any training data. This applies in both File and Pipe modes. Keep this
                    in mind when developing algorithms.

                    In distributed training, where you use multiple ML compute EC2 instances, you
                    might choose ``ShardedByS3Key`` . If the algorithm requires copying training
                    data to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ),
                    this copies 1/*n* of the number of objects.

                  - **AttributeNames** *(list) --*

                    A list of one or more attribute names to use that are found in a specified
                    augmented manifest file.

                    - *(string) --*

                - **FileSystemDataSource** *(dict) --*

                  The file system that is associated with a channel.

                  - **FileSystemId** *(string) --*

                    The file system id.

                  - **FileSystemAccessMode** *(string) --*

                    The access mode of the mount of the directory associated with the channel. A
                    directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
                    mode.

                  - **FileSystemType** *(string) --*

                    The file system type.

                  - **DirectoryPath** *(string) --*

                    The full path to the directory to associate with the channel.

              - **ContentType** *(string) --*

                The MIME type of the data.

              - **CompressionType** *(string) --*

                If training data is compressed, the compression type. The default value is ``None``
                . ``CompressionType`` is used only in Pipe input mode. In File mode, leave this
                field unset or set it to None.

              - **RecordWrapperType** *(string) --*

                Specify RecordIO as the value when input data is in raw format but the training
                algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
                individual S3 object in a RecordIO record. If the input data is already in RecordIO
                format, you don't need to set this attribute. For more information, see `Create a
                Dataset Using RecordIO
                <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
                .

                In File mode, leave this field unset or set it to None.

              - **InputMode** *(string) --*

                (Optional) The input mode to use for the data channel in a training job. If you
                don't set a value for ``InputMode`` , Amazon SageMaker uses the value set for
                ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
                setting in a  AlgorithmSpecification request when you have a channel that needs a
                different input mode from the training job's general setting. To download the data
                from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage
                volume, and mount the directory to a Docker volume, use ``File`` input mode. To
                stream data directly from Amazon S3 to the container, choose ``Pipe`` input mode.

                To use a model for incremental training, choose ``File`` input model.

              - **ShuffleConfig** *(dict) --*

                A configuration for a shuffle option for input data in a channel. If you use
                ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
                matches. If you use ``ManifestFile`` , the order of the S3 object references in the
                ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of
                the JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
                determined using the ``Seed`` value.

                For Pipe input mode, shuffling is done at the start of every epoch. With large
                datasets this ensures that the order of the training data is different for each
                epoch, it helps reduce bias and possible overfitting. In a multi-node training job
                when ShuffleConfig is combined with ``S3DataDistributionType`` of
                ``ShardedByS3Key`` , the data is shuffled across nodes so that the content sent to
                a particular node on the first epoch might be sent to a different node on the
                second epoch.

                - **Seed** *(integer) --*

                  Determines the shuffling order in ``ShuffleConfig`` value.

          - **OutputDataConfig** *(dict) --*

            The S3 path where model artifacts that you configured when creating the job are stored.
            Amazon SageMaker creates subfolders for model artifacts.

            - **KmsKeyId** *(string) --*

              The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
              the model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId``
              can be any of the following formats:

              * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // Amazon Resource Name (ARN) of a KMS Key
              ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // KMS Key Alias  ``"alias/ExampleAlias"``

              * // Amazon Resource Name (ARN) of a KMS Key Alias
              ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

              If you use a KMS key ID or an alias of your master key, the Amazon SageMaker
              execution role must include permissions to call ``kms:Encrypt`` . If you don't
              provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3 for
              your role's account. Amazon SageMaker uses server-side encryption with KMS-managed
              keys for ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject``
              permission that only allows objects with server-side encryption, set the condition
              key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information,
              see `KMS-Managed Encryption Keys
              <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
              *Amazon Simple Storage Service Developer Guide.*

              The KMS key policy must grant permission to the IAM role that you specify in your
              ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
              requests. For more information, see `Using Key Policies in AWS KMS
              <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
              in the *AWS Key Management Service Developer Guide* .

            - **S3OutputPath** *(string) --*

              Identifies the S3 path where you want Amazon SageMaker to store the model artifacts.
              For example, ``s3://bucket-name/key-name-prefix`` .

          - **ResourceConfig** *(dict) --*

            Resources, including ML compute instances and ML storage volumes, that are configured
            for model training.

            - **InstanceType** *(string) --*

              The ML compute instance type.

            - **InstanceCount** *(integer) --*

              The number of ML compute instances to use. For distributed training, provide a value
              greater than 1.

            - **VolumeSizeInGB** *(integer) --*

              The size of the ML storage volume that you want to provision.

              ML storage volumes store model artifacts and incremental states. Training algorithms
              might also use the ML storage volume for scratch space. If you want to store the
              training data in the ML storage volume, choose ``File`` as the ``TrainingInputMode``
              in the algorithm specification.

              You must specify sufficient ML storage for your scenario.

              .. note::

                Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

              .. note::

                Certain Nitro-based instances include local storage with a fixed total size,
                dependent on the instance type. When using these instances for training, Amazon
                SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage. You
                can't request a ``VolumeSizeInGB`` greater than the total size of the local
                instance storage.

                For a list of instance types that support local instance storage, including the
                total size per instance type, see `Instance Store Volumes
                <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
                .

            - **VolumeKmsKeyId** *(string) --*

              The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
              attached to the ML compute instance(s) that run the training job.

              .. note::

                Certain Nitro-based instances include local storage, dependent on the instance
                type. Local storage volumes are encrypted using a hardware module on the instance.
                You can't request a ``VolumeKmsKeyId`` when using an instance type with local
                storage.

                For a list of instance types that support local instance storage, see `Instance
                Store Volumes
                <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
                .

                For more information about local instance storage encryption, see `SSD Instance
                Store Volumes
                <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

              The ``VolumeKmsKeyId`` can be in any of the following formats:

              * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // Amazon Resource Name (ARN) of a KMS Key
              ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

          - **VpcConfig** *(dict) --*

            A  VpcConfig object that specifies the VPC that this training job has access to. For
            more information, see `Protect Training Jobs by Using an Amazon Virtual Private Cloud
            <https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html>`__ .

            - **SecurityGroupIds** *(list) --*

              The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for
              the VPC that is specified in the ``Subnets`` field.

              - *(string) --*

            - **Subnets** *(list) --*

              The ID of the subnets in the VPC to which you want to connect your training job or
              model.

              .. note::

                Amazon EC2 P3 accelerated computing instances are not available in the c/d/e
                availability zones of region us-east-1. If you want to create endpoints with P3
                instances in VPC mode in region us-east-1, create subnets in a/b/f availability
                zones instead.

              - *(string) --*

          - **StoppingCondition** *(dict) --*

            Specifies a limit to how long a model training job can run. When the job reaches the
            time limit, Amazon SageMaker ends the training job. Use this API to cap model training
            costs.

            To stop a job, Amazon SageMaker sends the algorithm the ``SIGTERM`` signal, which
            delays job termination for 120 seconds. Algorithms can use this 120-second window to
            save the model artifacts, so the results of training are not lost.

            - **MaxRuntimeInSeconds** *(integer) --*

              The maximum length of time, in seconds, that the training or compilation job can run.
              If job does not complete during this time, Amazon SageMaker ends the job. If value is
              not specified, default value is 1 day. The maximum value is 28 days.

            - **MaxWaitTimeInSeconds** *(integer) --*

              The maximum length of time, in seconds, how long you are willing to wait for a
              managed spot training job to complete. It is the amount of time spent waiting for
              Spot capacity plus the amount of time the training job runs. It must be equal to or
              greater than ``MaxRuntimeInSeconds`` .

          - **CreationTime** *(datetime) --*

            A timestamp that indicates when the training job was created.

          - **TrainingStartTime** *(datetime) --*

            Indicates the time when the training job starts on training instances. You are billed
            for the time interval between this time and the value of ``TrainingEndTime`` . The
            start time in CloudWatch Logs might be later than this time. The difference is due to
            the time it takes to download the training data and to the size of the training
            container.

          - **TrainingEndTime** *(datetime) --*

            Indicates the time when the training job ends on training instances. You are billed for
            the time interval between the value of ``TrainingStartTime`` and this time. For
            successful jobs and stopped jobs, this is the time after model artifacts are uploaded.
            For failed jobs, this is the time when Amazon SageMaker detects a job failure.

          - **LastModifiedTime** *(datetime) --*

            A timestamp that indicates when the status of the training job was last modified.

          - **SecondaryStatusTransitions** *(list) --*

            A history of all of the secondary statuses that the training job has transitioned
            through.

            - *(dict) --*

              An array element of  DescribeTrainingJobResponse$SecondaryStatusTransitions . It
              provides additional details about a status that the training job has transitioned
              through. A training job can be in one of several states, for example, starting,
              downloading, training, or uploading. Within each state, there are a number of
              intermediate states. For example, within the starting state, Amazon SageMaker could
              be starting the training job or launching the ML instances. These transitional states
              are referred to as the job's secondary status.

              - **Status** *(string) --*

                Contains a secondary status information from a training job.

                Status might be one of the following secondary statuses:

                  InProgress

                * ``Starting`` - Starting the training job.

                * ``Downloading`` - An optional stage for algorithms that support ``File`` training
                input mode. It indicates that data is being downloaded to the ML storage volumes.

                * ``Training`` - Training is in progress.

                * ``Uploading`` - Training is complete and the model artifacts are being uploaded
                to the S3 location.

                  Completed

                * ``Completed`` - The training job has completed.

                  Failed

                * ``Failed`` - The training job has failed. The reason for the failure is returned
                in the ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

                  Stopped

                * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed
                runtime.

                * ``Stopped`` - The training job has stopped.

                  Stopping

                * ``Stopping`` - Stopping the training job.

                We no longer support the following secondary statuses:

                * ``LaunchingMLInstances``

                * ``PreparingTrainingStack``

                * ``DownloadingTrainingImage``

              - **StartTime** *(datetime) --*

                A timestamp that shows when the training job transitioned to the current secondary
                status state.

              - **EndTime** *(datetime) --*

                A timestamp that shows when the training job transitioned out of this secondary
                status state into another secondary status state or when the training job has ended.

              - **StatusMessage** *(string) --*

                A detailed description of the progress within a secondary status.

                Amazon SageMaker provides secondary statuses and status messages that apply to each
                of them:

                  Starting

                * Starting the training job.

                * Launching requested ML instances.

                * Insufficient capacity error from EC2 while launching instances, retrying!

                * Launched instance was unhealthy, replacing it!

                * Preparing the instances for training.

                  Training

                * Downloading the training image.

                * Training image download completed. Training in progress.

                .. warning::

                  Status messages are subject to change. Therefore, we recommend not including them
                  in code that programmatically initiates actions. For examples, don't use status
                  messages in if statements.

                To have an overview of your training job's progress, view ``TrainingJobStatus`` and
                ``SecondaryStatus`` in  DescribeTrainingJob , and ``StatusMessage`` together. For
                example, at the start of a training job, you might see the following:

                * ``TrainingJobStatus`` - InProgress

                * ``SecondaryStatus`` - Training

                * ``StatusMessage`` - Downloading the training image

          - **FinalMetricDataList** *(list) --*

            A list of final metric values that are set when the training job completes. Used only
            if the training job was configured to use metrics.

            - *(dict) --*

              The name, value, and date and time of a metric that was emitted to Amazon CloudWatch.

              - **MetricName** *(string) --*

                The name of the metric.

              - **Value** *(float) --*

                The value of the metric.

              - **Timestamp** *(datetime) --*

                The date and time that the algorithm emitted the metric.

          - **EnableNetworkIsolation** *(boolean) --*

            If the ``TrainingJob`` was created with network isolation, the value is set to ``true``
            . If network isolation is enabled, nodes can't communicate beyond the VPC they run in.

          - **EnableInterContainerTrafficEncryption** *(boolean) --*

            To encrypt all communications between ML compute instances in distributed training,
            choose ``True`` . Encryption provides greater security for distributed training, but
            training might take longer. How long it takes depends on the amount of communication
            between compute instances, especially if you use a deep learning algorithm in
            distributed training.

          - **Tags** *(list) --*

            An array of key-value pairs. For more information, see `Using Cost Allocation Tags
            <https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html#allocation-what>`__
            in the *AWS Billing and Cost Management User Guide* .

            - *(dict) --*

              Describes a tag.

              - **Key** *(string) --*

                The tag key.

              - **Value** *(string) --*

                The tag value.

    - **NextToken** *(string) --*

      If the result of the previous ``Search`` request was truncated, the response includes a
      NextToken. To retrieve the next set of results, use the token in the next request.
    """


_RequiredClientSearchSearchExpressionFiltersTypeDef = TypedDict(
    "_RequiredClientSearchSearchExpressionFiltersTypeDef", {"Name": str}
)
_OptionalClientSearchSearchExpressionFiltersTypeDef = TypedDict(
    "_OptionalClientSearchSearchExpressionFiltersTypeDef",
    {"Operator": str, "Value": str},
    total=False,
)


class ClientSearchSearchExpressionFiltersTypeDef(
    _RequiredClientSearchSearchExpressionFiltersTypeDef,
    _OptionalClientSearchSearchExpressionFiltersTypeDef,
):
    """
    Type definition for `ClientSearchSearchExpression` `Filters`

    A conditional statement for a search expression that includes a resource property, a Boolean
    operator, and a value.

    If you don't specify an ``Operator`` and a ``Value`` , the filter searches for only the
    specified property. For example, defining a ``Filter`` for the ``FailureReason`` for the
    ``TrainingJob``  ``Resource`` searches for training job objects that have a value in the
    ``FailureReason`` field.

    If you specify a ``Value`` , but not an ``Operator`` , Amazon SageMaker uses the equals
    operator as the default.

    In search, there are several property types:

      Metrics

    To define a metric filter, enter a value using the form ``"Metrics.<name>"`` , where
    ``<name>`` is a metric name. For example, the following filter searches for training jobs
    with an ``"accuracy"`` metric greater than ``"0.9"`` :

     ``{``

     ``"Name": "Metrics.accuracy",``

     ``"Operator": "GREATER_THAN",``

     ``"Value": "0.9"``

     ``}``

      HyperParameters

    To define a hyperparameter filter, enter a value with the form ``"HyperParameters.<name>"`` .
    Decimal hyperparameter values are treated as a decimal in a comparison if the specified
    ``Value`` is also a decimal value. If the specified ``Value`` is an integer, the decimal
    hyperparameter values are treated as integers. For example, the following filter is satisfied
    by training jobs with a ``"learning_rate"`` hyperparameter that is less than ``"0.5"`` :

     ``{``

     ``"Name": "HyperParameters.learning_rate",``

     ``"Operator": "LESS_THAN",``

     ``"Value": "0.5"``

     ``}``

      Tags

    To define a tag filter, enter a value with the form ``"Tags.<key>"`` .

    - **Name** *(string) --* **[REQUIRED]**

      A property name. For example, ``TrainingJobName`` . For the list of valid property names
      returned in a search result for each supported resource, see  TrainingJob properties. You
      must specify a valid property name for the resource.

    - **Operator** *(string) --*

      A Boolean binary operator that is used to evaluate the filter. The operator field contains
      one of the following values:

        Equals

      The specified resource in ``Name`` equals the specified ``Value`` .

        NotEquals

      The specified resource in ``Name`` does not equal the specified ``Value`` .

        GreaterThan

      The specified resource in ``Name`` is greater than the specified ``Value`` . Not supported
      for text-based properties.

        GreaterThanOrEqualTo

      The specified resource in ``Name`` is greater than or equal to the specified ``Value`` .
      Not supported for text-based properties.

        LessThan

      The specified resource in ``Name`` is less than the specified ``Value`` . Not supported for
      text-based properties.

        LessThanOrEqualTo

      The specified resource in ``Name`` is less than or equal to the specified ``Value`` . Not
      supported for text-based properties.

        Contains

      Only supported for text-based properties. The word-list of the property contains the
      specified ``Value`` . A ``SearchExpression`` can include only one ``Contains`` operator.

      If you have specified a filter ``Value`` , the default is ``Equals`` .

    - **Value** *(string) --*

      A value used with ``Resource`` and ``Operator`` to determine if objects satisfy the
      filter's condition. For numerical properties, ``Value`` must be an integer or
      floating-point decimal. For timestamp properties, ``Value`` must be an ISO 8601 date-time
      string of the following format: ``YYYY-mm-dd'T'HH:MM:SS`` .
    """


_RequiredClientSearchSearchExpressionNestedFiltersFiltersTypeDef = TypedDict(
    "_RequiredClientSearchSearchExpressionNestedFiltersFiltersTypeDef", {"Name": str}
)
_OptionalClientSearchSearchExpressionNestedFiltersFiltersTypeDef = TypedDict(
    "_OptionalClientSearchSearchExpressionNestedFiltersFiltersTypeDef",
    {"Operator": str, "Value": str},
    total=False,
)


class ClientSearchSearchExpressionNestedFiltersFiltersTypeDef(
    _RequiredClientSearchSearchExpressionNestedFiltersFiltersTypeDef,
    _OptionalClientSearchSearchExpressionNestedFiltersFiltersTypeDef,
):
    """
    Type definition for `ClientSearchSearchExpressionNestedFilters` `Filters`

    A conditional statement for a search expression that includes a resource property, a
    Boolean operator, and a value.

    If you don't specify an ``Operator`` and a ``Value`` , the filter searches for only the
    specified property. For example, defining a ``Filter`` for the ``FailureReason`` for the
    ``TrainingJob``  ``Resource`` searches for training job objects that have a value in the
    ``FailureReason`` field.

    If you specify a ``Value`` , but not an ``Operator`` , Amazon SageMaker uses the equals
    operator as the default.

    In search, there are several property types:

      Metrics

    To define a metric filter, enter a value using the form ``"Metrics.<name>"`` , where
    ``<name>`` is a metric name. For example, the following filter searches for training jobs
    with an ``"accuracy"`` metric greater than ``"0.9"`` :

     ``{``

     ``"Name": "Metrics.accuracy",``

     ``"Operator": "GREATER_THAN",``

     ``"Value": "0.9"``

     ``}``

      HyperParameters

    To define a hyperparameter filter, enter a value with the form
    ``"HyperParameters.<name>"`` . Decimal hyperparameter values are treated as a decimal in
    a comparison if the specified ``Value`` is also a decimal value. If the specified
    ``Value`` is an integer, the decimal hyperparameter values are treated as integers. For
    example, the following filter is satisfied by training jobs with a ``"learning_rate"``
    hyperparameter that is less than ``"0.5"`` :

     ``{``

     ``"Name": "HyperParameters.learning_rate",``

     ``"Operator": "LESS_THAN",``

     ``"Value": "0.5"``

     ``}``

      Tags

    To define a tag filter, enter a value with the form ``"Tags.<key>"`` .

    - **Name** *(string) --* **[REQUIRED]**

      A property name. For example, ``TrainingJobName`` . For the list of valid property
      names returned in a search result for each supported resource, see  TrainingJob
      properties. You must specify a valid property name for the resource.

    - **Operator** *(string) --*

      A Boolean binary operator that is used to evaluate the filter. The operator field
      contains one of the following values:

        Equals

      The specified resource in ``Name`` equals the specified ``Value`` .

        NotEquals

      The specified resource in ``Name`` does not equal the specified ``Value`` .

        GreaterThan

      The specified resource in ``Name`` is greater than the specified ``Value`` . Not
      supported for text-based properties.

        GreaterThanOrEqualTo

      The specified resource in ``Name`` is greater than or equal to the specified ``Value``
      . Not supported for text-based properties.

        LessThan

      The specified resource in ``Name`` is less than the specified ``Value`` . Not supported
      for text-based properties.

        LessThanOrEqualTo

      The specified resource in ``Name`` is less than or equal to the specified ``Value`` .
      Not supported for text-based properties.

        Contains

      Only supported for text-based properties. The word-list of the property contains the
      specified ``Value`` . A ``SearchExpression`` can include only one ``Contains`` operator.

      If you have specified a filter ``Value`` , the default is ``Equals`` .

    - **Value** *(string) --*

      A value used with ``Resource`` and ``Operator`` to determine if objects satisfy the
      filter's condition. For numerical properties, ``Value`` must be an integer or
      floating-point decimal. For timestamp properties, ``Value`` must be an ISO 8601
      date-time string of the following format: ``YYYY-mm-dd'T'HH:MM:SS`` .
    """


_ClientSearchSearchExpressionNestedFiltersTypeDef = TypedDict(
    "_ClientSearchSearchExpressionNestedFiltersTypeDef",
    {
        "NestedPropertyName": str,
        "Filters": List[ClientSearchSearchExpressionNestedFiltersFiltersTypeDef],
    },
)


class ClientSearchSearchExpressionNestedFiltersTypeDef(
    _ClientSearchSearchExpressionNestedFiltersTypeDef
):
    """
    Type definition for `ClientSearchSearchExpression` `NestedFilters`

    Defines a list of ``NestedFilters`` objects. To satisfy the conditions specified in the
    ``NestedFilters`` call, a resource must satisfy the conditions of all of the filters.

    For example, you could define a ``NestedFilters`` using the training job's
    ``InputDataConfig`` property to filter on ``Channel`` objects.

    A ``NestedFilters`` object contains multiple filters. For example, to find all training jobs
    whose name contains ``train`` and that have ``cat/data`` in their ``S3Uri`` (specified in
    ``InputDataConfig`` ), you need to create a ``NestedFilters`` object that specifies the
    ``InputDataConfig`` property with the following ``Filter`` objects:

    * ``'{Name:"InputDataConfig.ChannelName", "Operator":"EQUALS", "Value":"train"}',``

    * ``'{Name:"InputDataConfig.DataSource.S3DataSource.S3Uri", "Operator":"CONTAINS",
    "Value":"cat/data"}'``

    - **NestedPropertyName** *(string) --* **[REQUIRED]**

      The name of the property to use in the nested filters. The value must match a listed
      property name, such as ``InputDataConfig`` .

    - **Filters** *(list) --* **[REQUIRED]**

      A list of filters. Each filter acts on a property. Filters must contain at least one
      ``Filters`` value. For example, a ``NestedFilters`` call might include a filter on the
      ``PropertyName`` parameter of the ``InputDataConfig`` property:
      ``InputDataConfig.DataSource.S3DataSource.S3Uri`` .

      - *(dict) --*

        A conditional statement for a search expression that includes a resource property, a
        Boolean operator, and a value.

        If you don't specify an ``Operator`` and a ``Value`` , the filter searches for only the
        specified property. For example, defining a ``Filter`` for the ``FailureReason`` for the
        ``TrainingJob``  ``Resource`` searches for training job objects that have a value in the
        ``FailureReason`` field.

        If you specify a ``Value`` , but not an ``Operator`` , Amazon SageMaker uses the equals
        operator as the default.

        In search, there are several property types:

          Metrics

        To define a metric filter, enter a value using the form ``"Metrics.<name>"`` , where
        ``<name>`` is a metric name. For example, the following filter searches for training jobs
        with an ``"accuracy"`` metric greater than ``"0.9"`` :

         ``{``

         ``"Name": "Metrics.accuracy",``

         ``"Operator": "GREATER_THAN",``

         ``"Value": "0.9"``

         ``}``

          HyperParameters

        To define a hyperparameter filter, enter a value with the form
        ``"HyperParameters.<name>"`` . Decimal hyperparameter values are treated as a decimal in
        a comparison if the specified ``Value`` is also a decimal value. If the specified
        ``Value`` is an integer, the decimal hyperparameter values are treated as integers. For
        example, the following filter is satisfied by training jobs with a ``"learning_rate"``
        hyperparameter that is less than ``"0.5"`` :

         ``{``

         ``"Name": "HyperParameters.learning_rate",``

         ``"Operator": "LESS_THAN",``

         ``"Value": "0.5"``

         ``}``

          Tags

        To define a tag filter, enter a value with the form ``"Tags.<key>"`` .

        - **Name** *(string) --* **[REQUIRED]**

          A property name. For example, ``TrainingJobName`` . For the list of valid property
          names returned in a search result for each supported resource, see  TrainingJob
          properties. You must specify a valid property name for the resource.

        - **Operator** *(string) --*

          A Boolean binary operator that is used to evaluate the filter. The operator field
          contains one of the following values:

            Equals

          The specified resource in ``Name`` equals the specified ``Value`` .

            NotEquals

          The specified resource in ``Name`` does not equal the specified ``Value`` .

            GreaterThan

          The specified resource in ``Name`` is greater than the specified ``Value`` . Not
          supported for text-based properties.

            GreaterThanOrEqualTo

          The specified resource in ``Name`` is greater than or equal to the specified ``Value``
          . Not supported for text-based properties.

            LessThan

          The specified resource in ``Name`` is less than the specified ``Value`` . Not supported
          for text-based properties.

            LessThanOrEqualTo

          The specified resource in ``Name`` is less than or equal to the specified ``Value`` .
          Not supported for text-based properties.

            Contains

          Only supported for text-based properties. The word-list of the property contains the
          specified ``Value`` . A ``SearchExpression`` can include only one ``Contains`` operator.

          If you have specified a filter ``Value`` , the default is ``Equals`` .

        - **Value** *(string) --*

          A value used with ``Resource`` and ``Operator`` to determine if objects satisfy the
          filter's condition. For numerical properties, ``Value`` must be an integer or
          floating-point decimal. For timestamp properties, ``Value`` must be an ISO 8601
          date-time string of the following format: ``YYYY-mm-dd'T'HH:MM:SS`` .
    """


_ClientSearchSearchExpressionTypeDef = TypedDict(
    "_ClientSearchSearchExpressionTypeDef",
    {
        "Filters": List[ClientSearchSearchExpressionFiltersTypeDef],
        "NestedFilters": List[ClientSearchSearchExpressionNestedFiltersTypeDef],
        "SubExpressions": List[Dict],
        "Operator": str,
    },
    total=False,
)


class ClientSearchSearchExpressionTypeDef(_ClientSearchSearchExpressionTypeDef):
    """
    Type definition for `ClientSearch` `SearchExpression`

    A Boolean conditional statement. Resource objects must satisfy this condition to be included in
    search results. You must provide at least one subexpression, filter, or nested filter. The
    maximum number of recursive ``SubExpressions`` , ``NestedFilters`` , and ``Filters`` that can be
    included in a ``SearchExpression`` object is 50.

    - **Filters** *(list) --*

      A list of filter objects.

      - *(dict) --*

        A conditional statement for a search expression that includes a resource property, a Boolean
        operator, and a value.

        If you don't specify an ``Operator`` and a ``Value`` , the filter searches for only the
        specified property. For example, defining a ``Filter`` for the ``FailureReason`` for the
        ``TrainingJob``  ``Resource`` searches for training job objects that have a value in the
        ``FailureReason`` field.

        If you specify a ``Value`` , but not an ``Operator`` , Amazon SageMaker uses the equals
        operator as the default.

        In search, there are several property types:

          Metrics

        To define a metric filter, enter a value using the form ``"Metrics.<name>"`` , where
        ``<name>`` is a metric name. For example, the following filter searches for training jobs
        with an ``"accuracy"`` metric greater than ``"0.9"`` :

         ``{``

         ``"Name": "Metrics.accuracy",``

         ``"Operator": "GREATER_THAN",``

         ``"Value": "0.9"``

         ``}``

          HyperParameters

        To define a hyperparameter filter, enter a value with the form ``"HyperParameters.<name>"`` .
        Decimal hyperparameter values are treated as a decimal in a comparison if the specified
        ``Value`` is also a decimal value. If the specified ``Value`` is an integer, the decimal
        hyperparameter values are treated as integers. For example, the following filter is satisfied
        by training jobs with a ``"learning_rate"`` hyperparameter that is less than ``"0.5"`` :

         ``{``

         ``"Name": "HyperParameters.learning_rate",``

         ``"Operator": "LESS_THAN",``

         ``"Value": "0.5"``

         ``}``

          Tags

        To define a tag filter, enter a value with the form ``"Tags.<key>"`` .

        - **Name** *(string) --* **[REQUIRED]**

          A property name. For example, ``TrainingJobName`` . For the list of valid property names
          returned in a search result for each supported resource, see  TrainingJob properties. You
          must specify a valid property name for the resource.

        - **Operator** *(string) --*

          A Boolean binary operator that is used to evaluate the filter. The operator field contains
          one of the following values:

            Equals

          The specified resource in ``Name`` equals the specified ``Value`` .

            NotEquals

          The specified resource in ``Name`` does not equal the specified ``Value`` .

            GreaterThan

          The specified resource in ``Name`` is greater than the specified ``Value`` . Not supported
          for text-based properties.

            GreaterThanOrEqualTo

          The specified resource in ``Name`` is greater than or equal to the specified ``Value`` .
          Not supported for text-based properties.

            LessThan

          The specified resource in ``Name`` is less than the specified ``Value`` . Not supported for
          text-based properties.

            LessThanOrEqualTo

          The specified resource in ``Name`` is less than or equal to the specified ``Value`` . Not
          supported for text-based properties.

            Contains

          Only supported for text-based properties. The word-list of the property contains the
          specified ``Value`` . A ``SearchExpression`` can include only one ``Contains`` operator.

          If you have specified a filter ``Value`` , the default is ``Equals`` .

        - **Value** *(string) --*

          A value used with ``Resource`` and ``Operator`` to determine if objects satisfy the
          filter's condition. For numerical properties, ``Value`` must be an integer or
          floating-point decimal. For timestamp properties, ``Value`` must be an ISO 8601 date-time
          string of the following format: ``YYYY-mm-dd'T'HH:MM:SS`` .

    - **NestedFilters** *(list) --*

      A list of nested filter objects.

      - *(dict) --*

        Defines a list of ``NestedFilters`` objects. To satisfy the conditions specified in the
        ``NestedFilters`` call, a resource must satisfy the conditions of all of the filters.

        For example, you could define a ``NestedFilters`` using the training job's
        ``InputDataConfig`` property to filter on ``Channel`` objects.

        A ``NestedFilters`` object contains multiple filters. For example, to find all training jobs
        whose name contains ``train`` and that have ``cat/data`` in their ``S3Uri`` (specified in
        ``InputDataConfig`` ), you need to create a ``NestedFilters`` object that specifies the
        ``InputDataConfig`` property with the following ``Filter`` objects:

        * ``'{Name:"InputDataConfig.ChannelName", "Operator":"EQUALS", "Value":"train"}',``

        * ``'{Name:"InputDataConfig.DataSource.S3DataSource.S3Uri", "Operator":"CONTAINS",
        "Value":"cat/data"}'``

        - **NestedPropertyName** *(string) --* **[REQUIRED]**

          The name of the property to use in the nested filters. The value must match a listed
          property name, such as ``InputDataConfig`` .

        - **Filters** *(list) --* **[REQUIRED]**

          A list of filters. Each filter acts on a property. Filters must contain at least one
          ``Filters`` value. For example, a ``NestedFilters`` call might include a filter on the
          ``PropertyName`` parameter of the ``InputDataConfig`` property:
          ``InputDataConfig.DataSource.S3DataSource.S3Uri`` .

          - *(dict) --*

            A conditional statement for a search expression that includes a resource property, a
            Boolean operator, and a value.

            If you don't specify an ``Operator`` and a ``Value`` , the filter searches for only the
            specified property. For example, defining a ``Filter`` for the ``FailureReason`` for the
            ``TrainingJob``  ``Resource`` searches for training job objects that have a value in the
            ``FailureReason`` field.

            If you specify a ``Value`` , but not an ``Operator`` , Amazon SageMaker uses the equals
            operator as the default.

            In search, there are several property types:

              Metrics

            To define a metric filter, enter a value using the form ``"Metrics.<name>"`` , where
            ``<name>`` is a metric name. For example, the following filter searches for training jobs
            with an ``"accuracy"`` metric greater than ``"0.9"`` :

             ``{``

             ``"Name": "Metrics.accuracy",``

             ``"Operator": "GREATER_THAN",``

             ``"Value": "0.9"``

             ``}``

              HyperParameters

            To define a hyperparameter filter, enter a value with the form
            ``"HyperParameters.<name>"`` . Decimal hyperparameter values are treated as a decimal in
            a comparison if the specified ``Value`` is also a decimal value. If the specified
            ``Value`` is an integer, the decimal hyperparameter values are treated as integers. For
            example, the following filter is satisfied by training jobs with a ``"learning_rate"``
            hyperparameter that is less than ``"0.5"`` :

             ``{``

             ``"Name": "HyperParameters.learning_rate",``

             ``"Operator": "LESS_THAN",``

             ``"Value": "0.5"``

             ``}``

              Tags

            To define a tag filter, enter a value with the form ``"Tags.<key>"`` .

            - **Name** *(string) --* **[REQUIRED]**

              A property name. For example, ``TrainingJobName`` . For the list of valid property
              names returned in a search result for each supported resource, see  TrainingJob
              properties. You must specify a valid property name for the resource.

            - **Operator** *(string) --*

              A Boolean binary operator that is used to evaluate the filter. The operator field
              contains one of the following values:

                Equals

              The specified resource in ``Name`` equals the specified ``Value`` .

                NotEquals

              The specified resource in ``Name`` does not equal the specified ``Value`` .

                GreaterThan

              The specified resource in ``Name`` is greater than the specified ``Value`` . Not
              supported for text-based properties.

                GreaterThanOrEqualTo

              The specified resource in ``Name`` is greater than or equal to the specified ``Value``
              . Not supported for text-based properties.

                LessThan

              The specified resource in ``Name`` is less than the specified ``Value`` . Not supported
              for text-based properties.

                LessThanOrEqualTo

              The specified resource in ``Name`` is less than or equal to the specified ``Value`` .
              Not supported for text-based properties.

                Contains

              Only supported for text-based properties. The word-list of the property contains the
              specified ``Value`` . A ``SearchExpression`` can include only one ``Contains`` operator.

              If you have specified a filter ``Value`` , the default is ``Equals`` .

            - **Value** *(string) --*

              A value used with ``Resource`` and ``Operator`` to determine if objects satisfy the
              filter's condition. For numerical properties, ``Value`` must be an integer or
              floating-point decimal. For timestamp properties, ``Value`` must be an ISO 8601
              date-time string of the following format: ``YYYY-mm-dd'T'HH:MM:SS`` .

    - **SubExpressions** *(list) --*

      A list of search expression objects.

      - *(dict) --*

        A multi-expression that searches for the specified resource or resources in a search. All
        resource objects that satisfy the expression's condition are included in the search results.
        You must specify at least one subexpression, filter, or nested filter. A ``SearchExpression``
        can contain up to twenty elements.

        A ``SearchExpression`` contains the following components:

        * A list of ``Filter`` objects. Each filter defines a simple Boolean expression comprised of
        a resource property name, Boolean operator, and value. A ``SearchExpression`` can include
        only one ``Contains`` operator.

        * A list of ``NestedFilter`` objects. Each nested filter defines a list of Boolean
        expressions using a list of resource properties. A nested filter is satisfied if a single
        object in the list satisfies all Boolean expressions.

        * A list of ``SearchExpression`` objects. A search expression object can be nested in a list
        of search expression objects.

        * A Boolean operator: ``And`` or ``Or`` .

    - **Operator** *(string) --*

      A Boolean operator used to evaluate the search expression. If you want every conditional
      statement in all lists to be satisfied for the entire search expression to be true, specify
      ``And`` . If only a single conditional statement needs to be true for the entire search
      expression to be true, specify ``Or`` . The default value is ``And`` .
    """


_ClientUpdateCodeRepositoryGitConfigTypeDef = TypedDict(
    "_ClientUpdateCodeRepositoryGitConfigTypeDef", {"SecretArn": str}, total=False
)


class ClientUpdateCodeRepositoryGitConfigTypeDef(
    _ClientUpdateCodeRepositoryGitConfigTypeDef
):
    """
    Type definition for `ClientUpdateCodeRepository` `GitConfig`

    The configuration of the git repository, including the URL and the Amazon Resource Name (ARN) of
    the AWS Secrets Manager secret that contains the credentials used to access the repository. The
    secret must have a staging label of ``AWSCURRENT`` and must be in the following format:

     ``{"username": *UserName* , "password": *Password* }``

    - **SecretArn** *(string) --*

      The Amazon Resource Name (ARN) of the AWS Secrets Manager secret that contains the credentials
      used to access the git repository. The secret must have a staging label of ``AWSCURRENT`` and
      must be in the following format:

       ``{"username": *UserName* , "password": *Password* }``
    """


_ClientUpdateCodeRepositoryResponseTypeDef = TypedDict(
    "_ClientUpdateCodeRepositoryResponseTypeDef",
    {"CodeRepositoryArn": str},
    total=False,
)


class ClientUpdateCodeRepositoryResponseTypeDef(
    _ClientUpdateCodeRepositoryResponseTypeDef
):
    """
    Type definition for `ClientUpdateCodeRepository` `Response`

    - **CodeRepositoryArn** *(string) --*

      The ARN of the Git repository.
    """


_ClientUpdateEndpointResponseTypeDef = TypedDict(
    "_ClientUpdateEndpointResponseTypeDef", {"EndpointArn": str}, total=False
)


class ClientUpdateEndpointResponseTypeDef(_ClientUpdateEndpointResponseTypeDef):
    """
    Type definition for `ClientUpdateEndpoint` `Response`

    - **EndpointArn** *(string) --*

      The Amazon Resource Name (ARN) of the endpoint.
    """


_RequiredClientUpdateEndpointWeightsAndCapacitiesDesiredWeightsAndCapacitiesTypeDef = TypedDict(
    "_RequiredClientUpdateEndpointWeightsAndCapacitiesDesiredWeightsAndCapacitiesTypeDef",
    {"VariantName": str},
)
_OptionalClientUpdateEndpointWeightsAndCapacitiesDesiredWeightsAndCapacitiesTypeDef = TypedDict(
    "_OptionalClientUpdateEndpointWeightsAndCapacitiesDesiredWeightsAndCapacitiesTypeDef",
    {"DesiredWeight": float, "DesiredInstanceCount": int},
    total=False,
)


class ClientUpdateEndpointWeightsAndCapacitiesDesiredWeightsAndCapacitiesTypeDef(
    _RequiredClientUpdateEndpointWeightsAndCapacitiesDesiredWeightsAndCapacitiesTypeDef,
    _OptionalClientUpdateEndpointWeightsAndCapacitiesDesiredWeightsAndCapacitiesTypeDef,
):
    """
    Type definition for `ClientUpdateEndpointWeightsAndCapacities` `DesiredWeightsAndCapacities`

    Specifies weight and capacity values for a production variant.

    - **VariantName** *(string) --* **[REQUIRED]**

      The name of the variant to update.

    - **DesiredWeight** *(float) --*

      The variant's weight.

    - **DesiredInstanceCount** *(integer) --*

      The variant's capacity.
    """


_ClientUpdateEndpointWeightsAndCapacitiesResponseTypeDef = TypedDict(
    "_ClientUpdateEndpointWeightsAndCapacitiesResponseTypeDef",
    {"EndpointArn": str},
    total=False,
)


class ClientUpdateEndpointWeightsAndCapacitiesResponseTypeDef(
    _ClientUpdateEndpointWeightsAndCapacitiesResponseTypeDef
):
    """
    Type definition for `ClientUpdateEndpointWeightsAndCapacities` `Response`

    - **EndpointArn** *(string) --*

      The Amazon Resource Name (ARN) of the updated endpoint.
    """


_ClientUpdateNotebookInstanceLifecycleConfigOnCreateTypeDef = TypedDict(
    "_ClientUpdateNotebookInstanceLifecycleConfigOnCreateTypeDef",
    {"Content": str},
    total=False,
)


class ClientUpdateNotebookInstanceLifecycleConfigOnCreateTypeDef(
    _ClientUpdateNotebookInstanceLifecycleConfigOnCreateTypeDef
):
    """
    Type definition for `ClientUpdateNotebookInstanceLifecycleConfig` `OnCreate`

    Contains the notebook instance lifecycle configuration script.

    Each lifecycle configuration script has a limit of 16384 characters.

    The value of the ``$PATH`` environment variable that is available to both scripts is
    ``/sbin:bin:/usr/sbin:/usr/bin`` .

    View CloudWatch Logs for notebook instance lifecycle configurations in log group
    ``/aws/sagemaker/NotebookInstances`` in log stream
    ``[notebook-instance-name]/[LifecycleConfigHook]`` .

    Lifecycle configuration scripts cannot run for longer than 5 minutes. If a script runs for
    longer than 5 minutes, it fails and the notebook instance is not created or started.

    For information about notebook instance lifestyle configurations, see `Step 2.1\\: (Optional)
    Customize a Notebook Instance
    <https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html>`__ .

    - **Content** *(string) --*

      A base64-encoded string that contains a shell script for a notebook instance lifecycle
      configuration.
    """


_ClientUpdateNotebookInstanceLifecycleConfigOnStartTypeDef = TypedDict(
    "_ClientUpdateNotebookInstanceLifecycleConfigOnStartTypeDef",
    {"Content": str},
    total=False,
)


class ClientUpdateNotebookInstanceLifecycleConfigOnStartTypeDef(
    _ClientUpdateNotebookInstanceLifecycleConfigOnStartTypeDef
):
    """
    Type definition for `ClientUpdateNotebookInstanceLifecycleConfig` `OnStart`

    Contains the notebook instance lifecycle configuration script.

    Each lifecycle configuration script has a limit of 16384 characters.

    The value of the ``$PATH`` environment variable that is available to both scripts is
    ``/sbin:bin:/usr/sbin:/usr/bin`` .

    View CloudWatch Logs for notebook instance lifecycle configurations in log group
    ``/aws/sagemaker/NotebookInstances`` in log stream
    ``[notebook-instance-name]/[LifecycleConfigHook]`` .

    Lifecycle configuration scripts cannot run for longer than 5 minutes. If a script runs for
    longer than 5 minutes, it fails and the notebook instance is not created or started.

    For information about notebook instance lifestyle configurations, see `Step 2.1\\: (Optional)
    Customize a Notebook Instance
    <https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html>`__ .

    - **Content** *(string) --*

      A base64-encoded string that contains a shell script for a notebook instance lifecycle
      configuration.
    """


_ClientUpdateWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef = TypedDict(
    "_ClientUpdateWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef",
    {"UserPool": str, "UserGroup": str, "ClientId": str},
)


class ClientUpdateWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef(
    _ClientUpdateWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef
):
    """
    Type definition for `ClientUpdateWorkteamMemberDefinitions` `CognitoMemberDefinition`

    The Amazon Cognito user group that is part of the work team.

    - **UserPool** *(string) --* **[REQUIRED]**

      An identifier for a user pool. The user pool must be in the same region as the service that
      you are calling.

    - **UserGroup** *(string) --* **[REQUIRED]**

      An identifier for a user group.

    - **ClientId** *(string) --* **[REQUIRED]**

      An identifier for an application client. You must create the app client ID using Amazon
      Cognito.
    """


_ClientUpdateWorkteamMemberDefinitionsTypeDef = TypedDict(
    "_ClientUpdateWorkteamMemberDefinitionsTypeDef",
    {
        "CognitoMemberDefinition": ClientUpdateWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef
    },
    total=False,
)


class ClientUpdateWorkteamMemberDefinitionsTypeDef(
    _ClientUpdateWorkteamMemberDefinitionsTypeDef
):
    """
    Type definition for `ClientUpdateWorkteam` `MemberDefinitions`

    Defines the Amazon Cognito user group that is part of a work team.

    - **CognitoMemberDefinition** *(dict) --*

      The Amazon Cognito user group that is part of the work team.

      - **UserPool** *(string) --* **[REQUIRED]**

        An identifier for a user pool. The user pool must be in the same region as the service that
        you are calling.

      - **UserGroup** *(string) --* **[REQUIRED]**

        An identifier for a user group.

      - **ClientId** *(string) --* **[REQUIRED]**

        An identifier for an application client. You must create the app client ID using Amazon
        Cognito.
    """


_ClientUpdateWorkteamNotificationConfigurationTypeDef = TypedDict(
    "_ClientUpdateWorkteamNotificationConfigurationTypeDef",
    {"NotificationTopicArn": str},
    total=False,
)


class ClientUpdateWorkteamNotificationConfigurationTypeDef(
    _ClientUpdateWorkteamNotificationConfigurationTypeDef
):
    """
    Type definition for `ClientUpdateWorkteam` `NotificationConfiguration`

    Configures SNS topic notifications for available or expiring work items

    - **NotificationTopicArn** *(string) --*

      The ARN for the SNS topic to which notifications should be published.
    """


_ClientUpdateWorkteamResponseWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef = TypedDict(
    "_ClientUpdateWorkteamResponseWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef",
    {"UserPool": str, "UserGroup": str, "ClientId": str},
    total=False,
)


class ClientUpdateWorkteamResponseWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef(
    _ClientUpdateWorkteamResponseWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef
):
    """
    Type definition for `ClientUpdateWorkteamResponseWorkteamMemberDefinitions` `CognitoMemberDefinition`

    The Amazon Cognito user group that is part of the work team.

    - **UserPool** *(string) --*

      An identifier for a user pool. The user pool must be in the same region as the
      service that you are calling.

    - **UserGroup** *(string) --*

      An identifier for a user group.

    - **ClientId** *(string) --*

      An identifier for an application client. You must create the app client ID using
      Amazon Cognito.
    """


_ClientUpdateWorkteamResponseWorkteamMemberDefinitionsTypeDef = TypedDict(
    "_ClientUpdateWorkteamResponseWorkteamMemberDefinitionsTypeDef",
    {
        "CognitoMemberDefinition": ClientUpdateWorkteamResponseWorkteamMemberDefinitionsCognitoMemberDefinitionTypeDef
    },
    total=False,
)


class ClientUpdateWorkteamResponseWorkteamMemberDefinitionsTypeDef(
    _ClientUpdateWorkteamResponseWorkteamMemberDefinitionsTypeDef
):
    """
    Type definition for `ClientUpdateWorkteamResponseWorkteam` `MemberDefinitions`

    Defines the Amazon Cognito user group that is part of a work team.

    - **CognitoMemberDefinition** *(dict) --*

      The Amazon Cognito user group that is part of the work team.

      - **UserPool** *(string) --*

        An identifier for a user pool. The user pool must be in the same region as the
        service that you are calling.

      - **UserGroup** *(string) --*

        An identifier for a user group.

      - **ClientId** *(string) --*

        An identifier for an application client. You must create the app client ID using
        Amazon Cognito.
    """


_ClientUpdateWorkteamResponseWorkteamNotificationConfigurationTypeDef = TypedDict(
    "_ClientUpdateWorkteamResponseWorkteamNotificationConfigurationTypeDef",
    {"NotificationTopicArn": str},
    total=False,
)


class ClientUpdateWorkteamResponseWorkteamNotificationConfigurationTypeDef(
    _ClientUpdateWorkteamResponseWorkteamNotificationConfigurationTypeDef
):
    """
    Type definition for `ClientUpdateWorkteamResponseWorkteam` `NotificationConfiguration`

    Configures SNS notifications of available or expiring work items for work teams.

    - **NotificationTopicArn** *(string) --*

      The ARN for the SNS topic to which notifications should be published.
    """


_ClientUpdateWorkteamResponseWorkteamTypeDef = TypedDict(
    "_ClientUpdateWorkteamResponseWorkteamTypeDef",
    {
        "WorkteamName": str,
        "MemberDefinitions": List[
            ClientUpdateWorkteamResponseWorkteamMemberDefinitionsTypeDef
        ],
        "WorkteamArn": str,
        "ProductListingIds": List[str],
        "Description": str,
        "SubDomain": str,
        "CreateDate": datetime,
        "LastUpdatedDate": datetime,
        "NotificationConfiguration": ClientUpdateWorkteamResponseWorkteamNotificationConfigurationTypeDef,
    },
    total=False,
)


class ClientUpdateWorkteamResponseWorkteamTypeDef(
    _ClientUpdateWorkteamResponseWorkteamTypeDef
):
    """
    Type definition for `ClientUpdateWorkteamResponse` `Workteam`

    A ``Workteam`` object that describes the updated work team.

    - **WorkteamName** *(string) --*

      The name of the work team.

    - **MemberDefinitions** *(list) --*

      The Amazon Cognito user groups that make up the work team.

      - *(dict) --*

        Defines the Amazon Cognito user group that is part of a work team.

        - **CognitoMemberDefinition** *(dict) --*

          The Amazon Cognito user group that is part of the work team.

          - **UserPool** *(string) --*

            An identifier for a user pool. The user pool must be in the same region as the
            service that you are calling.

          - **UserGroup** *(string) --*

            An identifier for a user group.

          - **ClientId** *(string) --*

            An identifier for an application client. You must create the app client ID using
            Amazon Cognito.

    - **WorkteamArn** *(string) --*

      The Amazon Resource Name (ARN) that identifies the work team.

    - **ProductListingIds** *(list) --*

      The Amazon Marketplace identifier for a vendor's work team.

      - *(string) --*

    - **Description** *(string) --*

      A description of the work team.

    - **SubDomain** *(string) --*

      The URI of the labeling job's user interface. Workers open this URI to start labeling your
      data objects.

    - **CreateDate** *(datetime) --*

      The date and time that the work team was created (timestamp).

    - **LastUpdatedDate** *(datetime) --*

      The date and time that the work team was last updated (timestamp).

    - **NotificationConfiguration** *(dict) --*

      Configures SNS notifications of available or expiring work items for work teams.

      - **NotificationTopicArn** *(string) --*

        The ARN for the SNS topic to which notifications should be published.
    """


_ClientUpdateWorkteamResponseTypeDef = TypedDict(
    "_ClientUpdateWorkteamResponseTypeDef",
    {"Workteam": ClientUpdateWorkteamResponseWorkteamTypeDef},
    total=False,
)


class ClientUpdateWorkteamResponseTypeDef(_ClientUpdateWorkteamResponseTypeDef):
    """
    Type definition for `ClientUpdateWorkteam` `Response`

    - **Workteam** *(dict) --*

      A ``Workteam`` object that describes the updated work team.

      - **WorkteamName** *(string) --*

        The name of the work team.

      - **MemberDefinitions** *(list) --*

        The Amazon Cognito user groups that make up the work team.

        - *(dict) --*

          Defines the Amazon Cognito user group that is part of a work team.

          - **CognitoMemberDefinition** *(dict) --*

            The Amazon Cognito user group that is part of the work team.

            - **UserPool** *(string) --*

              An identifier for a user pool. The user pool must be in the same region as the
              service that you are calling.

            - **UserGroup** *(string) --*

              An identifier for a user group.

            - **ClientId** *(string) --*

              An identifier for an application client. You must create the app client ID using
              Amazon Cognito.

      - **WorkteamArn** *(string) --*

        The Amazon Resource Name (ARN) that identifies the work team.

      - **ProductListingIds** *(list) --*

        The Amazon Marketplace identifier for a vendor's work team.

        - *(string) --*

      - **Description** *(string) --*

        A description of the work team.

      - **SubDomain** *(string) --*

        The URI of the labeling job's user interface. Workers open this URI to start labeling your
        data objects.

      - **CreateDate** *(datetime) --*

        The date and time that the work team was created (timestamp).

      - **LastUpdatedDate** *(datetime) --*

        The date and time that the work team was last updated (timestamp).

      - **NotificationConfiguration** *(dict) --*

        Configures SNS notifications of available or expiring work items for work teams.

        - **NotificationTopicArn** *(string) --*

          The ARN for the SNS topic to which notifications should be published.
    """


_EndpointDeletedWaitWaiterConfigTypeDef = TypedDict(
    "_EndpointDeletedWaitWaiterConfigTypeDef",
    {"Delay": int, "MaxAttempts": int},
    total=False,
)


class EndpointDeletedWaitWaiterConfigTypeDef(_EndpointDeletedWaitWaiterConfigTypeDef):
    """
    Type definition for `EndpointDeletedWait` `WaiterConfig`

    A dictionary that provides parameters to control waiting behavior.

    - **Delay** *(integer) --*

      The amount of time in seconds to wait between attempts. Default: 30

    - **MaxAttempts** *(integer) --*

      The maximum number of attempts to be made. Default: 60
    """


_EndpointInServiceWaitWaiterConfigTypeDef = TypedDict(
    "_EndpointInServiceWaitWaiterConfigTypeDef",
    {"Delay": int, "MaxAttempts": int},
    total=False,
)


class EndpointInServiceWaitWaiterConfigTypeDef(
    _EndpointInServiceWaitWaiterConfigTypeDef
):
    """
    Type definition for `EndpointInServiceWait` `WaiterConfig`

    A dictionary that provides parameters to control waiting behavior.

    - **Delay** *(integer) --*

      The amount of time in seconds to wait between attempts. Default: 30

    - **MaxAttempts** *(integer) --*

      The maximum number of attempts to be made. Default: 120
    """


_ListAlgorithmsPaginatePaginationConfigTypeDef = TypedDict(
    "_ListAlgorithmsPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListAlgorithmsPaginatePaginationConfigTypeDef(
    _ListAlgorithmsPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListAlgorithmsPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListAlgorithmsPaginateResponseAlgorithmSummaryListTypeDef = TypedDict(
    "_ListAlgorithmsPaginateResponseAlgorithmSummaryListTypeDef",
    {
        "AlgorithmName": str,
        "AlgorithmArn": str,
        "AlgorithmDescription": str,
        "CreationTime": datetime,
        "AlgorithmStatus": str,
    },
    total=False,
)


class ListAlgorithmsPaginateResponseAlgorithmSummaryListTypeDef(
    _ListAlgorithmsPaginateResponseAlgorithmSummaryListTypeDef
):
    """
    Type definition for `ListAlgorithmsPaginateResponse` `AlgorithmSummaryList`

    Provides summary information about an algorithm.

    - **AlgorithmName** *(string) --*

      The name of the algorithm that is described by the summary.

    - **AlgorithmArn** *(string) --*

      The Amazon Resource Name (ARN) of the algorithm.

    - **AlgorithmDescription** *(string) --*

      A brief description of the algorithm.

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the algorithm was created.

    - **AlgorithmStatus** *(string) --*

      The overall status of the algorithm.
    """


_ListAlgorithmsPaginateResponseTypeDef = TypedDict(
    "_ListAlgorithmsPaginateResponseTypeDef",
    {
        "AlgorithmSummaryList": List[
            ListAlgorithmsPaginateResponseAlgorithmSummaryListTypeDef
        ]
    },
    total=False,
)


class ListAlgorithmsPaginateResponseTypeDef(_ListAlgorithmsPaginateResponseTypeDef):
    """
    Type definition for `ListAlgorithmsPaginate` `Response`

    - **AlgorithmSummaryList** *(list) --*

      >An array of ``AlgorithmSummary`` objects, each of which lists an algorithm.

      - *(dict) --*

        Provides summary information about an algorithm.

        - **AlgorithmName** *(string) --*

          The name of the algorithm that is described by the summary.

        - **AlgorithmArn** *(string) --*

          The Amazon Resource Name (ARN) of the algorithm.

        - **AlgorithmDescription** *(string) --*

          A brief description of the algorithm.

        - **CreationTime** *(datetime) --*

          A timestamp that shows when the algorithm was created.

        - **AlgorithmStatus** *(string) --*

          The overall status of the algorithm.
    """


_ListCodeRepositoriesPaginatePaginationConfigTypeDef = TypedDict(
    "_ListCodeRepositoriesPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListCodeRepositoriesPaginatePaginationConfigTypeDef(
    _ListCodeRepositoriesPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListCodeRepositoriesPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListCodeRepositoriesPaginateResponseCodeRepositorySummaryListGitConfigTypeDef = TypedDict(
    "_ListCodeRepositoriesPaginateResponseCodeRepositorySummaryListGitConfigTypeDef",
    {"RepositoryUrl": str, "Branch": str, "SecretArn": str},
    total=False,
)


class ListCodeRepositoriesPaginateResponseCodeRepositorySummaryListGitConfigTypeDef(
    _ListCodeRepositoriesPaginateResponseCodeRepositorySummaryListGitConfigTypeDef
):
    """
    Type definition for `ListCodeRepositoriesPaginateResponseCodeRepositorySummaryList` `GitConfig`

    Configuration details for the Git repository, including the URL where it is located and
    the ARN of the AWS Secrets Manager secret that contains the credentials used to access
    the repository.

    - **RepositoryUrl** *(string) --*

      The URL where the Git repository is located.

    - **Branch** *(string) --*

      The default branch for the Git repository.

    - **SecretArn** *(string) --*

      The Amazon Resource Name (ARN) of the AWS Secrets Manager secret that contains the
      credentials used to access the git repository. The secret must have a staging label of
      ``AWSCURRENT`` and must be in the following format:

       ``{"username": *UserName* , "password": *Password* }``
    """


_ListCodeRepositoriesPaginateResponseCodeRepositorySummaryListTypeDef = TypedDict(
    "_ListCodeRepositoriesPaginateResponseCodeRepositorySummaryListTypeDef",
    {
        "CodeRepositoryName": str,
        "CodeRepositoryArn": str,
        "CreationTime": datetime,
        "LastModifiedTime": datetime,
        "GitConfig": ListCodeRepositoriesPaginateResponseCodeRepositorySummaryListGitConfigTypeDef,
    },
    total=False,
)


class ListCodeRepositoriesPaginateResponseCodeRepositorySummaryListTypeDef(
    _ListCodeRepositoriesPaginateResponseCodeRepositorySummaryListTypeDef
):
    """
    Type definition for `ListCodeRepositoriesPaginateResponse` `CodeRepositorySummaryList`

    Specifies summary information about a Git repository.

    - **CodeRepositoryName** *(string) --*

      The name of the Git repository.

    - **CodeRepositoryArn** *(string) --*

      The Amazon Resource Name (ARN) of the Git repository.

    - **CreationTime** *(datetime) --*

      The date and time that the Git repository was created.

    - **LastModifiedTime** *(datetime) --*

      The date and time that the Git repository was last modified.

    - **GitConfig** *(dict) --*

      Configuration details for the Git repository, including the URL where it is located and
      the ARN of the AWS Secrets Manager secret that contains the credentials used to access
      the repository.

      - **RepositoryUrl** *(string) --*

        The URL where the Git repository is located.

      - **Branch** *(string) --*

        The default branch for the Git repository.

      - **SecretArn** *(string) --*

        The Amazon Resource Name (ARN) of the AWS Secrets Manager secret that contains the
        credentials used to access the git repository. The secret must have a staging label of
        ``AWSCURRENT`` and must be in the following format:

         ``{"username": *UserName* , "password": *Password* }``
    """


_ListCodeRepositoriesPaginateResponseTypeDef = TypedDict(
    "_ListCodeRepositoriesPaginateResponseTypeDef",
    {
        "CodeRepositorySummaryList": List[
            ListCodeRepositoriesPaginateResponseCodeRepositorySummaryListTypeDef
        ]
    },
    total=False,
)


class ListCodeRepositoriesPaginateResponseTypeDef(
    _ListCodeRepositoriesPaginateResponseTypeDef
):
    """
    Type definition for `ListCodeRepositoriesPaginate` `Response`

    - **CodeRepositorySummaryList** *(list) --*

      Gets a list of summaries of the Git repositories. Each summary specifies the following values
      for the repository:

      * Name

      * Amazon Resource Name (ARN)

      * Creation time

      * Last modified time

      * Configuration information, including the URL location of the repository and the ARN of the
      AWS Secrets Manager secret that contains the credentials used to access the repository.

      - *(dict) --*

        Specifies summary information about a Git repository.

        - **CodeRepositoryName** *(string) --*

          The name of the Git repository.

        - **CodeRepositoryArn** *(string) --*

          The Amazon Resource Name (ARN) of the Git repository.

        - **CreationTime** *(datetime) --*

          The date and time that the Git repository was created.

        - **LastModifiedTime** *(datetime) --*

          The date and time that the Git repository was last modified.

        - **GitConfig** *(dict) --*

          Configuration details for the Git repository, including the URL where it is located and
          the ARN of the AWS Secrets Manager secret that contains the credentials used to access
          the repository.

          - **RepositoryUrl** *(string) --*

            The URL where the Git repository is located.

          - **Branch** *(string) --*

            The default branch for the Git repository.

          - **SecretArn** *(string) --*

            The Amazon Resource Name (ARN) of the AWS Secrets Manager secret that contains the
            credentials used to access the git repository. The secret must have a staging label of
            ``AWSCURRENT`` and must be in the following format:

             ``{"username": *UserName* , "password": *Password* }``
    """


_ListCompilationJobsPaginatePaginationConfigTypeDef = TypedDict(
    "_ListCompilationJobsPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListCompilationJobsPaginatePaginationConfigTypeDef(
    _ListCompilationJobsPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListCompilationJobsPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListCompilationJobsPaginateResponseCompilationJobSummariesTypeDef = TypedDict(
    "_ListCompilationJobsPaginateResponseCompilationJobSummariesTypeDef",
    {
        "CompilationJobName": str,
        "CompilationJobArn": str,
        "CreationTime": datetime,
        "CompilationStartTime": datetime,
        "CompilationEndTime": datetime,
        "CompilationTargetDevice": str,
        "LastModifiedTime": datetime,
        "CompilationJobStatus": str,
    },
    total=False,
)


class ListCompilationJobsPaginateResponseCompilationJobSummariesTypeDef(
    _ListCompilationJobsPaginateResponseCompilationJobSummariesTypeDef
):
    """
    Type definition for `ListCompilationJobsPaginateResponse` `CompilationJobSummaries`

    A summary of a model compilation job.

    - **CompilationJobName** *(string) --*

      The name of the model compilation job that you want a summary for.

    - **CompilationJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the model compilation job.

    - **CreationTime** *(datetime) --*

      The time when the model compilation job was created.

    - **CompilationStartTime** *(datetime) --*

      The time when the model compilation job started.

    - **CompilationEndTime** *(datetime) --*

      The time when the model compilation job completed.

    - **CompilationTargetDevice** *(string) --*

      The type of device that the model will run on after compilation has completed.

    - **LastModifiedTime** *(datetime) --*

      The time when the model compilation job was last modified.

    - **CompilationJobStatus** *(string) --*

      The status of the model compilation job.
    """


_ListCompilationJobsPaginateResponseTypeDef = TypedDict(
    "_ListCompilationJobsPaginateResponseTypeDef",
    {
        "CompilationJobSummaries": List[
            ListCompilationJobsPaginateResponseCompilationJobSummariesTypeDef
        ]
    },
    total=False,
)


class ListCompilationJobsPaginateResponseTypeDef(
    _ListCompilationJobsPaginateResponseTypeDef
):
    """
    Type definition for `ListCompilationJobsPaginate` `Response`

    - **CompilationJobSummaries** *(list) --*

      An array of  CompilationJobSummary objects, each describing a model compilation job.

      - *(dict) --*

        A summary of a model compilation job.

        - **CompilationJobName** *(string) --*

          The name of the model compilation job that you want a summary for.

        - **CompilationJobArn** *(string) --*

          The Amazon Resource Name (ARN) of the model compilation job.

        - **CreationTime** *(datetime) --*

          The time when the model compilation job was created.

        - **CompilationStartTime** *(datetime) --*

          The time when the model compilation job started.

        - **CompilationEndTime** *(datetime) --*

          The time when the model compilation job completed.

        - **CompilationTargetDevice** *(string) --*

          The type of device that the model will run on after compilation has completed.

        - **LastModifiedTime** *(datetime) --*

          The time when the model compilation job was last modified.

        - **CompilationJobStatus** *(string) --*

          The status of the model compilation job.
    """


_ListEndpointConfigsPaginatePaginationConfigTypeDef = TypedDict(
    "_ListEndpointConfigsPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListEndpointConfigsPaginatePaginationConfigTypeDef(
    _ListEndpointConfigsPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListEndpointConfigsPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListEndpointConfigsPaginateResponseEndpointConfigsTypeDef = TypedDict(
    "_ListEndpointConfigsPaginateResponseEndpointConfigsTypeDef",
    {"EndpointConfigName": str, "EndpointConfigArn": str, "CreationTime": datetime},
    total=False,
)


class ListEndpointConfigsPaginateResponseEndpointConfigsTypeDef(
    _ListEndpointConfigsPaginateResponseEndpointConfigsTypeDef
):
    """
    Type definition for `ListEndpointConfigsPaginateResponse` `EndpointConfigs`

    Provides summary information for an endpoint configuration.

    - **EndpointConfigName** *(string) --*

      The name of the endpoint configuration.

    - **EndpointConfigArn** *(string) --*

      The Amazon Resource Name (ARN) of the endpoint configuration.

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the endpoint configuration was created.
    """


_ListEndpointConfigsPaginateResponseTypeDef = TypedDict(
    "_ListEndpointConfigsPaginateResponseTypeDef",
    {
        "EndpointConfigs": List[
            ListEndpointConfigsPaginateResponseEndpointConfigsTypeDef
        ]
    },
    total=False,
)


class ListEndpointConfigsPaginateResponseTypeDef(
    _ListEndpointConfigsPaginateResponseTypeDef
):
    """
    Type definition for `ListEndpointConfigsPaginate` `Response`

    - **EndpointConfigs** *(list) --*

      An array of endpoint configurations.

      - *(dict) --*

        Provides summary information for an endpoint configuration.

        - **EndpointConfigName** *(string) --*

          The name of the endpoint configuration.

        - **EndpointConfigArn** *(string) --*

          The Amazon Resource Name (ARN) of the endpoint configuration.

        - **CreationTime** *(datetime) --*

          A timestamp that shows when the endpoint configuration was created.
    """


_ListEndpointsPaginatePaginationConfigTypeDef = TypedDict(
    "_ListEndpointsPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListEndpointsPaginatePaginationConfigTypeDef(
    _ListEndpointsPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListEndpointsPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListEndpointsPaginateResponseEndpointsTypeDef = TypedDict(
    "_ListEndpointsPaginateResponseEndpointsTypeDef",
    {
        "EndpointName": str,
        "EndpointArn": str,
        "CreationTime": datetime,
        "LastModifiedTime": datetime,
        "EndpointStatus": str,
    },
    total=False,
)


class ListEndpointsPaginateResponseEndpointsTypeDef(
    _ListEndpointsPaginateResponseEndpointsTypeDef
):
    """
    Type definition for `ListEndpointsPaginateResponse` `Endpoints`

    Provides summary information for an endpoint.

    - **EndpointName** *(string) --*

      The name of the endpoint.

    - **EndpointArn** *(string) --*

      The Amazon Resource Name (ARN) of the endpoint.

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the endpoint was created.

    - **LastModifiedTime** *(datetime) --*

      A timestamp that shows when the endpoint was last modified.

    - **EndpointStatus** *(string) --*

      The status of the endpoint.

      * ``OutOfService`` : Endpoint is not available to take incoming requests.

      * ``Creating`` :  CreateEndpoint is executing.

      * ``Updating`` :  UpdateEndpoint or  UpdateEndpointWeightsAndCapacities is executing.

      * ``SystemUpdating`` : Endpoint is undergoing maintenance and cannot be updated or
      deleted or re-scaled until it has completed. This maintenance operation does not change
      any customer-specified values such as VPC config, KMS encryption, model, instance type,
      or instance count.

      * ``RollingBack`` : Endpoint fails to scale up or down or change its variant weight and
      is in the process of rolling back to its previous configuration. Once the rollback
      completes, endpoint returns to an ``InService`` status. This transitional status only
      applies to an endpoint that has autoscaling enabled and is undergoing variant weight or
      capacity changes as part of an  UpdateEndpointWeightsAndCapacities call or when the
      UpdateEndpointWeightsAndCapacities operation is called explicitly.

      * ``InService`` : Endpoint is available to process incoming requests.

      * ``Deleting`` :  DeleteEndpoint is executing.

      * ``Failed`` : Endpoint could not be created, updated, or re-scaled. Use
      DescribeEndpointOutput$FailureReason for information about the failure.  DeleteEndpoint
      is the only operation that can be performed on a failed endpoint.

      To get a list of endpoints with a specified status, use the
      ListEndpointsInput$StatusEquals filter.
    """


_ListEndpointsPaginateResponseTypeDef = TypedDict(
    "_ListEndpointsPaginateResponseTypeDef",
    {"Endpoints": List[ListEndpointsPaginateResponseEndpointsTypeDef]},
    total=False,
)


class ListEndpointsPaginateResponseTypeDef(_ListEndpointsPaginateResponseTypeDef):
    """
    Type definition for `ListEndpointsPaginate` `Response`

    - **Endpoints** *(list) --*

      An array or endpoint objects.

      - *(dict) --*

        Provides summary information for an endpoint.

        - **EndpointName** *(string) --*

          The name of the endpoint.

        - **EndpointArn** *(string) --*

          The Amazon Resource Name (ARN) of the endpoint.

        - **CreationTime** *(datetime) --*

          A timestamp that shows when the endpoint was created.

        - **LastModifiedTime** *(datetime) --*

          A timestamp that shows when the endpoint was last modified.

        - **EndpointStatus** *(string) --*

          The status of the endpoint.

          * ``OutOfService`` : Endpoint is not available to take incoming requests.

          * ``Creating`` :  CreateEndpoint is executing.

          * ``Updating`` :  UpdateEndpoint or  UpdateEndpointWeightsAndCapacities is executing.

          * ``SystemUpdating`` : Endpoint is undergoing maintenance and cannot be updated or
          deleted or re-scaled until it has completed. This maintenance operation does not change
          any customer-specified values such as VPC config, KMS encryption, model, instance type,
          or instance count.

          * ``RollingBack`` : Endpoint fails to scale up or down or change its variant weight and
          is in the process of rolling back to its previous configuration. Once the rollback
          completes, endpoint returns to an ``InService`` status. This transitional status only
          applies to an endpoint that has autoscaling enabled and is undergoing variant weight or
          capacity changes as part of an  UpdateEndpointWeightsAndCapacities call or when the
          UpdateEndpointWeightsAndCapacities operation is called explicitly.

          * ``InService`` : Endpoint is available to process incoming requests.

          * ``Deleting`` :  DeleteEndpoint is executing.

          * ``Failed`` : Endpoint could not be created, updated, or re-scaled. Use
          DescribeEndpointOutput$FailureReason for information about the failure.  DeleteEndpoint
          is the only operation that can be performed on a failed endpoint.

          To get a list of endpoints with a specified status, use the
          ListEndpointsInput$StatusEquals filter.
    """


_ListHyperParameterTuningJobsPaginatePaginationConfigTypeDef = TypedDict(
    "_ListHyperParameterTuningJobsPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListHyperParameterTuningJobsPaginatePaginationConfigTypeDef(
    _ListHyperParameterTuningJobsPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListHyperParameterTuningJobsPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesObjectiveStatusCountersTypeDef = TypedDict(
    "_ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesObjectiveStatusCountersTypeDef",
    {"Succeeded": int, "Pending": int, "Failed": int},
    total=False,
)


class ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesObjectiveStatusCountersTypeDef(
    _ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesObjectiveStatusCountersTypeDef
):
    """
    Type definition for `ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummaries` `ObjectiveStatusCounters`

    The  ObjectiveStatusCounters object that specifies the numbers of training jobs,
    categorized by objective metric status, that this tuning job launched.

    - **Succeeded** *(integer) --*

      The number of training jobs whose final objective metric was evaluated by the
      hyperparameter tuning job and used in the hyperparameter tuning process.

    - **Pending** *(integer) --*

      The number of training jobs that are in progress and pending evaluation of their final
      objective metric.

    - **Failed** *(integer) --*

      The number of training jobs whose final objective metric was not evaluated and used in
      the hyperparameter tuning process. This typically occurs when the training job failed
      or did not emit an objective metric.
    """


_ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesResourceLimitsTypeDef = TypedDict(
    "_ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesResourceLimitsTypeDef",
    {"MaxNumberOfTrainingJobs": int, "MaxParallelTrainingJobs": int},
    total=False,
)


class ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesResourceLimitsTypeDef(
    _ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesResourceLimitsTypeDef
):
    """
    Type definition for `ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummaries` `ResourceLimits`

    The  ResourceLimits object that specifies the maximum number of training jobs and
    parallel training jobs allowed for this tuning job.

    - **MaxNumberOfTrainingJobs** *(integer) --*

      The maximum number of training jobs that a hyperparameter tuning job can launch.

    - **MaxParallelTrainingJobs** *(integer) --*

      The maximum number of concurrent training jobs that a hyperparameter tuning job can
      launch.
    """


_ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesTrainingJobStatusCountersTypeDef = TypedDict(
    "_ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesTrainingJobStatusCountersTypeDef",
    {
        "Completed": int,
        "InProgress": int,
        "RetryableError": int,
        "NonRetryableError": int,
        "Stopped": int,
    },
    total=False,
)


class ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesTrainingJobStatusCountersTypeDef(
    _ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesTrainingJobStatusCountersTypeDef
):
    """
    Type definition for `ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummaries` `TrainingJobStatusCounters`

    The  TrainingJobStatusCounters object that specifies the numbers of training jobs,
    categorized by status, that this tuning job launched.

    - **Completed** *(integer) --*

      The number of completed training jobs launched by the hyperparameter tuning job.

    - **InProgress** *(integer) --*

      The number of in-progress training jobs launched by a hyperparameter tuning job.

    - **RetryableError** *(integer) --*

      The number of training jobs that failed, but can be retried. A failed training job can
      be retried only if it failed because an internal service error occurred.

    - **NonRetryableError** *(integer) --*

      The number of training jobs that failed and can't be retried. A failed training job
      can't be retried if it failed because a client error occurred.

    - **Stopped** *(integer) --*

      The number of training jobs launched by a hyperparameter tuning job that were manually
      stopped.
    """


_ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesTypeDef = TypedDict(
    "_ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesTypeDef",
    {
        "HyperParameterTuningJobName": str,
        "HyperParameterTuningJobArn": str,
        "HyperParameterTuningJobStatus": str,
        "Strategy": str,
        "CreationTime": datetime,
        "HyperParameterTuningEndTime": datetime,
        "LastModifiedTime": datetime,
        "TrainingJobStatusCounters": ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesTrainingJobStatusCountersTypeDef,
        "ObjectiveStatusCounters": ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesObjectiveStatusCountersTypeDef,
        "ResourceLimits": ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesResourceLimitsTypeDef,
    },
    total=False,
)


class ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesTypeDef(
    _ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesTypeDef
):
    """
    Type definition for `ListHyperParameterTuningJobsPaginateResponse` `HyperParameterTuningJobSummaries`

    Provides summary information about a hyperparameter tuning job.

    - **HyperParameterTuningJobName** *(string) --*

      The name of the tuning job.

    - **HyperParameterTuningJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the tuning job.

    - **HyperParameterTuningJobStatus** *(string) --*

      The status of the tuning job.

    - **Strategy** *(string) --*

      Specifies the search strategy hyperparameter tuning uses to choose which hyperparameters
      to use for each iteration. Currently, the only valid value is Bayesian.

    - **CreationTime** *(datetime) --*

      The date and time that the tuning job was created.

    - **HyperParameterTuningEndTime** *(datetime) --*

      The date and time that the tuning job ended.

    - **LastModifiedTime** *(datetime) --*

      The date and time that the tuning job was modified.

    - **TrainingJobStatusCounters** *(dict) --*

      The  TrainingJobStatusCounters object that specifies the numbers of training jobs,
      categorized by status, that this tuning job launched.

      - **Completed** *(integer) --*

        The number of completed training jobs launched by the hyperparameter tuning job.

      - **InProgress** *(integer) --*

        The number of in-progress training jobs launched by a hyperparameter tuning job.

      - **RetryableError** *(integer) --*

        The number of training jobs that failed, but can be retried. A failed training job can
        be retried only if it failed because an internal service error occurred.

      - **NonRetryableError** *(integer) --*

        The number of training jobs that failed and can't be retried. A failed training job
        can't be retried if it failed because a client error occurred.

      - **Stopped** *(integer) --*

        The number of training jobs launched by a hyperparameter tuning job that were manually
        stopped.

    - **ObjectiveStatusCounters** *(dict) --*

      The  ObjectiveStatusCounters object that specifies the numbers of training jobs,
      categorized by objective metric status, that this tuning job launched.

      - **Succeeded** *(integer) --*

        The number of training jobs whose final objective metric was evaluated by the
        hyperparameter tuning job and used in the hyperparameter tuning process.

      - **Pending** *(integer) --*

        The number of training jobs that are in progress and pending evaluation of their final
        objective metric.

      - **Failed** *(integer) --*

        The number of training jobs whose final objective metric was not evaluated and used in
        the hyperparameter tuning process. This typically occurs when the training job failed
        or did not emit an objective metric.

    - **ResourceLimits** *(dict) --*

      The  ResourceLimits object that specifies the maximum number of training jobs and
      parallel training jobs allowed for this tuning job.

      - **MaxNumberOfTrainingJobs** *(integer) --*

        The maximum number of training jobs that a hyperparameter tuning job can launch.

      - **MaxParallelTrainingJobs** *(integer) --*

        The maximum number of concurrent training jobs that a hyperparameter tuning job can
        launch.
    """


_ListHyperParameterTuningJobsPaginateResponseTypeDef = TypedDict(
    "_ListHyperParameterTuningJobsPaginateResponseTypeDef",
    {
        "HyperParameterTuningJobSummaries": List[
            ListHyperParameterTuningJobsPaginateResponseHyperParameterTuningJobSummariesTypeDef
        ]
    },
    total=False,
)


class ListHyperParameterTuningJobsPaginateResponseTypeDef(
    _ListHyperParameterTuningJobsPaginateResponseTypeDef
):
    """
    Type definition for `ListHyperParameterTuningJobsPaginate` `Response`

    - **HyperParameterTuningJobSummaries** *(list) --*

      A list of  HyperParameterTuningJobSummary objects that describe the tuning jobs that the
      ``ListHyperParameterTuningJobs`` request returned.

      - *(dict) --*

        Provides summary information about a hyperparameter tuning job.

        - **HyperParameterTuningJobName** *(string) --*

          The name of the tuning job.

        - **HyperParameterTuningJobArn** *(string) --*

          The Amazon Resource Name (ARN) of the tuning job.

        - **HyperParameterTuningJobStatus** *(string) --*

          The status of the tuning job.

        - **Strategy** *(string) --*

          Specifies the search strategy hyperparameter tuning uses to choose which hyperparameters
          to use for each iteration. Currently, the only valid value is Bayesian.

        - **CreationTime** *(datetime) --*

          The date and time that the tuning job was created.

        - **HyperParameterTuningEndTime** *(datetime) --*

          The date and time that the tuning job ended.

        - **LastModifiedTime** *(datetime) --*

          The date and time that the tuning job was modified.

        - **TrainingJobStatusCounters** *(dict) --*

          The  TrainingJobStatusCounters object that specifies the numbers of training jobs,
          categorized by status, that this tuning job launched.

          - **Completed** *(integer) --*

            The number of completed training jobs launched by the hyperparameter tuning job.

          - **InProgress** *(integer) --*

            The number of in-progress training jobs launched by a hyperparameter tuning job.

          - **RetryableError** *(integer) --*

            The number of training jobs that failed, but can be retried. A failed training job can
            be retried only if it failed because an internal service error occurred.

          - **NonRetryableError** *(integer) --*

            The number of training jobs that failed and can't be retried. A failed training job
            can't be retried if it failed because a client error occurred.

          - **Stopped** *(integer) --*

            The number of training jobs launched by a hyperparameter tuning job that were manually
            stopped.

        - **ObjectiveStatusCounters** *(dict) --*

          The  ObjectiveStatusCounters object that specifies the numbers of training jobs,
          categorized by objective metric status, that this tuning job launched.

          - **Succeeded** *(integer) --*

            The number of training jobs whose final objective metric was evaluated by the
            hyperparameter tuning job and used in the hyperparameter tuning process.

          - **Pending** *(integer) --*

            The number of training jobs that are in progress and pending evaluation of their final
            objective metric.

          - **Failed** *(integer) --*

            The number of training jobs whose final objective metric was not evaluated and used in
            the hyperparameter tuning process. This typically occurs when the training job failed
            or did not emit an objective metric.

        - **ResourceLimits** *(dict) --*

          The  ResourceLimits object that specifies the maximum number of training jobs and
          parallel training jobs allowed for this tuning job.

          - **MaxNumberOfTrainingJobs** *(integer) --*

            The maximum number of training jobs that a hyperparameter tuning job can launch.

          - **MaxParallelTrainingJobs** *(integer) --*

            The maximum number of concurrent training jobs that a hyperparameter tuning job can
            launch.
    """


_ListLabelingJobsForWorkteamPaginatePaginationConfigTypeDef = TypedDict(
    "_ListLabelingJobsForWorkteamPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListLabelingJobsForWorkteamPaginatePaginationConfigTypeDef(
    _ListLabelingJobsForWorkteamPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListLabelingJobsForWorkteamPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListLabelingJobsForWorkteamPaginateResponseLabelingJobSummaryListLabelCountersTypeDef = TypedDict(
    "_ListLabelingJobsForWorkteamPaginateResponseLabelingJobSummaryListLabelCountersTypeDef",
    {"HumanLabeled": int, "PendingHuman": int, "Total": int},
    total=False,
)


class ListLabelingJobsForWorkteamPaginateResponseLabelingJobSummaryListLabelCountersTypeDef(
    _ListLabelingJobsForWorkteamPaginateResponseLabelingJobSummaryListLabelCountersTypeDef
):
    """
    Type definition for `ListLabelingJobsForWorkteamPaginateResponseLabelingJobSummaryList` `LabelCounters`

    Provides information about the progress of a labeling job.

    - **HumanLabeled** *(integer) --*

      The total number of data objects labeled by a human worker.

    - **PendingHuman** *(integer) --*

      The total number of data objects that need to be labeled by a human worker.

    - **Total** *(integer) --*

      The total number of tasks in the labeling job.
    """


_ListLabelingJobsForWorkteamPaginateResponseLabelingJobSummaryListTypeDef = TypedDict(
    "_ListLabelingJobsForWorkteamPaginateResponseLabelingJobSummaryListTypeDef",
    {
        "LabelingJobName": str,
        "JobReferenceCode": str,
        "WorkRequesterAccountId": str,
        "CreationTime": datetime,
        "LabelCounters": ListLabelingJobsForWorkteamPaginateResponseLabelingJobSummaryListLabelCountersTypeDef,
        "NumberOfHumanWorkersPerDataObject": int,
    },
    total=False,
)


class ListLabelingJobsForWorkteamPaginateResponseLabelingJobSummaryListTypeDef(
    _ListLabelingJobsForWorkteamPaginateResponseLabelingJobSummaryListTypeDef
):
    """
    Type definition for `ListLabelingJobsForWorkteamPaginateResponse` `LabelingJobSummaryList`

    Provides summary information for a work team.

    - **LabelingJobName** *(string) --*

      The name of the labeling job that the work team is assigned to.

    - **JobReferenceCode** *(string) --*

      A unique identifier for a labeling job. You can use this to refer to a specific labeling
      job.

    - **WorkRequesterAccountId** *(string) --*

    - **CreationTime** *(datetime) --*

      The date and time that the labeling job was created.

    - **LabelCounters** *(dict) --*

      Provides information about the progress of a labeling job.

      - **HumanLabeled** *(integer) --*

        The total number of data objects labeled by a human worker.

      - **PendingHuman** *(integer) --*

        The total number of data objects that need to be labeled by a human worker.

      - **Total** *(integer) --*

        The total number of tasks in the labeling job.

    - **NumberOfHumanWorkersPerDataObject** *(integer) --*

      The configured number of workers per data object.
    """


_ListLabelingJobsForWorkteamPaginateResponseTypeDef = TypedDict(
    "_ListLabelingJobsForWorkteamPaginateResponseTypeDef",
    {
        "LabelingJobSummaryList": List[
            ListLabelingJobsForWorkteamPaginateResponseLabelingJobSummaryListTypeDef
        ]
    },
    total=False,
)


class ListLabelingJobsForWorkteamPaginateResponseTypeDef(
    _ListLabelingJobsForWorkteamPaginateResponseTypeDef
):
    """
    Type definition for `ListLabelingJobsForWorkteamPaginate` `Response`

    - **LabelingJobSummaryList** *(list) --*

      An array of ``LabelingJobSummary`` objects, each describing a labeling job.

      - *(dict) --*

        Provides summary information for a work team.

        - **LabelingJobName** *(string) --*

          The name of the labeling job that the work team is assigned to.

        - **JobReferenceCode** *(string) --*

          A unique identifier for a labeling job. You can use this to refer to a specific labeling
          job.

        - **WorkRequesterAccountId** *(string) --*

        - **CreationTime** *(datetime) --*

          The date and time that the labeling job was created.

        - **LabelCounters** *(dict) --*

          Provides information about the progress of a labeling job.

          - **HumanLabeled** *(integer) --*

            The total number of data objects labeled by a human worker.

          - **PendingHuman** *(integer) --*

            The total number of data objects that need to be labeled by a human worker.

          - **Total** *(integer) --*

            The total number of tasks in the labeling job.

        - **NumberOfHumanWorkersPerDataObject** *(integer) --*

          The configured number of workers per data object.
    """


_ListLabelingJobsPaginatePaginationConfigTypeDef = TypedDict(
    "_ListLabelingJobsPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListLabelingJobsPaginatePaginationConfigTypeDef(
    _ListLabelingJobsPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListLabelingJobsPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataAttributesTypeDef = TypedDict(
    "_ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataAttributesTypeDef",
    {"ContentClassifiers": List[str]},
    total=False,
)


class ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataAttributesTypeDef(
    _ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataAttributesTypeDef
):
    """
    Type definition for `ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfig` `DataAttributes`

    Attributes of the data specified by the customer.

    - **ContentClassifiers** *(list) --*

      Declares that your content is free of personally identifiable information or adult
      content. Amazon SageMaker may restrict the Amazon Mechanical Turk workers that can
      view your task based on this information.

      - *(string) --*
    """


_ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataSourceS3DataSourceTypeDef = TypedDict(
    "_ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataSourceS3DataSourceTypeDef",
    {"ManifestS3Uri": str},
    total=False,
)


class ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataSourceS3DataSourceTypeDef(
    _ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataSourceS3DataSourceTypeDef
):
    """
    Type definition for `ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataSource` `S3DataSource`

    The Amazon S3 location of the input data objects.

    - **ManifestS3Uri** *(string) --*

      The Amazon S3 location of the manifest file that describes the input data objects.
    """


_ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataSourceTypeDef = TypedDict(
    "_ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataSourceTypeDef",
    {
        "S3DataSource": ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataSourceS3DataSourceTypeDef
    },
    total=False,
)


class ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataSourceTypeDef(
    _ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataSourceTypeDef
):
    """
    Type definition for `ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfig` `DataSource`

    The location of the input data.

    - **S3DataSource** *(dict) --*

      The Amazon S3 location of the input data objects.

      - **ManifestS3Uri** *(string) --*

        The Amazon S3 location of the manifest file that describes the input data objects.
    """


_ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigTypeDef = TypedDict(
    "_ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigTypeDef",
    {
        "DataSource": ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataSourceTypeDef,
        "DataAttributes": ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigDataAttributesTypeDef,
    },
    total=False,
)


class ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigTypeDef(
    _ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigTypeDef
):
    """
    Type definition for `ListLabelingJobsPaginateResponseLabelingJobSummaryList` `InputConfig`

    Input configuration for the labeling job.

    - **DataSource** *(dict) --*

      The location of the input data.

      - **S3DataSource** *(dict) --*

        The Amazon S3 location of the input data objects.

        - **ManifestS3Uri** *(string) --*

          The Amazon S3 location of the manifest file that describes the input data objects.

    - **DataAttributes** *(dict) --*

      Attributes of the data specified by the customer.

      - **ContentClassifiers** *(list) --*

        Declares that your content is free of personally identifiable information or adult
        content. Amazon SageMaker may restrict the Amazon Mechanical Turk workers that can
        view your task based on this information.

        - *(string) --*
    """


_ListLabelingJobsPaginateResponseLabelingJobSummaryListLabelCountersTypeDef = TypedDict(
    "_ListLabelingJobsPaginateResponseLabelingJobSummaryListLabelCountersTypeDef",
    {
        "TotalLabeled": int,
        "HumanLabeled": int,
        "MachineLabeled": int,
        "FailedNonRetryableError": int,
        "Unlabeled": int,
    },
    total=False,
)


class ListLabelingJobsPaginateResponseLabelingJobSummaryListLabelCountersTypeDef(
    _ListLabelingJobsPaginateResponseLabelingJobSummaryListLabelCountersTypeDef
):
    """
    Type definition for `ListLabelingJobsPaginateResponseLabelingJobSummaryList` `LabelCounters`

    Counts showing the progress of the labeling job.

    - **TotalLabeled** *(integer) --*

      The total number of objects labeled.

    - **HumanLabeled** *(integer) --*

      The total number of objects labeled by a human worker.

    - **MachineLabeled** *(integer) --*

      The total number of objects labeled by automated data labeling.

    - **FailedNonRetryableError** *(integer) --*

      The total number of objects that could not be labeled due to an error.

    - **Unlabeled** *(integer) --*

      The total number of objects not yet labeled.
    """


_ListLabelingJobsPaginateResponseLabelingJobSummaryListLabelingJobOutputTypeDef = TypedDict(
    "_ListLabelingJobsPaginateResponseLabelingJobSummaryListLabelingJobOutputTypeDef",
    {"OutputDatasetS3Uri": str, "FinalActiveLearningModelArn": str},
    total=False,
)


class ListLabelingJobsPaginateResponseLabelingJobSummaryListLabelingJobOutputTypeDef(
    _ListLabelingJobsPaginateResponseLabelingJobSummaryListLabelingJobOutputTypeDef
):
    """
    Type definition for `ListLabelingJobsPaginateResponseLabelingJobSummaryList` `LabelingJobOutput`

    The location of the output produced by the labeling job.

    - **OutputDatasetS3Uri** *(string) --*

      The Amazon S3 bucket location of the manifest file for labeled data.

    - **FinalActiveLearningModelArn** *(string) --*

      The Amazon Resource Name (ARN) for the most recent Amazon SageMaker model trained as
      part of automated data labeling.
    """


_ListLabelingJobsPaginateResponseLabelingJobSummaryListTypeDef = TypedDict(
    "_ListLabelingJobsPaginateResponseLabelingJobSummaryListTypeDef",
    {
        "LabelingJobName": str,
        "LabelingJobArn": str,
        "CreationTime": datetime,
        "LastModifiedTime": datetime,
        "LabelingJobStatus": str,
        "LabelCounters": ListLabelingJobsPaginateResponseLabelingJobSummaryListLabelCountersTypeDef,
        "WorkteamArn": str,
        "PreHumanTaskLambdaArn": str,
        "AnnotationConsolidationLambdaArn": str,
        "FailureReason": str,
        "LabelingJobOutput": ListLabelingJobsPaginateResponseLabelingJobSummaryListLabelingJobOutputTypeDef,
        "InputConfig": ListLabelingJobsPaginateResponseLabelingJobSummaryListInputConfigTypeDef,
    },
    total=False,
)


class ListLabelingJobsPaginateResponseLabelingJobSummaryListTypeDef(
    _ListLabelingJobsPaginateResponseLabelingJobSummaryListTypeDef
):
    """
    Type definition for `ListLabelingJobsPaginateResponse` `LabelingJobSummaryList`

    Provides summary information about a labeling job.

    - **LabelingJobName** *(string) --*

      The name of the labeling job.

    - **LabelingJobArn** *(string) --*

      The Amazon Resource Name (ARN) assigned to the labeling job when it was created.

    - **CreationTime** *(datetime) --*

      The date and time that the job was created (timestamp).

    - **LastModifiedTime** *(datetime) --*

      The date and time that the job was last modified (timestamp).

    - **LabelingJobStatus** *(string) --*

      The current status of the labeling job.

    - **LabelCounters** *(dict) --*

      Counts showing the progress of the labeling job.

      - **TotalLabeled** *(integer) --*

        The total number of objects labeled.

      - **HumanLabeled** *(integer) --*

        The total number of objects labeled by a human worker.

      - **MachineLabeled** *(integer) --*

        The total number of objects labeled by automated data labeling.

      - **FailedNonRetryableError** *(integer) --*

        The total number of objects that could not be labeled due to an error.

      - **Unlabeled** *(integer) --*

        The total number of objects not yet labeled.

    - **WorkteamArn** *(string) --*

      The Amazon Resource Name (ARN) of the work team assigned to the job.

    - **PreHumanTaskLambdaArn** *(string) --*

      The Amazon Resource Name (ARN) of a Lambda function. The function is run before each data
      object is sent to a worker.

    - **AnnotationConsolidationLambdaArn** *(string) --*

      The Amazon Resource Name (ARN) of the Lambda function used to consolidate the annotations
      from individual workers into a label for a data object. For more information, see
      `Annotation Consolidation
      <https://docs.aws.amazon.com/sagemaker/latest/dg/sms-annotation-consolidation.html>`__ .

    - **FailureReason** *(string) --*

      If the ``LabelingJobStatus`` field is ``Failed`` , this field contains a description of
      the error.

    - **LabelingJobOutput** *(dict) --*

      The location of the output produced by the labeling job.

      - **OutputDatasetS3Uri** *(string) --*

        The Amazon S3 bucket location of the manifest file for labeled data.

      - **FinalActiveLearningModelArn** *(string) --*

        The Amazon Resource Name (ARN) for the most recent Amazon SageMaker model trained as
        part of automated data labeling.

    - **InputConfig** *(dict) --*

      Input configuration for the labeling job.

      - **DataSource** *(dict) --*

        The location of the input data.

        - **S3DataSource** *(dict) --*

          The Amazon S3 location of the input data objects.

          - **ManifestS3Uri** *(string) --*

            The Amazon S3 location of the manifest file that describes the input data objects.

      - **DataAttributes** *(dict) --*

        Attributes of the data specified by the customer.

        - **ContentClassifiers** *(list) --*

          Declares that your content is free of personally identifiable information or adult
          content. Amazon SageMaker may restrict the Amazon Mechanical Turk workers that can
          view your task based on this information.

          - *(string) --*
    """


_ListLabelingJobsPaginateResponseTypeDef = TypedDict(
    "_ListLabelingJobsPaginateResponseTypeDef",
    {
        "LabelingJobSummaryList": List[
            ListLabelingJobsPaginateResponseLabelingJobSummaryListTypeDef
        ]
    },
    total=False,
)


class ListLabelingJobsPaginateResponseTypeDef(_ListLabelingJobsPaginateResponseTypeDef):
    """
    Type definition for `ListLabelingJobsPaginate` `Response`

    - **LabelingJobSummaryList** *(list) --*

      An array of ``LabelingJobSummary`` objects, each describing a labeling job.

      - *(dict) --*

        Provides summary information about a labeling job.

        - **LabelingJobName** *(string) --*

          The name of the labeling job.

        - **LabelingJobArn** *(string) --*

          The Amazon Resource Name (ARN) assigned to the labeling job when it was created.

        - **CreationTime** *(datetime) --*

          The date and time that the job was created (timestamp).

        - **LastModifiedTime** *(datetime) --*

          The date and time that the job was last modified (timestamp).

        - **LabelingJobStatus** *(string) --*

          The current status of the labeling job.

        - **LabelCounters** *(dict) --*

          Counts showing the progress of the labeling job.

          - **TotalLabeled** *(integer) --*

            The total number of objects labeled.

          - **HumanLabeled** *(integer) --*

            The total number of objects labeled by a human worker.

          - **MachineLabeled** *(integer) --*

            The total number of objects labeled by automated data labeling.

          - **FailedNonRetryableError** *(integer) --*

            The total number of objects that could not be labeled due to an error.

          - **Unlabeled** *(integer) --*

            The total number of objects not yet labeled.

        - **WorkteamArn** *(string) --*

          The Amazon Resource Name (ARN) of the work team assigned to the job.

        - **PreHumanTaskLambdaArn** *(string) --*

          The Amazon Resource Name (ARN) of a Lambda function. The function is run before each data
          object is sent to a worker.

        - **AnnotationConsolidationLambdaArn** *(string) --*

          The Amazon Resource Name (ARN) of the Lambda function used to consolidate the annotations
          from individual workers into a label for a data object. For more information, see
          `Annotation Consolidation
          <https://docs.aws.amazon.com/sagemaker/latest/dg/sms-annotation-consolidation.html>`__ .

        - **FailureReason** *(string) --*

          If the ``LabelingJobStatus`` field is ``Failed`` , this field contains a description of
          the error.

        - **LabelingJobOutput** *(dict) --*

          The location of the output produced by the labeling job.

          - **OutputDatasetS3Uri** *(string) --*

            The Amazon S3 bucket location of the manifest file for labeled data.

          - **FinalActiveLearningModelArn** *(string) --*

            The Amazon Resource Name (ARN) for the most recent Amazon SageMaker model trained as
            part of automated data labeling.

        - **InputConfig** *(dict) --*

          Input configuration for the labeling job.

          - **DataSource** *(dict) --*

            The location of the input data.

            - **S3DataSource** *(dict) --*

              The Amazon S3 location of the input data objects.

              - **ManifestS3Uri** *(string) --*

                The Amazon S3 location of the manifest file that describes the input data objects.

          - **DataAttributes** *(dict) --*

            Attributes of the data specified by the customer.

            - **ContentClassifiers** *(list) --*

              Declares that your content is free of personally identifiable information or adult
              content. Amazon SageMaker may restrict the Amazon Mechanical Turk workers that can
              view your task based on this information.

              - *(string) --*
    """


_ListModelPackagesPaginatePaginationConfigTypeDef = TypedDict(
    "_ListModelPackagesPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListModelPackagesPaginatePaginationConfigTypeDef(
    _ListModelPackagesPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListModelPackagesPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListModelPackagesPaginateResponseModelPackageSummaryListTypeDef = TypedDict(
    "_ListModelPackagesPaginateResponseModelPackageSummaryListTypeDef",
    {
        "ModelPackageName": str,
        "ModelPackageArn": str,
        "ModelPackageDescription": str,
        "CreationTime": datetime,
        "ModelPackageStatus": str,
    },
    total=False,
)


class ListModelPackagesPaginateResponseModelPackageSummaryListTypeDef(
    _ListModelPackagesPaginateResponseModelPackageSummaryListTypeDef
):
    """
    Type definition for `ListModelPackagesPaginateResponse` `ModelPackageSummaryList`

    Provides summary information about a model package.

    - **ModelPackageName** *(string) --*

      The name of the model package.

    - **ModelPackageArn** *(string) --*

      The Amazon Resource Name (ARN) of the model package.

    - **ModelPackageDescription** *(string) --*

      A brief description of the model package.

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the model package was created.

    - **ModelPackageStatus** *(string) --*

      The overall status of the model package.
    """


_ListModelPackagesPaginateResponseTypeDef = TypedDict(
    "_ListModelPackagesPaginateResponseTypeDef",
    {
        "ModelPackageSummaryList": List[
            ListModelPackagesPaginateResponseModelPackageSummaryListTypeDef
        ]
    },
    total=False,
)


class ListModelPackagesPaginateResponseTypeDef(
    _ListModelPackagesPaginateResponseTypeDef
):
    """
    Type definition for `ListModelPackagesPaginate` `Response`

    - **ModelPackageSummaryList** *(list) --*

      An array of ``ModelPackageSummary`` objects, each of which lists a model package.

      - *(dict) --*

        Provides summary information about a model package.

        - **ModelPackageName** *(string) --*

          The name of the model package.

        - **ModelPackageArn** *(string) --*

          The Amazon Resource Name (ARN) of the model package.

        - **ModelPackageDescription** *(string) --*

          A brief description of the model package.

        - **CreationTime** *(datetime) --*

          A timestamp that shows when the model package was created.

        - **ModelPackageStatus** *(string) --*

          The overall status of the model package.
    """


_ListModelsPaginatePaginationConfigTypeDef = TypedDict(
    "_ListModelsPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListModelsPaginatePaginationConfigTypeDef(
    _ListModelsPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListModelsPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListModelsPaginateResponseModelsTypeDef = TypedDict(
    "_ListModelsPaginateResponseModelsTypeDef",
    {"ModelName": str, "ModelArn": str, "CreationTime": datetime},
    total=False,
)


class ListModelsPaginateResponseModelsTypeDef(_ListModelsPaginateResponseModelsTypeDef):
    """
    Type definition for `ListModelsPaginateResponse` `Models`

    Provides summary information about a model.

    - **ModelName** *(string) --*

      The name of the model that you want a summary for.

    - **ModelArn** *(string) --*

      The Amazon Resource Name (ARN) of the model.

    - **CreationTime** *(datetime) --*

      A timestamp that indicates when the model was created.
    """


_ListModelsPaginateResponseTypeDef = TypedDict(
    "_ListModelsPaginateResponseTypeDef",
    {"Models": List[ListModelsPaginateResponseModelsTypeDef]},
    total=False,
)


class ListModelsPaginateResponseTypeDef(_ListModelsPaginateResponseTypeDef):
    """
    Type definition for `ListModelsPaginate` `Response`

    - **Models** *(list) --*

      An array of ``ModelSummary`` objects, each of which lists a model.

      - *(dict) --*

        Provides summary information about a model.

        - **ModelName** *(string) --*

          The name of the model that you want a summary for.

        - **ModelArn** *(string) --*

          The Amazon Resource Name (ARN) of the model.

        - **CreationTime** *(datetime) --*

          A timestamp that indicates when the model was created.
    """


_ListNotebookInstanceLifecycleConfigsPaginatePaginationConfigTypeDef = TypedDict(
    "_ListNotebookInstanceLifecycleConfigsPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListNotebookInstanceLifecycleConfigsPaginatePaginationConfigTypeDef(
    _ListNotebookInstanceLifecycleConfigsPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListNotebookInstanceLifecycleConfigsPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListNotebookInstanceLifecycleConfigsPaginateResponseNotebookInstanceLifecycleConfigsTypeDef = TypedDict(
    "_ListNotebookInstanceLifecycleConfigsPaginateResponseNotebookInstanceLifecycleConfigsTypeDef",
    {
        "NotebookInstanceLifecycleConfigName": str,
        "NotebookInstanceLifecycleConfigArn": str,
        "CreationTime": datetime,
        "LastModifiedTime": datetime,
    },
    total=False,
)


class ListNotebookInstanceLifecycleConfigsPaginateResponseNotebookInstanceLifecycleConfigsTypeDef(
    _ListNotebookInstanceLifecycleConfigsPaginateResponseNotebookInstanceLifecycleConfigsTypeDef
):
    """
    Type definition for `ListNotebookInstanceLifecycleConfigsPaginateResponse` `NotebookInstanceLifecycleConfigs`

    Provides a summary of a notebook instance lifecycle configuration.

    - **NotebookInstanceLifecycleConfigName** *(string) --*

      The name of the lifecycle configuration.

    - **NotebookInstanceLifecycleConfigArn** *(string) --*

      The Amazon Resource Name (ARN) of the lifecycle configuration.

    - **CreationTime** *(datetime) --*

      A timestamp that tells when the lifecycle configuration was created.

    - **LastModifiedTime** *(datetime) --*

      A timestamp that tells when the lifecycle configuration was last modified.
    """


_ListNotebookInstanceLifecycleConfigsPaginateResponseTypeDef = TypedDict(
    "_ListNotebookInstanceLifecycleConfigsPaginateResponseTypeDef",
    {
        "NotebookInstanceLifecycleConfigs": List[
            ListNotebookInstanceLifecycleConfigsPaginateResponseNotebookInstanceLifecycleConfigsTypeDef
        ]
    },
    total=False,
)


class ListNotebookInstanceLifecycleConfigsPaginateResponseTypeDef(
    _ListNotebookInstanceLifecycleConfigsPaginateResponseTypeDef
):
    """
    Type definition for `ListNotebookInstanceLifecycleConfigsPaginate` `Response`

    - **NotebookInstanceLifecycleConfigs** *(list) --*

      An array of ``NotebookInstanceLifecycleConfiguration`` objects, each listing a lifecycle
      configuration.

      - *(dict) --*

        Provides a summary of a notebook instance lifecycle configuration.

        - **NotebookInstanceLifecycleConfigName** *(string) --*

          The name of the lifecycle configuration.

        - **NotebookInstanceLifecycleConfigArn** *(string) --*

          The Amazon Resource Name (ARN) of the lifecycle configuration.

        - **CreationTime** *(datetime) --*

          A timestamp that tells when the lifecycle configuration was created.

        - **LastModifiedTime** *(datetime) --*

          A timestamp that tells when the lifecycle configuration was last modified.
    """


_ListNotebookInstancesPaginatePaginationConfigTypeDef = TypedDict(
    "_ListNotebookInstancesPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListNotebookInstancesPaginatePaginationConfigTypeDef(
    _ListNotebookInstancesPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListNotebookInstancesPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListNotebookInstancesPaginateResponseNotebookInstancesTypeDef = TypedDict(
    "_ListNotebookInstancesPaginateResponseNotebookInstancesTypeDef",
    {
        "NotebookInstanceName": str,
        "NotebookInstanceArn": str,
        "NotebookInstanceStatus": str,
        "Url": str,
        "InstanceType": str,
        "CreationTime": datetime,
        "LastModifiedTime": datetime,
        "NotebookInstanceLifecycleConfigName": str,
        "DefaultCodeRepository": str,
        "AdditionalCodeRepositories": List[str],
    },
    total=False,
)


class ListNotebookInstancesPaginateResponseNotebookInstancesTypeDef(
    _ListNotebookInstancesPaginateResponseNotebookInstancesTypeDef
):
    """
    Type definition for `ListNotebookInstancesPaginateResponse` `NotebookInstances`

    Provides summary information for an Amazon SageMaker notebook instance.

    - **NotebookInstanceName** *(string) --*

      The name of the notebook instance that you want a summary for.

    - **NotebookInstanceArn** *(string) --*

      The Amazon Resource Name (ARN) of the notebook instance.

    - **NotebookInstanceStatus** *(string) --*

      The status of the notebook instance.

    - **Url** *(string) --*

      The URL that you use to connect to the Jupyter instance running in your notebook instance.

    - **InstanceType** *(string) --*

      The type of ML compute instance that the notebook instance is running on.

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the notebook instance was created.

    - **LastModifiedTime** *(datetime) --*

      A timestamp that shows when the notebook instance was last modified.

    - **NotebookInstanceLifecycleConfigName** *(string) --*

      The name of a notebook instance lifecycle configuration associated with this notebook
      instance.

      For information about notebook instance lifestyle configurations, see `Step 2.1\\:
      (Optional) Customize a Notebook Instance
      <https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html>`__ .

    - **DefaultCodeRepository** *(string) --*

      The Git repository associated with the notebook instance as its default code repository.
      This can be either the name of a Git repository stored as a resource in your account, or
      the URL of a Git repository in `AWS CodeCommit
      <https://docs.aws.amazon.com/codecommit/latest/userguide/welcome.html>`__ or in any other
      Git repository. When you open a notebook instance, it opens in the directory that
      contains this repository. For more information, see `Associating Git Repositories with
      Amazon SageMaker Notebook Instances
      <https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-git-repo.html>`__ .

    - **AdditionalCodeRepositories** *(list) --*

      An array of up to three Git repositories associated with the notebook instance. These can
      be either the names of Git repositories stored as resources in your account, or the URL
      of Git repositories in `AWS CodeCommit
      <https://docs.aws.amazon.com/codecommit/latest/userguide/welcome.html>`__ or in any other
      Git repository. These repositories are cloned at the same level as the default repository
      of your notebook instance. For more information, see `Associating Git Repositories with
      Amazon SageMaker Notebook Instances
      <https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-git-repo.html>`__ .

      - *(string) --*
    """


_ListNotebookInstancesPaginateResponseTypeDef = TypedDict(
    "_ListNotebookInstancesPaginateResponseTypeDef",
    {
        "NotebookInstances": List[
            ListNotebookInstancesPaginateResponseNotebookInstancesTypeDef
        ]
    },
    total=False,
)


class ListNotebookInstancesPaginateResponseTypeDef(
    _ListNotebookInstancesPaginateResponseTypeDef
):
    """
    Type definition for `ListNotebookInstancesPaginate` `Response`

    - **NotebookInstances** *(list) --*

      An array of ``NotebookInstanceSummary`` objects, one for each notebook instance.

      - *(dict) --*

        Provides summary information for an Amazon SageMaker notebook instance.

        - **NotebookInstanceName** *(string) --*

          The name of the notebook instance that you want a summary for.

        - **NotebookInstanceArn** *(string) --*

          The Amazon Resource Name (ARN) of the notebook instance.

        - **NotebookInstanceStatus** *(string) --*

          The status of the notebook instance.

        - **Url** *(string) --*

          The URL that you use to connect to the Jupyter instance running in your notebook instance.

        - **InstanceType** *(string) --*

          The type of ML compute instance that the notebook instance is running on.

        - **CreationTime** *(datetime) --*

          A timestamp that shows when the notebook instance was created.

        - **LastModifiedTime** *(datetime) --*

          A timestamp that shows when the notebook instance was last modified.

        - **NotebookInstanceLifecycleConfigName** *(string) --*

          The name of a notebook instance lifecycle configuration associated with this notebook
          instance.

          For information about notebook instance lifestyle configurations, see `Step 2.1\\:
          (Optional) Customize a Notebook Instance
          <https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html>`__ .

        - **DefaultCodeRepository** *(string) --*

          The Git repository associated with the notebook instance as its default code repository.
          This can be either the name of a Git repository stored as a resource in your account, or
          the URL of a Git repository in `AWS CodeCommit
          <https://docs.aws.amazon.com/codecommit/latest/userguide/welcome.html>`__ or in any other
          Git repository. When you open a notebook instance, it opens in the directory that
          contains this repository. For more information, see `Associating Git Repositories with
          Amazon SageMaker Notebook Instances
          <https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-git-repo.html>`__ .

        - **AdditionalCodeRepositories** *(list) --*

          An array of up to three Git repositories associated with the notebook instance. These can
          be either the names of Git repositories stored as resources in your account, or the URL
          of Git repositories in `AWS CodeCommit
          <https://docs.aws.amazon.com/codecommit/latest/userguide/welcome.html>`__ or in any other
          Git repository. These repositories are cloned at the same level as the default repository
          of your notebook instance. For more information, see `Associating Git Repositories with
          Amazon SageMaker Notebook Instances
          <https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-git-repo.html>`__ .

          - *(string) --*
    """


_ListSubscribedWorkteamsPaginatePaginationConfigTypeDef = TypedDict(
    "_ListSubscribedWorkteamsPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListSubscribedWorkteamsPaginatePaginationConfigTypeDef(
    _ListSubscribedWorkteamsPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListSubscribedWorkteamsPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListSubscribedWorkteamsPaginateResponseSubscribedWorkteamsTypeDef = TypedDict(
    "_ListSubscribedWorkteamsPaginateResponseSubscribedWorkteamsTypeDef",
    {
        "WorkteamArn": str,
        "MarketplaceTitle": str,
        "SellerName": str,
        "MarketplaceDescription": str,
        "ListingId": str,
    },
    total=False,
)


class ListSubscribedWorkteamsPaginateResponseSubscribedWorkteamsTypeDef(
    _ListSubscribedWorkteamsPaginateResponseSubscribedWorkteamsTypeDef
):
    """
    Type definition for `ListSubscribedWorkteamsPaginateResponse` `SubscribedWorkteams`

    Describes a work team of a vendor that does the a labelling job.

    - **WorkteamArn** *(string) --*

      The Amazon Resource Name (ARN) of the vendor that you have subscribed.

    - **MarketplaceTitle** *(string) --*

      The title of the service provided by the vendor in the Amazon Marketplace.

    - **SellerName** *(string) --*

      The name of the vendor in the Amazon Marketplace.

    - **MarketplaceDescription** *(string) --*

      The description of the vendor from the Amazon Marketplace.

    - **ListingId** *(string) --*
    """


_ListSubscribedWorkteamsPaginateResponseTypeDef = TypedDict(
    "_ListSubscribedWorkteamsPaginateResponseTypeDef",
    {
        "SubscribedWorkteams": List[
            ListSubscribedWorkteamsPaginateResponseSubscribedWorkteamsTypeDef
        ]
    },
    total=False,
)


class ListSubscribedWorkteamsPaginateResponseTypeDef(
    _ListSubscribedWorkteamsPaginateResponseTypeDef
):
    """
    Type definition for `ListSubscribedWorkteamsPaginate` `Response`

    - **SubscribedWorkteams** *(list) --*

      An array of ``Workteam`` objects, each describing a work team.

      - *(dict) --*

        Describes a work team of a vendor that does the a labelling job.

        - **WorkteamArn** *(string) --*

          The Amazon Resource Name (ARN) of the vendor that you have subscribed.

        - **MarketplaceTitle** *(string) --*

          The title of the service provided by the vendor in the Amazon Marketplace.

        - **SellerName** *(string) --*

          The name of the vendor in the Amazon Marketplace.

        - **MarketplaceDescription** *(string) --*

          The description of the vendor from the Amazon Marketplace.

        - **ListingId** *(string) --*
    """


_ListTagsPaginatePaginationConfigTypeDef = TypedDict(
    "_ListTagsPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListTagsPaginatePaginationConfigTypeDef(_ListTagsPaginatePaginationConfigTypeDef):
    """
    Type definition for `ListTagsPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListTagsPaginateResponseTagsTypeDef = TypedDict(
    "_ListTagsPaginateResponseTagsTypeDef", {"Key": str, "Value": str}, total=False
)


class ListTagsPaginateResponseTagsTypeDef(_ListTagsPaginateResponseTagsTypeDef):
    """
    Type definition for `ListTagsPaginateResponse` `Tags`

    Describes a tag.

    - **Key** *(string) --*

      The tag key.

    - **Value** *(string) --*

      The tag value.
    """


_ListTagsPaginateResponseTypeDef = TypedDict(
    "_ListTagsPaginateResponseTypeDef",
    {"Tags": List[ListTagsPaginateResponseTagsTypeDef]},
    total=False,
)


class ListTagsPaginateResponseTypeDef(_ListTagsPaginateResponseTypeDef):
    """
    Type definition for `ListTagsPaginate` `Response`

    - **Tags** *(list) --*

      An array of ``Tag`` objects, each with a tag key and a value.

      - *(dict) --*

        Describes a tag.

        - **Key** *(string) --*

          The tag key.

        - **Value** *(string) --*

          The tag value.
    """


_ListTrainingJobsForHyperParameterTuningJobPaginatePaginationConfigTypeDef = TypedDict(
    "_ListTrainingJobsForHyperParameterTuningJobPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListTrainingJobsForHyperParameterTuningJobPaginatePaginationConfigTypeDef(
    _ListTrainingJobsForHyperParameterTuningJobPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListTrainingJobsForHyperParameterTuningJobPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListTrainingJobsForHyperParameterTuningJobPaginateResponseTrainingJobSummariesFinalHyperParameterTuningJobObjectiveMetricTypeDef = TypedDict(
    "_ListTrainingJobsForHyperParameterTuningJobPaginateResponseTrainingJobSummariesFinalHyperParameterTuningJobObjectiveMetricTypeDef",
    {"Type": str, "MetricName": str, "Value": float},
    total=False,
)


class ListTrainingJobsForHyperParameterTuningJobPaginateResponseTrainingJobSummariesFinalHyperParameterTuningJobObjectiveMetricTypeDef(
    _ListTrainingJobsForHyperParameterTuningJobPaginateResponseTrainingJobSummariesFinalHyperParameterTuningJobObjectiveMetricTypeDef
):
    """
    Type definition for `ListTrainingJobsForHyperParameterTuningJobPaginateResponseTrainingJobSummaries` `FinalHyperParameterTuningJobObjectiveMetric`

    The  FinalHyperParameterTuningJobObjectiveMetric object that specifies the value of the
    objective metric of the tuning job that launched this training job.

    - **Type** *(string) --*

      Whether to minimize or maximize the objective metric. Valid values are Minimize and
      Maximize.

    - **MetricName** *(string) --*

      The name of the objective metric.

    - **Value** *(float) --*

      The value of the objective metric.
    """


_ListTrainingJobsForHyperParameterTuningJobPaginateResponseTrainingJobSummariesTypeDef = TypedDict(
    "_ListTrainingJobsForHyperParameterTuningJobPaginateResponseTrainingJobSummariesTypeDef",
    {
        "TrainingJobName": str,
        "TrainingJobArn": str,
        "TuningJobName": str,
        "CreationTime": datetime,
        "TrainingStartTime": datetime,
        "TrainingEndTime": datetime,
        "TrainingJobStatus": str,
        "TunedHyperParameters": Dict[str, str],
        "FailureReason": str,
        "FinalHyperParameterTuningJobObjectiveMetric": ListTrainingJobsForHyperParameterTuningJobPaginateResponseTrainingJobSummariesFinalHyperParameterTuningJobObjectiveMetricTypeDef,
        "ObjectiveStatus": str,
    },
    total=False,
)


class ListTrainingJobsForHyperParameterTuningJobPaginateResponseTrainingJobSummariesTypeDef(
    _ListTrainingJobsForHyperParameterTuningJobPaginateResponseTrainingJobSummariesTypeDef
):
    """
    Type definition for `ListTrainingJobsForHyperParameterTuningJobPaginateResponse` `TrainingJobSummaries`

    Specifies summary information about a training job.

    - **TrainingJobName** *(string) --*

      The name of the training job.

    - **TrainingJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the training job.

    - **TuningJobName** *(string) --*

      The HyperParameter tuning job that launched the training job.

    - **CreationTime** *(datetime) --*

      The date and time that the training job was created.

    - **TrainingStartTime** *(datetime) --*

      The date and time that the training job started.

    - **TrainingEndTime** *(datetime) --*

      Specifies the time when the training job ends on training instances. You are billed for
      the time interval between the value of ``TrainingStartTime`` and this time. For
      successful jobs and stopped jobs, this is the time after model artifacts are uploaded.
      For failed jobs, this is the time when Amazon SageMaker detects a job failure.

    - **TrainingJobStatus** *(string) --*

      The status of the training job.

    - **TunedHyperParameters** *(dict) --*

      A list of the hyperparameters for which you specified ranges to search.

      - *(string) --*

        - *(string) --*

    - **FailureReason** *(string) --*

      The reason that the training job failed.

    - **FinalHyperParameterTuningJobObjectiveMetric** *(dict) --*

      The  FinalHyperParameterTuningJobObjectiveMetric object that specifies the value of the
      objective metric of the tuning job that launched this training job.

      - **Type** *(string) --*

        Whether to minimize or maximize the objective metric. Valid values are Minimize and
        Maximize.

      - **MetricName** *(string) --*

        The name of the objective metric.

      - **Value** *(float) --*

        The value of the objective metric.

    - **ObjectiveStatus** *(string) --*

      The status of the objective metric for the training job:

      * Succeeded: The final objective metric for the training job was evaluated by the
      hyperparameter tuning job and used in the hyperparameter tuning process.

      * Pending: The training job is in progress and evaluation of its final objective metric
      is pending.

      * Failed: The final objective metric for the training job was not evaluated, and was not
      used in the hyperparameter tuning process. This typically occurs when the training job
      failed or did not emit an objective metric.
    """


_ListTrainingJobsForHyperParameterTuningJobPaginateResponseTypeDef = TypedDict(
    "_ListTrainingJobsForHyperParameterTuningJobPaginateResponseTypeDef",
    {
        "TrainingJobSummaries": List[
            ListTrainingJobsForHyperParameterTuningJobPaginateResponseTrainingJobSummariesTypeDef
        ]
    },
    total=False,
)


class ListTrainingJobsForHyperParameterTuningJobPaginateResponseTypeDef(
    _ListTrainingJobsForHyperParameterTuningJobPaginateResponseTypeDef
):
    """
    Type definition for `ListTrainingJobsForHyperParameterTuningJobPaginate` `Response`

    - **TrainingJobSummaries** *(list) --*

      A list of  TrainingJobSummary objects that describe the training jobs that the
      ``ListTrainingJobsForHyperParameterTuningJob`` request returned.

      - *(dict) --*

        Specifies summary information about a training job.

        - **TrainingJobName** *(string) --*

          The name of the training job.

        - **TrainingJobArn** *(string) --*

          The Amazon Resource Name (ARN) of the training job.

        - **TuningJobName** *(string) --*

          The HyperParameter tuning job that launched the training job.

        - **CreationTime** *(datetime) --*

          The date and time that the training job was created.

        - **TrainingStartTime** *(datetime) --*

          The date and time that the training job started.

        - **TrainingEndTime** *(datetime) --*

          Specifies the time when the training job ends on training instances. You are billed for
          the time interval between the value of ``TrainingStartTime`` and this time. For
          successful jobs and stopped jobs, this is the time after model artifacts are uploaded.
          For failed jobs, this is the time when Amazon SageMaker detects a job failure.

        - **TrainingJobStatus** *(string) --*

          The status of the training job.

        - **TunedHyperParameters** *(dict) --*

          A list of the hyperparameters for which you specified ranges to search.

          - *(string) --*

            - *(string) --*

        - **FailureReason** *(string) --*

          The reason that the training job failed.

        - **FinalHyperParameterTuningJobObjectiveMetric** *(dict) --*

          The  FinalHyperParameterTuningJobObjectiveMetric object that specifies the value of the
          objective metric of the tuning job that launched this training job.

          - **Type** *(string) --*

            Whether to minimize or maximize the objective metric. Valid values are Minimize and
            Maximize.

          - **MetricName** *(string) --*

            The name of the objective metric.

          - **Value** *(float) --*

            The value of the objective metric.

        - **ObjectiveStatus** *(string) --*

          The status of the objective metric for the training job:

          * Succeeded: The final objective metric for the training job was evaluated by the
          hyperparameter tuning job and used in the hyperparameter tuning process.

          * Pending: The training job is in progress and evaluation of its final objective metric
          is pending.

          * Failed: The final objective metric for the training job was not evaluated, and was not
          used in the hyperparameter tuning process. This typically occurs when the training job
          failed or did not emit an objective metric.
    """


_ListTrainingJobsPaginatePaginationConfigTypeDef = TypedDict(
    "_ListTrainingJobsPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListTrainingJobsPaginatePaginationConfigTypeDef(
    _ListTrainingJobsPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListTrainingJobsPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListTrainingJobsPaginateResponseTrainingJobSummariesTypeDef = TypedDict(
    "_ListTrainingJobsPaginateResponseTrainingJobSummariesTypeDef",
    {
        "TrainingJobName": str,
        "TrainingJobArn": str,
        "CreationTime": datetime,
        "TrainingEndTime": datetime,
        "LastModifiedTime": datetime,
        "TrainingJobStatus": str,
    },
    total=False,
)


class ListTrainingJobsPaginateResponseTrainingJobSummariesTypeDef(
    _ListTrainingJobsPaginateResponseTrainingJobSummariesTypeDef
):
    """
    Type definition for `ListTrainingJobsPaginateResponse` `TrainingJobSummaries`

    Provides summary information about a training job.

    - **TrainingJobName** *(string) --*

      The name of the training job that you want a summary for.

    - **TrainingJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the training job.

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the training job was created.

    - **TrainingEndTime** *(datetime) --*

      A timestamp that shows when the training job ended. This field is set only if the
      training job has one of the terminal statuses (``Completed`` , ``Failed`` , or
      ``Stopped`` ).

    - **LastModifiedTime** *(datetime) --*

      Timestamp when the training job was last modified.

    - **TrainingJobStatus** *(string) --*

      The status of the training job.
    """


_ListTrainingJobsPaginateResponseTypeDef = TypedDict(
    "_ListTrainingJobsPaginateResponseTypeDef",
    {
        "TrainingJobSummaries": List[
            ListTrainingJobsPaginateResponseTrainingJobSummariesTypeDef
        ]
    },
    total=False,
)


class ListTrainingJobsPaginateResponseTypeDef(_ListTrainingJobsPaginateResponseTypeDef):
    """
    Type definition for `ListTrainingJobsPaginate` `Response`

    - **TrainingJobSummaries** *(list) --*

      An array of ``TrainingJobSummary`` objects, each listing a training job.

      - *(dict) --*

        Provides summary information about a training job.

        - **TrainingJobName** *(string) --*

          The name of the training job that you want a summary for.

        - **TrainingJobArn** *(string) --*

          The Amazon Resource Name (ARN) of the training job.

        - **CreationTime** *(datetime) --*

          A timestamp that shows when the training job was created.

        - **TrainingEndTime** *(datetime) --*

          A timestamp that shows when the training job ended. This field is set only if the
          training job has one of the terminal statuses (``Completed`` , ``Failed`` , or
          ``Stopped`` ).

        - **LastModifiedTime** *(datetime) --*

          Timestamp when the training job was last modified.

        - **TrainingJobStatus** *(string) --*

          The status of the training job.
    """


_ListTransformJobsPaginatePaginationConfigTypeDef = TypedDict(
    "_ListTransformJobsPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListTransformJobsPaginatePaginationConfigTypeDef(
    _ListTransformJobsPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListTransformJobsPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListTransformJobsPaginateResponseTransformJobSummariesTypeDef = TypedDict(
    "_ListTransformJobsPaginateResponseTransformJobSummariesTypeDef",
    {
        "TransformJobName": str,
        "TransformJobArn": str,
        "CreationTime": datetime,
        "TransformEndTime": datetime,
        "LastModifiedTime": datetime,
        "TransformJobStatus": str,
        "FailureReason": str,
    },
    total=False,
)


class ListTransformJobsPaginateResponseTransformJobSummariesTypeDef(
    _ListTransformJobsPaginateResponseTransformJobSummariesTypeDef
):
    """
    Type definition for `ListTransformJobsPaginateResponse` `TransformJobSummaries`

    Provides a summary of a transform job. Multiple ``TransformJobSummary`` objects are
    returned as a list after in response to a  ListTransformJobs call.

    - **TransformJobName** *(string) --*

      The name of the transform job.

    - **TransformJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the transform job.

    - **CreationTime** *(datetime) --*

      A timestamp that shows when the transform Job was created.

    - **TransformEndTime** *(datetime) --*

      Indicates when the transform job ends on compute instances. For successful jobs and
      stopped jobs, this is the exact time recorded after the results are uploaded. For failed
      jobs, this is when Amazon SageMaker detected that the job failed.

    - **LastModifiedTime** *(datetime) --*

      Indicates when the transform job was last modified.

    - **TransformJobStatus** *(string) --*

      The status of the transform job.

    - **FailureReason** *(string) --*

      If the transform job failed, the reason it failed.
    """


_ListTransformJobsPaginateResponseTypeDef = TypedDict(
    "_ListTransformJobsPaginateResponseTypeDef",
    {
        "TransformJobSummaries": List[
            ListTransformJobsPaginateResponseTransformJobSummariesTypeDef
        ]
    },
    total=False,
)


class ListTransformJobsPaginateResponseTypeDef(
    _ListTransformJobsPaginateResponseTypeDef
):
    """
    Type definition for `ListTransformJobsPaginate` `Response`

    - **TransformJobSummaries** *(list) --*

      An array of ``TransformJobSummary`` objects.

      - *(dict) --*

        Provides a summary of a transform job. Multiple ``TransformJobSummary`` objects are
        returned as a list after in response to a  ListTransformJobs call.

        - **TransformJobName** *(string) --*

          The name of the transform job.

        - **TransformJobArn** *(string) --*

          The Amazon Resource Name (ARN) of the transform job.

        - **CreationTime** *(datetime) --*

          A timestamp that shows when the transform Job was created.

        - **TransformEndTime** *(datetime) --*

          Indicates when the transform job ends on compute instances. For successful jobs and
          stopped jobs, this is the exact time recorded after the results are uploaded. For failed
          jobs, this is when Amazon SageMaker detected that the job failed.

        - **LastModifiedTime** *(datetime) --*

          Indicates when the transform job was last modified.

        - **TransformJobStatus** *(string) --*

          The status of the transform job.

        - **FailureReason** *(string) --*

          If the transform job failed, the reason it failed.
    """


_ListWorkteamsPaginatePaginationConfigTypeDef = TypedDict(
    "_ListWorkteamsPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class ListWorkteamsPaginatePaginationConfigTypeDef(
    _ListWorkteamsPaginatePaginationConfigTypeDef
):
    """
    Type definition for `ListWorkteamsPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_ListWorkteamsPaginateResponseWorkteamsMemberDefinitionsCognitoMemberDefinitionTypeDef = TypedDict(
    "_ListWorkteamsPaginateResponseWorkteamsMemberDefinitionsCognitoMemberDefinitionTypeDef",
    {"UserPool": str, "UserGroup": str, "ClientId": str},
    total=False,
)


class ListWorkteamsPaginateResponseWorkteamsMemberDefinitionsCognitoMemberDefinitionTypeDef(
    _ListWorkteamsPaginateResponseWorkteamsMemberDefinitionsCognitoMemberDefinitionTypeDef
):
    """
    Type definition for `ListWorkteamsPaginateResponseWorkteamsMemberDefinitions` `CognitoMemberDefinition`

    The Amazon Cognito user group that is part of the work team.

    - **UserPool** *(string) --*

      An identifier for a user pool. The user pool must be in the same region as the
      service that you are calling.

    - **UserGroup** *(string) --*

      An identifier for a user group.

    - **ClientId** *(string) --*

      An identifier for an application client. You must create the app client ID using
      Amazon Cognito.
    """


_ListWorkteamsPaginateResponseWorkteamsMemberDefinitionsTypeDef = TypedDict(
    "_ListWorkteamsPaginateResponseWorkteamsMemberDefinitionsTypeDef",
    {
        "CognitoMemberDefinition": ListWorkteamsPaginateResponseWorkteamsMemberDefinitionsCognitoMemberDefinitionTypeDef
    },
    total=False,
)


class ListWorkteamsPaginateResponseWorkteamsMemberDefinitionsTypeDef(
    _ListWorkteamsPaginateResponseWorkteamsMemberDefinitionsTypeDef
):
    """
    Type definition for `ListWorkteamsPaginateResponseWorkteams` `MemberDefinitions`

    Defines the Amazon Cognito user group that is part of a work team.

    - **CognitoMemberDefinition** *(dict) --*

      The Amazon Cognito user group that is part of the work team.

      - **UserPool** *(string) --*

        An identifier for a user pool. The user pool must be in the same region as the
        service that you are calling.

      - **UserGroup** *(string) --*

        An identifier for a user group.

      - **ClientId** *(string) --*

        An identifier for an application client. You must create the app client ID using
        Amazon Cognito.
    """


_ListWorkteamsPaginateResponseWorkteamsNotificationConfigurationTypeDef = TypedDict(
    "_ListWorkteamsPaginateResponseWorkteamsNotificationConfigurationTypeDef",
    {"NotificationTopicArn": str},
    total=False,
)


class ListWorkteamsPaginateResponseWorkteamsNotificationConfigurationTypeDef(
    _ListWorkteamsPaginateResponseWorkteamsNotificationConfigurationTypeDef
):
    """
    Type definition for `ListWorkteamsPaginateResponseWorkteams` `NotificationConfiguration`

    Configures SNS notifications of available or expiring work items for work teams.

    - **NotificationTopicArn** *(string) --*

      The ARN for the SNS topic to which notifications should be published.
    """


_ListWorkteamsPaginateResponseWorkteamsTypeDef = TypedDict(
    "_ListWorkteamsPaginateResponseWorkteamsTypeDef",
    {
        "WorkteamName": str,
        "MemberDefinitions": List[
            ListWorkteamsPaginateResponseWorkteamsMemberDefinitionsTypeDef
        ],
        "WorkteamArn": str,
        "ProductListingIds": List[str],
        "Description": str,
        "SubDomain": str,
        "CreateDate": datetime,
        "LastUpdatedDate": datetime,
        "NotificationConfiguration": ListWorkteamsPaginateResponseWorkteamsNotificationConfigurationTypeDef,
    },
    total=False,
)


class ListWorkteamsPaginateResponseWorkteamsTypeDef(
    _ListWorkteamsPaginateResponseWorkteamsTypeDef
):
    """
    Type definition for `ListWorkteamsPaginateResponse` `Workteams`

    Provides details about a labeling work team.

    - **WorkteamName** *(string) --*

      The name of the work team.

    - **MemberDefinitions** *(list) --*

      The Amazon Cognito user groups that make up the work team.

      - *(dict) --*

        Defines the Amazon Cognito user group that is part of a work team.

        - **CognitoMemberDefinition** *(dict) --*

          The Amazon Cognito user group that is part of the work team.

          - **UserPool** *(string) --*

            An identifier for a user pool. The user pool must be in the same region as the
            service that you are calling.

          - **UserGroup** *(string) --*

            An identifier for a user group.

          - **ClientId** *(string) --*

            An identifier for an application client. You must create the app client ID using
            Amazon Cognito.

    - **WorkteamArn** *(string) --*

      The Amazon Resource Name (ARN) that identifies the work team.

    - **ProductListingIds** *(list) --*

      The Amazon Marketplace identifier for a vendor's work team.

      - *(string) --*

    - **Description** *(string) --*

      A description of the work team.

    - **SubDomain** *(string) --*

      The URI of the labeling job's user interface. Workers open this URI to start labeling
      your data objects.

    - **CreateDate** *(datetime) --*

      The date and time that the work team was created (timestamp).

    - **LastUpdatedDate** *(datetime) --*

      The date and time that the work team was last updated (timestamp).

    - **NotificationConfiguration** *(dict) --*

      Configures SNS notifications of available or expiring work items for work teams.

      - **NotificationTopicArn** *(string) --*

        The ARN for the SNS topic to which notifications should be published.
    """


_ListWorkteamsPaginateResponseTypeDef = TypedDict(
    "_ListWorkteamsPaginateResponseTypeDef",
    {"Workteams": List[ListWorkteamsPaginateResponseWorkteamsTypeDef]},
    total=False,
)


class ListWorkteamsPaginateResponseTypeDef(_ListWorkteamsPaginateResponseTypeDef):
    """
    Type definition for `ListWorkteamsPaginate` `Response`

    - **Workteams** *(list) --*

      An array of ``Workteam`` objects, each describing a work team.

      - *(dict) --*

        Provides details about a labeling work team.

        - **WorkteamName** *(string) --*

          The name of the work team.

        - **MemberDefinitions** *(list) --*

          The Amazon Cognito user groups that make up the work team.

          - *(dict) --*

            Defines the Amazon Cognito user group that is part of a work team.

            - **CognitoMemberDefinition** *(dict) --*

              The Amazon Cognito user group that is part of the work team.

              - **UserPool** *(string) --*

                An identifier for a user pool. The user pool must be in the same region as the
                service that you are calling.

              - **UserGroup** *(string) --*

                An identifier for a user group.

              - **ClientId** *(string) --*

                An identifier for an application client. You must create the app client ID using
                Amazon Cognito.

        - **WorkteamArn** *(string) --*

          The Amazon Resource Name (ARN) that identifies the work team.

        - **ProductListingIds** *(list) --*

          The Amazon Marketplace identifier for a vendor's work team.

          - *(string) --*

        - **Description** *(string) --*

          A description of the work team.

        - **SubDomain** *(string) --*

          The URI of the labeling job's user interface. Workers open this URI to start labeling
          your data objects.

        - **CreateDate** *(datetime) --*

          The date and time that the work team was created (timestamp).

        - **LastUpdatedDate** *(datetime) --*

          The date and time that the work team was last updated (timestamp).

        - **NotificationConfiguration** *(dict) --*

          Configures SNS notifications of available or expiring work items for work teams.

          - **NotificationTopicArn** *(string) --*

            The ARN for the SNS topic to which notifications should be published.
    """


_NotebookInstanceDeletedWaitWaiterConfigTypeDef = TypedDict(
    "_NotebookInstanceDeletedWaitWaiterConfigTypeDef",
    {"Delay": int, "MaxAttempts": int},
    total=False,
)


class NotebookInstanceDeletedWaitWaiterConfigTypeDef(
    _NotebookInstanceDeletedWaitWaiterConfigTypeDef
):
    """
    Type definition for `NotebookInstanceDeletedWait` `WaiterConfig`

    A dictionary that provides parameters to control waiting behavior.

    - **Delay** *(integer) --*

      The amount of time in seconds to wait between attempts. Default: 30

    - **MaxAttempts** *(integer) --*

      The maximum number of attempts to be made. Default: 60
    """


_NotebookInstanceInServiceWaitWaiterConfigTypeDef = TypedDict(
    "_NotebookInstanceInServiceWaitWaiterConfigTypeDef",
    {"Delay": int, "MaxAttempts": int},
    total=False,
)


class NotebookInstanceInServiceWaitWaiterConfigTypeDef(
    _NotebookInstanceInServiceWaitWaiterConfigTypeDef
):
    """
    Type definition for `NotebookInstanceInServiceWait` `WaiterConfig`

    A dictionary that provides parameters to control waiting behavior.

    - **Delay** *(integer) --*

      The amount of time in seconds to wait between attempts. Default: 30

    - **MaxAttempts** *(integer) --*

      The maximum number of attempts to be made. Default: 60
    """


_NotebookInstanceStoppedWaitWaiterConfigTypeDef = TypedDict(
    "_NotebookInstanceStoppedWaitWaiterConfigTypeDef",
    {"Delay": int, "MaxAttempts": int},
    total=False,
)


class NotebookInstanceStoppedWaitWaiterConfigTypeDef(
    _NotebookInstanceStoppedWaitWaiterConfigTypeDef
):
    """
    Type definition for `NotebookInstanceStoppedWait` `WaiterConfig`

    A dictionary that provides parameters to control waiting behavior.

    - **Delay** *(integer) --*

      The amount of time in seconds to wait between attempts. Default: 30

    - **MaxAttempts** *(integer) --*

      The maximum number of attempts to be made. Default: 60
    """


_SearchPaginatePaginationConfigTypeDef = TypedDict(
    "_SearchPaginatePaginationConfigTypeDef",
    {"MaxItems": int, "PageSize": int, "StartingToken": str},
    total=False,
)


class SearchPaginatePaginationConfigTypeDef(_SearchPaginatePaginationConfigTypeDef):
    """
    Type definition for `SearchPaginate` `PaginationConfig`

    A dictionary that provides parameters to control pagination.

    - **MaxItems** *(integer) --*

      The total number of items to return. If the total number of items available is more than the
      value specified in max-items then a ``NextToken`` will be provided in the output that you can
      use to resume pagination.

    - **PageSize** *(integer) --*

      The size of each page.

    - **StartingToken** *(string) --*

      A token to specify where to start paginating. This is the ``NextToken`` from a previous
      response.
    """


_SearchPaginateResponseResultsTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef",
    {"Name": str, "Regex": str},
    total=False,
)


class SearchPaginateResponseResultsTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef(
    _SearchPaginateResponseResultsTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef
):
    """
    Type definition for `SearchPaginateResponseResultsTrainingJobAlgorithmSpecification` `MetricDefinitions`

    Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
    Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
    metric that a hyperparameter tuning job uses as its objective metric to choose the
    best training job.

    - **Name** *(string) --*

      The name of the metric.

    - **Regex** *(string) --*

      A regular expression that searches the output of a training job and gets the
      value of the metric. For more information about using regular expressions to
      define metrics, see `Defining Objective Metrics
      <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
      .
    """


_SearchPaginateResponseResultsTrainingJobAlgorithmSpecificationTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTrainingJobAlgorithmSpecificationTypeDef",
    {
        "TrainingImage": str,
        "AlgorithmName": str,
        "TrainingInputMode": str,
        "MetricDefinitions": List[
            SearchPaginateResponseResultsTrainingJobAlgorithmSpecificationMetricDefinitionsTypeDef
        ],
    },
    total=False,
)


class SearchPaginateResponseResultsTrainingJobAlgorithmSpecificationTypeDef(
    _SearchPaginateResponseResultsTrainingJobAlgorithmSpecificationTypeDef
):
    """
    Type definition for `SearchPaginateResponseResultsTrainingJob` `AlgorithmSpecification`

    Information about the algorithm used for training, and algorithm metadata.

    - **TrainingImage** *(string) --*

      The registry path of the Docker image that contains the training algorithm. For
      information about docker registry paths for built-in algorithms, see `Algorithms
      Provided by Amazon SageMaker\\: Common Parameters
      <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
      . Amazon SageMaker supports both ``registry/repository[:tag]`` and
      ``registry/repository[@digest]`` image path formats. For more information, see `Using
      Your Own Algorithms with Amazon SageMaker
      <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

    - **AlgorithmName** *(string) --*

      The name of the algorithm resource to use for the training job. This must be an
      algorithm resource that you created or subscribe to on AWS Marketplace. If you
      specify a value for this parameter, you can't specify a value for ``TrainingImage`` .

    - **TrainingInputMode** *(string) --*

      The input mode that the algorithm supports. For the input modes that Amazon SageMaker
      algorithms support, see `Algorithms
      <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ . If an algorithm
      supports the ``File`` input mode, Amazon SageMaker downloads the training data from
      S3 to the provisioned ML storage Volume, and mounts the directory to docker volume
      for training container. If an algorithm supports the ``Pipe`` input mode, Amazon
      SageMaker streams data directly from S3 to the container.

      In File mode, make sure you provision ML storage volume with sufficient capacity to
      accommodate the data download from S3. In addition to the training data, the ML
      storage volume also stores the output model. The algorithm container use ML storage
      volume to also store intermediate information, if any.

      For distributed algorithms using File mode, training data is distributed uniformly,
      and your training duration is predictable if the input data objects size is
      approximately same. Amazon SageMaker does not split the files any further for model
      training. If the object sizes are skewed, training won't be optimal as the data
      distribution is also skewed where one host in a training cluster is overloaded, thus
      becoming bottleneck in training.

    - **MetricDefinitions** *(list) --*

      A list of metric definition objects. Each object specifies the metric name and
      regular expressions used to parse algorithm logs. Amazon SageMaker publishes each
      metric to Amazon CloudWatch.

      - *(dict) --*

        Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
        Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
        metric that a hyperparameter tuning job uses as its objective metric to choose the
        best training job.

        - **Name** *(string) --*

          The name of the metric.

        - **Regex** *(string) --*

          A regular expression that searches the output of a training job and gets the
          value of the metric. For more information about using regular expressions to
          define metrics, see `Defining Objective Metrics
          <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
          .
    """


_SearchPaginateResponseResultsTrainingJobFinalMetricDataListTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTrainingJobFinalMetricDataListTypeDef",
    {"MetricName": str, "Value": float, "Timestamp": datetime},
    total=False,
)


class SearchPaginateResponseResultsTrainingJobFinalMetricDataListTypeDef(
    _SearchPaginateResponseResultsTrainingJobFinalMetricDataListTypeDef
):
    """
    Type definition for `SearchPaginateResponseResultsTrainingJob` `FinalMetricDataList`

    The name, value, and date and time of a metric that was emitted to Amazon CloudWatch.

    - **MetricName** *(string) --*

      The name of the metric.

    - **Value** *(float) --*

      The value of the metric.

    - **Timestamp** *(datetime) --*

      The date and time that the algorithm emitted the metric.
    """


_SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef",
    {
        "FileSystemId": str,
        "FileSystemAccessMode": str,
        "FileSystemType": str,
        "DirectoryPath": str,
    },
    total=False,
)


class SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef(
    _SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef
):
    """
    Type definition for `SearchPaginateResponseResultsTrainingJobInputDataConfigDataSource` `FileSystemDataSource`

    The file system that is associated with a channel.

    - **FileSystemId** *(string) --*

      The file system id.

    - **FileSystemAccessMode** *(string) --*

      The access mode of the mount of the directory associated with the channel. A
      directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
      mode.

    - **FileSystemType** *(string) --*

      The file system type.

    - **DirectoryPath** *(string) --*

      The full path to the directory to associate with the channel.
    """


_SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef",
    {
        "S3DataType": str,
        "S3Uri": str,
        "S3DataDistributionType": str,
        "AttributeNames": List[str],
    },
    total=False,
)


class SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef(
    _SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef
):
    """
    Type definition for `SearchPaginateResponseResultsTrainingJobInputDataConfigDataSource` `S3DataSource`

    The S3 location of the data source that is associated with a channel.

    - **S3DataType** *(string) --*

      If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
      SageMaker uses all objects that match the specified key name prefix for model
      training.

      If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
      manifest file containing a list of object keys that you want Amazon SageMaker
      to use for model training.

      If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
      augmented manifest file in JSON lines format. This file contains the data you
      want to use for model training. ``AugmentedManifestFile`` can only be used if
      the Channel's input mode is ``Pipe`` .

    - **S3Uri** *(string) --*

      Depending on the value specified for the ``S3DataType`` , identifies either a
      key name prefix or a manifest. For example:

      * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

      * A manifest might look like this: ``s3://bucketname/example.manifest``   The
      manifest is an S3 object which is a JSON file with the following format:  The
      preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
      "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
       ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
        ``]``   The preceding JSON matches the following ``s3Uris`` :
        ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
        ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
        set of ``s3uris`` in this manifest is the input data for the channel for this
        datasource. The object that each ``s3uris`` points to must be readable by the
        IAM role that Amazon SageMaker uses to perform tasks on your behalf.

    - **S3DataDistributionType** *(string) --*

      If you want Amazon SageMaker to replicate the entire dataset on each ML compute
      instance that is launched for model training, specify ``FullyReplicated`` .

      If you want Amazon SageMaker to replicate a subset of data on each ML compute
      instance that is launched for model training, specify ``ShardedByS3Key`` . If
      there are *n* ML compute instances launched for a training job, each instance
      gets approximately 1/*n* of the number of S3 objects. In this case, model
      training on each machine uses only the subset of training data.

      Don't choose more ML compute instances for training than available S3 objects.
      If you do, some nodes won't get any data and you will pay for nodes that aren't
      getting any training data. This applies in both File and Pipe modes. Keep this
      in mind when developing algorithms.

      In distributed training, where you use multiple ML compute EC2 instances, you
      might choose ``ShardedByS3Key`` . If the algorithm requires copying training
      data to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ),
      this copies 1/*n* of the number of objects.

    - **AttributeNames** *(list) --*

      A list of one or more attribute names to use that are found in a specified
      augmented manifest file.

      - *(string) --*
    """


_SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceTypeDef",
    {
        "S3DataSource": SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceS3DataSourceTypeDef,
        "FileSystemDataSource": SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceFileSystemDataSourceTypeDef,
    },
    total=False,
)


class SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceTypeDef(
    _SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceTypeDef
):
    """
    Type definition for `SearchPaginateResponseResultsTrainingJobInputDataConfig` `DataSource`

    The location of the channel data.

    - **S3DataSource** *(dict) --*

      The S3 location of the data source that is associated with a channel.

      - **S3DataType** *(string) --*

        If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
        SageMaker uses all objects that match the specified key name prefix for model
        training.

        If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
        manifest file containing a list of object keys that you want Amazon SageMaker
        to use for model training.

        If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
        augmented manifest file in JSON lines format. This file contains the data you
        want to use for model training. ``AugmentedManifestFile`` can only be used if
        the Channel's input mode is ``Pipe`` .

      - **S3Uri** *(string) --*

        Depending on the value specified for the ``S3DataType`` , identifies either a
        key name prefix or a manifest. For example:

        * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

        * A manifest might look like this: ``s3://bucketname/example.manifest``   The
        manifest is an S3 object which is a JSON file with the following format:  The
        preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
        "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
         ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
          ``]``   The preceding JSON matches the following ``s3Uris`` :
          ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
          ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
          set of ``s3uris`` in this manifest is the input data for the channel for this
          datasource. The object that each ``s3uris`` points to must be readable by the
          IAM role that Amazon SageMaker uses to perform tasks on your behalf.

      - **S3DataDistributionType** *(string) --*

        If you want Amazon SageMaker to replicate the entire dataset on each ML compute
        instance that is launched for model training, specify ``FullyReplicated`` .

        If you want Amazon SageMaker to replicate a subset of data on each ML compute
        instance that is launched for model training, specify ``ShardedByS3Key`` . If
        there are *n* ML compute instances launched for a training job, each instance
        gets approximately 1/*n* of the number of S3 objects. In this case, model
        training on each machine uses only the subset of training data.

        Don't choose more ML compute instances for training than available S3 objects.
        If you do, some nodes won't get any data and you will pay for nodes that aren't
        getting any training data. This applies in both File and Pipe modes. Keep this
        in mind when developing algorithms.

        In distributed training, where you use multiple ML compute EC2 instances, you
        might choose ``ShardedByS3Key`` . If the algorithm requires copying training
        data to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ),
        this copies 1/*n* of the number of objects.

      - **AttributeNames** *(list) --*

        A list of one or more attribute names to use that are found in a specified
        augmented manifest file.

        - *(string) --*

    - **FileSystemDataSource** *(dict) --*

      The file system that is associated with a channel.

      - **FileSystemId** *(string) --*

        The file system id.

      - **FileSystemAccessMode** *(string) --*

        The access mode of the mount of the directory associated with the channel. A
        directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
        mode.

      - **FileSystemType** *(string) --*

        The file system type.

      - **DirectoryPath** *(string) --*

        The full path to the directory to associate with the channel.
    """


_SearchPaginateResponseResultsTrainingJobInputDataConfigShuffleConfigTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTrainingJobInputDataConfigShuffleConfigTypeDef",
    {"Seed": int},
    total=False,
)


class SearchPaginateResponseResultsTrainingJobInputDataConfigShuffleConfigTypeDef(
    _SearchPaginateResponseResultsTrainingJobInputDataConfigShuffleConfigTypeDef
):
    """
    Type definition for `SearchPaginateResponseResultsTrainingJobInputDataConfig` `ShuffleConfig`

    A configuration for a shuffle option for input data in a channel. If you use
    ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
    matches. If you use ``ManifestFile`` , the order of the S3 object references in the
    ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of
    the JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
    determined using the ``Seed`` value.

    For Pipe input mode, shuffling is done at the start of every epoch. With large
    datasets this ensures that the order of the training data is different for each
    epoch, it helps reduce bias and possible overfitting. In a multi-node training job
    when ShuffleConfig is combined with ``S3DataDistributionType`` of
    ``ShardedByS3Key`` , the data is shuffled across nodes so that the content sent to
    a particular node on the first epoch might be sent to a different node on the
    second epoch.

    - **Seed** *(integer) --*

      Determines the shuffling order in ``ShuffleConfig`` value.
    """


_SearchPaginateResponseResultsTrainingJobInputDataConfigTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTrainingJobInputDataConfigTypeDef",
    {
        "ChannelName": str,
        "DataSource": SearchPaginateResponseResultsTrainingJobInputDataConfigDataSourceTypeDef,
        "ContentType": str,
        "CompressionType": str,
        "RecordWrapperType": str,
        "InputMode": str,
        "ShuffleConfig": SearchPaginateResponseResultsTrainingJobInputDataConfigShuffleConfigTypeDef,
    },
    total=False,
)


class SearchPaginateResponseResultsTrainingJobInputDataConfigTypeDef(
    _SearchPaginateResponseResultsTrainingJobInputDataConfigTypeDef
):
    """
    Type definition for `SearchPaginateResponseResultsTrainingJob` `InputDataConfig`

    A channel is a named input source that training algorithms can consume.

    - **ChannelName** *(string) --*

      The name of the channel.

    - **DataSource** *(dict) --*

      The location of the channel data.

      - **S3DataSource** *(dict) --*

        The S3 location of the data source that is associated with a channel.

        - **S3DataType** *(string) --*

          If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
          SageMaker uses all objects that match the specified key name prefix for model
          training.

          If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
          manifest file containing a list of object keys that you want Amazon SageMaker
          to use for model training.

          If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
          augmented manifest file in JSON lines format. This file contains the data you
          want to use for model training. ``AugmentedManifestFile`` can only be used if
          the Channel's input mode is ``Pipe`` .

        - **S3Uri** *(string) --*

          Depending on the value specified for the ``S3DataType`` , identifies either a
          key name prefix or a manifest. For example:

          * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

          * A manifest might look like this: ``s3://bucketname/example.manifest``   The
          manifest is an S3 object which is a JSON file with the following format:  The
          preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
          "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
           ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
            ``]``   The preceding JSON matches the following ``s3Uris`` :
            ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
            ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
            set of ``s3uris`` in this manifest is the input data for the channel for this
            datasource. The object that each ``s3uris`` points to must be readable by the
            IAM role that Amazon SageMaker uses to perform tasks on your behalf.

        - **S3DataDistributionType** *(string) --*

          If you want Amazon SageMaker to replicate the entire dataset on each ML compute
          instance that is launched for model training, specify ``FullyReplicated`` .

          If you want Amazon SageMaker to replicate a subset of data on each ML compute
          instance that is launched for model training, specify ``ShardedByS3Key`` . If
          there are *n* ML compute instances launched for a training job, each instance
          gets approximately 1/*n* of the number of S3 objects. In this case, model
          training on each machine uses only the subset of training data.

          Don't choose more ML compute instances for training than available S3 objects.
          If you do, some nodes won't get any data and you will pay for nodes that aren't
          getting any training data. This applies in both File and Pipe modes. Keep this
          in mind when developing algorithms.

          In distributed training, where you use multiple ML compute EC2 instances, you
          might choose ``ShardedByS3Key`` . If the algorithm requires copying training
          data to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ),
          this copies 1/*n* of the number of objects.

        - **AttributeNames** *(list) --*

          A list of one or more attribute names to use that are found in a specified
          augmented manifest file.

          - *(string) --*

      - **FileSystemDataSource** *(dict) --*

        The file system that is associated with a channel.

        - **FileSystemId** *(string) --*

          The file system id.

        - **FileSystemAccessMode** *(string) --*

          The access mode of the mount of the directory associated with the channel. A
          directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
          mode.

        - **FileSystemType** *(string) --*

          The file system type.

        - **DirectoryPath** *(string) --*

          The full path to the directory to associate with the channel.

    - **ContentType** *(string) --*

      The MIME type of the data.

    - **CompressionType** *(string) --*

      If training data is compressed, the compression type. The default value is ``None``
      . ``CompressionType`` is used only in Pipe input mode. In File mode, leave this
      field unset or set it to None.

    - **RecordWrapperType** *(string) --*

      Specify RecordIO as the value when input data is in raw format but the training
      algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
      individual S3 object in a RecordIO record. If the input data is already in RecordIO
      format, you don't need to set this attribute. For more information, see `Create a
      Dataset Using RecordIO
      <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
      .

      In File mode, leave this field unset or set it to None.

    - **InputMode** *(string) --*

      (Optional) The input mode to use for the data channel in a training job. If you
      don't set a value for ``InputMode`` , Amazon SageMaker uses the value set for
      ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
      setting in a  AlgorithmSpecification request when you have a channel that needs a
      different input mode from the training job's general setting. To download the data
      from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage
      volume, and mount the directory to a Docker volume, use ``File`` input mode. To
      stream data directly from Amazon S3 to the container, choose ``Pipe`` input mode.

      To use a model for incremental training, choose ``File`` input model.

    - **ShuffleConfig** *(dict) --*

      A configuration for a shuffle option for input data in a channel. If you use
      ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
      matches. If you use ``ManifestFile`` , the order of the S3 object references in the
      ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of
      the JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
      determined using the ``Seed`` value.

      For Pipe input mode, shuffling is done at the start of every epoch. With large
      datasets this ensures that the order of the training data is different for each
      epoch, it helps reduce bias and possible overfitting. In a multi-node training job
      when ShuffleConfig is combined with ``S3DataDistributionType`` of
      ``ShardedByS3Key`` , the data is shuffled across nodes so that the content sent to
      a particular node on the first epoch might be sent to a different node on the
      second epoch.

      - **Seed** *(integer) --*

        Determines the shuffling order in ``ShuffleConfig`` value.
    """


_SearchPaginateResponseResultsTrainingJobModelArtifactsTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTrainingJobModelArtifactsTypeDef",
    {"S3ModelArtifacts": str},
    total=False,
)


class SearchPaginateResponseResultsTrainingJobModelArtifactsTypeDef(
    _SearchPaginateResponseResultsTrainingJobModelArtifactsTypeDef
):
    """
    Type definition for `SearchPaginateResponseResultsTrainingJob` `ModelArtifacts`

    Information about the Amazon S3 location that is configured for storing model artifacts.

    - **S3ModelArtifacts** *(string) --*

      The path of the S3 object that contains the model artifacts. For example,
      ``s3://bucket-name/keynameprefix/model.tar.gz`` .
    """


_SearchPaginateResponseResultsTrainingJobOutputDataConfigTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTrainingJobOutputDataConfigTypeDef",
    {"KmsKeyId": str, "S3OutputPath": str},
    total=False,
)


class SearchPaginateResponseResultsTrainingJobOutputDataConfigTypeDef(
    _SearchPaginateResponseResultsTrainingJobOutputDataConfigTypeDef
):
    """
    Type definition for `SearchPaginateResponseResultsTrainingJob` `OutputDataConfig`

    The S3 path where model artifacts that you configured when creating the job are stored.
    Amazon SageMaker creates subfolders for model artifacts.

    - **KmsKeyId** *(string) --*

      The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
      the model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId``
      can be any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // KMS Key Alias  ``"alias/ExampleAlias"``

      * // Amazon Resource Name (ARN) of a KMS Key Alias
      ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

      If you use a KMS key ID or an alias of your master key, the Amazon SageMaker
      execution role must include permissions to call ``kms:Encrypt`` . If you don't
      provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3 for
      your role's account. Amazon SageMaker uses server-side encryption with KMS-managed
      keys for ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject``
      permission that only allows objects with server-side encryption, set the condition
      key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information,
      see `KMS-Managed Encryption Keys
      <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
      *Amazon Simple Storage Service Developer Guide.*

      The KMS key policy must grant permission to the IAM role that you specify in your
      ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
      requests. For more information, see `Using Key Policies in AWS KMS
      <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
      in the *AWS Key Management Service Developer Guide* .

    - **S3OutputPath** *(string) --*

      Identifies the S3 path where you want Amazon SageMaker to store the model artifacts.
      For example, ``s3://bucket-name/key-name-prefix`` .
    """


_SearchPaginateResponseResultsTrainingJobResourceConfigTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTrainingJobResourceConfigTypeDef",
    {
        "InstanceType": str,
        "InstanceCount": int,
        "VolumeSizeInGB": int,
        "VolumeKmsKeyId": str,
    },
    total=False,
)


class SearchPaginateResponseResultsTrainingJobResourceConfigTypeDef(
    _SearchPaginateResponseResultsTrainingJobResourceConfigTypeDef
):
    """
    Type definition for `SearchPaginateResponseResultsTrainingJob` `ResourceConfig`

    Resources, including ML compute instances and ML storage volumes, that are configured
    for model training.

    - **InstanceType** *(string) --*

      The ML compute instance type.

    - **InstanceCount** *(integer) --*

      The number of ML compute instances to use. For distributed training, provide a value
      greater than 1.

    - **VolumeSizeInGB** *(integer) --*

      The size of the ML storage volume that you want to provision.

      ML storage volumes store model artifacts and incremental states. Training algorithms
      might also use the ML storage volume for scratch space. If you want to store the
      training data in the ML storage volume, choose ``File`` as the ``TrainingInputMode``
      in the algorithm specification.

      You must specify sufficient ML storage for your scenario.

      .. note::

        Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

      .. note::

        Certain Nitro-based instances include local storage with a fixed total size,
        dependent on the instance type. When using these instances for training, Amazon
        SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage. You
        can't request a ``VolumeSizeInGB`` greater than the total size of the local
        instance storage.

        For a list of instance types that support local instance storage, including the
        total size per instance type, see `Instance Store Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
        .

    - **VolumeKmsKeyId** *(string) --*

      The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
      attached to the ML compute instance(s) that run the training job.

      .. note::

        Certain Nitro-based instances include local storage, dependent on the instance
        type. Local storage volumes are encrypted using a hardware module on the instance.
        You can't request a ``VolumeKmsKeyId`` when using an instance type with local
        storage.

        For a list of instance types that support local instance storage, see `Instance
        Store Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
        .

        For more information about local instance storage encryption, see `SSD Instance
        Store Volumes
        <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

      The ``VolumeKmsKeyId`` can be in any of the following formats:

      * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

      * // Amazon Resource Name (ARN) of a KMS Key
      ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``
    """


_SearchPaginateResponseResultsTrainingJobSecondaryStatusTransitionsTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTrainingJobSecondaryStatusTransitionsTypeDef",
    {"Status": str, "StartTime": datetime, "EndTime": datetime, "StatusMessage": str},
    total=False,
)


class SearchPaginateResponseResultsTrainingJobSecondaryStatusTransitionsTypeDef(
    _SearchPaginateResponseResultsTrainingJobSecondaryStatusTransitionsTypeDef
):
    """
    Type definition for `SearchPaginateResponseResultsTrainingJob` `SecondaryStatusTransitions`

    An array element of  DescribeTrainingJobResponse$SecondaryStatusTransitions . It
    provides additional details about a status that the training job has transitioned
    through. A training job can be in one of several states, for example, starting,
    downloading, training, or uploading. Within each state, there are a number of
    intermediate states. For example, within the starting state, Amazon SageMaker could
    be starting the training job or launching the ML instances. These transitional states
    are referred to as the job's secondary status.

    - **Status** *(string) --*

      Contains a secondary status information from a training job.

      Status might be one of the following secondary statuses:

        InProgress

      * ``Starting`` - Starting the training job.

      * ``Downloading`` - An optional stage for algorithms that support ``File`` training
      input mode. It indicates that data is being downloaded to the ML storage volumes.

      * ``Training`` - Training is in progress.

      * ``Uploading`` - Training is complete and the model artifacts are being uploaded
      to the S3 location.

        Completed

      * ``Completed`` - The training job has completed.

        Failed

      * ``Failed`` - The training job has failed. The reason for the failure is returned
      in the ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

        Stopped

      * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed
      runtime.

      * ``Stopped`` - The training job has stopped.

        Stopping

      * ``Stopping`` - Stopping the training job.

      We no longer support the following secondary statuses:

      * ``LaunchingMLInstances``

      * ``PreparingTrainingStack``

      * ``DownloadingTrainingImage``

    - **StartTime** *(datetime) --*

      A timestamp that shows when the training job transitioned to the current secondary
      status state.

    - **EndTime** *(datetime) --*

      A timestamp that shows when the training job transitioned out of this secondary
      status state into another secondary status state or when the training job has ended.

    - **StatusMessage** *(string) --*

      A detailed description of the progress within a secondary status.

      Amazon SageMaker provides secondary statuses and status messages that apply to each
      of them:

        Starting

      * Starting the training job.

      * Launching requested ML instances.

      * Insufficient capacity error from EC2 while launching instances, retrying!

      * Launched instance was unhealthy, replacing it!

      * Preparing the instances for training.

        Training

      * Downloading the training image.

      * Training image download completed. Training in progress.

      .. warning::

        Status messages are subject to change. Therefore, we recommend not including them
        in code that programmatically initiates actions. For examples, don't use status
        messages in if statements.

      To have an overview of your training job's progress, view ``TrainingJobStatus`` and
      ``SecondaryStatus`` in  DescribeTrainingJob , and ``StatusMessage`` together. For
      example, at the start of a training job, you might see the following:

      * ``TrainingJobStatus`` - InProgress

      * ``SecondaryStatus`` - Training

      * ``StatusMessage`` - Downloading the training image
    """


_SearchPaginateResponseResultsTrainingJobStoppingConditionTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTrainingJobStoppingConditionTypeDef",
    {"MaxRuntimeInSeconds": int, "MaxWaitTimeInSeconds": int},
    total=False,
)


class SearchPaginateResponseResultsTrainingJobStoppingConditionTypeDef(
    _SearchPaginateResponseResultsTrainingJobStoppingConditionTypeDef
):
    """
    Type definition for `SearchPaginateResponseResultsTrainingJob` `StoppingCondition`

    Specifies a limit to how long a model training job can run. When the job reaches the
    time limit, Amazon SageMaker ends the training job. Use this API to cap model training
    costs.

    To stop a job, Amazon SageMaker sends the algorithm the ``SIGTERM`` signal, which
    delays job termination for 120 seconds. Algorithms can use this 120-second window to
    save the model artifacts, so the results of training are not lost.

    - **MaxRuntimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, that the training or compilation job can run.
      If job does not complete during this time, Amazon SageMaker ends the job. If value is
      not specified, default value is 1 day. The maximum value is 28 days.

    - **MaxWaitTimeInSeconds** *(integer) --*

      The maximum length of time, in seconds, how long you are willing to wait for a
      managed spot training job to complete. It is the amount of time spent waiting for
      Spot capacity plus the amount of time the training job runs. It must be equal to or
      greater than ``MaxRuntimeInSeconds`` .
    """


_SearchPaginateResponseResultsTrainingJobTagsTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTrainingJobTagsTypeDef",
    {"Key": str, "Value": str},
    total=False,
)


class SearchPaginateResponseResultsTrainingJobTagsTypeDef(
    _SearchPaginateResponseResultsTrainingJobTagsTypeDef
):
    """
    Type definition for `SearchPaginateResponseResultsTrainingJob` `Tags`

    Describes a tag.

    - **Key** *(string) --*

      The tag key.

    - **Value** *(string) --*

      The tag value.
    """


_SearchPaginateResponseResultsTrainingJobVpcConfigTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTrainingJobVpcConfigTypeDef",
    {"SecurityGroupIds": List[str], "Subnets": List[str]},
    total=False,
)


class SearchPaginateResponseResultsTrainingJobVpcConfigTypeDef(
    _SearchPaginateResponseResultsTrainingJobVpcConfigTypeDef
):
    """
    Type definition for `SearchPaginateResponseResultsTrainingJob` `VpcConfig`

    A  VpcConfig object that specifies the VPC that this training job has access to. For
    more information, see `Protect Training Jobs by Using an Amazon Virtual Private Cloud
    <https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html>`__ .

    - **SecurityGroupIds** *(list) --*

      The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for
      the VPC that is specified in the ``Subnets`` field.

      - *(string) --*

    - **Subnets** *(list) --*

      The ID of the subnets in the VPC to which you want to connect your training job or
      model.

      .. note::

        Amazon EC2 P3 accelerated computing instances are not available in the c/d/e
        availability zones of region us-east-1. If you want to create endpoints with P3
        instances in VPC mode in region us-east-1, create subnets in a/b/f availability
        zones instead.

      - *(string) --*
    """


_SearchPaginateResponseResultsTrainingJobTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTrainingJobTypeDef",
    {
        "TrainingJobName": str,
        "TrainingJobArn": str,
        "TuningJobArn": str,
        "LabelingJobArn": str,
        "ModelArtifacts": SearchPaginateResponseResultsTrainingJobModelArtifactsTypeDef,
        "TrainingJobStatus": str,
        "SecondaryStatus": str,
        "FailureReason": str,
        "HyperParameters": Dict[str, str],
        "AlgorithmSpecification": SearchPaginateResponseResultsTrainingJobAlgorithmSpecificationTypeDef,
        "RoleArn": str,
        "InputDataConfig": List[
            SearchPaginateResponseResultsTrainingJobInputDataConfigTypeDef
        ],
        "OutputDataConfig": SearchPaginateResponseResultsTrainingJobOutputDataConfigTypeDef,
        "ResourceConfig": SearchPaginateResponseResultsTrainingJobResourceConfigTypeDef,
        "VpcConfig": SearchPaginateResponseResultsTrainingJobVpcConfigTypeDef,
        "StoppingCondition": SearchPaginateResponseResultsTrainingJobStoppingConditionTypeDef,
        "CreationTime": datetime,
        "TrainingStartTime": datetime,
        "TrainingEndTime": datetime,
        "LastModifiedTime": datetime,
        "SecondaryStatusTransitions": List[
            SearchPaginateResponseResultsTrainingJobSecondaryStatusTransitionsTypeDef
        ],
        "FinalMetricDataList": List[
            SearchPaginateResponseResultsTrainingJobFinalMetricDataListTypeDef
        ],
        "EnableNetworkIsolation": bool,
        "EnableInterContainerTrafficEncryption": bool,
        "Tags": List[SearchPaginateResponseResultsTrainingJobTagsTypeDef],
    },
    total=False,
)


class SearchPaginateResponseResultsTrainingJobTypeDef(
    _SearchPaginateResponseResultsTrainingJobTypeDef
):
    """
    Type definition for `SearchPaginateResponseResults` `TrainingJob`

    A ``TrainingJob`` object that is returned as part of a ``Search`` request.

    - **TrainingJobName** *(string) --*

      The name of the training job.

    - **TrainingJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the training job.

    - **TuningJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the associated hyperparameter tuning job if the
      training job was launched by a hyperparameter tuning job.

    - **LabelingJobArn** *(string) --*

      The Amazon Resource Name (ARN) of the labeling job.

    - **ModelArtifacts** *(dict) --*

      Information about the Amazon S3 location that is configured for storing model artifacts.

      - **S3ModelArtifacts** *(string) --*

        The path of the S3 object that contains the model artifacts. For example,
        ``s3://bucket-name/keynameprefix/model.tar.gz`` .

    - **TrainingJobStatus** *(string) --*

      The status of the training job.

      Training job statuses are:

      * ``InProgress`` - The training is in progress.

      * ``Completed`` - The training job has completed.

      * ``Failed`` - The training job has failed. To see the reason for the failure, see the
      ``FailureReason`` field in the response to a ``DescribeTrainingJobResponse`` call.

      * ``Stopping`` - The training job is stopping.

      * ``Stopped`` - The training job has stopped.

      For more detailed information, see ``SecondaryStatus`` .

    - **SecondaryStatus** *(string) --*

      Provides detailed information about the state of the training job. For detailed
      information about the secondary status of the training job, see ``StatusMessage`` under
       SecondaryStatusTransition .

      Amazon SageMaker provides primary statuses and secondary statuses that apply to each of
      them:

        InProgress

      * ``Starting`` - Starting the training job.

      * ``Downloading`` - An optional stage for algorithms that support ``File`` training
      input mode. It indicates that data is being downloaded to the ML storage volumes.

      * ``Training`` - Training is in progress.

      * ``Uploading`` - Training is complete and the model artifacts are being uploaded to
      the S3 location.

        Completed

      * ``Completed`` - The training job has completed.

        Failed

      * ``Failed`` - The training job has failed. The reason for the failure is returned in
      the ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

        Stopped

      * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed
      runtime.

      * ``Stopped`` - The training job has stopped.

        Stopping

      * ``Stopping`` - Stopping the training job.

      .. warning::

        Valid values for ``SecondaryStatus`` are subject to change.

      We no longer support the following secondary statuses:

      * ``LaunchingMLInstances``

      * ``PreparingTrainingStack``

      * ``DownloadingTrainingImage``

    - **FailureReason** *(string) --*

      If the training job failed, the reason it failed.

    - **HyperParameters** *(dict) --*

      Algorithm-specific parameters.

      - *(string) --*

        - *(string) --*

    - **AlgorithmSpecification** *(dict) --*

      Information about the algorithm used for training, and algorithm metadata.

      - **TrainingImage** *(string) --*

        The registry path of the Docker image that contains the training algorithm. For
        information about docker registry paths for built-in algorithms, see `Algorithms
        Provided by Amazon SageMaker\\: Common Parameters
        <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
        . Amazon SageMaker supports both ``registry/repository[:tag]`` and
        ``registry/repository[@digest]`` image path formats. For more information, see `Using
        Your Own Algorithms with Amazon SageMaker
        <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

      - **AlgorithmName** *(string) --*

        The name of the algorithm resource to use for the training job. This must be an
        algorithm resource that you created or subscribe to on AWS Marketplace. If you
        specify a value for this parameter, you can't specify a value for ``TrainingImage`` .

      - **TrainingInputMode** *(string) --*

        The input mode that the algorithm supports. For the input modes that Amazon SageMaker
        algorithms support, see `Algorithms
        <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ . If an algorithm
        supports the ``File`` input mode, Amazon SageMaker downloads the training data from
        S3 to the provisioned ML storage Volume, and mounts the directory to docker volume
        for training container. If an algorithm supports the ``Pipe`` input mode, Amazon
        SageMaker streams data directly from S3 to the container.

        In File mode, make sure you provision ML storage volume with sufficient capacity to
        accommodate the data download from S3. In addition to the training data, the ML
        storage volume also stores the output model. The algorithm container use ML storage
        volume to also store intermediate information, if any.

        For distributed algorithms using File mode, training data is distributed uniformly,
        and your training duration is predictable if the input data objects size is
        approximately same. Amazon SageMaker does not split the files any further for model
        training. If the object sizes are skewed, training won't be optimal as the data
        distribution is also skewed where one host in a training cluster is overloaded, thus
        becoming bottleneck in training.

      - **MetricDefinitions** *(list) --*

        A list of metric definition objects. Each object specifies the metric name and
        regular expressions used to parse algorithm logs. Amazon SageMaker publishes each
        metric to Amazon CloudWatch.

        - *(dict) --*

          Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
          Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
          metric that a hyperparameter tuning job uses as its objective metric to choose the
          best training job.

          - **Name** *(string) --*

            The name of the metric.

          - **Regex** *(string) --*

            A regular expression that searches the output of a training job and gets the
            value of the metric. For more information about using regular expressions to
            define metrics, see `Defining Objective Metrics
            <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
            .

    - **RoleArn** *(string) --*

      The AWS Identity and Access Management (IAM) role configured for the training job.

    - **InputDataConfig** *(list) --*

      An array of ``Channel`` objects that describes each data input channel.

      - *(dict) --*

        A channel is a named input source that training algorithms can consume.

        - **ChannelName** *(string) --*

          The name of the channel.

        - **DataSource** *(dict) --*

          The location of the channel data.

          - **S3DataSource** *(dict) --*

            The S3 location of the data source that is associated with a channel.

            - **S3DataType** *(string) --*

              If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
              SageMaker uses all objects that match the specified key name prefix for model
              training.

              If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
              manifest file containing a list of object keys that you want Amazon SageMaker
              to use for model training.

              If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
              augmented manifest file in JSON lines format. This file contains the data you
              want to use for model training. ``AugmentedManifestFile`` can only be used if
              the Channel's input mode is ``Pipe`` .

            - **S3Uri** *(string) --*

              Depending on the value specified for the ``S3DataType`` , identifies either a
              key name prefix or a manifest. For example:

              * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

              * A manifest might look like this: ``s3://bucketname/example.manifest``   The
              manifest is an S3 object which is a JSON file with the following format:  The
              preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
              "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
               ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
                ``]``   The preceding JSON matches the following ``s3Uris`` :
                ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
                set of ``s3uris`` in this manifest is the input data for the channel for this
                datasource. The object that each ``s3uris`` points to must be readable by the
                IAM role that Amazon SageMaker uses to perform tasks on your behalf.

            - **S3DataDistributionType** *(string) --*

              If you want Amazon SageMaker to replicate the entire dataset on each ML compute
              instance that is launched for model training, specify ``FullyReplicated`` .

              If you want Amazon SageMaker to replicate a subset of data on each ML compute
              instance that is launched for model training, specify ``ShardedByS3Key`` . If
              there are *n* ML compute instances launched for a training job, each instance
              gets approximately 1/*n* of the number of S3 objects. In this case, model
              training on each machine uses only the subset of training data.

              Don't choose more ML compute instances for training than available S3 objects.
              If you do, some nodes won't get any data and you will pay for nodes that aren't
              getting any training data. This applies in both File and Pipe modes. Keep this
              in mind when developing algorithms.

              In distributed training, where you use multiple ML compute EC2 instances, you
              might choose ``ShardedByS3Key`` . If the algorithm requires copying training
              data to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ),
              this copies 1/*n* of the number of objects.

            - **AttributeNames** *(list) --*

              A list of one or more attribute names to use that are found in a specified
              augmented manifest file.

              - *(string) --*

          - **FileSystemDataSource** *(dict) --*

            The file system that is associated with a channel.

            - **FileSystemId** *(string) --*

              The file system id.

            - **FileSystemAccessMode** *(string) --*

              The access mode of the mount of the directory associated with the channel. A
              directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
              mode.

            - **FileSystemType** *(string) --*

              The file system type.

            - **DirectoryPath** *(string) --*

              The full path to the directory to associate with the channel.

        - **ContentType** *(string) --*

          The MIME type of the data.

        - **CompressionType** *(string) --*

          If training data is compressed, the compression type. The default value is ``None``
          . ``CompressionType`` is used only in Pipe input mode. In File mode, leave this
          field unset or set it to None.

        - **RecordWrapperType** *(string) --*

          Specify RecordIO as the value when input data is in raw format but the training
          algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
          individual S3 object in a RecordIO record. If the input data is already in RecordIO
          format, you don't need to set this attribute. For more information, see `Create a
          Dataset Using RecordIO
          <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
          .

          In File mode, leave this field unset or set it to None.

        - **InputMode** *(string) --*

          (Optional) The input mode to use for the data channel in a training job. If you
          don't set a value for ``InputMode`` , Amazon SageMaker uses the value set for
          ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
          setting in a  AlgorithmSpecification request when you have a channel that needs a
          different input mode from the training job's general setting. To download the data
          from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage
          volume, and mount the directory to a Docker volume, use ``File`` input mode. To
          stream data directly from Amazon S3 to the container, choose ``Pipe`` input mode.

          To use a model for incremental training, choose ``File`` input model.

        - **ShuffleConfig** *(dict) --*

          A configuration for a shuffle option for input data in a channel. If you use
          ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
          matches. If you use ``ManifestFile`` , the order of the S3 object references in the
          ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of
          the JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
          determined using the ``Seed`` value.

          For Pipe input mode, shuffling is done at the start of every epoch. With large
          datasets this ensures that the order of the training data is different for each
          epoch, it helps reduce bias and possible overfitting. In a multi-node training job
          when ShuffleConfig is combined with ``S3DataDistributionType`` of
          ``ShardedByS3Key`` , the data is shuffled across nodes so that the content sent to
          a particular node on the first epoch might be sent to a different node on the
          second epoch.

          - **Seed** *(integer) --*

            Determines the shuffling order in ``ShuffleConfig`` value.

    - **OutputDataConfig** *(dict) --*

      The S3 path where model artifacts that you configured when creating the job are stored.
      Amazon SageMaker creates subfolders for model artifacts.

      - **KmsKeyId** *(string) --*

        The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
        the model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId``
        can be any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // KMS Key Alias  ``"alias/ExampleAlias"``

        * // Amazon Resource Name (ARN) of a KMS Key Alias
        ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

        If you use a KMS key ID or an alias of your master key, the Amazon SageMaker
        execution role must include permissions to call ``kms:Encrypt`` . If you don't
        provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3 for
        your role's account. Amazon SageMaker uses server-side encryption with KMS-managed
        keys for ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject``
        permission that only allows objects with server-side encryption, set the condition
        key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information,
        see `KMS-Managed Encryption Keys
        <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
        *Amazon Simple Storage Service Developer Guide.*

        The KMS key policy must grant permission to the IAM role that you specify in your
        ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
        requests. For more information, see `Using Key Policies in AWS KMS
        <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
        in the *AWS Key Management Service Developer Guide* .

      - **S3OutputPath** *(string) --*

        Identifies the S3 path where you want Amazon SageMaker to store the model artifacts.
        For example, ``s3://bucket-name/key-name-prefix`` .

    - **ResourceConfig** *(dict) --*

      Resources, including ML compute instances and ML storage volumes, that are configured
      for model training.

      - **InstanceType** *(string) --*

        The ML compute instance type.

      - **InstanceCount** *(integer) --*

        The number of ML compute instances to use. For distributed training, provide a value
        greater than 1.

      - **VolumeSizeInGB** *(integer) --*

        The size of the ML storage volume that you want to provision.

        ML storage volumes store model artifacts and incremental states. Training algorithms
        might also use the ML storage volume for scratch space. If you want to store the
        training data in the ML storage volume, choose ``File`` as the ``TrainingInputMode``
        in the algorithm specification.

        You must specify sufficient ML storage for your scenario.

        .. note::

          Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

        .. note::

          Certain Nitro-based instances include local storage with a fixed total size,
          dependent on the instance type. When using these instances for training, Amazon
          SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage. You
          can't request a ``VolumeSizeInGB`` greater than the total size of the local
          instance storage.

          For a list of instance types that support local instance storage, including the
          total size per instance type, see `Instance Store Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
          .

      - **VolumeKmsKeyId** *(string) --*

        The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
        attached to the ML compute instance(s) that run the training job.

        .. note::

          Certain Nitro-based instances include local storage, dependent on the instance
          type. Local storage volumes are encrypted using a hardware module on the instance.
          You can't request a ``VolumeKmsKeyId`` when using an instance type with local
          storage.

          For a list of instance types that support local instance storage, see `Instance
          Store Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
          .

          For more information about local instance storage encryption, see `SSD Instance
          Store Volumes
          <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

        The ``VolumeKmsKeyId`` can be in any of the following formats:

        * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

        * // Amazon Resource Name (ARN) of a KMS Key
        ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

    - **VpcConfig** *(dict) --*

      A  VpcConfig object that specifies the VPC that this training job has access to. For
      more information, see `Protect Training Jobs by Using an Amazon Virtual Private Cloud
      <https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html>`__ .

      - **SecurityGroupIds** *(list) --*

        The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for
        the VPC that is specified in the ``Subnets`` field.

        - *(string) --*

      - **Subnets** *(list) --*

        The ID of the subnets in the VPC to which you want to connect your training job or
        model.

        .. note::

          Amazon EC2 P3 accelerated computing instances are not available in the c/d/e
          availability zones of region us-east-1. If you want to create endpoints with P3
          instances in VPC mode in region us-east-1, create subnets in a/b/f availability
          zones instead.

        - *(string) --*

    - **StoppingCondition** *(dict) --*

      Specifies a limit to how long a model training job can run. When the job reaches the
      time limit, Amazon SageMaker ends the training job. Use this API to cap model training
      costs.

      To stop a job, Amazon SageMaker sends the algorithm the ``SIGTERM`` signal, which
      delays job termination for 120 seconds. Algorithms can use this 120-second window to
      save the model artifacts, so the results of training are not lost.

      - **MaxRuntimeInSeconds** *(integer) --*

        The maximum length of time, in seconds, that the training or compilation job can run.
        If job does not complete during this time, Amazon SageMaker ends the job. If value is
        not specified, default value is 1 day. The maximum value is 28 days.

      - **MaxWaitTimeInSeconds** *(integer) --*

        The maximum length of time, in seconds, how long you are willing to wait for a
        managed spot training job to complete. It is the amount of time spent waiting for
        Spot capacity plus the amount of time the training job runs. It must be equal to or
        greater than ``MaxRuntimeInSeconds`` .

    - **CreationTime** *(datetime) --*

      A timestamp that indicates when the training job was created.

    - **TrainingStartTime** *(datetime) --*

      Indicates the time when the training job starts on training instances. You are billed
      for the time interval between this time and the value of ``TrainingEndTime`` . The
      start time in CloudWatch Logs might be later than this time. The difference is due to
      the time it takes to download the training data and to the size of the training
      container.

    - **TrainingEndTime** *(datetime) --*

      Indicates the time when the training job ends on training instances. You are billed for
      the time interval between the value of ``TrainingStartTime`` and this time. For
      successful jobs and stopped jobs, this is the time after model artifacts are uploaded.
      For failed jobs, this is the time when Amazon SageMaker detects a job failure.

    - **LastModifiedTime** *(datetime) --*

      A timestamp that indicates when the status of the training job was last modified.

    - **SecondaryStatusTransitions** *(list) --*

      A history of all of the secondary statuses that the training job has transitioned
      through.

      - *(dict) --*

        An array element of  DescribeTrainingJobResponse$SecondaryStatusTransitions . It
        provides additional details about a status that the training job has transitioned
        through. A training job can be in one of several states, for example, starting,
        downloading, training, or uploading. Within each state, there are a number of
        intermediate states. For example, within the starting state, Amazon SageMaker could
        be starting the training job or launching the ML instances. These transitional states
        are referred to as the job's secondary status.

        - **Status** *(string) --*

          Contains a secondary status information from a training job.

          Status might be one of the following secondary statuses:

            InProgress

          * ``Starting`` - Starting the training job.

          * ``Downloading`` - An optional stage for algorithms that support ``File`` training
          input mode. It indicates that data is being downloaded to the ML storage volumes.

          * ``Training`` - Training is in progress.

          * ``Uploading`` - Training is complete and the model artifacts are being uploaded
          to the S3 location.

            Completed

          * ``Completed`` - The training job has completed.

            Failed

          * ``Failed`` - The training job has failed. The reason for the failure is returned
          in the ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

            Stopped

          * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed
          runtime.

          * ``Stopped`` - The training job has stopped.

            Stopping

          * ``Stopping`` - Stopping the training job.

          We no longer support the following secondary statuses:

          * ``LaunchingMLInstances``

          * ``PreparingTrainingStack``

          * ``DownloadingTrainingImage``

        - **StartTime** *(datetime) --*

          A timestamp that shows when the training job transitioned to the current secondary
          status state.

        - **EndTime** *(datetime) --*

          A timestamp that shows when the training job transitioned out of this secondary
          status state into another secondary status state or when the training job has ended.

        - **StatusMessage** *(string) --*

          A detailed description of the progress within a secondary status.

          Amazon SageMaker provides secondary statuses and status messages that apply to each
          of them:

            Starting

          * Starting the training job.

          * Launching requested ML instances.

          * Insufficient capacity error from EC2 while launching instances, retrying!

          * Launched instance was unhealthy, replacing it!

          * Preparing the instances for training.

            Training

          * Downloading the training image.

          * Training image download completed. Training in progress.

          .. warning::

            Status messages are subject to change. Therefore, we recommend not including them
            in code that programmatically initiates actions. For examples, don't use status
            messages in if statements.

          To have an overview of your training job's progress, view ``TrainingJobStatus`` and
          ``SecondaryStatus`` in  DescribeTrainingJob , and ``StatusMessage`` together. For
          example, at the start of a training job, you might see the following:

          * ``TrainingJobStatus`` - InProgress

          * ``SecondaryStatus`` - Training

          * ``StatusMessage`` - Downloading the training image

    - **FinalMetricDataList** *(list) --*

      A list of final metric values that are set when the training job completes. Used only
      if the training job was configured to use metrics.

      - *(dict) --*

        The name, value, and date and time of a metric that was emitted to Amazon CloudWatch.

        - **MetricName** *(string) --*

          The name of the metric.

        - **Value** *(float) --*

          The value of the metric.

        - **Timestamp** *(datetime) --*

          The date and time that the algorithm emitted the metric.

    - **EnableNetworkIsolation** *(boolean) --*

      If the ``TrainingJob`` was created with network isolation, the value is set to ``true``
      . If network isolation is enabled, nodes can't communicate beyond the VPC they run in.

    - **EnableInterContainerTrafficEncryption** *(boolean) --*

      To encrypt all communications between ML compute instances in distributed training,
      choose ``True`` . Encryption provides greater security for distributed training, but
      training might take longer. How long it takes depends on the amount of communication
      between compute instances, especially if you use a deep learning algorithm in
      distributed training.

    - **Tags** *(list) --*

      An array of key-value pairs. For more information, see `Using Cost Allocation Tags
      <https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html#allocation-what>`__
      in the *AWS Billing and Cost Management User Guide* .

      - *(dict) --*

        Describes a tag.

        - **Key** *(string) --*

          The tag key.

        - **Value** *(string) --*

          The tag value.
    """


_SearchPaginateResponseResultsTypeDef = TypedDict(
    "_SearchPaginateResponseResultsTypeDef",
    {"TrainingJob": SearchPaginateResponseResultsTrainingJobTypeDef},
    total=False,
)


class SearchPaginateResponseResultsTypeDef(_SearchPaginateResponseResultsTypeDef):
    """
    Type definition for `SearchPaginateResponse` `Results`

    An individual search result record that contains a single resource object.

    - **TrainingJob** *(dict) --*

      A ``TrainingJob`` object that is returned as part of a ``Search`` request.

      - **TrainingJobName** *(string) --*

        The name of the training job.

      - **TrainingJobArn** *(string) --*

        The Amazon Resource Name (ARN) of the training job.

      - **TuningJobArn** *(string) --*

        The Amazon Resource Name (ARN) of the associated hyperparameter tuning job if the
        training job was launched by a hyperparameter tuning job.

      - **LabelingJobArn** *(string) --*

        The Amazon Resource Name (ARN) of the labeling job.

      - **ModelArtifacts** *(dict) --*

        Information about the Amazon S3 location that is configured for storing model artifacts.

        - **S3ModelArtifacts** *(string) --*

          The path of the S3 object that contains the model artifacts. For example,
          ``s3://bucket-name/keynameprefix/model.tar.gz`` .

      - **TrainingJobStatus** *(string) --*

        The status of the training job.

        Training job statuses are:

        * ``InProgress`` - The training is in progress.

        * ``Completed`` - The training job has completed.

        * ``Failed`` - The training job has failed. To see the reason for the failure, see the
        ``FailureReason`` field in the response to a ``DescribeTrainingJobResponse`` call.

        * ``Stopping`` - The training job is stopping.

        * ``Stopped`` - The training job has stopped.

        For more detailed information, see ``SecondaryStatus`` .

      - **SecondaryStatus** *(string) --*

        Provides detailed information about the state of the training job. For detailed
        information about the secondary status of the training job, see ``StatusMessage`` under
         SecondaryStatusTransition .

        Amazon SageMaker provides primary statuses and secondary statuses that apply to each of
        them:

          InProgress

        * ``Starting`` - Starting the training job.

        * ``Downloading`` - An optional stage for algorithms that support ``File`` training
        input mode. It indicates that data is being downloaded to the ML storage volumes.

        * ``Training`` - Training is in progress.

        * ``Uploading`` - Training is complete and the model artifacts are being uploaded to
        the S3 location.

          Completed

        * ``Completed`` - The training job has completed.

          Failed

        * ``Failed`` - The training job has failed. The reason for the failure is returned in
        the ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

          Stopped

        * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed
        runtime.

        * ``Stopped`` - The training job has stopped.

          Stopping

        * ``Stopping`` - Stopping the training job.

        .. warning::

          Valid values for ``SecondaryStatus`` are subject to change.

        We no longer support the following secondary statuses:

        * ``LaunchingMLInstances``

        * ``PreparingTrainingStack``

        * ``DownloadingTrainingImage``

      - **FailureReason** *(string) --*

        If the training job failed, the reason it failed.

      - **HyperParameters** *(dict) --*

        Algorithm-specific parameters.

        - *(string) --*

          - *(string) --*

      - **AlgorithmSpecification** *(dict) --*

        Information about the algorithm used for training, and algorithm metadata.

        - **TrainingImage** *(string) --*

          The registry path of the Docker image that contains the training algorithm. For
          information about docker registry paths for built-in algorithms, see `Algorithms
          Provided by Amazon SageMaker\\: Common Parameters
          <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
          . Amazon SageMaker supports both ``registry/repository[:tag]`` and
          ``registry/repository[@digest]`` image path formats. For more information, see `Using
          Your Own Algorithms with Amazon SageMaker
          <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

        - **AlgorithmName** *(string) --*

          The name of the algorithm resource to use for the training job. This must be an
          algorithm resource that you created or subscribe to on AWS Marketplace. If you
          specify a value for this parameter, you can't specify a value for ``TrainingImage`` .

        - **TrainingInputMode** *(string) --*

          The input mode that the algorithm supports. For the input modes that Amazon SageMaker
          algorithms support, see `Algorithms
          <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ . If an algorithm
          supports the ``File`` input mode, Amazon SageMaker downloads the training data from
          S3 to the provisioned ML storage Volume, and mounts the directory to docker volume
          for training container. If an algorithm supports the ``Pipe`` input mode, Amazon
          SageMaker streams data directly from S3 to the container.

          In File mode, make sure you provision ML storage volume with sufficient capacity to
          accommodate the data download from S3. In addition to the training data, the ML
          storage volume also stores the output model. The algorithm container use ML storage
          volume to also store intermediate information, if any.

          For distributed algorithms using File mode, training data is distributed uniformly,
          and your training duration is predictable if the input data objects size is
          approximately same. Amazon SageMaker does not split the files any further for model
          training. If the object sizes are skewed, training won't be optimal as the data
          distribution is also skewed where one host in a training cluster is overloaded, thus
          becoming bottleneck in training.

        - **MetricDefinitions** *(list) --*

          A list of metric definition objects. Each object specifies the metric name and
          regular expressions used to parse algorithm logs. Amazon SageMaker publishes each
          metric to Amazon CloudWatch.

          - *(dict) --*

            Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
            Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
            metric that a hyperparameter tuning job uses as its objective metric to choose the
            best training job.

            - **Name** *(string) --*

              The name of the metric.

            - **Regex** *(string) --*

              A regular expression that searches the output of a training job and gets the
              value of the metric. For more information about using regular expressions to
              define metrics, see `Defining Objective Metrics
              <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
              .

      - **RoleArn** *(string) --*

        The AWS Identity and Access Management (IAM) role configured for the training job.

      - **InputDataConfig** *(list) --*

        An array of ``Channel`` objects that describes each data input channel.

        - *(dict) --*

          A channel is a named input source that training algorithms can consume.

          - **ChannelName** *(string) --*

            The name of the channel.

          - **DataSource** *(dict) --*

            The location of the channel data.

            - **S3DataSource** *(dict) --*

              The S3 location of the data source that is associated with a channel.

              - **S3DataType** *(string) --*

                If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
                SageMaker uses all objects that match the specified key name prefix for model
                training.

                If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
                manifest file containing a list of object keys that you want Amazon SageMaker
                to use for model training.

                If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
                augmented manifest file in JSON lines format. This file contains the data you
                want to use for model training. ``AugmentedManifestFile`` can only be used if
                the Channel's input mode is ``Pipe`` .

              - **S3Uri** *(string) --*

                Depending on the value specified for the ``S3DataType`` , identifies either a
                key name prefix or a manifest. For example:

                * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

                * A manifest might look like this: ``s3://bucketname/example.manifest``   The
                manifest is an S3 object which is a JSON file with the following format:  The
                preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
                "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
                 ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
                  ``]``   The preceding JSON matches the following ``s3Uris`` :
                  ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                  ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                  ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
                  set of ``s3uris`` in this manifest is the input data for the channel for this
                  datasource. The object that each ``s3uris`` points to must be readable by the
                  IAM role that Amazon SageMaker uses to perform tasks on your behalf.

              - **S3DataDistributionType** *(string) --*

                If you want Amazon SageMaker to replicate the entire dataset on each ML compute
                instance that is launched for model training, specify ``FullyReplicated`` .

                If you want Amazon SageMaker to replicate a subset of data on each ML compute
                instance that is launched for model training, specify ``ShardedByS3Key`` . If
                there are *n* ML compute instances launched for a training job, each instance
                gets approximately 1/*n* of the number of S3 objects. In this case, model
                training on each machine uses only the subset of training data.

                Don't choose more ML compute instances for training than available S3 objects.
                If you do, some nodes won't get any data and you will pay for nodes that aren't
                getting any training data. This applies in both File and Pipe modes. Keep this
                in mind when developing algorithms.

                In distributed training, where you use multiple ML compute EC2 instances, you
                might choose ``ShardedByS3Key`` . If the algorithm requires copying training
                data to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ),
                this copies 1/*n* of the number of objects.

              - **AttributeNames** *(list) --*

                A list of one or more attribute names to use that are found in a specified
                augmented manifest file.

                - *(string) --*

            - **FileSystemDataSource** *(dict) --*

              The file system that is associated with a channel.

              - **FileSystemId** *(string) --*

                The file system id.

              - **FileSystemAccessMode** *(string) --*

                The access mode of the mount of the directory associated with the channel. A
                directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
                mode.

              - **FileSystemType** *(string) --*

                The file system type.

              - **DirectoryPath** *(string) --*

                The full path to the directory to associate with the channel.

          - **ContentType** *(string) --*

            The MIME type of the data.

          - **CompressionType** *(string) --*

            If training data is compressed, the compression type. The default value is ``None``
            . ``CompressionType`` is used only in Pipe input mode. In File mode, leave this
            field unset or set it to None.

          - **RecordWrapperType** *(string) --*

            Specify RecordIO as the value when input data is in raw format but the training
            algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
            individual S3 object in a RecordIO record. If the input data is already in RecordIO
            format, you don't need to set this attribute. For more information, see `Create a
            Dataset Using RecordIO
            <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
            .

            In File mode, leave this field unset or set it to None.

          - **InputMode** *(string) --*

            (Optional) The input mode to use for the data channel in a training job. If you
            don't set a value for ``InputMode`` , Amazon SageMaker uses the value set for
            ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
            setting in a  AlgorithmSpecification request when you have a channel that needs a
            different input mode from the training job's general setting. To download the data
            from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage
            volume, and mount the directory to a Docker volume, use ``File`` input mode. To
            stream data directly from Amazon S3 to the container, choose ``Pipe`` input mode.

            To use a model for incremental training, choose ``File`` input model.

          - **ShuffleConfig** *(dict) --*

            A configuration for a shuffle option for input data in a channel. If you use
            ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
            matches. If you use ``ManifestFile`` , the order of the S3 object references in the
            ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of
            the JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
            determined using the ``Seed`` value.

            For Pipe input mode, shuffling is done at the start of every epoch. With large
            datasets this ensures that the order of the training data is different for each
            epoch, it helps reduce bias and possible overfitting. In a multi-node training job
            when ShuffleConfig is combined with ``S3DataDistributionType`` of
            ``ShardedByS3Key`` , the data is shuffled across nodes so that the content sent to
            a particular node on the first epoch might be sent to a different node on the
            second epoch.

            - **Seed** *(integer) --*

              Determines the shuffling order in ``ShuffleConfig`` value.

      - **OutputDataConfig** *(dict) --*

        The S3 path where model artifacts that you configured when creating the job are stored.
        Amazon SageMaker creates subfolders for model artifacts.

        - **KmsKeyId** *(string) --*

          The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
          the model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId``
          can be any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // KMS Key Alias  ``"alias/ExampleAlias"``

          * // Amazon Resource Name (ARN) of a KMS Key Alias
          ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

          If you use a KMS key ID or an alias of your master key, the Amazon SageMaker
          execution role must include permissions to call ``kms:Encrypt`` . If you don't
          provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3 for
          your role's account. Amazon SageMaker uses server-side encryption with KMS-managed
          keys for ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject``
          permission that only allows objects with server-side encryption, set the condition
          key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information,
          see `KMS-Managed Encryption Keys
          <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
          *Amazon Simple Storage Service Developer Guide.*

          The KMS key policy must grant permission to the IAM role that you specify in your
          ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
          requests. For more information, see `Using Key Policies in AWS KMS
          <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
          in the *AWS Key Management Service Developer Guide* .

        - **S3OutputPath** *(string) --*

          Identifies the S3 path where you want Amazon SageMaker to store the model artifacts.
          For example, ``s3://bucket-name/key-name-prefix`` .

      - **ResourceConfig** *(dict) --*

        Resources, including ML compute instances and ML storage volumes, that are configured
        for model training.

        - **InstanceType** *(string) --*

          The ML compute instance type.

        - **InstanceCount** *(integer) --*

          The number of ML compute instances to use. For distributed training, provide a value
          greater than 1.

        - **VolumeSizeInGB** *(integer) --*

          The size of the ML storage volume that you want to provision.

          ML storage volumes store model artifacts and incremental states. Training algorithms
          might also use the ML storage volume for scratch space. If you want to store the
          training data in the ML storage volume, choose ``File`` as the ``TrainingInputMode``
          in the algorithm specification.

          You must specify sufficient ML storage for your scenario.

          .. note::

            Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

          .. note::

            Certain Nitro-based instances include local storage with a fixed total size,
            dependent on the instance type. When using these instances for training, Amazon
            SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage. You
            can't request a ``VolumeSizeInGB`` greater than the total size of the local
            instance storage.

            For a list of instance types that support local instance storage, including the
            total size per instance type, see `Instance Store Volumes
            <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
            .

        - **VolumeKmsKeyId** *(string) --*

          The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
          attached to the ML compute instance(s) that run the training job.

          .. note::

            Certain Nitro-based instances include local storage, dependent on the instance
            type. Local storage volumes are encrypted using a hardware module on the instance.
            You can't request a ``VolumeKmsKeyId`` when using an instance type with local
            storage.

            For a list of instance types that support local instance storage, see `Instance
            Store Volumes
            <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
            .

            For more information about local instance storage encryption, see `SSD Instance
            Store Volumes
            <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

          The ``VolumeKmsKeyId`` can be in any of the following formats:

          * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

          * // Amazon Resource Name (ARN) of a KMS Key
          ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

      - **VpcConfig** *(dict) --*

        A  VpcConfig object that specifies the VPC that this training job has access to. For
        more information, see `Protect Training Jobs by Using an Amazon Virtual Private Cloud
        <https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html>`__ .

        - **SecurityGroupIds** *(list) --*

          The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for
          the VPC that is specified in the ``Subnets`` field.

          - *(string) --*

        - **Subnets** *(list) --*

          The ID of the subnets in the VPC to which you want to connect your training job or
          model.

          .. note::

            Amazon EC2 P3 accelerated computing instances are not available in the c/d/e
            availability zones of region us-east-1. If you want to create endpoints with P3
            instances in VPC mode in region us-east-1, create subnets in a/b/f availability
            zones instead.

          - *(string) --*

      - **StoppingCondition** *(dict) --*

        Specifies a limit to how long a model training job can run. When the job reaches the
        time limit, Amazon SageMaker ends the training job. Use this API to cap model training
        costs.

        To stop a job, Amazon SageMaker sends the algorithm the ``SIGTERM`` signal, which
        delays job termination for 120 seconds. Algorithms can use this 120-second window to
        save the model artifacts, so the results of training are not lost.

        - **MaxRuntimeInSeconds** *(integer) --*

          The maximum length of time, in seconds, that the training or compilation job can run.
          If job does not complete during this time, Amazon SageMaker ends the job. If value is
          not specified, default value is 1 day. The maximum value is 28 days.

        - **MaxWaitTimeInSeconds** *(integer) --*

          The maximum length of time, in seconds, how long you are willing to wait for a
          managed spot training job to complete. It is the amount of time spent waiting for
          Spot capacity plus the amount of time the training job runs. It must be equal to or
          greater than ``MaxRuntimeInSeconds`` .

      - **CreationTime** *(datetime) --*

        A timestamp that indicates when the training job was created.

      - **TrainingStartTime** *(datetime) --*

        Indicates the time when the training job starts on training instances. You are billed
        for the time interval between this time and the value of ``TrainingEndTime`` . The
        start time in CloudWatch Logs might be later than this time. The difference is due to
        the time it takes to download the training data and to the size of the training
        container.

      - **TrainingEndTime** *(datetime) --*

        Indicates the time when the training job ends on training instances. You are billed for
        the time interval between the value of ``TrainingStartTime`` and this time. For
        successful jobs and stopped jobs, this is the time after model artifacts are uploaded.
        For failed jobs, this is the time when Amazon SageMaker detects a job failure.

      - **LastModifiedTime** *(datetime) --*

        A timestamp that indicates when the status of the training job was last modified.

      - **SecondaryStatusTransitions** *(list) --*

        A history of all of the secondary statuses that the training job has transitioned
        through.

        - *(dict) --*

          An array element of  DescribeTrainingJobResponse$SecondaryStatusTransitions . It
          provides additional details about a status that the training job has transitioned
          through. A training job can be in one of several states, for example, starting,
          downloading, training, or uploading. Within each state, there are a number of
          intermediate states. For example, within the starting state, Amazon SageMaker could
          be starting the training job or launching the ML instances. These transitional states
          are referred to as the job's secondary status.

          - **Status** *(string) --*

            Contains a secondary status information from a training job.

            Status might be one of the following secondary statuses:

              InProgress

            * ``Starting`` - Starting the training job.

            * ``Downloading`` - An optional stage for algorithms that support ``File`` training
            input mode. It indicates that data is being downloaded to the ML storage volumes.

            * ``Training`` - Training is in progress.

            * ``Uploading`` - Training is complete and the model artifacts are being uploaded
            to the S3 location.

              Completed

            * ``Completed`` - The training job has completed.

              Failed

            * ``Failed`` - The training job has failed. The reason for the failure is returned
            in the ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

              Stopped

            * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed
            runtime.

            * ``Stopped`` - The training job has stopped.

              Stopping

            * ``Stopping`` - Stopping the training job.

            We no longer support the following secondary statuses:

            * ``LaunchingMLInstances``

            * ``PreparingTrainingStack``

            * ``DownloadingTrainingImage``

          - **StartTime** *(datetime) --*

            A timestamp that shows when the training job transitioned to the current secondary
            status state.

          - **EndTime** *(datetime) --*

            A timestamp that shows when the training job transitioned out of this secondary
            status state into another secondary status state or when the training job has ended.

          - **StatusMessage** *(string) --*

            A detailed description of the progress within a secondary status.

            Amazon SageMaker provides secondary statuses and status messages that apply to each
            of them:

              Starting

            * Starting the training job.

            * Launching requested ML instances.

            * Insufficient capacity error from EC2 while launching instances, retrying!

            * Launched instance was unhealthy, replacing it!

            * Preparing the instances for training.

              Training

            * Downloading the training image.

            * Training image download completed. Training in progress.

            .. warning::

              Status messages are subject to change. Therefore, we recommend not including them
              in code that programmatically initiates actions. For examples, don't use status
              messages in if statements.

            To have an overview of your training job's progress, view ``TrainingJobStatus`` and
            ``SecondaryStatus`` in  DescribeTrainingJob , and ``StatusMessage`` together. For
            example, at the start of a training job, you might see the following:

            * ``TrainingJobStatus`` - InProgress

            * ``SecondaryStatus`` - Training

            * ``StatusMessage`` - Downloading the training image

      - **FinalMetricDataList** *(list) --*

        A list of final metric values that are set when the training job completes. Used only
        if the training job was configured to use metrics.

        - *(dict) --*

          The name, value, and date and time of a metric that was emitted to Amazon CloudWatch.

          - **MetricName** *(string) --*

            The name of the metric.

          - **Value** *(float) --*

            The value of the metric.

          - **Timestamp** *(datetime) --*

            The date and time that the algorithm emitted the metric.

      - **EnableNetworkIsolation** *(boolean) --*

        If the ``TrainingJob`` was created with network isolation, the value is set to ``true``
        . If network isolation is enabled, nodes can't communicate beyond the VPC they run in.

      - **EnableInterContainerTrafficEncryption** *(boolean) --*

        To encrypt all communications between ML compute instances in distributed training,
        choose ``True`` . Encryption provides greater security for distributed training, but
        training might take longer. How long it takes depends on the amount of communication
        between compute instances, especially if you use a deep learning algorithm in
        distributed training.

      - **Tags** *(list) --*

        An array of key-value pairs. For more information, see `Using Cost Allocation Tags
        <https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html#allocation-what>`__
        in the *AWS Billing and Cost Management User Guide* .

        - *(dict) --*

          Describes a tag.

          - **Key** *(string) --*

            The tag key.

          - **Value** *(string) --*

            The tag value.
    """


_SearchPaginateResponseTypeDef = TypedDict(
    "_SearchPaginateResponseTypeDef",
    {"Results": List[SearchPaginateResponseResultsTypeDef]},
    total=False,
)


class SearchPaginateResponseTypeDef(_SearchPaginateResponseTypeDef):
    """
    Type definition for `SearchPaginate` `Response`

    - **Results** *(list) --*

      A list of ``SearchResult`` objects.

      - *(dict) --*

        An individual search result record that contains a single resource object.

        - **TrainingJob** *(dict) --*

          A ``TrainingJob`` object that is returned as part of a ``Search`` request.

          - **TrainingJobName** *(string) --*

            The name of the training job.

          - **TrainingJobArn** *(string) --*

            The Amazon Resource Name (ARN) of the training job.

          - **TuningJobArn** *(string) --*

            The Amazon Resource Name (ARN) of the associated hyperparameter tuning job if the
            training job was launched by a hyperparameter tuning job.

          - **LabelingJobArn** *(string) --*

            The Amazon Resource Name (ARN) of the labeling job.

          - **ModelArtifacts** *(dict) --*

            Information about the Amazon S3 location that is configured for storing model artifacts.

            - **S3ModelArtifacts** *(string) --*

              The path of the S3 object that contains the model artifacts. For example,
              ``s3://bucket-name/keynameprefix/model.tar.gz`` .

          - **TrainingJobStatus** *(string) --*

            The status of the training job.

            Training job statuses are:

            * ``InProgress`` - The training is in progress.

            * ``Completed`` - The training job has completed.

            * ``Failed`` - The training job has failed. To see the reason for the failure, see the
            ``FailureReason`` field in the response to a ``DescribeTrainingJobResponse`` call.

            * ``Stopping`` - The training job is stopping.

            * ``Stopped`` - The training job has stopped.

            For more detailed information, see ``SecondaryStatus`` .

          - **SecondaryStatus** *(string) --*

            Provides detailed information about the state of the training job. For detailed
            information about the secondary status of the training job, see ``StatusMessage`` under
             SecondaryStatusTransition .

            Amazon SageMaker provides primary statuses and secondary statuses that apply to each of
            them:

              InProgress

            * ``Starting`` - Starting the training job.

            * ``Downloading`` - An optional stage for algorithms that support ``File`` training
            input mode. It indicates that data is being downloaded to the ML storage volumes.

            * ``Training`` - Training is in progress.

            * ``Uploading`` - Training is complete and the model artifacts are being uploaded to
            the S3 location.

              Completed

            * ``Completed`` - The training job has completed.

              Failed

            * ``Failed`` - The training job has failed. The reason for the failure is returned in
            the ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

              Stopped

            * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed
            runtime.

            * ``Stopped`` - The training job has stopped.

              Stopping

            * ``Stopping`` - Stopping the training job.

            .. warning::

              Valid values for ``SecondaryStatus`` are subject to change.

            We no longer support the following secondary statuses:

            * ``LaunchingMLInstances``

            * ``PreparingTrainingStack``

            * ``DownloadingTrainingImage``

          - **FailureReason** *(string) --*

            If the training job failed, the reason it failed.

          - **HyperParameters** *(dict) --*

            Algorithm-specific parameters.

            - *(string) --*

              - *(string) --*

          - **AlgorithmSpecification** *(dict) --*

            Information about the algorithm used for training, and algorithm metadata.

            - **TrainingImage** *(string) --*

              The registry path of the Docker image that contains the training algorithm. For
              information about docker registry paths for built-in algorithms, see `Algorithms
              Provided by Amazon SageMaker\\: Common Parameters
              <https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html>`__
              . Amazon SageMaker supports both ``registry/repository[:tag]`` and
              ``registry/repository[@digest]`` image path formats. For more information, see `Using
              Your Own Algorithms with Amazon SageMaker
              <https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html>`__ .

            - **AlgorithmName** *(string) --*

              The name of the algorithm resource to use for the training job. This must be an
              algorithm resource that you created or subscribe to on AWS Marketplace. If you
              specify a value for this parameter, you can't specify a value for ``TrainingImage`` .

            - **TrainingInputMode** *(string) --*

              The input mode that the algorithm supports. For the input modes that Amazon SageMaker
              algorithms support, see `Algorithms
              <https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html>`__ . If an algorithm
              supports the ``File`` input mode, Amazon SageMaker downloads the training data from
              S3 to the provisioned ML storage Volume, and mounts the directory to docker volume
              for training container. If an algorithm supports the ``Pipe`` input mode, Amazon
              SageMaker streams data directly from S3 to the container.

              In File mode, make sure you provision ML storage volume with sufficient capacity to
              accommodate the data download from S3. In addition to the training data, the ML
              storage volume also stores the output model. The algorithm container use ML storage
              volume to also store intermediate information, if any.

              For distributed algorithms using File mode, training data is distributed uniformly,
              and your training duration is predictable if the input data objects size is
              approximately same. Amazon SageMaker does not split the files any further for model
              training. If the object sizes are skewed, training won't be optimal as the data
              distribution is also skewed where one host in a training cluster is overloaded, thus
              becoming bottleneck in training.

            - **MetricDefinitions** *(list) --*

              A list of metric definition objects. Each object specifies the metric name and
              regular expressions used to parse algorithm logs. Amazon SageMaker publishes each
              metric to Amazon CloudWatch.

              - *(dict) --*

                Specifies a metric that the training algorithm writes to ``stderr`` or ``stdout`` .
                Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify one
                metric that a hyperparameter tuning job uses as its objective metric to choose the
                best training job.

                - **Name** *(string) --*

                  The name of the metric.

                - **Regex** *(string) --*

                  A regular expression that searches the output of a training job and gets the
                  value of the metric. For more information about using regular expressions to
                  define metrics, see `Defining Objective Metrics
                  <https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html>`__
                  .

          - **RoleArn** *(string) --*

            The AWS Identity and Access Management (IAM) role configured for the training job.

          - **InputDataConfig** *(list) --*

            An array of ``Channel`` objects that describes each data input channel.

            - *(dict) --*

              A channel is a named input source that training algorithms can consume.

              - **ChannelName** *(string) --*

                The name of the channel.

              - **DataSource** *(dict) --*

                The location of the channel data.

                - **S3DataSource** *(dict) --*

                  The S3 location of the data source that is associated with a channel.

                  - **S3DataType** *(string) --*

                    If you choose ``S3Prefix`` , ``S3Uri`` identifies a key name prefix. Amazon
                    SageMaker uses all objects that match the specified key name prefix for model
                    training.

                    If you choose ``ManifestFile`` , ``S3Uri`` identifies an object that is a
                    manifest file containing a list of object keys that you want Amazon SageMaker
                    to use for model training.

                    If you choose ``AugmentedManifestFile`` , S3Uri identifies an object that is an
                    augmented manifest file in JSON lines format. This file contains the data you
                    want to use for model training. ``AugmentedManifestFile`` can only be used if
                    the Channel's input mode is ``Pipe`` .

                  - **S3Uri** *(string) --*

                    Depending on the value specified for the ``S3DataType`` , identifies either a
                    key name prefix or a manifest. For example:

                    * A key name prefix might look like this: ``s3://bucketname/exampleprefix`` .

                    * A manifest might look like this: ``s3://bucketname/example.manifest``   The
                    manifest is an S3 object which is a JSON file with the following format:  The
                    preceding JSON matches the following ``s3Uris`` :   ``[ {"prefix":
                    "s3://customer_bucket/some/prefix/"},``    ``"relative/path/to/custdata-1",``
                     ``"relative/path/custdata-2",``    ``...``    ``"relative/path/custdata-N"``
                      ``]``   The preceding JSON matches the following ``s3Uris`` :
                      ``s3://customer_bucket/some/prefix/relative/path/to/custdata-1``
                      ``s3://customer_bucket/some/prefix/relative/path/custdata-2``    ``...``
                      ``s3://customer_bucket/some/prefix/relative/path/custdata-N``   The complete
                      set of ``s3uris`` in this manifest is the input data for the channel for this
                      datasource. The object that each ``s3uris`` points to must be readable by the
                      IAM role that Amazon SageMaker uses to perform tasks on your behalf.

                  - **S3DataDistributionType** *(string) --*

                    If you want Amazon SageMaker to replicate the entire dataset on each ML compute
                    instance that is launched for model training, specify ``FullyReplicated`` .

                    If you want Amazon SageMaker to replicate a subset of data on each ML compute
                    instance that is launched for model training, specify ``ShardedByS3Key`` . If
                    there are *n* ML compute instances launched for a training job, each instance
                    gets approximately 1/*n* of the number of S3 objects. In this case, model
                    training on each machine uses only the subset of training data.

                    Don't choose more ML compute instances for training than available S3 objects.
                    If you do, some nodes won't get any data and you will pay for nodes that aren't
                    getting any training data. This applies in both File and Pipe modes. Keep this
                    in mind when developing algorithms.

                    In distributed training, where you use multiple ML compute EC2 instances, you
                    might choose ``ShardedByS3Key`` . If the algorithm requires copying training
                    data to the ML storage volume (when ``TrainingInputMode`` is set to ``File`` ),
                    this copies 1/*n* of the number of objects.

                  - **AttributeNames** *(list) --*

                    A list of one or more attribute names to use that are found in a specified
                    augmented manifest file.

                    - *(string) --*

                - **FileSystemDataSource** *(dict) --*

                  The file system that is associated with a channel.

                  - **FileSystemId** *(string) --*

                    The file system id.

                  - **FileSystemAccessMode** *(string) --*

                    The access mode of the mount of the directory associated with the channel. A
                    directory can be mounted either in ``ro`` (read-only) or ``rw`` (read-write)
                    mode.

                  - **FileSystemType** *(string) --*

                    The file system type.

                  - **DirectoryPath** *(string) --*

                    The full path to the directory to associate with the channel.

              - **ContentType** *(string) --*

                The MIME type of the data.

              - **CompressionType** *(string) --*

                If training data is compressed, the compression type. The default value is ``None``
                . ``CompressionType`` is used only in Pipe input mode. In File mode, leave this
                field unset or set it to None.

              - **RecordWrapperType** *(string) --*

                Specify RecordIO as the value when input data is in raw format but the training
                algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps each
                individual S3 object in a RecordIO record. If the input data is already in RecordIO
                format, you don't need to set this attribute. For more information, see `Create a
                Dataset Using RecordIO
                <https://mxnet.incubator.apache.org/architecture/note_data_loading.html#data-format>`__
                .

                In File mode, leave this field unset or set it to None.

              - **InputMode** *(string) --*

                (Optional) The input mode to use for the data channel in a training job. If you
                don't set a value for ``InputMode`` , Amazon SageMaker uses the value set for
                ``TrainingInputMode`` . Use this parameter to override the ``TrainingInputMode``
                setting in a  AlgorithmSpecification request when you have a channel that needs a
                different input mode from the training job's general setting. To download the data
                from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage
                volume, and mount the directory to a Docker volume, use ``File`` input mode. To
                stream data directly from Amazon S3 to the container, choose ``Pipe`` input mode.

                To use a model for incremental training, choose ``File`` input model.

              - **ShuffleConfig** *(dict) --*

                A configuration for a shuffle option for input data in a channel. If you use
                ``S3Prefix`` for ``S3DataType`` , this shuffles the results of the S3 key prefix
                matches. If you use ``ManifestFile`` , the order of the S3 object references in the
                ``ManifestFile`` is shuffled. If you use ``AugmentedManifestFile`` , the order of
                the JSON lines in the ``AugmentedManifestFile`` is shuffled. The shuffling order is
                determined using the ``Seed`` value.

                For Pipe input mode, shuffling is done at the start of every epoch. With large
                datasets this ensures that the order of the training data is different for each
                epoch, it helps reduce bias and possible overfitting. In a multi-node training job
                when ShuffleConfig is combined with ``S3DataDistributionType`` of
                ``ShardedByS3Key`` , the data is shuffled across nodes so that the content sent to
                a particular node on the first epoch might be sent to a different node on the
                second epoch.

                - **Seed** *(integer) --*

                  Determines the shuffling order in ``ShuffleConfig`` value.

          - **OutputDataConfig** *(dict) --*

            The S3 path where model artifacts that you configured when creating the job are stored.
            Amazon SageMaker creates subfolders for model artifacts.

            - **KmsKeyId** *(string) --*

              The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt
              the model artifacts at rest using Amazon S3 server-side encryption. The ``KmsKeyId``
              can be any of the following formats:

              * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // Amazon Resource Name (ARN) of a KMS Key
              ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // KMS Key Alias  ``"alias/ExampleAlias"``

              * // Amazon Resource Name (ARN) of a KMS Key Alias
              ``"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"``

              If you use a KMS key ID or an alias of your master key, the Amazon SageMaker
              execution role must include permissions to call ``kms:Encrypt`` . If you don't
              provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3 for
              your role's account. Amazon SageMaker uses server-side encryption with KMS-managed
              keys for ``OutputDataConfig`` . If you use a bucket policy with an ``s3:PutObject``
              permission that only allows objects with server-side encryption, set the condition
              key of ``s3:x-amz-server-side-encryption`` to ``"aws:kms"`` . For more information,
              see `KMS-Managed Encryption Keys
              <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html>`__ in the
              *Amazon Simple Storage Service Developer Guide.*

              The KMS key policy must grant permission to the IAM role that you specify in your
              ``CreateTrainingJob`` , ``CreateTransformJob`` , or ``CreateHyperParameterTuningJob``
              requests. For more information, see `Using Key Policies in AWS KMS
              <https://docs.aws.amazon.com/http:/docs.aws.amazon.com/kms/latest/developerguide/key-policies.html>`__
              in the *AWS Key Management Service Developer Guide* .

            - **S3OutputPath** *(string) --*

              Identifies the S3 path where you want Amazon SageMaker to store the model artifacts.
              For example, ``s3://bucket-name/key-name-prefix`` .

          - **ResourceConfig** *(dict) --*

            Resources, including ML compute instances and ML storage volumes, that are configured
            for model training.

            - **InstanceType** *(string) --*

              The ML compute instance type.

            - **InstanceCount** *(integer) --*

              The number of ML compute instances to use. For distributed training, provide a value
              greater than 1.

            - **VolumeSizeInGB** *(integer) --*

              The size of the ML storage volume that you want to provision.

              ML storage volumes store model artifacts and incremental states. Training algorithms
              might also use the ML storage volume for scratch space. If you want to store the
              training data in the ML storage volume, choose ``File`` as the ``TrainingInputMode``
              in the algorithm specification.

              You must specify sufficient ML storage for your scenario.

              .. note::

                Amazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.

              .. note::

                Certain Nitro-based instances include local storage with a fixed total size,
                dependent on the instance type. When using these instances for training, Amazon
                SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage. You
                can't request a ``VolumeSizeInGB`` greater than the total size of the local
                instance storage.

                For a list of instance types that support local instance storage, including the
                total size per instance type, see `Instance Store Volumes
                <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
                .

            - **VolumeKmsKeyId** *(string) --*

              The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
              attached to the ML compute instance(s) that run the training job.

              .. note::

                Certain Nitro-based instances include local storage, dependent on the instance
                type. Local storage volumes are encrypted using a hardware module on the instance.
                You can't request a ``VolumeKmsKeyId`` when using an instance type with local
                storage.

                For a list of instance types that support local instance storage, see `Instance
                Store Volumes
                <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes>`__
                .

                For more information about local instance storage encryption, see `SSD Instance
                Store Volumes
                <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html>`__ .

              The ``VolumeKmsKeyId`` can be in any of the following formats:

              * // KMS Key ID  ``"1234abcd-12ab-34cd-56ef-1234567890ab"``

              * // Amazon Resource Name (ARN) of a KMS Key
              ``"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"``

          - **VpcConfig** *(dict) --*

            A  VpcConfig object that specifies the VPC that this training job has access to. For
            more information, see `Protect Training Jobs by Using an Amazon Virtual Private Cloud
            <https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html>`__ .

            - **SecurityGroupIds** *(list) --*

              The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for
              the VPC that is specified in the ``Subnets`` field.

              - *(string) --*

            - **Subnets** *(list) --*

              The ID of the subnets in the VPC to which you want to connect your training job or
              model.

              .. note::

                Amazon EC2 P3 accelerated computing instances are not available in the c/d/e
                availability zones of region us-east-1. If you want to create endpoints with P3
                instances in VPC mode in region us-east-1, create subnets in a/b/f availability
                zones instead.

              - *(string) --*

          - **StoppingCondition** *(dict) --*

            Specifies a limit to how long a model training job can run. When the job reaches the
            time limit, Amazon SageMaker ends the training job. Use this API to cap model training
            costs.

            To stop a job, Amazon SageMaker sends the algorithm the ``SIGTERM`` signal, which
            delays job termination for 120 seconds. Algorithms can use this 120-second window to
            save the model artifacts, so the results of training are not lost.

            - **MaxRuntimeInSeconds** *(integer) --*

              The maximum length of time, in seconds, that the training or compilation job can run.
              If job does not complete during this time, Amazon SageMaker ends the job. If value is
              not specified, default value is 1 day. The maximum value is 28 days.

            - **MaxWaitTimeInSeconds** *(integer) --*

              The maximum length of time, in seconds, how long you are willing to wait for a
              managed spot training job to complete. It is the amount of time spent waiting for
              Spot capacity plus the amount of time the training job runs. It must be equal to or
              greater than ``MaxRuntimeInSeconds`` .

          - **CreationTime** *(datetime) --*

            A timestamp that indicates when the training job was created.

          - **TrainingStartTime** *(datetime) --*

            Indicates the time when the training job starts on training instances. You are billed
            for the time interval between this time and the value of ``TrainingEndTime`` . The
            start time in CloudWatch Logs might be later than this time. The difference is due to
            the time it takes to download the training data and to the size of the training
            container.

          - **TrainingEndTime** *(datetime) --*

            Indicates the time when the training job ends on training instances. You are billed for
            the time interval between the value of ``TrainingStartTime`` and this time. For
            successful jobs and stopped jobs, this is the time after model artifacts are uploaded.
            For failed jobs, this is the time when Amazon SageMaker detects a job failure.

          - **LastModifiedTime** *(datetime) --*

            A timestamp that indicates when the status of the training job was last modified.

          - **SecondaryStatusTransitions** *(list) --*

            A history of all of the secondary statuses that the training job has transitioned
            through.

            - *(dict) --*

              An array element of  DescribeTrainingJobResponse$SecondaryStatusTransitions . It
              provides additional details about a status that the training job has transitioned
              through. A training job can be in one of several states, for example, starting,
              downloading, training, or uploading. Within each state, there are a number of
              intermediate states. For example, within the starting state, Amazon SageMaker could
              be starting the training job or launching the ML instances. These transitional states
              are referred to as the job's secondary status.

              - **Status** *(string) --*

                Contains a secondary status information from a training job.

                Status might be one of the following secondary statuses:

                  InProgress

                * ``Starting`` - Starting the training job.

                * ``Downloading`` - An optional stage for algorithms that support ``File`` training
                input mode. It indicates that data is being downloaded to the ML storage volumes.

                * ``Training`` - Training is in progress.

                * ``Uploading`` - Training is complete and the model artifacts are being uploaded
                to the S3 location.

                  Completed

                * ``Completed`` - The training job has completed.

                  Failed

                * ``Failed`` - The training job has failed. The reason for the failure is returned
                in the ``FailureReason`` field of ``DescribeTrainingJobResponse`` .

                  Stopped

                * ``MaxRuntimeExceeded`` - The job stopped because it exceeded the maximum allowed
                runtime.

                * ``Stopped`` - The training job has stopped.

                  Stopping

                * ``Stopping`` - Stopping the training job.

                We no longer support the following secondary statuses:

                * ``LaunchingMLInstances``

                * ``PreparingTrainingStack``

                * ``DownloadingTrainingImage``

              - **StartTime** *(datetime) --*

                A timestamp that shows when the training job transitioned to the current secondary
                status state.

              - **EndTime** *(datetime) --*

                A timestamp that shows when the training job transitioned out of this secondary
                status state into another secondary status state or when the training job has ended.

              - **StatusMessage** *(string) --*

                A detailed description of the progress within a secondary status.

                Amazon SageMaker provides secondary statuses and status messages that apply to each
                of them:

                  Starting

                * Starting the training job.

                * Launching requested ML instances.

                * Insufficient capacity error from EC2 while launching instances, retrying!

                * Launched instance was unhealthy, replacing it!

                * Preparing the instances for training.

                  Training

                * Downloading the training image.

                * Training image download completed. Training in progress.

                .. warning::

                  Status messages are subject to change. Therefore, we recommend not including them
                  in code that programmatically initiates actions. For examples, don't use status
                  messages in if statements.

                To have an overview of your training job's progress, view ``TrainingJobStatus`` and
                ``SecondaryStatus`` in  DescribeTrainingJob , and ``StatusMessage`` together. For
                example, at the start of a training job, you might see the following:

                * ``TrainingJobStatus`` - InProgress

                * ``SecondaryStatus`` - Training

                * ``StatusMessage`` - Downloading the training image

          - **FinalMetricDataList** *(list) --*

            A list of final metric values that are set when the training job completes. Used only
            if the training job was configured to use metrics.

            - *(dict) --*

              The name, value, and date and time of a metric that was emitted to Amazon CloudWatch.

              - **MetricName** *(string) --*

                The name of the metric.

              - **Value** *(float) --*

                The value of the metric.

              - **Timestamp** *(datetime) --*

                The date and time that the algorithm emitted the metric.

          - **EnableNetworkIsolation** *(boolean) --*

            If the ``TrainingJob`` was created with network isolation, the value is set to ``true``
            . If network isolation is enabled, nodes can't communicate beyond the VPC they run in.

          - **EnableInterContainerTrafficEncryption** *(boolean) --*

            To encrypt all communications between ML compute instances in distributed training,
            choose ``True`` . Encryption provides greater security for distributed training, but
            training might take longer. How long it takes depends on the amount of communication
            between compute instances, especially if you use a deep learning algorithm in
            distributed training.

          - **Tags** *(list) --*

            An array of key-value pairs. For more information, see `Using Cost Allocation Tags
            <https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html#allocation-what>`__
            in the *AWS Billing and Cost Management User Guide* .

            - *(dict) --*

              Describes a tag.

              - **Key** *(string) --*

                The tag key.

              - **Value** *(string) --*

                The tag value.
    """


_RequiredSearchPaginateSearchExpressionFiltersTypeDef = TypedDict(
    "_RequiredSearchPaginateSearchExpressionFiltersTypeDef", {"Name": str}
)
_OptionalSearchPaginateSearchExpressionFiltersTypeDef = TypedDict(
    "_OptionalSearchPaginateSearchExpressionFiltersTypeDef",
    {"Operator": str, "Value": str},
    total=False,
)


class SearchPaginateSearchExpressionFiltersTypeDef(
    _RequiredSearchPaginateSearchExpressionFiltersTypeDef,
    _OptionalSearchPaginateSearchExpressionFiltersTypeDef,
):
    """
    Type definition for `SearchPaginateSearchExpression` `Filters`

    A conditional statement for a search expression that includes a resource property, a Boolean
    operator, and a value.

    If you don't specify an ``Operator`` and a ``Value`` , the filter searches for only the
    specified property. For example, defining a ``Filter`` for the ``FailureReason`` for the
    ``TrainingJob``  ``Resource`` searches for training job objects that have a value in the
    ``FailureReason`` field.

    If you specify a ``Value`` , but not an ``Operator`` , Amazon SageMaker uses the equals
    operator as the default.

    In search, there are several property types:

      Metrics

    To define a metric filter, enter a value using the form ``"Metrics.<name>"`` , where
    ``<name>`` is a metric name. For example, the following filter searches for training jobs
    with an ``"accuracy"`` metric greater than ``"0.9"`` :

     ``{``

     ``"Name": "Metrics.accuracy",``

     ``"Operator": "GREATER_THAN",``

     ``"Value": "0.9"``

     ``}``

      HyperParameters

    To define a hyperparameter filter, enter a value with the form ``"HyperParameters.<name>"`` .
    Decimal hyperparameter values are treated as a decimal in a comparison if the specified
    ``Value`` is also a decimal value. If the specified ``Value`` is an integer, the decimal
    hyperparameter values are treated as integers. For example, the following filter is satisfied
    by training jobs with a ``"learning_rate"`` hyperparameter that is less than ``"0.5"`` :

     ``{``

     ``"Name": "HyperParameters.learning_rate",``

     ``"Operator": "LESS_THAN",``

     ``"Value": "0.5"``

     ``}``

      Tags

    To define a tag filter, enter a value with the form ``"Tags.<key>"`` .

    - **Name** *(string) --* **[REQUIRED]**

      A property name. For example, ``TrainingJobName`` . For the list of valid property names
      returned in a search result for each supported resource, see  TrainingJob properties. You
      must specify a valid property name for the resource.

    - **Operator** *(string) --*

      A Boolean binary operator that is used to evaluate the filter. The operator field contains
      one of the following values:

        Equals

      The specified resource in ``Name`` equals the specified ``Value`` .

        NotEquals

      The specified resource in ``Name`` does not equal the specified ``Value`` .

        GreaterThan

      The specified resource in ``Name`` is greater than the specified ``Value`` . Not supported
      for text-based properties.

        GreaterThanOrEqualTo

      The specified resource in ``Name`` is greater than or equal to the specified ``Value`` .
      Not supported for text-based properties.

        LessThan

      The specified resource in ``Name`` is less than the specified ``Value`` . Not supported for
      text-based properties.

        LessThanOrEqualTo

      The specified resource in ``Name`` is less than or equal to the specified ``Value`` . Not
      supported for text-based properties.

        Contains

      Only supported for text-based properties. The word-list of the property contains the
      specified ``Value`` . A ``SearchExpression`` can include only one ``Contains`` operator.

      If you have specified a filter ``Value`` , the default is ``Equals`` .

    - **Value** *(string) --*

      A value used with ``Resource`` and ``Operator`` to determine if objects satisfy the
      filter's condition. For numerical properties, ``Value`` must be an integer or
      floating-point decimal. For timestamp properties, ``Value`` must be an ISO 8601 date-time
      string of the following format: ``YYYY-mm-dd'T'HH:MM:SS`` .
    """


_RequiredSearchPaginateSearchExpressionNestedFiltersFiltersTypeDef = TypedDict(
    "_RequiredSearchPaginateSearchExpressionNestedFiltersFiltersTypeDef", {"Name": str}
)
_OptionalSearchPaginateSearchExpressionNestedFiltersFiltersTypeDef = TypedDict(
    "_OptionalSearchPaginateSearchExpressionNestedFiltersFiltersTypeDef",
    {"Operator": str, "Value": str},
    total=False,
)


class SearchPaginateSearchExpressionNestedFiltersFiltersTypeDef(
    _RequiredSearchPaginateSearchExpressionNestedFiltersFiltersTypeDef,
    _OptionalSearchPaginateSearchExpressionNestedFiltersFiltersTypeDef,
):
    """
    Type definition for `SearchPaginateSearchExpressionNestedFilters` `Filters`

    A conditional statement for a search expression that includes a resource property, a
    Boolean operator, and a value.

    If you don't specify an ``Operator`` and a ``Value`` , the filter searches for only the
    specified property. For example, defining a ``Filter`` for the ``FailureReason`` for the
    ``TrainingJob``  ``Resource`` searches for training job objects that have a value in the
    ``FailureReason`` field.

    If you specify a ``Value`` , but not an ``Operator`` , Amazon SageMaker uses the equals
    operator as the default.

    In search, there are several property types:

      Metrics

    To define a metric filter, enter a value using the form ``"Metrics.<name>"`` , where
    ``<name>`` is a metric name. For example, the following filter searches for training jobs
    with an ``"accuracy"`` metric greater than ``"0.9"`` :

     ``{``

     ``"Name": "Metrics.accuracy",``

     ``"Operator": "GREATER_THAN",``

     ``"Value": "0.9"``

     ``}``

      HyperParameters

    To define a hyperparameter filter, enter a value with the form
    ``"HyperParameters.<name>"`` . Decimal hyperparameter values are treated as a decimal in
    a comparison if the specified ``Value`` is also a decimal value. If the specified
    ``Value`` is an integer, the decimal hyperparameter values are treated as integers. For
    example, the following filter is satisfied by training jobs with a ``"learning_rate"``
    hyperparameter that is less than ``"0.5"`` :

     ``{``

     ``"Name": "HyperParameters.learning_rate",``

     ``"Operator": "LESS_THAN",``

     ``"Value": "0.5"``

     ``}``

      Tags

    To define a tag filter, enter a value with the form ``"Tags.<key>"`` .

    - **Name** *(string) --* **[REQUIRED]**

      A property name. For example, ``TrainingJobName`` . For the list of valid property
      names returned in a search result for each supported resource, see  TrainingJob
      properties. You must specify a valid property name for the resource.

    - **Operator** *(string) --*

      A Boolean binary operator that is used to evaluate the filter. The operator field
      contains one of the following values:

        Equals

      The specified resource in ``Name`` equals the specified ``Value`` .

        NotEquals

      The specified resource in ``Name`` does not equal the specified ``Value`` .

        GreaterThan

      The specified resource in ``Name`` is greater than the specified ``Value`` . Not
      supported for text-based properties.

        GreaterThanOrEqualTo

      The specified resource in ``Name`` is greater than or equal to the specified ``Value``
      . Not supported for text-based properties.

        LessThan

      The specified resource in ``Name`` is less than the specified ``Value`` . Not supported
      for text-based properties.

        LessThanOrEqualTo

      The specified resource in ``Name`` is less than or equal to the specified ``Value`` .
      Not supported for text-based properties.

        Contains

      Only supported for text-based properties. The word-list of the property contains the
      specified ``Value`` . A ``SearchExpression`` can include only one ``Contains`` operator.

      If you have specified a filter ``Value`` , the default is ``Equals`` .

    - **Value** *(string) --*

      A value used with ``Resource`` and ``Operator`` to determine if objects satisfy the
      filter's condition. For numerical properties, ``Value`` must be an integer or
      floating-point decimal. For timestamp properties, ``Value`` must be an ISO 8601
      date-time string of the following format: ``YYYY-mm-dd'T'HH:MM:SS`` .
    """


_SearchPaginateSearchExpressionNestedFiltersTypeDef = TypedDict(
    "_SearchPaginateSearchExpressionNestedFiltersTypeDef",
    {
        "NestedPropertyName": str,
        "Filters": List[SearchPaginateSearchExpressionNestedFiltersFiltersTypeDef],
    },
)


class SearchPaginateSearchExpressionNestedFiltersTypeDef(
    _SearchPaginateSearchExpressionNestedFiltersTypeDef
):
    """
    Type definition for `SearchPaginateSearchExpression` `NestedFilters`

    Defines a list of ``NestedFilters`` objects. To satisfy the conditions specified in the
    ``NestedFilters`` call, a resource must satisfy the conditions of all of the filters.

    For example, you could define a ``NestedFilters`` using the training job's
    ``InputDataConfig`` property to filter on ``Channel`` objects.

    A ``NestedFilters`` object contains multiple filters. For example, to find all training jobs
    whose name contains ``train`` and that have ``cat/data`` in their ``S3Uri`` (specified in
    ``InputDataConfig`` ), you need to create a ``NestedFilters`` object that specifies the
    ``InputDataConfig`` property with the following ``Filter`` objects:

    * ``'{Name:"InputDataConfig.ChannelName", "Operator":"EQUALS", "Value":"train"}',``

    * ``'{Name:"InputDataConfig.DataSource.S3DataSource.S3Uri", "Operator":"CONTAINS",
    "Value":"cat/data"}'``

    - **NestedPropertyName** *(string) --* **[REQUIRED]**

      The name of the property to use in the nested filters. The value must match a listed
      property name, such as ``InputDataConfig`` .

    - **Filters** *(list) --* **[REQUIRED]**

      A list of filters. Each filter acts on a property. Filters must contain at least one
      ``Filters`` value. For example, a ``NestedFilters`` call might include a filter on the
      ``PropertyName`` parameter of the ``InputDataConfig`` property:
      ``InputDataConfig.DataSource.S3DataSource.S3Uri`` .

      - *(dict) --*

        A conditional statement for a search expression that includes a resource property, a
        Boolean operator, and a value.

        If you don't specify an ``Operator`` and a ``Value`` , the filter searches for only the
        specified property. For example, defining a ``Filter`` for the ``FailureReason`` for the
        ``TrainingJob``  ``Resource`` searches for training job objects that have a value in the
        ``FailureReason`` field.

        If you specify a ``Value`` , but not an ``Operator`` , Amazon SageMaker uses the equals
        operator as the default.

        In search, there are several property types:

          Metrics

        To define a metric filter, enter a value using the form ``"Metrics.<name>"`` , where
        ``<name>`` is a metric name. For example, the following filter searches for training jobs
        with an ``"accuracy"`` metric greater than ``"0.9"`` :

         ``{``

         ``"Name": "Metrics.accuracy",``

         ``"Operator": "GREATER_THAN",``

         ``"Value": "0.9"``

         ``}``

          HyperParameters

        To define a hyperparameter filter, enter a value with the form
        ``"HyperParameters.<name>"`` . Decimal hyperparameter values are treated as a decimal in
        a comparison if the specified ``Value`` is also a decimal value. If the specified
        ``Value`` is an integer, the decimal hyperparameter values are treated as integers. For
        example, the following filter is satisfied by training jobs with a ``"learning_rate"``
        hyperparameter that is less than ``"0.5"`` :

         ``{``

         ``"Name": "HyperParameters.learning_rate",``

         ``"Operator": "LESS_THAN",``

         ``"Value": "0.5"``

         ``}``

          Tags

        To define a tag filter, enter a value with the form ``"Tags.<key>"`` .

        - **Name** *(string) --* **[REQUIRED]**

          A property name. For example, ``TrainingJobName`` . For the list of valid property
          names returned in a search result for each supported resource, see  TrainingJob
          properties. You must specify a valid property name for the resource.

        - **Operator** *(string) --*

          A Boolean binary operator that is used to evaluate the filter. The operator field
          contains one of the following values:

            Equals

          The specified resource in ``Name`` equals the specified ``Value`` .

            NotEquals

          The specified resource in ``Name`` does not equal the specified ``Value`` .

            GreaterThan

          The specified resource in ``Name`` is greater than the specified ``Value`` . Not
          supported for text-based properties.

            GreaterThanOrEqualTo

          The specified resource in ``Name`` is greater than or equal to the specified ``Value``
          . Not supported for text-based properties.

            LessThan

          The specified resource in ``Name`` is less than the specified ``Value`` . Not supported
          for text-based properties.

            LessThanOrEqualTo

          The specified resource in ``Name`` is less than or equal to the specified ``Value`` .
          Not supported for text-based properties.

            Contains

          Only supported for text-based properties. The word-list of the property contains the
          specified ``Value`` . A ``SearchExpression`` can include only one ``Contains`` operator.

          If you have specified a filter ``Value`` , the default is ``Equals`` .

        - **Value** *(string) --*

          A value used with ``Resource`` and ``Operator`` to determine if objects satisfy the
          filter's condition. For numerical properties, ``Value`` must be an integer or
          floating-point decimal. For timestamp properties, ``Value`` must be an ISO 8601
          date-time string of the following format: ``YYYY-mm-dd'T'HH:MM:SS`` .
    """


_SearchPaginateSearchExpressionTypeDef = TypedDict(
    "_SearchPaginateSearchExpressionTypeDef",
    {
        "Filters": List[SearchPaginateSearchExpressionFiltersTypeDef],
        "NestedFilters": List[SearchPaginateSearchExpressionNestedFiltersTypeDef],
        "SubExpressions": List[Dict],
        "Operator": str,
    },
    total=False,
)


class SearchPaginateSearchExpressionTypeDef(_SearchPaginateSearchExpressionTypeDef):
    """
    Type definition for `SearchPaginate` `SearchExpression`

    A Boolean conditional statement. Resource objects must satisfy this condition to be included in
    search results. You must provide at least one subexpression, filter, or nested filter. The
    maximum number of recursive ``SubExpressions`` , ``NestedFilters`` , and ``Filters`` that can be
    included in a ``SearchExpression`` object is 50.

    - **Filters** *(list) --*

      A list of filter objects.

      - *(dict) --*

        A conditional statement for a search expression that includes a resource property, a Boolean
        operator, and a value.

        If you don't specify an ``Operator`` and a ``Value`` , the filter searches for only the
        specified property. For example, defining a ``Filter`` for the ``FailureReason`` for the
        ``TrainingJob``  ``Resource`` searches for training job objects that have a value in the
        ``FailureReason`` field.

        If you specify a ``Value`` , but not an ``Operator`` , Amazon SageMaker uses the equals
        operator as the default.

        In search, there are several property types:

          Metrics

        To define a metric filter, enter a value using the form ``"Metrics.<name>"`` , where
        ``<name>`` is a metric name. For example, the following filter searches for training jobs
        with an ``"accuracy"`` metric greater than ``"0.9"`` :

         ``{``

         ``"Name": "Metrics.accuracy",``

         ``"Operator": "GREATER_THAN",``

         ``"Value": "0.9"``

         ``}``

          HyperParameters

        To define a hyperparameter filter, enter a value with the form ``"HyperParameters.<name>"`` .
        Decimal hyperparameter values are treated as a decimal in a comparison if the specified
        ``Value`` is also a decimal value. If the specified ``Value`` is an integer, the decimal
        hyperparameter values are treated as integers. For example, the following filter is satisfied
        by training jobs with a ``"learning_rate"`` hyperparameter that is less than ``"0.5"`` :

         ``{``

         ``"Name": "HyperParameters.learning_rate",``

         ``"Operator": "LESS_THAN",``

         ``"Value": "0.5"``

         ``}``

          Tags

        To define a tag filter, enter a value with the form ``"Tags.<key>"`` .

        - **Name** *(string) --* **[REQUIRED]**

          A property name. For example, ``TrainingJobName`` . For the list of valid property names
          returned in a search result for each supported resource, see  TrainingJob properties. You
          must specify a valid property name for the resource.

        - **Operator** *(string) --*

          A Boolean binary operator that is used to evaluate the filter. The operator field contains
          one of the following values:

            Equals

          The specified resource in ``Name`` equals the specified ``Value`` .

            NotEquals

          The specified resource in ``Name`` does not equal the specified ``Value`` .

            GreaterThan

          The specified resource in ``Name`` is greater than the specified ``Value`` . Not supported
          for text-based properties.

            GreaterThanOrEqualTo

          The specified resource in ``Name`` is greater than or equal to the specified ``Value`` .
          Not supported for text-based properties.

            LessThan

          The specified resource in ``Name`` is less than the specified ``Value`` . Not supported for
          text-based properties.

            LessThanOrEqualTo

          The specified resource in ``Name`` is less than or equal to the specified ``Value`` . Not
          supported for text-based properties.

            Contains

          Only supported for text-based properties. The word-list of the property contains the
          specified ``Value`` . A ``SearchExpression`` can include only one ``Contains`` operator.

          If you have specified a filter ``Value`` , the default is ``Equals`` .

        - **Value** *(string) --*

          A value used with ``Resource`` and ``Operator`` to determine if objects satisfy the
          filter's condition. For numerical properties, ``Value`` must be an integer or
          floating-point decimal. For timestamp properties, ``Value`` must be an ISO 8601 date-time
          string of the following format: ``YYYY-mm-dd'T'HH:MM:SS`` .

    - **NestedFilters** *(list) --*

      A list of nested filter objects.

      - *(dict) --*

        Defines a list of ``NestedFilters`` objects. To satisfy the conditions specified in the
        ``NestedFilters`` call, a resource must satisfy the conditions of all of the filters.

        For example, you could define a ``NestedFilters`` using the training job's
        ``InputDataConfig`` property to filter on ``Channel`` objects.

        A ``NestedFilters`` object contains multiple filters. For example, to find all training jobs
        whose name contains ``train`` and that have ``cat/data`` in their ``S3Uri`` (specified in
        ``InputDataConfig`` ), you need to create a ``NestedFilters`` object that specifies the
        ``InputDataConfig`` property with the following ``Filter`` objects:

        * ``'{Name:"InputDataConfig.ChannelName", "Operator":"EQUALS", "Value":"train"}',``

        * ``'{Name:"InputDataConfig.DataSource.S3DataSource.S3Uri", "Operator":"CONTAINS",
        "Value":"cat/data"}'``

        - **NestedPropertyName** *(string) --* **[REQUIRED]**

          The name of the property to use in the nested filters. The value must match a listed
          property name, such as ``InputDataConfig`` .

        - **Filters** *(list) --* **[REQUIRED]**

          A list of filters. Each filter acts on a property. Filters must contain at least one
          ``Filters`` value. For example, a ``NestedFilters`` call might include a filter on the
          ``PropertyName`` parameter of the ``InputDataConfig`` property:
          ``InputDataConfig.DataSource.S3DataSource.S3Uri`` .

          - *(dict) --*

            A conditional statement for a search expression that includes a resource property, a
            Boolean operator, and a value.

            If you don't specify an ``Operator`` and a ``Value`` , the filter searches for only the
            specified property. For example, defining a ``Filter`` for the ``FailureReason`` for the
            ``TrainingJob``  ``Resource`` searches for training job objects that have a value in the
            ``FailureReason`` field.

            If you specify a ``Value`` , but not an ``Operator`` , Amazon SageMaker uses the equals
            operator as the default.

            In search, there are several property types:

              Metrics

            To define a metric filter, enter a value using the form ``"Metrics.<name>"`` , where
            ``<name>`` is a metric name. For example, the following filter searches for training jobs
            with an ``"accuracy"`` metric greater than ``"0.9"`` :

             ``{``

             ``"Name": "Metrics.accuracy",``

             ``"Operator": "GREATER_THAN",``

             ``"Value": "0.9"``

             ``}``

              HyperParameters

            To define a hyperparameter filter, enter a value with the form
            ``"HyperParameters.<name>"`` . Decimal hyperparameter values are treated as a decimal in
            a comparison if the specified ``Value`` is also a decimal value. If the specified
            ``Value`` is an integer, the decimal hyperparameter values are treated as integers. For
            example, the following filter is satisfied by training jobs with a ``"learning_rate"``
            hyperparameter that is less than ``"0.5"`` :

             ``{``

             ``"Name": "HyperParameters.learning_rate",``

             ``"Operator": "LESS_THAN",``

             ``"Value": "0.5"``

             ``}``

              Tags

            To define a tag filter, enter a value with the form ``"Tags.<key>"`` .

            - **Name** *(string) --* **[REQUIRED]**

              A property name. For example, ``TrainingJobName`` . For the list of valid property
              names returned in a search result for each supported resource, see  TrainingJob
              properties. You must specify a valid property name for the resource.

            - **Operator** *(string) --*

              A Boolean binary operator that is used to evaluate the filter. The operator field
              contains one of the following values:

                Equals

              The specified resource in ``Name`` equals the specified ``Value`` .

                NotEquals

              The specified resource in ``Name`` does not equal the specified ``Value`` .

                GreaterThan

              The specified resource in ``Name`` is greater than the specified ``Value`` . Not
              supported for text-based properties.

                GreaterThanOrEqualTo

              The specified resource in ``Name`` is greater than or equal to the specified ``Value``
              . Not supported for text-based properties.

                LessThan

              The specified resource in ``Name`` is less than the specified ``Value`` . Not supported
              for text-based properties.

                LessThanOrEqualTo

              The specified resource in ``Name`` is less than or equal to the specified ``Value`` .
              Not supported for text-based properties.

                Contains

              Only supported for text-based properties. The word-list of the property contains the
              specified ``Value`` . A ``SearchExpression`` can include only one ``Contains`` operator.

              If you have specified a filter ``Value`` , the default is ``Equals`` .

            - **Value** *(string) --*

              A value used with ``Resource`` and ``Operator`` to determine if objects satisfy the
              filter's condition. For numerical properties, ``Value`` must be an integer or
              floating-point decimal. For timestamp properties, ``Value`` must be an ISO 8601
              date-time string of the following format: ``YYYY-mm-dd'T'HH:MM:SS`` .

    - **SubExpressions** *(list) --*

      A list of search expression objects.

      - *(dict) --*

        A multi-expression that searches for the specified resource or resources in a search. All
        resource objects that satisfy the expression's condition are included in the search results.
        You must specify at least one subexpression, filter, or nested filter. A ``SearchExpression``
        can contain up to twenty elements.

        A ``SearchExpression`` contains the following components:

        * A list of ``Filter`` objects. Each filter defines a simple Boolean expression comprised of
        a resource property name, Boolean operator, and value. A ``SearchExpression`` can include
        only one ``Contains`` operator.

        * A list of ``NestedFilter`` objects. Each nested filter defines a list of Boolean
        expressions using a list of resource properties. A nested filter is satisfied if a single
        object in the list satisfies all Boolean expressions.

        * A list of ``SearchExpression`` objects. A search expression object can be nested in a list
        of search expression objects.

        * A Boolean operator: ``And`` or ``Or`` .

    - **Operator** *(string) --*

      A Boolean operator used to evaluate the search expression. If you want every conditional
      statement in all lists to be satisfied for the entire search expression to be true, specify
      ``And`` . If only a single conditional statement needs to be true for the entire search
      expression to be true, specify ``Or`` . The default value is ``And`` .
    """


_TrainingJobCompletedOrStoppedWaitWaiterConfigTypeDef = TypedDict(
    "_TrainingJobCompletedOrStoppedWaitWaiterConfigTypeDef",
    {"Delay": int, "MaxAttempts": int},
    total=False,
)


class TrainingJobCompletedOrStoppedWaitWaiterConfigTypeDef(
    _TrainingJobCompletedOrStoppedWaitWaiterConfigTypeDef
):
    """
    Type definition for `TrainingJobCompletedOrStoppedWait` `WaiterConfig`

    A dictionary that provides parameters to control waiting behavior.

    - **Delay** *(integer) --*

      The amount of time in seconds to wait between attempts. Default: 120

    - **MaxAttempts** *(integer) --*

      The maximum number of attempts to be made. Default: 180
    """


_TransformJobCompletedOrStoppedWaitWaiterConfigTypeDef = TypedDict(
    "_TransformJobCompletedOrStoppedWaitWaiterConfigTypeDef",
    {"Delay": int, "MaxAttempts": int},
    total=False,
)


class TransformJobCompletedOrStoppedWaitWaiterConfigTypeDef(
    _TransformJobCompletedOrStoppedWaitWaiterConfigTypeDef
):
    """
    Type definition for `TransformJobCompletedOrStoppedWait` `WaiterConfig`

    A dictionary that provides parameters to control waiting behavior.

    - **Delay** *(integer) --*

      The amount of time in seconds to wait between attempts. Default: 60

    - **MaxAttempts** *(integer) --*

      The maximum number of attempts to be made. Default: 60
    """
